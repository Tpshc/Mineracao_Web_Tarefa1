ar
X
iv
:1
40
4.
09
53
v2
  [
cs
.L
O
] 
 4
 A
pr
 2
01
4
Implementing Anti–Unification Modulo Equational Theory
Jochen Burghardt1 and Birgit Heinz2
1 GMD Berlin, jochen@first.gmd.de, http://www.first.gmd.de/persons/Burghardt.Jochen.html
2 TU Berlin, heinz@cs.tu-berlin.de, http://www.cs.tu-berlin.de/h?einz
Technical Report
Arbeitspapiere der GMD 1006
June 1996
ISSN 0723–0508
GMD – Forschungszentrum
Informationstechnik GmbH
D–53754 Sankt Augustin
Tel. *49–2241–14–0
Fax *49–2241–14–2618
Telex 889469 gmd d
http://www.gmd.de
Abstract. We present an implementation of E–anti–unification as defined in [Hei95], where
tree–grammar descriptions of equivalence classes of terms are used to compute generalizations
modulo equational theories. We discuss several improvements, including an efficient implemen-
tation of variable–restricted E–anti–unification from [Hei95], and give some runtime figures
about them.
We present applications in various areas, including lemma generation in equational induc-
tive proofs, intelligence tests, diverging Knuth–Bendix completion, strengthening of induction
hypotheses, and theory formation about finite algebras.
3
1 Introduction
An important task in the field of artificial intelligence is generalization. To the extent that a gener-
alization approach allows us to incorporate certain background knowledge, it opens up applications
in various fields of computer science. Inductive logic programming, for example, is concerned with
generalization wrt. Horn–logic theories, with potential applications in automated scientific discovery,
knowledge discovery in databases, automatic programming, and other areas.
[Hei95] gives several algorithms for generalizing terms wrt. equational background theories; they
are applied to lemma generation in equational induction proofs. In this paper, we describe the
implementation of these algorithms and give some further applications.
As a motivating example, consider the sequence 0, 1, 4, 9, represented by terms 0, suc(0), suc4(0),
suc9(0), respectively. Trained people with a knowledge of addition and multiplication of natural
numbers will easily recognize that square numbers computable by the scheme x ? x are the desired
solution for finding the continuation of the numbers. However, syntactical anti–unification merely
leads to the term y, which is too general to be used for computing a continuation of the above
sequence.
A useful mechanism for computing schemes is anti–unification extended to take account of equational
theories. Addition and multiplication of natural numbers can be specified by the equations of Theory
(1) in Fig. 3. In Fig. 1, we demonstrate that x ? x is one of the generalizations resulting from anti–
unification of the above terms 0, suc(0), suc4(0), suc9(0) modulo equational Theory (1), since each
of them equals an instance of x ? x.
0: 0 =E1 . . . =E1 0 ? 0 =E1 . . .
1: suc(0) =E1 . . . =E1 suc(0) ? suc(0) =E1 . . .
4: suc4(0) =E1 . . . =E1 suc
2(0) ? suc2(0) =E1 . . .
9: suc9(0) =E1 . . . =E1 suc
3(0) ? suc3(0) =E1 . . .
? ?
Syntactical
Anti–Unification
Syntactical
Anti–Unification
? ?
y x ? x
Fig. 1. Anti–Unification Modulo Equational Theory (1) from Fig. 3
Some problems arise if generalizations of terms wrt. equational theories have to be computed:
– There may exist many generalizations allowing the elements of a sequence of terms to be com-
puted.
– The set of generalizations wrt. equational theory is usually infinite (see, however, Fig. 42 in
Sect. 7.2).
– Hence, only approaches enumerating its elements can be provided.
– Depending on the application area, the set of possible generalizations may contain useless or
undesired computation schemes.
4
In [Hei95], an approach to generalization modulo canonical equational theories, called anti–
narrowing, has been developed. This approach simply allows all generalizations of terms modulo
canonical theories to be enumerated; useless generalizations can only be eliminated after their com-
putation using corresponding criteria.
Instead of enumerating all generalizations of terms modulo equational theory, a compact, finite
representation of the set of all generalizations is desirable for several reasons, e.g. to enable all
useless generalizations to be eliminated at one go.
[Hei95] therefore investigates a second approach to E–anti–unification based on regular tree gram-
mars1. At the heart of the approach is an algorithm that takes two sorts or regular tree languages
s, s?, and computes a sort or regular tree language ? of all syntactical generalizations of terms from
s and s?:
 L(?) = {t ? t? | t ?  L(s), t? ?  L(s?)}.
In order to E–anti–unify two terms modulo a given background equational theory E, their equiv-
alence classes modulo E are represented by sorts s, s?; the corresponding ? then contains all E–
generalizations of both terms.
In this paper, we describe the implementation of the sort approach to E–anti–unification including
technical optimizations and run-time measurements. We present several applications:
– generation of lemma candidates in blocked situations of an inductive proof (Sect. 6)
– construction of series–formation laws (Sect. 7)
– some other potential applications, which are only sketched (Sect. 8).
Section 2 introduces some necessary formal definitions and notations. Section 3 presents the imple-
mentation of E–Anti–Unification. Section 4 discusses how to enumerate the terms of a computed
sort. Section 5 gives an elaborate example of E–anti–unification. Sections 6 to 8 present the above–
mentioned applications. In Sect. 11, we show that for each finite algebra we can always generate a
closed representation of all its quantifier–free and variable–bounded theorems. The PROLOG source
code of our implementation is listed in Appendix A.
1 Called “sorts” in this paper, following [Com90]
5
2 Definitions and Notations
Definition 1. Let V be an enumerable set of variables, F a finite set of function symbols, each
with fixed arity; ar(f) denotes the arity of f ? F . Terms are built from V ?F ; T denotes the set of
terms.
We assume familiarity with the classic definitions and notations of terms. We say that a term t starts
with a function symbol f if t = f(t1, . . . , tn) for some terms t1, . . . , tn. vars(t) describes the set of
variables occurring in a term t ? T . A term is called linear if no variable occurs in it twice. A term
t is called a ground term if t does not contain any variables.
Definition 2. Lists are built from [ ] and cons, written as (.) as in PROLOG; length(L) denotes the
number of elements of the list L; head(L) denotes its first element. The list–comprehension notation
[t | p(t)] denotes a list of all t, such that p(t) holds, in some arbitrary order.
?t1, . . . , tn? denotes an n-tuple; ?ni (?t1, . . . , tn?) := ti denotes its i-th projection.
:= means equal by definition. A ? B means that A is a subset of B, or A is equal to B.
#A denotes the number of elements of a finite set A. ?[A] := {?(a) | a ? A} denotes the image of
the set A under the mapping ?; ??1[A] := {a | ?(a) ? A} denotes the inverse image of A under ?.
For a set A, we denote its n-fold cartesian product by An.
Definition 3. Substitutions are defined as usual; {x1 ? t1, . . . , xn ? tn} denotes a substitution
that maps each variable xi to the term ti. Sometimes we also use a set–comprehension–like notation:
{x ? t | p(x, t)} denotes a substitution that maps each x to t such that p(x, t) holds. dom(?) :=
{x ? V | ?x 6= x} denotes the domain of ?.
? is called a linear substitution if ??x1, . . . , xn? is a linear term, where dom(?) = {x1, . . . , xn}. ? is
called a flat substitution if ?x ? V for all x ? V . ? is called a renaming substitution if it is a bijective
mapping from variables to variables, and hence is both linear and flat.
t is called an instance of t?, and t? an anti–instance of t, if a substitution ? exists such that t = ?t?.
If ? is a renaming, t is also called a variant of t?.
Definition 4. An equational theory E is a finite set of equations tl = tr. The relation (=E) is
defined as usual as the smallest reflexive, symmetric, and transitive rewrite relation that contains
E.
The equivalence class of a term t mod. (=E) is denoted by t := {t? ? T | t? =E t}. T /E denotes
the algebra of equivalence classes. We assume that in each equivalence class t, some term nf(t) is
distinguished, which we call the normal form of t. Let N := nf [T ] be the set of all normal forms. t,
nf(t), and N depend on E.
Note that we do not require (=E) to be computable by a confluent and noetherian term–rewriting
system. However, we require that each equivalence class t be a regular tree language.
Definition 5. Let SNAME be an enumerable set of sort names, and let the sets V , F , and SNAME
be pairwise disjoint. Let S denote the set of all sort expressions; a sort expression is a sort name or
has one of the forms
s1 | s2, where s1, s2 ? S;
f(s1, . . . , sn), where f ? F , s1, . . . , sn ? S; or
6
x for x ? V .
A sort definition is of the form sn
.
= se, where sn is a sort name and se is a sort expression. We say
that sn is defined by se.
Given a system of sort definitions where each occurring sort name has exactly one definition, we
define their semantics as their least fixed point. We denote the semantics of a sort expression s by
 L(s) ? T , which has the following properties:
 L(s1 | s2) =  L(s1) ?  L(s2)
 L(x) = {x} for x ? V
 L(f(s1, . . . , sn)) = {f(t1, . . . , tn) | ti ?  L(si)} for f ? F
 L(sn) =  L(se) for sn
.
= se
Observe that T ? S, and  L(t) = {t} for each t ? T . The empty sort is denoted by ?. A sort
definition of the form s
.
= f1(s11, . . . , s1n1) | . . . | fm(sm1, . . . , smnm) is said to be in head normal
form, where s, sij ? SNAME , fi ? F ? V , and ni = ar(fi). For proof–technical reasons, we define a
system of sort definitions as being in normal form if each sort definition has either the form
– s
.
= s1 | . . . | sn with s, s1, . . . , sn ? SNAME , or
– s
.
= f(s1, . . . , sn) with s, s1, . . . , sn ? SNAME ,
and if no cycles
s1
.
= . . . | s2 | . . .
s2
.
= . . . | s3 | . . .
. . .
sn?1
.
= . . . | sn | . . .
sn
.
= . . . | s1 | . . .
occur. Each system of sort definitions can be transformed into head normal form, and into normal
form, maintaining its semantics. Any system of sort definitions in head normal form, or in normal
form, has exactly one fixed point.
Theorem 6. Assume a system of sort definitions in normal form. Let p be a family of unary
predicates, indexed over the set of all defined sort names. Show for each defined sort name s:
?t ? T ps(t)? ps1(t) ? . . . ? psn(t) if s
.
= s1 | . . . | sn
?t ? T ps(t)? ?t1, . . . , tn ? T t = f(t1, . . . , tn) ? ps1(t1) ? . . . ? psn(tn) if s
.
= f(s1, . . . , sn)
?t ? T ps(t)? t = x if s
.
= x
Then, ?t ? T t ?  L(s)? ps(t) holds for each defined sort name s.
Definition 7. A term t is called a generalization of t1 and t2 iff there exist substitutions ?1 and
?2 such that ?1t = t1 and ?2t = t2. t is called the most specific generalization iff each generalization
t? of t1 and t2 is an anti–instance of t. The most specific generalization t of two terms t1, t2 always
exists and is unique up to renaming. We sometimes use the notation t1 ? t2 := t.
The above definitions can be extended to generalization of n terms; we write t1 ? . . . ? tn to denote
the most specific generalization of t1, . . . , tn.
7
Definition 8. A term t is called an E-generalization of terms t1, t2 iff there exist substitutions ?1
and ?2 such that ?1t =E t1 and ?2t =E t2.
As in to unification, a most specific E-generalization of arbitrary terms does not usually exist. A set
G ? T is called a correct set of E-generalizations of t1, t2 iff each member is an E-generalization of
t1, t2. G is called complete if, for each E-generalization t of t1, t2, G contains an instance of t. G is
called complete wrt. linear generalizations if for each linear term t, which is an E-generalization of
t1, t2, G contains an instance of t.
The following algorithm can be traced back to the early seventies [Plo70,Plo71,Rey70]. It takes two
terms t, t? and computes the syntactical generalization t ? t?.
Algorithm 9. Let V be an infinite set of new variables and ? : T × T ? V an injective mapping.
1. Define sg(f(t1, . . . , tn), f(t
?
1, . . . , t
?
n)) := f(sg(t1, t
?
1), . . . , sg(tn, t
?
n)).
2. Define sg(f(t1, . . . , tn), f
?(t?1, . . . , t
?
m)) := ?(f(t1, . . . , tn), f
?(t?1, . . . , t
?
m)), if f 6= f
?.
Since syntactical anti–unification is unique only up to renaming, the mapping ? is used to fix one
concrete variable naming that is the same in all subterms. In the example in Fig. 2, the use of ?
ensures that both occurrences of sg(3, 4) yield the same result, viz. the variable v34.
sg(3 + y ? 3, 4 + x ? 4)
= sg(3, 4) + sg(y ? 3, x ? 4)
= sg(3, 4) + sg(y, x) ? sg(3, 4)
= v34 + vyx ? v34
Fig. 2. Example: Computation of Syntactical Anti–Unification
Lemma 10. Algorithm 9 can be extended to anti–unify N terms simultaneously, requiring ? :
T N ? V . For any such ? and any finite V ? V , we may define the substitutions ?i for i = 1, . . . , N
by ?i?(t1, . . . , tN ) := ti. We have dom(?i) = V for all i.
The result of Alg. 9 then satisfies the following correctness property:
?isg([t1, . . . , tN ]) = ti for i = 1, . . . , N provided we choose V ? vars(sg([t1, . . . , tN ])).
8
3 E–Anti–Unification
In this section, we describe the implementation of E–anti–unification based on sorts.
Section 3.2 restates the algorithm rsg from [Hei95] for computing a sort containing all linear gen-
eralizations; Sect. 3.3 discusses how to subsequently modify this sort in order to get all nonlinear
generalizations as well. To obtain the sort of all generalizations, Alg. 12 from Sect. 3.2 is run as a
first phase, then the algorithm from Sect. 3.3 is run as the second phase; cf. also Sect. 5.
In Sect. 3.4, the algorithm rsgV for computing the sort of all generalization terms that contain only
variables from a given set V is restated from [Hei95]. Note that all linear and nonlinear generalizations
are computed in one phase only, thus saving a large amount of computation time; cf. Sect. 3.6, Fig. 15.
Section 3.5 discusses a technical optimization that applies to both rsg and rsgV and helps to avoid
many useless recursive calls. Sect. 3.6 presents some figures for runtime measurements and the
improvement factors of technical optimizations.
3.1 Modeling Equivalence Classes as Sorts
The algorithms from Sect. 3.2/3.3 and from Sect. 3.4 both require the representation of the equiv-
alence classes of the input terms as sorts. In this paper, we do not treat this issue in detail; rather,
we drew up the respective sort definitions manually.
Figure 3 shows the equational theories used in this paper; we will refer to them as background
theories. For example, Theory (1) consists of all equations that have a “1” in the leftmost column.
Figure 23 refers to Theory (1) and shows the sort definition of s0 and s1, representing 0 and suc(0),
respectively. Figure 4 shows the sort representation of 0 to suc5(0) wrt. Theory (5); sp, se, so, and
sn denote the sets of positive (i.e. > 0), even, odd, and arbitrary natural numbers, respectively.
In Theory (6), we have included the (?) operator, such that equivalence classes of terms are no
longer regular tree languages, and hence cannot be described by our sorts; for example, the sort
definition s0
.
= 0 | . . . | s0 ? s0 | s1 ? s1 | . . . | si ? si | . . . would become infinite. We can, however,
approximate the equivalence classes from below by cutting off the sort definitions at a certain n, i.e.,
omitting all greater numbers. Figure 5 shows the approximations of 0 to suc5(0), where we set the
cut–off point to n = 5, i.e. s6? s6 | . . . | si ? si | . . . is missing; hence, the equivalence classes do not
contain terms that yield an intermediate result greater than 5 when evaluated to normal form.
In Sect. 9, we discuss the use of sort–definition schemes that allow several sort definitions to be
abbreviated by one scheme. Figure 51 shows a sort–definition scheme for background Theory (0).
Figure 50, shows sort–definition schemes of equivalence classes mod. append and reverse.
[Emm94] describes an algorithm for building the sort definitions automatically from a given con-
fluent and noetherian term–rewriting system. However, there is no implementation that fits our
data structures. See also Thm. 15 and Cor. 16 in Sect. 11, which provide sufficient criteria for an
equational theory in order that the equivalence classes are regular tree languages.
3.2 Linear Generalizations
The following algorithm from [Hei95] takes two sorts s, s? and computes a sort ? containing all linear
syntactical generalizations t ? t? of terms t ?  L(s), t? ?  L(s?), i.e.
? ? {t ? t? | t ?  L(s), t? ?  L(s?), t ? t? linear }.
9
012 567 9 x + 0 = x
012 567 9 x + suc(y) = suc(x + y)
67 x? 0 = x
67 suc(x)? suc(y) = x? y
12 5 7 9 x ? 0 = 0
12 5 7 9 x ? suc(y) = x ? y + x
9 0/y = 0
9 suc(x)/suc(0) = suc(x)
9 suc(x)/suc(suc(y)) = suc( (x? suc(suc(y))) / suc(suc(y)) )
2 dup(0) = 0 duplicate
2 dup(suc(x)) = suc(suc(dup(x)))
5 if(0, x, y) = y if then else
5 if(suc(z), x, y) = x
5 ev(0) = suc(0) is even
5 ev(suc(0)) = 0
5 ev(suc(suc(x))) = ev(x)
4 len([ ]) = 0 length
4 len(x.y) = suc(len(y))
34 8 app([ ], x) = x append
34 8 app(x.y, z) = x.app(y, z)
34 8 rev([ ]) = [ ] reverse
34 8 rev(x.y) = app(rev(y), [x])
8 rot([ ]) = [ ] rotate
8 rot(x.y) = app(y, [x])
8 il(x, [ ]) = x interleave
8 il([ ], x) = x
8 il(x.y, z.w) = x.z.il(y, w)
Fig. 3. Background Equational Theories Used
s0
.
= 0 | if(sp, s0, sn) | if(s0, sn, s0) | ev(so) | s0 + s0 | s0?sn | sn?s0
s1
.
= suc(s0) | if(sp, s1, sn) | if(s0, sn, s1) | ev(se) | s1 + s0 | s0+s1 | s1?s1
s2
.
= suc(s1) | if(sp, s2, sn) | if(s0, sn, s2) | s2 + s0 | s1 + s1 | s0+s2 | s1?s2 | s2?s1
s3
.
= suc(s2) | if(sp, s3, sn) | if(s0, sn, s3) | s3 + s0 | s2 + s1 | s1+s2 | s0+s3 | s1?s3 | s3?s1
s4
.
= suc(s3) | if(sp, s4, sn) | if(s0, sn, s4) | s4 + s0 | s3 + s1 | s2+s2 | s1+s3 | s0+s4 | s1?s4 |s2?s2 |s4?s1
s5
.
= suc(s4) | if(sp, s5, sn) | if(s0, sn, s5) | s5 + s0 | s4 + s1 | s3+s2 | s2+s3 | s1+s4 | s0+s5 |s1?s5 |s5?s1
sp
.
= suc(sn) | if(sp, sp, sn) | if(s0, sn, sp) | ev(se) | sp + sn | sn+sp | sp?sp
se
.
= 0 | if(sp, se, sn) | if(s0, sn, se) | ev(so) | suc(so) | se+se | so+so | se?sn | sn?se
so
.
= suc(se) | if(sp, so, sn) | if(s0, sn, so) | ev(se) | so + se | se+so | so?so
sn
.
= 0 | suc(sn) | if(sn, sn, sn) | ev(sn) | sn + sn | sn?sn
Fig. 4. Equivalence Classes for Background Theory (5) from Fig. 3
10
s0
.
= 0 | s0 + s0 | s0 ? s0 | s1 ? s1 | s2 ? s2 | s3 ? s3 | s4 ? s4 | s5 ? s5
s1
.
= suc(s0) | s1 + s0 | s0 + s1 | s1 ? s0 | s2 ? s1 | s3 ? s2 | s4 ? s3 | s5 ? s4
s2
.
= suc(s1) | s2 + s0 | s1 + s1 | s0 + s2 | s2 ? s0 | s3 ? s1 | s4 ? s2 | s5 ? s3
s3
.
= suc(s2) | s3 + s0 | s2 + s1 | s1 + s2 | s0 + s3 | s3 ? s0 | s4 ? s1 | s5 ? s2
s4
.
= suc(s3) | s4 + s0 | s3 + s1 | s2 + s2 | s1 + s3 | s0 + s4 | s4 ? s0 | s5 ? s1
s5
.
= suc(s4) | s5 + s0 | s4 + s1 | s3 + s2 | s2 + s3 | s1 + s4 | s0 + s5 | s5 ? s0
sn
.
= 0 | suc(sn) | sn + sn | sn ? sn
Fig. 5. Equivalence Classes for Background Theory (6) from Fig. 3
Algorithm 11. Let s and s? be sort names, and ? be a new sort name. Let V be an infinite set
of new variables, and ? : S × S ? V an injective mapping. Define rsg(s, s?) := ?, where a new sort
definition is introduced for ?:
1. If rsg(s, s?) has been called before, then ? is already defined.
2. If s
.
= s1 | . . . | sn, then define ?
.
= rsg(s1, s
?) | . . . | rsg(sn, s?).
3. If s?
.
= s?1 | . . . | s
?
n, then define ?
.
= rsg(s, s?1) | . . . | rsg(s, s
?
n).
4. If s
.
= f(s1, . . . , sn) and s
? .= f(s?1, . . . , s
?
n), then define ?
.
= f(rsg(s1, s
?
1), . . . , rsg(sn, s
?
n)).
5. If s
.
= f(s1, . . . , sn) and s
? .= f ?(s?1, . . . , s
?
n) with f 6= f
?, then define ?
.
= ?(s, s?).
As shown in [Hei95],  L(rsg(s, s?)) is a correct set of generalizations which is complete for the linear
ones, i.e., t ?  L(rsg(s1, s2))? ?t1 ?  L(s1), t2 ?  L(s2) t = t1 ? t2, and t1 ?  L(s1) ? t2 ?  L(s2) ? t :=
t1 ? t2 linear? t ?  L(rsg(s1, s2)).
Note that Case 1. requires us to maintain a set of argument pairs for which rsg has already been
called, and to check the argument pair of each new call against this set. This set is called Occ in the
implementation; it was initially implemented by a PROLOG list, then by a binary search tree, and
now by a balanced binary search tree. A membership test in a balanced tree with 50 entries takes
about 4 msec user time. See also Sect. 3.6 for the impact of balancing on runtime.
Assuming all sort definitions in head normal form, we can slightly improve the above algorithm in
order to produce less variables. For example, given the sort definitions of s0, s1 from Fig. 23, the
sort s01 computed in Fig. 24 would comprise twelve different variables if computed by rsg, while it
actually – computed by hsg below – has only one variable.
Since  L(hsg(s1, s2)) ?  L(rsg(s1, s2)), Alg. 12 is still correct; since for each generalization t ?
 L(rsg(s1, s2)) we have ?t ?  L(hsg(s1, s2)) for some flat substitution ?, Alg. 12 is also complete
for the linear generalizations.
Algorithm 12. Let s, s?, V , and ? be as in Alg. 11. Define hsg(s, s?) as follows:
1. If hsg(s, s?) has been called earlier, its result is already defined.
2. If s
.
= mi=1 fi(si1, . . . , sini), and s
? .= m
?
j=1 f
?
j(s
?
j1, . . . , s
?
jn?
j
),
then let ? be a new sort name,
define ?
.
= ?(s, s?) | mi=1
m?
j=1 hsg(fi(si1, . . . , sini), f
?
j(s
?
j1, . . . , s
?
jn?
j
));
let hsg(s, s?) := ?.
3. Define hsg(f(s1, . . . , sn), f(s
?
1, . . . , s
?
n)) := f(hsg(s1, s
?
1), . . . , hsg(sn, s
?
n)).
4. Define hsg(f(s1, . . . , sn), f
?(s?1, . . . , s
?
m)) := ?, if f 6= f
?.
Usually, most of the disjuncts in Case 2. start with different function symbols, fi 6= f
?
j , and hence
evaluate to ? by Case 4. In Sect. 3.5, we will discuss an optimization that avoids these recursive
calls of hsg.
11
Algorithms 11 and 12 can both be extended to compute the linear generalizations of N sorts simul-
taneously, requiring ? : SN ? V . Our implementation is capable of that, and we will tacitly use
rsg([s?, s??, . . . , s(N)]) with N arguments where appropriate in this paper. Note that it makes sense to
have multiple occurrences of the same sort among the input arguments. For example, using the sort
definitions from Fig. 23, we have 0 ? 0 ? (0 + 0) ? (0 + 0) = v ? v ?  L(hsg(s0, s0)) \  L(s0). Moreover,
it is important to maintain the order of argument sorts during computation, since otherwise, for
example
hsg(s1, s1)
= . . . | hsg(s0, s1) + hsg(s1, s0) | . . .
= . . . | hsg(s0, s1) + hsg(s0, s1) | . . .
= . . . | v01 + v01 | . . .
although 1 is not equal to any instance of v01 + v01. For these reasons, we treat the argument of the
extended hsg as a list rather than as a set of sorts.
3.3 Nonlinear Generalizations
The result sorts of the above algorithm contains all linear generalizations, but only some nonlinear
ones. That is not generally sufficient, as the example in Sect. 5 shows (see in particular the difference
between s01 and s
?
01 in Fig. 30).
In order to obtain as well all nonlinear generalizations, which are more specific, we need a second
phase which introduces common variables to related sorts. We use the abbreviation infs(V ) :=
{
?
v?V ?
N
i (?
?1(v)) | 1 6 i 6 N}; note that ??1 exists since ? is injective. Below, we will assume
N = 2 for the sake of simplicity.
[Hei95] proceeds as follows: for each set of variables {v1, . . . , vn} from the result sorts, whenever
infs({v1, . . . , vn}) does not contain the empty sort, a new variable v? is introduced which can be
thought of intuitively as generalizing the sorts in infs(V ), and each occurrence of each vi is replaced
by vi | v
?. For example, using the definitions from Sect. 5, we have v01 = ?(s0, s1), v0n = ?(s0, sn),
vn1 = ?(sn, s1), and vnn = ?(sn, sn); hence infs({v0n, vn1}) = {s0 ? sn , sn ? s1} = {s0, s1} since
s0?s1 ? sn. Thus, v0n, v0n are replaced by v0n |v?, and v0n |v?, respectively. Similarly, for any subset
of {v01, v0n, vn1, vnn} that contains more than one element, a new variable would be added.
We follow this approach, except that we only consider maximal sets {v1, . . . , vn} of variables, i.e.
where {} ? infs({v1, . . . , vn, vn+1}) for any vn+1. For each generalization term t obtained by the
[Hei95] approach, we get a more specific generalization term ?t for some flat substitution ?. By
analogy with the remark in Sect. 3.2, this shows the algorithm is still complete. In the above example,
we would add only one variable for the set {v01, v0n, vn1, vnn}, which is maximal.
In the example in Sect. 5 / Fig. 30, the second phase leads to the modification of sort s01 to s
?
01,
etc. Unlike the former sort, the latter, for example, contains the term v?01 ? v
?
01, meaning that 0 and
1 are both quadratic numbers.
We explain below how the n-tuples v1, . . . , vn of variables with non–empty sort intersections {} 6?
infs({v1, . . . , vn}) are found. The replacement of each vi by vi | v? is then straightforward. As the
computation of sort intersections is very time–consuming, we try to minimize the number of such
computations by applying some — correct — heuristics explained below. Note, however, that when
each defined sort name corresponds to an equivalence class (unlike sn), computing their intersections
is trivial, since different equivalence classes are always disjoint.
Let V be the set of variables newly generated by the first phase. Each variable v ? V is assigned a
pair ?sv, s?v? := ?
?1(v) of sorts such that v represents all generalizations of any term from sv with
12
any term from s?v. Let S := {sv | v ? V } ? {s
?
v | v ? V } be the set of all relevant sorts. In the first
step, we compute the set
I2 := {?s1, s2, s12? | s1, s2 ? S, {} 6= s12 = s1 ? s2, s1 ? s2}
of all non–empty intersections of sorts from S. This is accomplished by the PROLOG predicate
calc sort infs. The relation (?) is an arbitrary irreflexive total ordering on S. Without the condi-
tion s1 ? s2, we had ?s2, s1, s12? ? I2 whenever ?s1, s2, s12? ? I2; the additional ordering condition
helps to keep the memory requirements small. I2 is represented by a balanced binary tree. Then,
the set
L2 := {?v1, v2? | v1, v2 ? V, {} 6? infs({v1, v2}), v1 ? v2}
of all pairs of variables with non–empty intersections is computed by calc inf2s. The remarks on
s1 ? s2 apply similarly to the ordering condition v1 ? v2. Each variable in the set V is equipped
with its number of occurrences in L2, i.e. for each v ? V . Let
iv := #({?v, v
?? | ?v, v?? ? L2} ? {?v?, v? | ?v?, v? ? L2});
then the set V 2 := {?v, iv? | v ? V } is computed using the predicates calc varcnt and
collect varcnt. The predicate calc infs list then takes L2 and V 2 as input: it calls calc infs
for each ?v1, v2? ? L2, which in turn computes the set of all maximal V12 such that v1, v2 ? V12, and
{} 6? infs(V12). The rules for calc infs are given in Fig. 6; the start configuration is
{v1, v2} L2 [ ]
for each pair ?v1, v2? ? L2. All the rules in this paper are priorized, i.e. the n-th rule is tried only
if the 1-st, . . . , n ? 1-th did not succeed. Out denotes the output so far. The set Susp contains
“suspended” variable sets V that are subsumed by some earlier output, see rule (Suplist). The
suspension is released as soon as a new variable can be joined to the actual set V , see rule (Inf Inh).
The actual set V is reported as a maximal one only if no suspended variable sets exist, see rules
(Output Max ), (Max Subs Susp). Rule (Inf Inh) has two successors, the output of both of which
has to be joined; + denotes the appending of two lists. Rule (Count) is justified since v? can have
non–empty intersections with at most iv? different variables (“intersection of variables” v1, . . . , vn
meaning infs({v1, . . . , vn})). In order to allow fast lookup of iv? in rule (Count), and fast testing of
?v?, v??, . . .? 6? L2 in rule (Sublist2 ), both L2 and V 2 are given additionally in balanced–tree form to
the algorithm.
Figure 7 shows an example intersection hierarchy for the variables a, b, c, d; a common upper
bound of v1, . . . , vn indicates that {} 6? infs(v1, . . . , vn). While setting up I2, the six intersec-
tion sets infs({a, b}), infs({a, c}), infs({a, d}), infs({b, c}), infs({b, d}), infs({c, d}) are computed
and tested to determine whether they contain the empty set. Note that these computations are
unavoidable, since any two sorts could intersect independently of the others. During the run of
calc infs list, only two more intersection sets need to be computed and checked; they are flagged
right to the rule (Inf Inh) in Figs. 8 and 9 which show the corresponding example run. See also
Sect. 5 for a second example.
13
V [v? | List] Susp
v? ? V (Member)
V List Susp
V [v? | List] Susp
iv? < #V (Count)V List Susp
V [v? | List] Susp ?v?? ? V ?v?, v??, . . .? 6? L2
(Sublist2)
V List Susp ??v??, v?, . . .? 6? L2
V [v? | List] Susp
?V ? ? Out V ? {v?} ? V ? (Suplist)
V List [v? | Susp]
V [v? | List] Susp
{} 6? infs(V ? {v?}) (Inf Inh)
V ? {v?} List ++Susp [ ]
V List ++Susp [ ]
V [v? | List] Susp
(Inf Empty)
V List Susp
V [ ] [ ]
?V ? ? Out V ? V ? (Max Subsumed)
V [ ] [ ]
(Output Max)
output V
V [ ] [v? | Susp]
(Max Subs Susp)
Fig. 6. Rules for calc infs
r r r r
r r r r
r
a b c d
e f g h
i
 
 
 
?
?
?
 
 
 
?
?
?
??
??
??
 
 
 
 
 
 
?
?
?
Fig. 7. Example: Intersection Hierarchy
14
L2 = {?a, b?, ?a, c?, ?b, c?, ?b, d?, ?c, d?}
V 2 = {?a, 2?, ?b, 3?, ?c, 3?, ?d, 2?}
[a,b] [a,b,c,d] []
(Member)
[a,b] [b,c,d] []
(Member)
[a,b] [c,d] []
(Inf Inh) infs({a,b,c})
[a,b,c] [d] []
(Sublist2)
[a,b,c] [] []
(Output Max [a,b,c])
[a,b] [d] []
(Sublist2)
[a,b] [] []
(Max Subsumed)
[a,c] [a,b,c,d] []
(Member)
[a,c] [b,c,d] []
(Suplist)
[a,c] [c,d] [b]
(Member)
[a,c] [d] [b]
(Sublist2)
[a,c] [] [b]
(Max Subs Susp)
(Contd. in Fig. 9)
Fig. 8. Example: Intersection Computation Run
15
[b,c] [a,b,c,d] []
(Suplist)
[b,c] [b,c,d] [a]
(Member)
[b,c] [c,d] [a]
(Member)
[b,c] [d] [a]
(Inf Inh) infs({b,c,d})
[b,c,d] [a] []
(Sublist2)
[b,c,d] [] []
(Output Max [b,c,d])
[b,c] [a] []
(Suplist)
[b,c] [] [a]
(Max Subs Susp)
[b,d] [a,b,c,d] []
(Sublist2)
[b,d] [b,c,d] []
(Member)
[b,d] [c,d] []
(Suplist)
[b,d] [d] [c]
(Member)
[b,d] [] [c]
(Max Subs Susp)
[c,d] [a,b,c,d] []
(Sublist2)
[c,d] [b,c,d] []
(Suplist)
[c,d] [c,d] [b]
(Member)
[c,d] [d] [b]
(Member)
[c,d] [] [b]
(Max subs susp)
Fig. 9. Example: Intersection Computation Run (contd.)
16
3.4 Variable–Restricted E–Anti–Unification
The following algorithm from [Hei95] takes two input sorts s, s? and a finite set V of variables and
computes the set of all generalizations of terms from s and s? that contain only variables from the
set V . The call rsgV ({}, s, s?) computes precisely the intersection of the sorts s and s?. Note that
not only linear generalizations are computed; hence, the computationally expensive second phase
described in Sect. 3.3 can be omitted. See Sect. 3.6 for figures on the runtime improvement thus
achieved. The remarks from Sect. 3.2 about extending the algorithm to N arguments also apply to
rsgV .
Algorithm 13. Let s and s? be sorts and ? a new sort name. Let ? : S × S ? V be an injective
mapping. Let V be a finite set of variables, such that TP := ??1[V ] ? T × T is a finite set of term
pairs. (Note that each term is also a sort expression.) Define rsgV (V, s, s
?) := ?, where a new sort
definition for ? is introduced by the following cases.
1. If rsgV (V, s, s
?) has been called before, then ? is already defined.
2. If s
.
= s1 | . . . | sn, then define ?
.
= rsgV (V, s1, s
?) | . . . | rsgV (V, sn, s?).
3. If s?
.
= s?1 | . . . | s
?
n, then define ?
.
= rsgV (V, s, s
?
1) | . . . | rsgV (V, s, s
?
n).
4. If s
.
= f(s1, . . . , sn), and s
? .= f(s?1, . . . , s
?
n),
then define ?
.
= f(rsgV (V, s1, s
?
1), . . . , rsgV (V, sn, s
?
n)).
5. If s
.
= f(s1, . . . , sn), and s
? .= f ?(s?1, . . . , s
?
n?), then define ?
.
= ?t,t???TP?( L(s)× L(s?)) ?(t, t
?).
Lemma 14. Given ? : T N ? V and V , we may define ?i?(t1, . . . , tN ) := ti for all ?t1, . . . , tN ? ?
??1[V ] and i = 1, . . . , N . We have dom(?i) = V for all i. We assume that for each x ? V , x =
?(t1, . . . , tn) such that not all t1, . . . , tn start with the same function symbol.
The result of Alg. 13 then satisfies the following correctness property:
t ?  L(rsgV (V, [s1, . . . , sN ]))? vars(t) ? V ?
N
?
i=1
?it ?  L(si)
Hence, when the argument sorts of rsgV are equivalence classes of terms, we have
t ?  L(rsgV (V, [t1, . . . , tN ]))? vars(t) ? V ?
N
?
i=1
?it =E ti
Proof. We show the lemma only for N = 2, using Thm. 6 with
p?(t) :? ?1t ?  L(s) ? ?2t ?  L(s?) ? vars(t) ? V if ?
.
= rsgV (V, s, s
?)
p?(t) :? t = ?(t
?, t??) if ?
.
= ?(t?, t??)
p?(t) :? t ?  L(?) else
In the latter case, we have nothing to show. In the two former cases, we make a case distinction
according to the rule from Alg. 13 that defined ?. The second case has been introduced to put the
result sort definitions into normal form.
1. In this case, no new sort definition is introduced.
17
2. We have p?(t)
? ?1t ?  L(s) ? ?2t ?  L(s?) ? vars(t) ? V by Def. of p?
? ?i ?1t ?  L(si) ? ?2t ?  L(s?) ? vars(t) ? V by Def. of  L(s)
? ?i p?i(t) by Def. of p?i
3. Similar to 2.
4. p?(t)
? ?1t ?  L(s) ? ?2t ?  L(s?) ? vars(t) ? V by Def. of p?
? ?t11 ?  L(s1), . . . , t1n ?  L(sn) ?t21 ?  L(s?1), . . . , t2n ?  L(s
?
n)
?1t = f(t11, . . . , t1n) ? ?2t = f(t21, . . . , t2n) ? vars(t) ? V by Def. of  L(s),  L(s?)
? ?t1, . . . , tn t = f(t1, . . . , tn)
?
?n
i=1 ?1ti ?  L(si) ? ?2ti ?  L(s
?
i) ? vars(ti) ? V (?)
? ?t1, . . . , tn t = f(t1, . . . , tn) ?
?n
i=1 p?i(ti) by Def. of p?i
(?): “?”: since ?1x and ?2x never start with the same function symbol f ,
we must have t = f(t1, . . . , tn)
with ?1ti = t1i ?  L(si),
the case is similar for ?2
“?”: choose t1i := ?1ti, and t2i := ?2ti
5. p?(t)
? ?1t ?  L(f(s1, . . . , sn)) and ?2t ?  L(f ?(s?1, . . . , s
?
n?)) and vars(t) ? V by Def. of p?
? ?1t = f(. . .) and ?2t = f ?(. . .) and vars(t) ? V
? t ? V and vars(t) ? V
? t ? V by Def. of vars
? t = ?(t?, t??) for some ?t?, t??? ? TP by Def. of TP
?
?
?t?,t????TP?( L(s)× L(s?)) p?(t?,t??)(t) by Def. of p?(t?,t??)
conversely:
?
?t?,t????TP?( L(s)× L(s?)) p?(t?,t??)(t)
? t = ?(t?, t??) for some ?t?, t??? ? TP ? ( L(s)×  L(s?)) by Def. of p?(t?,t??)
? ?1t = t? ?  L(s) and ?2t = t?? ?  L(s?) and t ? V by Def. of ?1, ?2
? p?(t) by Def. of p?
In Case 5., all pairs in ?t, t?? ? TP are checked for whether t ?  L(s) and t? ?  L(s?). For checking
t ?  L(s), a straightforward algorithm as shown in Fig. 10 is used. The notation t : s means that
term t is a member of the sort s; intermediate results are cached if s is a sort name.
3.5 Optimized Argument Selection
We now discuss how to avoid recursive calls of rsgV , and analogously of rsg, that yield ?.
Consider the sort definitions of s0 and s1 in Fig. 23. In the naive implementation, hsg(s0, s1) amounts
to sixteen recursive calls, shown in lines 3 to 6 of Fig. 24. However, by comparing the leading function
symbols in each call, we can see immediately that twelve of them will return the empty sort, and
can hence be ignored, while only four of them start with identical function symbols and thus need
to be further evaluated:
hsg(s0 + s0, s0 + s1) | hsg(s0 + s0, s1 + s0) | hsg(s0 ? sn, s1 ? s1) | hsg(sn ? s0, s1 ? s1).
The situation is slightly more complicated when computing rsgV : certain combinations of different
leading function symbols may lead to a variable in V and thus cannot be ignored; e.g. if v1 =
18
t : s
s
.
= s? (Sort Def)
t : s?
t : s1 |s2
(Disjunction L)
t : s1
t : s1 |s2
(Disjunction R)
t : s2
f(t1, . . . , tn) : f(s1, . . . , sn)
(Function)
t1 : s1 . . . tn : sn
Fig. 10. Simple Algorithm for Testing Sort Membership
?(0, suc(0)) and v2 = ?(0, 0 + 0), the calls rsgV ({v1, v2}, 0, suc(0)) and rsgV ({v1, v2}, 0, s0 + s0) will
result in v1, and v2, respectively.
r
v1
r
v2
r
r
  ?
suc ???
+
  ?
0
Fig. 11. Example: Search Tree
We present below an algorithm for selecting the argument pairs for recursive rsgV calls. In a first
step, we use the set V to build a search tree V T ? of pairs2 of different function symbols which need
to be considered by rsgV . Building the search tree is a straightforward matter. In the above example,
we get the tree shown in Fig. 11. In the general case, each path in the search tree has a length of N .
The sort definitions are expected to be in head normal form, i.e., of the general form
s
.
= f1(s11, . . . , s1n1) | . . . | fm(sm1, . . . , smnm).
We sort the disjuncts f1(s11, . . . , s1n1), . . . , fm(sm1, . . . , smnm) ascendingly by their leading function
symbols, assuming an arbitrary irreflexive total ordering ?, and group together all disjuncts with the
same function symbol (called “pre–grouping” to distinguish it from the kernel grouping algorithm).
For example, from the definitions of s0 and s1 in Fig. 23, we get after sorting
[ 0, s0 + s0, s0 ? sn, sn ? s0 ]
[ suc(s0), s0 + s1, s1 + s0, s1 ? s1 ],
and after pre–grouping
[ [0], [s0 + s0], [s0 ? sn, sn ? s0] ] =: Ps1
[ [suc(s0)], [s0 + s1, s1 + s0], [s1 ? s1] ] =: Ps2.
In the general case, we get N such lists of pre–groups. These lists of pre–groups, together with the
search tree, are given to the kernel grouping algorithm shown in Fig. 12, which produces a list of
N -tuples, each serving as arguments for a subsequent recursive rsgV call.
2 N-tuples in the general case, where N sorts are simultaneously anti–unified.
19
The kernel grouping algorithm takes four input arguments:
– a flag E which can take the values eq or ne, the latter indicating that different function symbols
have occurred in the current group
– the search tree V T ?
– the current group (a list of pre–groups)
– the current list of lists of pre–groups.
A pre–group, like [s0 +s1, s1 +s0], is denoted by P , or P
?; a list of pre–groups by Ps, Ps?, or Group.
? P denotes the common head symbol of all terms in the pre–group P . For a search (sub)tree V T ,
we denote by V Tf the subtree of V T at the branch labeled f ; if a branch labeled f does not exist
within V T , we get V Tf = nil, which denotes the empty search tree.
The output accumulator is not shown in Fig. 12; instead, in rule (Output), the statement “output
reverse(Group)” occurs. If this statement is reached, Group = [PN , . . . , P1] is a list of length N ,
and a list [?t1, . . . , tN ? | ti ? Pi, i = 1, . . . , N ] of all N -tuples, such that the i-th component is a
member of the i-th pre–group of reverse(Group), is added to the output; the order of tuples within
the list does not matter. The rule (Output) and the rules named (Abort . . . ) do not have a successor,
whereas rules (Join) and (Follow) have two. The start configuration is
eq V T ? [ ] [Ps1, . . . , P sN ]
where V T ? is the initial search tree and Ps1, . . . , P sN are the N lists of pre–groups obtained after
pre–grouping. Figure 13 shows a computation example. For the sake of readability, pre–groups are
written in braces, and the Psi in the fourth argument are separated by semicolons.
The same algorithm can also be used for rsg and hsg instead of rsgV by providing an empty search
tree.
We give below an estimation of the time complexity of the grouping algorithm. Assume that we
are given N sorts whose definitions are in head normal form and have each at most m disjuncts on
their right–hand side; moreover, assume that the initial search tree V T ? was built from n variables.
Sorting the disjuncts by leading function symbols takes N ·m · logm time; pre–grouping takes N ·m
time. We obtain N lists, each of which contains at most m groups. For the sake of brevity, we denote
the third argument of the rules in Fig. 12 by G, and the fourth by H . Any 4-tuple ?E, V T,G,H?
that occurs during the computation is called a state; a state is called final if a rule without successors
is applied to it. If V T of a state is a subtree of V T ?, we call the list of function symbols along the
way from the root of V T ? to the root of V T the path of that state. Proceeding from V T to V Tf
means appending f to the actual path. Observe the following properties of the rules:
1. To any state with E = ne whose actual V T is not a subtree of V T ?, the rule (Abort Ne) will be
applied, i.e. this state is final. Hence, each non–final state with E = ne corresponds to a node
in V T ?, viz. the root of the actual V T .
2. A non–final state with E = ne and a path [f1, . . . , fk] has H = [Psk+1, . . . , P sN ]. Moreover, we
have fi =? Pi for some Pi in Psi for all i = 1, . . . , k.
3. Each successor of a state with E = ne corresponds to a different subtree V Tf of V T
? (possibly
V Tf = nil), or has head(H) shortened by one element. The latter makes it impossible to reach
V Tf again, since f =? P ? ? P ?? for all later P ?? in Ps?, using the terminology common to rules
(Join), (Follow), (Skip), and (Init).
4. At most m different non–final states with E = ne may correspond to the same node of V T ?.
This follows from 1 and 3.
5. E has the value eq iff there is a function symbol f such that ? P = f for all P in G; in this case,
we write ? G := f .
20
eq V T [P | Group] [[P ? | Ps?] | Rest]
f =? P =? P ? (Join)
eq V Tf [P
?, P | Group] Rest
eq V T [P | Group] [Ps? | Rest]
E V T Group [ ]
(Output)
output reverse(Group)
ne nil Group Any
(Abort Ne)
eq nil [P | Group] [[P ? | Ps?] | Rest]
? P ?? P ? (Abort Eq)
E V T Group [[P ? | Ps?] | Rest] f =? P ?
(Follow)
ne V Tf [P
? | Group] Rest Group 6= [ ]
E V T Group [Ps? | Rest]
E V T Group [[P ? | Ps?] | Rest]
Group 6= [ ] (Skip)
E V T Group [Ps? | Rest]
E V T [ ] [[P ? | Ps?] | Rest]
f =? P ? (Init)
eq V Tf [P
?] Rest
eq V T [ ] [Ps? | Rest]
E V T Group [[ ] | Rest]
(Abort [ ])
Fig. 12. Grouping Rules
21
Precedence: (0) ? (s) ? (*) ? (+)
Input: [[0,s0*sn,sn*s0,s0+s0], [suc(s0),s1*s1,s0+s1,s1+s0]]
Pre–Grouped: [[[0],[s0*sn,sn*s0],[s0+s0]],[[suc(s0)],[s1*s1],[s0+s1,s1+s0]]]
Initial Search Tree V T ?:
0
??
s
?? (nil denotes empty subtree)
Output: [[0,suc(s0)],[s0*sn,s1*s1],[sn*s0,s1*s1],[s0+s0,s0+s1],[s0+s0,s1+s0]]
eq 0 [] [ [{0},{S0*Sn,Sn*S0},{S0+S0}] ; [{suc(S0)},{S1*S1},{S0+S1,S1+S0}] ]
(Init)
eq s [{0}] [ [{suc(S0)},{S1*S1},{S0+S1,S1+S0}] ]
(Follow s)
ne nil [{suc(S0)},{0}] [ ]
(Output [0,suc(S0)])
eq s [{0}] [ [{S1*S1},{S0+S1,S1+S0}] ]
(Skip)
eq s [{0}] [ [{S0+S1,S1+S0}] ]
(Skip)
eq s [{0}] [ [] ]
(Abort [])
eq 0 [] [ [{S0*Sn,Sn*S0},{S0+S0}] ; [{suc(S0)},{S1*S1},{S0+S1,S1+S0}] ]
(Init)
eq nil [{S0*Sn,Sn*S0}] [ [{suc(S0)},{S1*S1},{S0+S1,S1+S0}] ]
(Skip)
eq nil [{S0*Sn,Sn*S0}] [ [{S1*S1},{S0+S1,S1+S0}] ]
(Join *)
eq nil [{S1*S1},{S0*Sn,Sn*S0}] [ ]
(Output [S0*Sn,S1*S1],[Sn*S0,S1*S1])
eq nil [{S0*Sn,Sn*S0}] [ [{S0+S1,S1+S0}] ]
(Abort Eq)
eq 0 [] [ [{S0+S0}] ; [{suc(S0)},{S1*S1},{S0+S1,S1+S0}] ]
(Init)
eq nil [{S0+S0}] [ [{suc(S0)},{S1*S1},{S0+S1,S1+S0}] ]
(Skip)
eq nil [{S0+S0}] [ [{S1*S1},{S0+S1,S1+S0}] ]
(Skip)
eq nil [{S0+S0}] [ [{S0+S1,S1+S0}] ]
(Join +)
eq nil [{S0+S1,S1+S0},{S0+S0}] [ ]
(Output [S0+S0,S0+S1],[S0+S0,S1+S0])
eq nil [{S0+S0}] [ [] ]
(Abort [])
eq 0 [] [ [] ; [{suc(S0)},{S1*S1},{S0+S1,S1+S0}] ]
(Abort [])
Fig. 13. Example: Argument Selection Run
22
6. At most m different states with E = eq and G 6= [ ] may have the same ? G and the same
length(G), since each rule either increases length(G) or shortens head(H), the latter being
possible at most m times. No rule decreases length(G); and it always holds that length(G) 6 N .
7. Similar to 6, at most m different states with E = eq and G = [ ] can exist.
8. Each non–final state has at most two final states as successors.
9. The initial search tree has N · n + 1 nodes, if no two variables share a part of their path except
for the root node. In all other cases, the number of nodes is decreased by path sharing.
From 9, there are at most N ·n+1 nodes in V T ?; from 1 and 4, there are at most m · (N ·n+1) non–
final states with E = ne; from 6 and 7, there are at most m ·m ·N +m non–final states with E = eq.
Hence, there are at most m · (N ·n+ 1) +m ·m ·N +m = m · (N ·n+N ·m+ 2) 6 m ·N · (m+n+ 1)
non–final states, and, by 8, at most 3 ·m ·N · (m+n+ 1) states in all. A final state may result in an
output of at most gN N -tuples, where g is the maximum number of disjuncts of a sort–definition’s
right–hand side that start with the same function symbol. Including sorting and pre–grouping, our
approach takes Ø(N ·m · (m+ n) · gN) time. Since the naive approach — without grouping — takes
Ø(mN ) time, grouping makes sense especially for N > 2, i.e. when more than two input sorts are
to be anti–unified. Moreover, using the grouping algorithm makes the runtime more insensitive to
the number of different function symbols in the background theory. Figure 14 shows some runtime
measurements for grouping including pre–grouping. See Sect. 3.6 for more measurements.
Sort Defs of User Time in msec No. of Output Groups
s0, s1 13 4
s0, s1, s2 23 10
s0, s1, s2, s3 39 32
s0, s1, s2, s3, s4 102 144
Fig. 14. Runtimes for Grouping
3.6 Runtimes
In this section, we discuss some figures for runtime measurements. All runtimes given in this paper
refer to user time of a SICStus PROLOG 2.1 #8 implementation on a SUN 4/50GX SPARC with
40 MHz clock and 64 MBytes main storage.
During development of the implementation prototype, we experimented with several technical op-
timizations. The impact of the successful ones (see Fig. 15) on runtimes are discussed below. Since
runtime measurements have not been conducted systematically at all stages of development, we tried
to estimate their impact from the available data shown in Figs. 38 and 40. These data are categorized
and summarized in Fig. 16, yielding estimations of the improvement factors obtained by applying
several optimizations simultaneously. Figure 17 gives a graphical representation of these factors, the
x–axis being scaled logarithmically. In Fig. 18, we have computed the impact of each single technical
improvement as far as possible, based on the data from Fig. 17.
Several measurements have been made in order to explore the practical runtime behavior of the
final version (with optimizations bdgsv) of the algorithm wrt. number and size of input sorts. Fig-
ure 19(a) shows the E–anti–unification runtime vs. size of sort definitions; figures denote runtime
of rsgV ({}, Sorts) in seconds. si denotes the equivalence class of i wrt. the respective background
theory, cf. Fig. 4, 5. “> n” means running out of memory after n seconds.
In the third column, we have included the (?) operator in the background theory, such that equiva-
lence classes of terms can no longer be described by our sorts. We therefore cut off the sort definitions
23
Abbr. Technical Optimization Described in Improvement
Factor
b use of balanced binary trees to implement Occ sets Sect. 3.2 1.5
d use of calc sort depths Sect. 4 below 6.3
g use of group cr sorts Sect. 3.5 8.3
s restricting the sort simplifier to simp1 . . . simp4 (obsolete)
t without user trace 2.1
v use of rsgV Sect. 3.4 21.4
Fig. 15. Technical Optimizations
From To Factor Line vs. Line in Figure
g v 3.0
1.9 5 6 38
2.0 1 2 38
2.0 3 4 38
3.7 14 15 38
3.7 16 17 38
4.6 12 13 38
v gstv 15.0
12.0 17 18 38
29.0 19 22 38
gstv dgsv 3.0
– 1 2 40
0.3 3 4 40
3.5 5 6 40
7.8 7 8 40
dgsv bdgsv 1.5
1.4 10 11 40
2.1 14 15 40
stv gstv 8.3 20 22 38
gsv gstv 2.1 21 22 38
Fig. 16. Measured Improvements of Technical Optimization Groups
r r r r r
r
r
g v gstv dgsv bdgsv
stv
gsv
3 15 3 1.5
8.3
2.1
???
???
???
???
???
?????
Fig. 17. Graphical Representation of Improvement Factors
24
at 20 — cf. Sect. 3.1. Since adding (?) to the background theory led to an erratic increase in runtime,
we additionally measured the dependency of runtime on the “cut–off point”; the result is shown in
Fig. 19 (b), indicating the runtimes in seconds for rsgV ({}, s0, s2) with cut–off points n from 2 to
20.
Figure 20 shows the runtime for rsgV ({}, s
i
X) wrt. the background theory of {+}, {+, ?}, and
{+, ?, /}, respectively, where siX denotes the list that contains i times the sort sX .
Optimization From To Factor
b dgsv bdgsv 1.5
d gsv dgsv 6.3 = 2.1 ? 3.0
g stv gstv 8.3
t gsv gstv 2.1
sv g gsv 21.4 = 3.0 ? 15.0/2.1
Fig. 18. Runtime Impact of Single Technical Optimizations
Sorts + +, ? +,?, ?
[s0, s1, s2] 0 0 > 266
[s0, s1, s3] 1 2
[s0, s1, s4] 0 3
[s0, s1, s5] 1 4
[s0, s1, s6] 1 5
[s0, s1, s7] 1 6
[s0, s1, s8] 1 9
[s0, s1, s9] 2 8
[s0, s1, s10] 2 10
[s0, s1, s11] 2 13
[s0, s1, s12] 2 15
[s0, s1, s13] 3 15
[s0, s1, s14] 3 17
[s0, s1, s15] 4 19
[s0, s1, s16] 6 21
[s0, s1, s17] 5 23
[s0, s1, s18] 7 24
[s0, s1, s19] 5 26
[s0, s1, s20] 7 29
(a)
n +,? +,?, ?
2 0
3 1
4 3
5 7
6 15
7 24
8 41
9 61
10 96
11 135
12 194
13 272
14 363
15 485
16 640
17 847
18 1066
19 1349
20 1804 1912
(b)
Fig. 19. E–Anti–Unification Runtime vs. Size of Sort Definitions
25
+ i = 2 3 4 5 6 7 8 9
s0 0 1 1 1 1 2 1 0
s1 0 0 1 6 11 27 87 279
s2 1 2 16 84 579 > 3034
s3 1 13 106 1267 > 5313
s4 2 31 576 > 5009
s5 4 92 2546
s6 7 221 > 4518
s7 10 492
s8 19 1080
s9 27 2092
s10 39 > 1874
s11 53
s12 77
s13 105
s14 138
s15 178
s16 232
s17 290
s18 379
s19 466
s20 577
+, ? i = 2 3 4 5 6 7 8 9
s0 1 1 1 4 15 38 113 344
s1 1 2 8 33 138 577 2400 > 7464
s2 2 9 49 318 2399 > 6466
s3 2 21 217 2632 > 5775
s4 3 57 962 > 5316
s5 7 133 > 2511
s6 10 309
s7 17 643
s8 24 1310
s9 34 2507
s10 49 > 2202
s11 67
s12 96
s13 123
s14 160
s15 209
s16 261
s17 335
s18 423
s19 525
s20 632
+, ?, / i = 2 3 4 5 6 7 8 9
s0 1 1 3 8 17 44
s1 794
s2
Fig. 20. E–Anti–Unification Runtime vs. Size and Number of Sorts
26
4 Sort Enumeration
The algorithms rsg and rsgV both return a sort as result. In this section, we describe how the terms
belonging to a given sort are enumerated.
Enumeration of all terms of a given sort is done depth first. It is checked whether the sort is finite;
in this case, a simple depth–first traversion is sufficient. For an infinite sort, the depth is limited
to a fixed bound which is iteratively deepened. The depth of a term is currently measured as the
maximum number of replacements of sort names by their definitions of all paths from the term root to
its leaves. However, several other depth measures are possible; see the remarks on the 0, 1, 2, 1, 4, 1, 6
series example in Sect. 7.2.
Cutting the depth at a fixed bound n introduces many dead ends in sort enumeration when dis-
junctions in sort definitions are tried that can lead only to terms of a depth greater than n. As this
usually happens at each of the n levels of recursive descent, the number of dead ends is in the order
of magnitude mn, where m is the maximum number of disjuncts occurring in a sort definition. For
an example, see Figs. 35 and 36 in Sect. 5. An important optimization therefore consists in recording
for each sort s the minimum depth mindepth(s) of any of its terms; rule (Sort Def ) is applicable
only if this minimum depth is smaller than the remaining depth bound.
The rules of the optimized enumeration algorithm are given in Fig. 21. The notation s : dp : t means
that t is a term of a depth 6 dp in  L(s), where s is an arbitrary sort expression. The resulting
speedup of 6.3 compared to standard enumeration can be seen from line “d” in Fig. 18. The values
of the sort’s minimum depths are computed using a bottom–up algorithm acting on all (new) sort
definitions simultaneously, similar to the inhabitance algorithm from [AM91], which is described in
Sect. 4.1.
Originally, our implementation had the additional capability of enumerating only terms in normal
form wrt. a given set of (linear) redices. However, line 9 in Fig. 40 shows that sort enumeration may
still take unacceptably long if only terms in normal form are to be enumerated. The restriction to
terms in normal form is therefore achieved by intersecting the solution sort with the sort of all terms
in normal form (provided all redices are linear terms, cf. Sect. 6.2), rather than by restricting the
enumeration algorithm to terms in normal form. See line 10 in Fig. 40.
? : dp : t
(Bottom)
fail
s : dp : t s
.
= s?,
(Sort Def)
s? : dp?1 : t dp > mindepth(s)
s1 |s2 : dp : t
(Disjunction L)
s1 : dp : t
s1 |s2 : dp : t
(Disjunction R)
s2 : dp : t
f(s1, . . . , sn) : dp : f(t1, . . . , tn)
(Function)
s1 : dp : t1 . . . sn : dp : tn
Fig. 21. Sort Enumeration Rules
27
4.1 Sort Depth Computation
Assume that all sort definitions are in head normal form. To each sort name s, associate a PROLOG
variable S that will hold the minimal depth of s when the algorithm is finished. For each sort
definition s
.
= f1(s11, . . . , s1n1) | . . . | fm(sm1, . . . , smnm), introduce an equation
S = min(max(S11, . . . , S1n1), . . . ,max(Sm1, . . . , Smnm)) + 1
into the set of depth equations. Since max is idempotent, multiple occurrences among its arguments
may be replaced by one. Since max is monotonic, max(Si1, . . . , Sini) can be omitted if S itself
occurs among Si1, . . . , Sini . If any nullary symbol is among f1, . . . , fm, the above depth equation
simply reads S = 1. Building the set of depth equations is achieved by the PROLOG predicate
calc sort depths1 list, which additionally distinguishes solved equations (i.e. ones containing no
uninstantiated PROLOG variables) from unsolved ones.
In a second phase, repeat the following solving algorithm until no further progress is obtained, which
will be the case after at least k cycles if there are k sort definitions. The solving algorithm checks
each unsolved equation as to whether one or more of its right–hand side max(. . .) expressions are
ground terms, meaning that all necessary data is available to compute its value. These expressions
are evaluated and substituted by their result. If one of the results is minimal, i.e. equals i? 1 in the
i-th cycle, the whole equation can be solved: S = i. Fig. 22 gives an example of a computation of
the depths of sorts from Fig. 4.
All equations that remain unsolved after the final cycle correspond to empty sorts, cf. [AM91]. Their
sort definitions’ right–hand sides are simply replaced by ?, and any occurrence of them in other sort
definitions is also replaced by ?, which may give rise to some obvious further simplifications.
In order to supply a different depth measure, max has to be replaced accordingly, and the optimiza-
tion based on its idempotence property may no longer be applicable.
i = 1 2 3
S0 = 1
S1 = min(S0, Se) + 1 = 2
S2 = min(S1) + 1 = min(2) + 1 = 3
S3 = min(S2,max(S1, S2)) + 1 = min(S2,max(2, S2)) + 1 = 4
S4 = min(S3,max(S1, S3), S2) + 1 = min(S3,max(2, S3), S2) + 1 = 4
S5 = min(S4,max(S1, S4),max(S2, S3)) + 1 = min(S4,max(2, S4),max(3, S3)) + 1 = 5
Sp = min(Sn, Se) + 1 = 2
Se = 1
So = min(Se) + 1 = 2
Sn = 1
Fig. 22. Example: Sort Depth Computation
28
5 An E–Anti–Unification Example
In this section, we give an elaborate example of how the E–anti–unification algorithms work. Consider
the background equational Theory (1) from Fig. 3, defining (+) and (?) over the 0–suc algebra. The
equivalence class of 0 and suc(0) can be defined as sorts s0 and s1, respectively, as shown in Fig. 23.
sn is not an equivalence class, but the sort of all terms. For example, the sort definition of s0 can
be read as follows: there are four possibilities for forming a term of the value 0: first, the constant 0
itself; second, adding two terms of value 0; third, multiplying a term of value 0 by any other term;
and fourth, multiplying them conversely.
The computation of hsg(s0, s1), according to Alg. 12, is shown in Fig. 24. The necessary auxiliary
computations are shown in Figs. 25 to 29. The resulting sort definitions are summarized in the
upper part of Fig. 30; They contain all the linear generalizations but only some of the nonlinear
ones. Figures 31 to 34 show the computation of variables with non–empty sort intersections using
the algorithm from Sect. 3.3, resulting in the new variable v?00 for v00, v0n, vn0, vnn, and v
?
01 for
v01, v0n, vn1, vnn. The lower part of Fig. 30 shows the appropriately modified sort definitions.  L(s
?
01)
is the set of all generalizations of 0 and suc(0) modulo +, ?.
Figures 35 and 36 show the enumeration of sort s?01 with a depth bound of 2. The actual depth
bound is shown in the second column, the i-th number referring to the i-th identifier (variable or
sort name) in the term. Terms flagged “<*****” do not contain any sort names and are output. In
Fig. 36, most terms that do not yield output are omitted.
s0
.
= 0 | s0 + s0 | s0 ? sn | sn ? s0
s1
.
= suc(s0) | s0 + s1 | s1 + s0 | s1 ? s1
sn
.
= 0 | suc(sn) | sn + sn | sn ? sn
Fig. 23. Sort Definition of s0, s1
s01
.
= hsg(s0, s1)
= v01 | hsg(0, suc(s0)) | hsg(0, s0 + s1) | hsg(0, s1 + s0) | hsg(0, s1 ? s1) |
hsg(s0 + s0, suc(s0)) | hsg(s0 + s0, s0 + s1) | hsg(s0 + s0, s1 + s0) | hsg(s0 + s0, s1 ? s1) |
hsg(s0 ? sn, suc(s0)) | hsg(s0 ? sn, s0 + s1) | hsg(s0 ? sn, s1 + s0) | hsg(s0 ? sn, s1 ? s1) |
hsg(sn ? s0, suc(s0)) | hsg(sn ? s0, s0 + s1) | hsg(sn ? s0, s1 + s0) | hsg(sn ? s0, s1 ? s1)
= v01 | ? | ? | ? | ? |
? | hsg(s0 + s0, s0 + s1) | hsg(s0 + s0, s1 + s0) | ? |
? | ? | ? | hsg(s0 ? sn, s1 ? s1) |
? | ? | ? | hsg(sn ? s0, s1 ? s1)
= v01 | hsg(s0, s0) + hsg(s0, s1) | hsg(s0, s1) + hsg(s0, s0) | hsg(s0, s1) ? hsg(sn, s1) | hsg(sn, s1) ? hsg(s0 ? s1)
= v01 | s00 + s01 | s01 + s00 | s01 ? sn1 | sn1 ? s01
Fig. 24. Computation of hsg(s0, s1)
29
s00
.
= hsg(s0, s0)
= v00 | hsg(0, 0) | hsg(0, s0 + s0) | hsg(0, s0 ? sn) | hsg(0, sn ? s0) |
hsg(s0 + s0, 0) | hsg(s0 + s0, s0 + s0) | hsg(s0 + s0, s0 ? sn) | hsg(s0 + s0, sn ? s0) |
hsg(s0 ? sn, 0) | hsg(s0 ? sn, s0 + s0) | hsg(s0 ? sn, s0 ? sn) | hsg(s0 ? sn, sn ? s0) |
hsg(sn ? s0, 0) | hsg(sn ? s0, s0 + s0) | hsg(sn ? s0, s0 ? sn) | hsg(sn ? s0, sn ? s0)
= v00 | 0 | hsg(s0, s0) + hsg(s0, s0) | hsg(s0, s0) ? hsg(sn, sn) |
hsg(s0, sn) ? hsg(sn, s0) | hsg(sn, s0) ? hsg(s0, sn) | hsg(sn, sn) ? hsg(s0, s0)
= v00 | 0 | s00 + s00 | s00 ? snn |
s0n ? sn0 | sn0 ? s0n | snn ? s00
Fig. 25. Computation of hsg(s0, s0)
s0n
.
= hsg(s0, sn)
= v0n | hsg(0, 0) | hsg(0, suc(sn)) | hsg(0, sn + sn) | hsg(0, sn ? sn) |
hsg(s0 + s0, 0) | hsg(s0 + s0, suc(sn)) | hsg(s0 + s0, sn + sn) | hsg(s0 + s0, sn ? sn) |
hsg(s0 ? sn, 0) | hsg(s0 ? sn, suc(sn)) | hsg(s0 ? sn, sn + sn) | hsg(s0 ? sn, sn ? sn) |
hsg(sn ? s0, 0) | hsg(sn ? s0, suc(sn)) | hsg(sn ? s0, sn + sn) | hsg(sn ? s0, sn ? sn)
= v0n | 0 | hsg(s0, sn) + hsg(s0, sn) | hsg(s0, sn) ? hsg(sn, sn) | hsg(sn, sn) ? hsg(s0, sn)
= v0n | 0 | s0n + s0n | s0n ? snn | snn ? s0n
Fig. 26. Computation of hsg(s0, sn)
sn0
.
= hsg(sn, sn)
= vn0 | hsg(0, 0) | hsg(0, s0 + s0) | hsg(0, s0 ? sn) | hsg(0, sn ? s0) |
hsg(suc(sn), 0) | hsg(suc(sn), s0 + s0) | hsg(suc(sn), s0 ? sn) | hsg(suc(sn), sn ? s0) |
hsg(sn + sn, 0) | hsg(sn + sn, s0 + s0) | hsg(sn + sn, s0 ? sn) | hsg(sn + sn, sn ? s0) |
hsg(sn ? sn, 0) | hsg(sn ? sn, s0 + s0) | hsg(sn ? sn, s0 ? sn) | hsg(sn ? sn, sn ? s0)
= vn0 | 0 | hsg(sn, s0) + hsg(sn, s0) | hsg(sn, s0) ? hsg(sn, sn) | hsg(sn, sn) ? hsg(sn, s0)
= vn0 | 0 | sn0 + sn0 | sn0 ? snn | snn ? sn0
Fig. 27. Computation of hsg(sn, s0)
30
sn1
.
= hsg(sn, s1)
= vn1 | hsg(0, suc(s0)) | hsg(0, s0 + s1) | hsg(0, s1 + s0) | hsg(0, s1 ? s1) |
hsg(suc(sn), suc(s0)) | hsg(suc(sn), s0 + s1) | hsg(suc(sn), s1 + s0) | hsg(suc(sn), s1 ? s1) |
hsg(sn + sn, suc(s0)) | hsg(sn + sn, s0 + s1) | hsg(sn + sn, s1 + s0) | hsg(sn + sn, s1 ? s1) |
hsg(sn ? sn, suc(s0)) | hsg(sn ? sn, s0 + s1) | hsg(sn ? sn, s1 + s0) | hsg(sn ? sn, s1 ? s1)
= vn1 | suc(hsg(sn, s0)) | hsg(sn, s0) + hsg(sn, s1) | hsg(sn, s1) + hsg(sn + s0) | hsg(sn, s1) ? hsg(sn ? s1)
= vn1 | suc(sn0) | sn0 + sn1 | sn1 + sn0 | sn1 ? sn1
Fig. 28. Computation of hsg(sn, s1)
snn
.
= hsg(sn, sn)
= vnn | hsg(0, 0) | hsg(0, suc(sn)) | hsg(0, sn + sn) | hsg(0, sn ? sn) |
hsg(suc(sn), 0) | hsg(suc(sn), suc(sn)) | hsg(suc(sn), sn + sn) | hsg(suc(sn), sn ? sn) |
hsg(sn + sn, 0) | hsg(sn + sn, suc(sn)) | hsg(sn + sn, sn + sn) | hsg(sn + sn, sn ? sn) |
hsg(sn ? sn, 0) | hsg(sn ? sn, suc(sn)) | hsg(sn ? sn, sn + sn) | hsg(sn ? sn, sn ? sn)
= vnn | 0 | suc(hsg(sn, sn)) | hsg(sn, sn) + hsg(sn, sn) | hsg(sn, sn) ? hsg(sn, sn)
= vnn | 0 | suc(snn) | snn + snn | snn ? snn
Fig. 29. Computation of hsg(sn, sn)
Linear Generalization:
s00
.
= v00 | 0 | s00 + s00 | s00 ? snn | s0n ? sn0 | sn0 ? s0n | snn ? s00
s01
.
= v01 | s00 + s01 | s01 + s00 | s01 ? sn1 | sn1 ? s01
s0n
.
= v0n | 0 | s0n + s0n | s0n ? snn | snn ? s0n
sn0
.
= vn0 | 0 | sn0 + sn0 | sn0 ? snn | snn ? sn0
sn1
.
= vn1 | suc(sn0) | sn0 + sn1 | sn1 + sn0 | sn1 ? sn1
snn
.
= vnn | 0 | suc(snn) | snn + snn | snn ? snn
Complete Generalization:
s?00
.
= v00 | v
?
00 | 0 | s
?
00 + s
?
00 | s
?
00 ? s
?
nn | s
?
0n ? s
?
n0 | s
?
n0 ? s
?
0n | s
?
nn ? s
?
00
s?01
.
= v01 | v
?
01 | s
?
00 + s
?
01 | s
?
01 + s
?
00 | s
?
01 ? s
?
n1 | s
?
n1 ? s
?
01
s?0n
.
= v0n | v
?
00 | v
?
01 | 0 | s
?
0n + s
?
0n | s
?
0n ? s
?
nn | s
?
nn ? s
?
0n
s?n0
.
= vn0 | v
?
00 | 0 | s
?
n0 + s
?
n0 | s
?
n0 ? s
?
nn | s
?
nn ? s
?
n0
s?n1
.
= vn1 | v
?
01 | suc(s
?
n0) | s
?
n0 + s
?
n1 | s
?
n1 + s
?
n0 | s
?
n1 ? s
?
n1
s?nn
.
= vnn | v
?
00 | v
?
01 | 0 | suc(s
?
nn) | s
?
nn + s
?
nn | s
?
nn ? s
?
nn
Fig. 30. Generalization of s0 and s1
31
S = { s0, s1, sn}
I2 = { ?s0, sn, s0?, ?s1, sn, s1?}
L2 = { ?v00, v0n?, ?v00, vn0?, ?v00, vnn?, ?v01, v0n?, ?v01, vn1?, ?v01, vnn?, ?v0n, vn0?, ?v0n, vn1?, ?v0n, vnn?,
?vn0, vnn?, ?vn1, vnn?}
V 2 = { ?v00, 3?, ?v01, 3?, ?v0n, 5?, ?vn0, 3?, ?vn1, 3?, ?vnn, 5?}
[V00,V0n] [V00,V01,V0n,Vn0,Vn1,Vnn] []
(Member)
[V00,V0n] [V01,V0n,Vn0,Vn1,Vnn] []
(Sublist2)
[V00,V0n] [V0n,Vn0,Vn1,Vnn] []
(Member)
[V00,V0n] [Vn0,Vn1,Vnn] []
(Inf Inh) infs({V00,V0n,Vn0})
[V00,V0n,Vn0] [Vn1,Vnn] []
(Sublist2)
[V00,V0n,Vn0] [Vnn] []
(Inf Inh) infs({V00,V0n,Vn0,Vnn})
[V00,V0n,Vn0,Vnn] [] []
(Output Max [V00,V0n,Vn0,Vnn])
[V00,V0n,Vn0] [] []
(Max Subsumed)
[V00,V0n] [Vn1,Vnn] []
(Sublist2)
[V00,V0n] [Vnn] []
(Suplist)
[V00,V0n] [] [Vnn]
(Max Subs Susp)
[V00,Vn0] [V00,V01,V0n,Vn0,Vn1,Vnn] []
(Member)
[V00,Vn0] [V01,V0n,Vn0,Vn1,Vnn] []
(Sublist2)
[V00,Vn0] [V0n,Vn0,Vn1,Vnn] []
(Suplist)
[V00,Vn0] [Vn0,Vn1,Vnn] [V0n]
(Member)
[V00,Vn0] [Vn1,Vnn] [V0n]
(Sublist2)
[V00,Vn0] [Vnn] [V0n]
(Suplist)
[V00,Vn0] [] [Vnn,V0n]
(Max Subs Susp)
(Contd. in Fig. 32)
Fig. 31. Intersection Computation for s0, s1
32
[V00,Vnn] [V00,V01,V0n,Vn0,Vn1,Vnn] []
(Member)
[V00,Vnn] [V01,V0n,Vn0,Vn1,Vnn] []
(Sublist2)
[V00,Vnn] [V0n,Vn0,Vn1,Vnn] []
(Suplist)
[V00,Vnn] [Vn0,Vn1,Vnn] [V0n]
(Suplist)
[V00,Vnn] [Vn1,Vnn] [Vn0,V0n]
(Sublist2)
[V00,Vnn] [Vnn] [Vn0,V0n]
(Member)
[V00,Vnn] [] [Vn0,V0n]
(Max Subs Susp)
[V01,V0n] [V00,V01,V0n,Vn0,Vn1,Vnn] []
(Sublist2)
[V01,V0n] [V01,V0n,Vn0,Vn1,Vnn] []
(Member)
[V01,V0n] [V0n,Vn0,Vn1,Vnn] []
(Member)
[V01,V0n] [Vn0,Vn1,Vnn] []
(Sublist2)
[V01,V0n] [Vn1,Vnn] []
(Inf Inh) infs({V01,V0n,Vn1})
[V01,V0n,Vn1] [Vnn] []
(Inf Inh) infs({V01,V0n,Vn1,Vnn})
[V01,V0n,Vn1,Vnn] [] []
(Output Max [V01,V0n,Vn1,Vnn])
[V01,V0n,Vn1] [] []
(Max Subsumed)
[V01,V0n] [Vnn] []
(Suplist)
[V01,V0n] [] [Vnn]
(Max Subs Susp)
[V01,Vn1] [V00,V01,V0n,Vn0,Vn1,Vnn] []
(Sublist2)
[V01,Vn1] [V01,V0n,Vn0,Vn1,Vnn] []
(Member)
[V01,Vn1] [V0n,Vn0,Vn1,Vnn] []
(Suplist)
[V01,Vn1] [Vn0,Vn1,Vnn] [V0n]
(Sublist2)
[V01,Vn1] [Vn1,Vnn] [V0n]
(Member)
[V01,Vn1] [Vnn] [V0n]
(Suplist)
[V01,Vn1] [] [Vnn,V0n]
(Max Subs Susp)
(Contd. in Fig. 33)
Fig. 32. Intersection Computation for s0, s1 (1. Contin.)
33
[V01,Vnn] [V00,V01,V0n,Vn0,Vn1,Vnn] []
(Sublist2)
[V01,Vnn] [V01,V0n,Vn0,Vn1,Vnn] []
(Member)
[V01,Vnn] [V0n,Vn0,Vn1,Vnn] []
(Suplist)
[V01,Vnn] [Vn0,Vn1,Vnn] [V0n]
(Sublist2)
[V01,Vnn] [Vn1,Vnn] [V0n]
(Suplist)
[V01,Vnn] [Vnn] [Vn1,V0n]
(Member)
[V01,Vnn] [] [Vn1,V0n]
(Max Subs Susp)
[V0n,Vn0] [V00,V01,V0n,Vn0,Vn1,Vnn] []
(Suplist)
[V0n,Vn0] [V01,V0n,Vn0,Vn1,Vnn] [V00]
(Sublist2)
[V0n,Vn0] [V0n,Vn0,Vn1,Vnn] [V00]
(Member)
[V0n,Vn0] [Vn0,Vn1,Vnn] [V00]
(Member)
[V0n,Vn0] [Vn1,Vnn] [V00]
(Sublist2)
[V0n,Vn0] [Vnn] [V00]
(Suplist)
[V0n,Vn0] [] [Vnn,V00]
(Max Subs Susp)
[V0n,Vn1] [V00,V01,V0n,Vn0,Vn1,Vnn] []
(Sublist2)
[V0n,Vn1] [V01,V0n,Vn0,Vn1,Vnn] []
(Suplist)
[V0n,Vn1] [V0n,Vn0,Vn1,Vnn] [V01]
(Member)
[V0n,Vn1] [Vn0,Vn1,Vnn] [V01]
(Sublist2)
[V0n,Vn1] [Vn1,Vnn] [V01]
(Member)
[V0n,Vn1] [Vnn] [V01]
(Suplist)
[V0n,Vn1] [] [Vnn,V01]
(Max Subs Susp)
(Contd. in Fig. 34)
Fig. 33. Intersection Computation for s0, s1 (2. Contin.)
34
[V0n,Vnn] [V00,V01,V0n,Vn0,Vn1,Vnn] []
(Suplist)
[V0n,Vnn] [V01,V0n,Vn0,Vn1,Vnn] [V00]
(Suplist)
[V0n,Vnn] [V0n,Vn0,Vn1,Vnn] [V01,V00]
(Member)
[V0n,Vnn] [Vn0,Vn1,Vnn] [V01,V00]
(Suplist)
[V0n,Vnn] [Vn1,Vnn] [Vn0,V01,V00]
(Suplist)
[V0n,Vnn] [Vnn] [Vn1,Vn0,V01,V00]
(Member)
[V0n,Vnn] [] [Vn1,Vn0,V01,V00]
(Max Subs Susp)
[Vn0,Vnn] [V00,V01,V0n,Vn0,Vn1,Vnn] []
(Suplist)
[Vn0,Vnn] [V01,V0n,Vn0,Vn1,Vnn] [V00]
(Sublist2)
[Vn0,Vnn] [V0n,Vn0,Vn1,Vnn] [V00]
(Suplist)
[Vn0,Vnn] [Vn0,Vn1,Vnn] [V0n,V00]
(Member)
[Vn0,Vnn] [Vn1,Vnn] [V0n,V00]
(Sublist2)
[Vn0,Vnn] [Vnn] [V0n,V00]
(Member)
[Vn0,Vnn] [] [V0n,V00]
(Max Subs Susp)
[Vn1,Vnn] [V00,V01,V0n,Vn0,Vn1,Vnn] []
(Sublist2)
[Vn1,Vnn] [V01,V0n,Vn0,Vn1,Vnn] []
(Suplist)
[Vn1,Vnn] [V0n,Vn0,Vn1,Vnn] [V01]
(Suplist)
[Vn1,Vnn] [Vn0,Vn1,Vnn] [V0n,V01]
(Sublist2)
[Vn1,Vnn] [Vn1,Vnn] [V0n,V01]
(Member)
[Vn1,Vnn] [Vnn] [V0n,V01]
(Member)
[Vn1,Vnn] [] [V0n,V01]
(Max Subs Susp)
Fig. 34. Intersection Computation for s0, s1 (3. Contin.)
35
S’01 2
V01 1 <*****
V’01 1 <*****
S’00+S’01 1,1
V00+V01 0,0 <*****
V00+V’01 0,0 <*****
V00+(S’00+S’01) 0,0
V00+(S’01+S’00) 0,0
V00+(S’01*S’n1) 0,0
V00+(S’n1*S’01) 0,0
V’00+V01 0,0 <*****
V’00+V’01 0,0 <*****
V’00+(S’00+S’01) 0,0
V’00+(S’01+S’00) 0,0
V’00+(S’01*S’n1) 0,0
V’00+(S’n1*S’01) 0,0
0+V01 0,0 <*****
0+V’01 0,0 <*****
0+(S’00+S’01) 0,0
0+(S’01+S’00) 0,0
0+(S’01*S’n1) 0,0
0+(S’n1*S’01) 0,0
(S’00+S’00)+V01 0,0
(S’00+S’00)+V’01 0,0
(S’00+S’00)+(S’00+S’01) 0,0
(S’00+S’00)+(S’01+S’00) 0,0
(S’00+S’00)+(S’01*S’n1) 0,0
(S’00+S’00)+(S’n1*S’01) 0,0
(S’00*S’nn)+V01 0,0
(S’00*S’nn)+V’01 0,0
(S’00*S’nn)+(S’00+S’01) 0,0
(S’00*S’nn)+(S’01+S’00) 0,0
(S’00*S’nn)+(S’01*S’n1) 0,0
(S’00*S’nn)+(S’n1*S’01) 0,0
(S’0n*S’n0)+V01 0,0
(S’0n*S’n0)+V’01 0,0
(S’0n*S’n0)+(S’00+S’01) 0,0
(S’0n*S’n0)+(S’01+S’00) 0,0
(S’0n*S’n0)+(S’01*S’n1) 0,0
(S’0n*S’n0)+(S’n1*S’01) 0,0
(S’n0*S’0n)+V01 0,0
(S’n0*S’0n)+V’01 0,0
(S’n0*S’0n)+(S’00+S’01) 0,0
(S’n0*S’0n)+(S’01+S’00) 0,0
(S’n0*S’0n)+(S’01*S’n1) 0,0
(S’n0*S’0n)+(S’n1*S’01) 0,0
(S’nn*S’00)+V01 0,0
(S’nn*S’00)+V’01 0,0
(S’nn*S’00)+(S’00+S’01) 0,0
(S’nn*S’00)+(S’01+S’00) 0,0
(S’nn*S’00)+(S’01*S’n1) 0,0
(S’nn*S’00)+(S’n1*S’01) 0,0
(Contd. in Fig. 36)
Fig. 35. Enumeration of s01
36
S’01+S’00 1,1
V01+V00 0,0 <*****
V01+V’00 0,0 <*****
V01+0 0,0 <*****
...
V’01+V00 0,0 <*****
V’01+V’00 0,0 <*****
V’01+0 0,0 <*****
...
S’01*S’n1 1,1
V01*Vn1 0,0 <*****
V01*V’01 0,0 <*****
...
V’01*Vn1 0,0 <*****
V’01*V’01 0,0 <*****
...
S’n1*S’01 1,1
Vn1*V01 0,0 <*****
Vn1*V’01 0,0 <*****
...
V’01*V01 0,0 <*****
V’01*V’01 0,0 <*****
...
(S’n1*S’n1)*(S’n1*S’01) 0,0
Fig. 36. Enumeration of s01 (contd.)
37
6 Lemma Generation
6.1 Implementation
One application of E–anti–unification is for generating lemma candidates in equational induction
proofs. In this section, we follow [Hei95] in showing how to generate candidates that are applicable
in a given blocked proof situation. The algorithm presented here takes as input a term t and a list
[?1, . . . , ?n] of ground substitutions, and generates as output the sort s
r of all terms t? such that
?it =E ?it
? for i = 1, . . . , n. In other words, each generated t? equals the given t at least on all given
example instances. The appropriate selection of the ?i is discussed in Sect. 6.3 below.
Note that for each universally valid equation t =E t
?, the right–hand side t? will be a member of
 L(sr), and that for each non–universally valid equation t =E t
?, t? can be excluded from sr by adding
a “counter–example instance” ?? with ??t 6=E ??t? to [?1, . . . , ?n].
The algorithm first computes the simultaneous syntactical anti–unification of all example instances
tl := ?1t ? . . . ? ?nt.
Usually, tl is a variant of t, cf. Sect. 6.3. Next, we compute the sort of all E–anti–unifiers of example
instances
sr := rsgV (vars(t
l), [?1t, . . . , ?nt]).
For each tr ?  L(sr), the equation tl = tr is then a lemma candidate. Note that using rsgV ensures
that vars(tr) ? vars(tl), thus excluding nonsense candidates like (x1 + x2) + x3 = x4 + x5. In order
to additionally restrict sr to terms in normal form, we may define the sort sNF of all terms in
normal form (see Sect. 6.2 below) and intersect sr with sNF . This will exclude candidates such as
(x1 + x2) + x3 = x1 + (x2 + (x3 + 0)).
6.2 Filter Sorts
In order to restrict the output of lemma generation or other applications to make it satisfy certain
additional criteria, we may intersect the result sort of E–anti–unification with appropriate filter sorts.
The definition and construction of these filter sorts is described below.
– The top sort sTOP of all valid terms at all depends on the variables that have been introduced
during E–anti–unification. Each such variable must be treated as a nullary function symbol. Let
V be the set of all variables occurring in any sort definition; then
sTOP
.
= x?V x | f?F f(sTOP , . . . , sTOP ).
– Provided all term–rewrite rules of the given background equational theory have linear left–hand
sides, we can compute the sort sRED of all reducible terms. Let l1, . . . , ln be the left–hand sides;
let
Li := {x? sTOP | x ? vars(li)} (li)
be the sorts obtained by replacing every variable by sTOP . Li contains all terms where li matches
at the root. Define the set of all reducible terms by
sRED
.
= ni=1 Li | f?F f(sRED, sTOP , . . . , sTOP ) | . . . | f(sTOP , . . . , sTOP , sRED).
38
– Since our sorts are closed wrt. relative complements, the sort of irreducible terms can simply be
computed by sNF := sTOP \ sRED.
– If there are nonlinear redices, the set TRED of reducible terms as well as the set TNF of irreducible
terms may no longer be a regular tree language and may thus not be representable by our
sorts, cf. e.g. [HH94,Com90]. However, by omitting all nonlinear left–hand sides, we can achieve
 L(sRED) ? TRED, and TNF ?  L(sNF ). Conversely, by replacing each nonlinear redex with a
linear anti–instance, we get TRED ?  L(sRED) and  L(sNF ) ? TNF .
– For every finite set of variables V ? W , we can compute the sort SWV of all terms t such that
V ? vars(t) ?W . Let A be the set of all occurring arities; for any a ? A, let
parts(V, a) := {?P1, . . . , Pa? | P1 ? . . . ? Pa = V, ?i, j i 6= j ? Pi ? Pj = {}}
denote the set of all partitions of the set V into a disjoint subsets; let parts(V, 0) = {}. Define
sW{}
.
= x?W x | f?F f(s
W
{} , . . . , s
W
{}),
sW{v}
.
= v | f?F ,ar(f)>1 f(s
W
{v}, s
W
{} , . . . , s
W
{}) | . . . | f(s
W
{} , . . . , s
W
{} , s
W
{v}),
sWV
.
= a?A f?F ,ar(f)=a ?P1,...,Pa??parts(V,a) f(s
W
P1
, . . . , sWPa).
Fig. 37 shows an example for F = {0, s,+}, V = {v1, v2} and W = {v1, v2, v3, v4}, using the
abbreviations s123412 := s
{v1,v2,v3,v4}
{v1,v2}
, s1234? := s
{v1,v2,v3,v4}
{} , and so on.
Note that filtering with sV{} can be avoided by computing with rsgV instead of rsg, which is
also much faster. However, for V 6= {} the filter sorts sWV provide a means of ensuring that each
solution term contains at least all variables from a given set V .
s123412
.
= suc(s123412 ) | s
1234
12 + s
1234
? | s
1234
? + s
1234
12 | s
1234
1 + s
1234
2 | s
1234
2 + s
1234
1
s12341
.
= v1 | suc(s
1234
1 ) | s
1234
? + s
1234
1 | s
1234
1 + s
1234
?
s12342
.
= v2 | suc(s
1234
2 ) | s
1234
? + s
1234
2 | s
1234
2 + s
1234
?
s1234?
.
= 0 | v1 | v2 | v3 | v4 | suc(s
1234
? ) | s
1234
? + s
1234
?
Fig. 37. Example: Variable Filter Sort
6.3 Selection of Ground Instances
As shown in Sect. 6.1, our lemma–generation algorithm needs some ground instances as input.
Regarding their selection, we have the following requirements: Let ?v1, . . . , vn? be the variables
occurring in the given left–hand side term t. A ground instance is defined by an n-tuple ?t1, . . . , tn?,
viz. {v1 ? t1, . . . , vn ? tn} (t). Similarly, a matrix
G =
?
?
?
?
t11 . . . t1n
...
...
tm1 . . . tmn
?
?
?
?
defines m ground instances of t, viz. one for each row. We have the following requirements with
respect to G:
1. In each column there occur two terms starting with different function symbols.
2. No two columns are identical.
39
3. In each column at least one “non–trivial” value occurs (e.g. 6? {0, 1}, 6? {[ ], [a]}).
4. There are not too many rows.
5. No two rows are identical.
6. The tij are not too large values.
Requirements 1. and 2. ensure that the syntactical anti–unification of all m ground instances yields a
variant of t; 3. enhances the quality of results; 4. to 6. are designed to obtain small runtimes. Fig. 20
gives an impression of the size and number of ground instances that can currently be handled by our
implementation. Note that by reimplementing in C and using up–to–date hardware, the runtimes
could be improved by about one order of magnitude.
By “quality of results” we mean – informally – the ratio of “desired” terms to overall enumerated
terms, weighted somehow by order of appearance. In other words, the earlier a desired term appears,
the higher the quality; and the more desired terms appear, the higher the quality. Which terms are
considered to be “desired” depends on the application; e.g. in lemma generation, tr is desired if the
equation tl = tr is universally valid. Since, in general, infinitely many terms are contained in the
result sort, a formal measure of quality can be defined e.g. by the expression q :=
??
i=1 di · ?
i, where
di = 1 if the i-th enumerated term belongs to the desired terms, di = 0 else, and 0 < ? < 1 is some
real number. We then always have 0 6 q 6 ?1?? .
Currently, the example ground instances still have to be provided manually. When automating this
process, Requirements 1., 2., and 5. are easy to satisfy as they are precisely defined. Requirement 3.
would call for special knowledge about the equational theory which is not generally available. We
propose dropping this requirement which is vague anyway, and enhancing the results’ quality by
adding more instances (i.e. rows), maintaining, however, a balance wrt. the contradicting Require-
ment 4. On a similarly informal level, Requirement 3. usually contradicts Requirement 6., since, for
example, the smallest terms are the nullary function symbols which mostly exhibit special behavior
wrt. equationally defined functions like +, ?, app and others.
The more the algorithms speeds can be improved, the less critical the selection of appropriate ground
examples becomes.
6.4 Results and Runtimes
Figure 38 shows some generated lemmas together with the required runtimes — cf. also Sect. 3.6.
The column “T” shows the background equational theory — cf. Fig. 3. The left–hand side of the
equation in the column “Law” was input to the algorithm; the right–hand side was generated; note,
for example, the difference between lines 23 and 24. Column “Rhs” indicates the normal forms
of the left–hand side’s ground instances. This is considered a measure of the size of the input
sorts to be anti–unified. In lines 12 to 24, ? stands for the empty list [ ], while ab, for example,
stands for the list [a, b]. Column “Nr” indicates the number of terms from the result sort that were
enumerated before the desired right–hand side appeared. Columns “A”, “I”, and “E” show the
runtime for anti–unification, intersecting with left–hand side’s variables sort (left empty if rsgV is
used), and enumeration, respectively. Column “?” shows the total runtime. Since the time resolution
was 5 seconds, shorter runtimes appear as “0”. The rightmost column indicates which technical
optimizations have been switched on — cf. Fig. 15.
As an example, in line 1, the algorithm was provided with the following instances of the left–hand–
side term v1 + (v2 + v3):
1 + (0 + 0) = 1,
0 + (1 + 0) = 1,
2 + (0 + 1) = 3.
40
It thus had to anti–unify the equivalence classes of suc(0), suc(0), and suc(suc(suc(0))) wrt. the
given background theory consisting of the four equations defining + and ?. Anti–Unification took 35
seconds; intersecting the sort of all E–generalizations with the sort of all terms in variables v1, v2, v3
took another 55 seconds, and enumerating the result sort took 10 seconds until the desired right
hand side v1 + (v2 + v3) appeared.
As can be seen from a comparison of lines 7 and 8, for example, there is a trade–off effect between
runtime and the quality of the result which can be controlled by the number and size of input sorts.
T Law Rhs Nr A I E ?
1 1 v1 + v2 + v3 = v1 + (v2 + v3) 1,1,3 6. 35 55 10 100 g
2 1 v1 + v2 + v3 = v1 + (v2 + v3) 1,1,3 6. 40 10 50 v
3 1 v1 ? (v2 + v3) = v1 ? v2 + v1 ? v3 0,2,2 10. 20 30 30 80 g
4 1 v1 ? (v2 + v3) = v1 ? v2 + v1 ? v3 0,2,2 10. 30 10 40 v
5 1 v1 ? v1 + v1 ? v2 + v1 ? v2 + v2 ? v2 = (v1 + v2) ? (v1 + v2) 4,1,4 4. 285 25 70 380 g
6 1 v1 ? v1 + v1 ? v2 + v1 ? v2 + v2 ? v2 = (v1 + v2) ? (v1 + v2) 4,1,4 4. 180 20 200 v
7 1 v1 ? v2 = v2 ? v1 0,0 3. 0 0 0 0 g
8 1 v1 ? v2 ? v3 = v1 ? (v2 ? v3) 0,0,2 31. 10 5 20 35 g
9 2 dup(v1) + dup(v2) = dup(v1 + v2) 2,4 2. 5 20 5 30 g
10 2 dup(v1) = v1 + v1 0,4 4. 0 5 0 5 g
11 2 v1 ? dup(v2) = dup(v1 ? v2) 0,0 13. 0 0 5 5 g
12 3 app(rev(v1), rev(v2)) = rev(app(v2, v1)) ba,cd,cb 1. 185 5 230 420 g
13 3 app(rev(v1), rev(v2)) = rev(app(v2, v1)) ba,cd,cb 1. 90 0 90 v
14 3 app(rev(v1), rev(v2)) = rev(app(v2, v1)) ?,bac,dcb 1. 110 5 150 265 g
15 3 app(rev(v1), rev(v2)) = rev(app(v2, v1)) ?,bac,dcb 1. 70 0 70 v
16 3 app(v1, app(v2, v3)) = app(app(v1, v2), v3) ab,cd,bd 3. 185 5 260 450 g
17 3 app(v1, app(v2, v3)) = app(app(v1, v2), v3) ab,cd,bd 3. 115 5 120 v
18 3 app(v1, app(v2, v3)) = app(app(v1, v2), v3) ab,cd,bd 3. ? ? 10 gstv
19 3 app(v1, app(v2, v3)) = app(app(v1, v2), v3) abc,bde,cb 3. 855 15 870 v
20 3 app(v1, app(v2, v3)) = app(app(v1, v2), v3) abc,bde,cb 3. 240 10 250 stv
21 3 app(v1, app(v2, v3)) = app(app(v1, v2), v3) abc,bde,cb 1. 50 15 65 gs v
22 3 app(v1, app(v2, v3)) = app(app(v1, v2), v3) abc,bde,cb 1. 20 10 30 gstv
23 3 v1 = rev(rev(v1)) ?,ab 4. 0 0 5 5 g
24 3 rev(rev(v1)) = v1 ?,ab 1. 0 0 5 5 g
25 4 len(app(v1, v2)) = len(v1) + len(v2) 1,2 4. 5 10 5 20 g
26 4 len(v1.app(v2, v3)) = suc(len(v2) + len(v3)) 2,3 10. 40 5 55 100 g
Fig. 38. Lemma–Generation Runtimes
41
7 Series Guessing
7.1 Implementation
A second application of E–anti–unification is the computation of possible continuations of term se-
quences, wellknown from intelligence tests. In this section, we discuss a corresponding algorithm.
Given a list of terms [tn, . . . , t1] and an example count k 6 n, the algorithm described below gener-
ates the sort sr of all its possible formation laws wrt. a given equational background theory. Each
formation–law term t? ? sr computes each list member beyond n ? k from its predecessors, using
only functions of the equational background theory. Note that for technical reasons we reverse the
usual list order, i.e. to compute formation laws of the quadratic numbers 0, 1, 4, 9, . . ., we start with
the list [suc9(0), suc4(0), suc(0), 0].
We proceed in a similar way to lemma generation (cf. Sect. 6.1). First, we select the k suffixes of
length n ? k, . . . , n ? 1 and annotate each one with its length plus one, i.e. with the rank of the
respective successor term within the series. We then syntactically anti–unify these length–annotated
suffixes:
[ sucn?k+1(0), tn?k, . . . , t1 ]
? . . .?
[ sucn(0), tn?1, . . . , tk, tk?1, . . . , t1 ]
tl = [ sucn?k+1(v0...k?1), t
?
n?k...n?1, . . . , t
?
1...k, t
?? ]
where t?i...j = ti ? . . . ? tj , and t
?? = [ ] ? [t1] ? . . . ? [tk?1, . . . , t1]. We compute the sort of
all E–anti–unifiers sr := rsgV (vars(t
l), [tn?k+1, . . . , tn]). Each t
r ?  L(sr) can be interpreted as
a series–formation law: applying the term–rewriting rule tl  tr to a length–annotated suffix
[suci(0), ti, . . . , t1] will result in the next series element ti+1, for n ? k 6 i < n. As in Sect. 6.1,
using rsgV ensures that vars(t
r) ? vars(tl). By intersecting sr with sNF , we can additionally
restrict it to terms in normal form. Fig. 39 gives an example for n = 4 and k = 3.
Note that tl is not usually a list of variables, but it contains function symbols. Consequently,
the terms from sr are more complicated than is intuitively expected; e.g. in the example in
Fig. 39, the result term considered is suc(v1) ? suc(v1), whereas the usual way would be to give
the series–construction law as v ? v. Alternatively, one might provide the rsgV call directly with
V = {?(sucn?k+1(0), ..., sucn(0)), ?(tn?k, ..., tn?1), . . . , ?(t1, ..., tk), ?([ ], ..., [tk?1, ..., t1])}, thus in-
tentionally over–generalizing. This might require some changes in the grouping algorithm from
Sect. 3.5. Moreover, Lemma 14 is no longer valid.
7.2 Results and Runtimes
Figure 40 shows some series laws that have been guessed together with the required runtime. Columns
“T”, “Nr”, “A”, “E”, “?” and the rightmost one are as in Fig. 38. The column “Series” shows the
series given to the algorithm; the column “L” shows the number k of example suffixes, i.e. the number
of anti–unified input sorts. The column “Law” shows the law that is expected to be generated; v1
denotes the previous member of series, v2 the pre–previous, and so on; m denotes the rank within
the series. Using the notions from Sect. 7.2, we have v1 = t
?
n?k...n?1, v2 = t
?
n?k?1...n?2, . . . , and
m = sucn?k+1(v0...k?1). Columns “D” and “N” show the runtimes for computing sort depths (cf.
Sect. 4), and for intersecting with the normal forms’ sort (cf. Sect. 6.2), respectively. In lines 1 to
9, the enumeration algorithm was restricted to output only terms in normal form. However, this
contradicted the technical optimization obtained by using sort depths (cf. Sect. 4). Therefore, in
lines 10 to 23, we explicitly intersected the sort of all generalizations with the sort of all normal
forms, dropping the normal–form restriction from the enumeration algorithm. The latter method
42
Given the series 0, 1, 4, 9, . . ., and k = 3
[ suc3(0), suc4(0), suc(0), 0] suc9(0) ? suc3(0) ? suc3(0)
[ suc2(0), suc(0), 0] suc4(0) ? suc2(0) ? suc2(0)
[ suc(0), 0 ] suc(0) ? suc(0) ? suc(0)
[ suc(v1), v2 | v3]  L(s1,4,9) ? suc(v1) ? suc(v1)
For example, we have suc(v1) ? suc(v1) ?  L(s1,4,9);
the corresponding rewrite rule is:
[ suc(v1), v2 | v3]  suc(v1) ? suc(v1)
This rule rewrites:
[ suc(0), 0 ]  suc(0)
[ suc2(0), suc(0), 0]  suc4(0)
[ suc3(0), suc4(0), suc(0), 0]  suc9(0)
[ suc4(0), suc9(0), suc4(0), suc(0), 0]  suc16(0)
. . .
Fig. 39. Example: Series Guessing
makes sort enumeration dead–end–free, and is thus faster for all but very small examples — cf. lines
9 and 10. An? in column “Nr” indicates that the desired law has not been enumerated among, say,
the first 100 terms. In this case, the column “?” shows a “>”.
Since tl is not usually a list of variables, but contains function symbols, m, v1, v2, . . . from Fig. 40 do,
in fact, stand for proper terms. For example, in line 23, we have v1 = suc
2(x), and the enumerated
law, viz. suc(x), has been abbreviated to p(v1), the predecessor of v1. The case is similar in line 21
— cf. also Fig. 42.
Some remarks on lines 13 to 16:
The desired solution if(ev(suc(m)), suc3(m), suc(0)) has the depth 5. Hence, all solutions
of depth 4 are enumerated before the desired one, the first being ev(x1) ? (x3 + x) +
if(if(x, x2, x1), suc(x3), ev(x)), which is, in fact, considered a “correct” solution — see Fig. 41, where
each column corresponds to a subterm of the solution (the marked column corresponds to the whole
term), irrelevant numbers are printed in small type. The solution ev(x1) ? suc(x2) + suc(ev(x1))
is shorter and of the same depth, but not in normal form. The shortest solution seems to be
suc(ev(x1)? suc2(x2)), which is deeper and not in normal form. If the depth measure of the enumer-
ation algorithm is changed such that unfolding a sort definition is counted only if the head symbol
of the right–hand side is not in {0, s}, the desired solution is of depth 2 and is thus enumerated first.
Some remarks on line 18:
While the function ev(·) allows one to distinguish series members with even and odd rank, no function
is available in background theory (5) to distinguish ranks 0, 1, and 2 mod. 3. For this reason, the series
in line 18 was expected by the authors to have no solution at all when given to the algorithm. Note
that the trivial solution v3 was prevented by setting L = 4, thus forcing the algorithm to compute
the first 1 from the two preceding 0’s. However, the algorithm found the solution ev(v1 + v2), which
is “correct”. This seems to indicate a possible strength of the algorithm: building series laws from a
well–defined limited set of functions rather than predicting the next series member(s).
Figure 42 gives some enumerated series laws. The column “T” indicates the background theory used.
In the column “Series”, the semicolon indicates the number of example suffixes: one for each series
member to the right of the semicolon. Column “D” shows the depth up to which the shown laws
appeared. An “?” means that the result sort is finite and is given completely in the column “Laws”;
43
T Series Law L Nr A D N E ?
1 1 0, 1, 4 m ?m 3? 1. 0 0 0 gstv
2 1 0, 1, 4 m ?m 3 1. 0 0 0 0 dgs v
3 1 0, 2, 4, 6 suc(suc(v1)) 3? 1. 15 20 35 gstv
4 1 0, 2, 4, 6 suc(suc(v1)) 3 1. 35 85 0 120 dgs v
5 1 0, 2, 4, 6 m + m 3? 3. 15 405 420 gstv
6 1 0, 2, 4, 6 m + m 3 3. 35 85 0 120 dgs v
7 1 1, 1, 2, 3, 5 v1 + v2. 3? 1. 10 225 235 gstv
8 1 1, 1, 2, 3, 5 v1 + v2 3 1. 15 15 0 30 dgs v
9 5 1, 1, 2, 3, 5 v1 + v2 3 45 10 ? ? dgs v
10 5 1, 1, 2, 3, 5 v1 + v2 3 1. 45 15 150 0 210 dgs v
11 5 1, 1, 2, 3, 5 v1 + v2 3 1. 45 5 100 0 150 bdgs v
12 5 1, 1, 2, 3, 5 v1 + v2 4 ? 200 55 610 – >865 bdgs v
13 5 0, 1, 2, 1, 4, 1, 6 if(ev(m),m, 1) 3 ? 60 20 190 >270 dgs v
14 5 0, 1, 2, 1, 4, 1, 6 if(ev(m),m, 1) 4 ? 255 285 160 >745 dgs v
15 5 0, 1, 2, 1, 4, 1, 6 if(ev(m),m, 1) 4 ? 200 50 100 >350 bdgs v
16 5 0, 1, 2, 1, 4, 1 if(ev(m),m, 1) 4 13. 125 25 170 0 320 bdgs v
17 5 0, 0, 1, 1, 0, 0, 1, 1 ev(v2) 5 1. 500 155 1500 0 2155 dgs v
18 5 0, 0, 1, 0, 0, 1 ev(v1 + v2) 4 1. 75 15 210 0 300 dgs v
19 5 0, 1, 3, 7 suc(v1 + v1) 3 1. 30 5 95 0 130 dgs v
20 5 1, 2, 2, 3, 3, 3, 4, 4, 4, 4 – 3 ? 60 20 205 – >285 dgs v
21 5 2, 3, 5, 9 p(v1 + v1) 3 1. 145 55 525 0 725 dgs v
22 5 1, 2, 3, 4, 5, 6 suc(m) 3 1. 125 40 425 0 590 dgs v
23 5 6, 5, 4, 3, 2, 1 p(v1) 3 1. 15 0 40 0 55 dgs v
Fig. 40. Series–Guessing Runtimes
We have
m = suc3(x)
v1 = suc(x1)
v2 = suc(x2)
v3 = x3
cf. line 16
in Fig. 42
+
? if
ev + (if s ev )
(x1) (x3 x) (x, x2 , x1), (x3), (x)
0 1 0 0 0 0 1 1 1 0 0 1 1 0 1 0
1 0 2 1 2 1 4 2 1 1 1 0 2 1 0 1
0 3 0 2 4 2 1 1 0 2 0 3 3 2 1 2
1 0 4 1 4 3 6 2 3 3 3 0 2 1 0 3
0 5 0 4 8 4 1 1 0 4 0 5 5 4 1 4
1 0 6 1 6 5 8 2 5 5 5 0 2 1 0 5
0 7 0 6 12 6 1 1 0 6 0 7 7 6 1 6
1 0 8 1 8 7 10 2 7 7 7 0 2 1 0 7
Fig. 41. Simplest Series Law for 0, 1, 2, 1, 4, 1, 6, . . .
44
T Series D m:v1,v2,. . . Laws
1 1 ;0,1,4 ? x1: x1 ? x1
2 1 1,2,3;4,5,6 ? suc3(x1):suc
3(x1), . . . suc
4(x1)
3 1 0;2,4,6 ? suc(x1):x2 suc
2(x2) suc
2(x1 + x1)
4 1 0,1,2,1;4,1,6 ? suc4(x1):suc(x2) . . .
5 1 1,1;2,3,5 2 suc2(x1):suc(x1), suc(x2) suc
2(x2 + x1) suc
2(x2 ? x2 + x1)
6 1 1,1,2;3,5,8 2 suc3(x1):suc
2(x2), suc(x1), suc(x3) suc
3(x3+(x1+x1)) suc
3(x2 + x1)
7 1 0;1,3,7 5 suc(x1):x2 suc(x1 + x1 ? x1) suc(x2 + x2)
8 1 2,3;5,9 2 suc2(x1):suc
3(x2), suc
2(x1) suc
5(x2 ? x2) suc
5(x2 + x2)
9 6 0;1,4 4 suc(x1):x1 suc(x1 + x1 + x1) x1+x1+x1+(suc(x1)?x1)
10 7 ;0,1,4 5 x1:x2 x1 ? x1 3 ? x
3
1 ? x
2
1 ? x
4
1
11 7 0,0,1;0,0,1 3 suc3(x1):x2, x3, x4 x4 (x4 + x3) ? (x4 ? x2)
12 5 ;0,1,4 3 x1: x1 ? x1 x1 ? if(x1, x1, 0)
13 5 1,1;2,3,5 4 suc2(x1):suc(x1), suc(x2) suc(suc(x1 + x2)) suc(if(x1, x1+x1, suc(0)))
14 5 0,0,1,1;0,0,1,1 3 suc4(x1):x2, x3, x4, x5 x5 ev(x3)
15 5 0,0;1,0,0,1 3 suc2(x1):x2, x3 ev(x2 + x3) ev(if(x2, x1, x3))
16 5 0,1,2,1;4,1,6 4 suc4(x1):suc(x2), suc(x3), suc(x4), x1 (ev(x1) + if(x1, x4, x3)) ? (ev(x1) + (x3 + x1))
17 8 abc;bca,cab ? suc(x1):[x2, x3, x4] [x4, x2, x3]
18 8 abab,aba;ab,a ? suc2(x1):[a, b|x2], [a, b, a|x3]
19 8 baba,aba;ba,a 2 suc2(x1):[x2, x3|x4], . . . il([x3], x4) [x3|rev(x4)]
20 8 a,ba;aba,baba 2 suc2(x1):[x2, x3|x4], [x3|x4] [x3, x2, x3|x4] il([x3,x3], app(x4,[x2]))
Fig. 42. Some Enumerated Series Laws
in all other cases, an arbitrary selection of the enumerated laws is shown. The column “m : v1, v2, . . .”
shows the result of syntactical anti–unification of examples.
Note that in lines 1 to 4, and 17 to 18, the result sort is finite, and precise statements can be made
about the series and their possible continuations. For example, from line 3 we can conclude that
there are only two ways to build the series 0, 2, 4, 6 from functions + and ?. From line 4 we can
conclude that there is no way to build 0, 1, 2, 1, 4, 1, 6 from these functions.
45
8 Other Potential Applications
In this section, we look at some other potential applications of E–anti–unification which we have
considered but not implemented.
8.1 Divergence Handling in Knuth–Bendix Completion
The Knuth–Bendix completion procedure is an important tool in equational reasoning. However,
its applicability is limited by the possibility of its generating an infinite sequence of term–rewriting
rules. Kirchner [Kir87,Kir89] proposes schematizing such a sequence using meta variables; Aven-
haus [Ave89] proposes consistently introducing new function symbols and new equations to achieve
termination of the Knuth–Bendix completion.
In any approach, it is necessary to recognize schemata in rule or term sequences. Kirchner proposes
using generalization modulo an equivalence relation to find useful schemata candidates, but has
not developed any approaches to anti–unification modulo equational theories. Nevertheless, useful
equational candidates could be suggested by using the mechanisms for anti–unification presented in
this paper.
Below, we sketch a possible approach for finding useful schemas using Exm. 2.1 from [Kir89]. Consider
the rewrite rules shown in Fig. 43 axiomatizing the “signed binary tree theory”. From these rules,
the completion procedure generates two infinite families of rules shown in Fig. 44. The rightmost
column shows the origin of each rule. For example, Rule 5 arose from superimposing Rule 4 at
position 1 on Rule 2 at the root, denoted by ?. Kirchner states in Example 2.3 that the first and
second family of rules can be schematized by the meta rule ?X,Y f(?X, f(X,Y ))  Y and
?X,Y f(f(Y,X),?X) Y , respectively, modulo the equational theory consisting of Rules 1 and 2
from Fig. 43.
1 ?? x  x
2 ?f(x, y)  f(?y,?x)
3 f(f(y, x),?x) y
4 f(?x, f(x, y)) y
Fig. 43. Input Rewrite Rules from Kirchner’s Example 2.1
We now focus on the first family and discuss the problems that arise when we try to reduce the
detection of the first meta rule to a series–guessing task like the ones described in Sect. 7.1.
Finding appropriate subsequences. A fair completion strategy will not produce the rules in the order
shown in Fig. 44; rather, it will produce a sequence of rules interleaving both rule families. Thus we
are left with the task of detecting subsequences that may obey common schemes. To achieve this,
we propose applying the series–guessing algorithm for the empty equational theory to the origin
information.
Each rule generated by the completion process can be assigned an “origin term” constructed from
the numbers of the input rules as constants and a 4–ary operator o (for “overlay”). For example,
Rules 4, 5, 9, and 10 from Figs. 43 and 44 are represented by the origin terms 4, o(4, ?.1, 2, ?),
o(o(4, ?.1, 2, ?), ?.1.1, 2, ?), and o(o(o(4, ?.1, 2, ?), ?.1.1, 2, ?), ?.1.1.1, 2, ?), respectively. Note that the
path concatenation operator “.” associates to the left. Applying the series–guessing algorithm to
this term sequence, and setting, say, the example count k = 2, we obtain one single law, viz.
[suc(suc(v1)), o(v2, v3.1, 2, ?), v2|v4] o(o(v2, v3.1, 2, ?), v3.1.1, 2, ?). If, by way of a negative example,
46
5 f(f(?x2,?x1), f(f(x1, x2), y))  y o(4, ?.1, 2, ?)
6 f(f(?x2, x1), f(f(?x1, x2), y))  y o(5, ?.1.2, 1, ?)
7 f(f(x2,?x1), f(f(x1,?x2), y))  y o(5, ?.1.1, 1, ?)
8 f(f(x2, x1), f(f(?x1,?x2), y))  y o(6, ?.1.1, 1, ?) or o(7, ?.1.2, 1, ?)
9 f(f(f(?x3,?x2),?x1), f(f(x1, f(x2, x3)), y))  y o(5, ?.1.1, 2, ?)
. . .
10 f(f(f(f(?x4,?x3),?x2),?x1), f(f(x1, f(x2, f(x3, x4))), y))  y o(9, ?.1.1.1, 2, ?)
. . .
11 f(f(y, f(x1, x2)), f(?x2,?x1))  y o(3, ?.1.2, 2, ?)
12 f(f(y, f(?x1, x2)), f(?x2, x1))  y o(11, ?.1.2.1, 1, ?)
13 f(f(y, f(x1,?x2)), f(x2,?x1))  y o(11, ?.1.2.2, 1, ?)
14 f(f(y, f(?x1,?x2)), f(x2, x1))  y o(12, ?.1.2.2, 1, ?) or o(13, . . . , 1, ?)
15 f(f(y, f(x1, f(x2, x3))), f(f(?x3,?x2),?x1))  y o(11, ?.1.2.2, 2, ?)
. . .
Fig. 44. Completion of the Theory from Fig. 43
we apply the series–guessing algorithm to Rules 4, 5, 11, 15, we get no law at all, thus indicating
that this sequence does not belong to a rule family.
Since series guessing wrt. the empty theory is quite fast, one might check all possible ascending
rule sequences whether their origin terms reveal a common law or not. Some optimization may be
achieved using the fact that a sequence has no law if any of its prefixes has no law. Moreover, efficient
data structures like substitution tree indexes [Gra94] might help to find all rule subsequences that
have a law.
Applying series guessing to a selected rule subsequence. Once we have selected one or more rule
sequences as described above, we may apply the series–guessing algorithm to the rules. Each series
law thus obtained will correspond to a meta rule that generalizes all rules of the subsequence modulo
the chosen equational background theory. For example, in a first attempt, we applied series guessing
to the rules shown in Fig. 45, however without success. Figure 46 documents a successful attempt
at series guessing for both k = 2 and k = 3, taking 17 and 28 seconds user time, respectively.
Dealing with variable names. Since the E–anti–unification approach presented here is based on
regular tree grammars, we treated variables as constants. This is no longer sufficient for the present
completion example: if the variables are named as in Figs. 43 and 44, the syntactical anti–unification
of length–annotated suffixes will yield the variables shown in Fig. 45. Note that x4 does not occur in
any argument of ?; in particular, a variable v = ?(?x3, f(?x4,?x3)) is missing. This is the reason
for the non–existence of a series law in Fig. 45. If we number the variables x1 to x4 in reverse order,
we have a similar problem, since then ?(x3, x4) is missing.
In a second attempt, we tried to circumvent this problem by modeling variables as functions of
natural numbers, i.e. x(i) for xi, where i denotes suc
i(0) for the sake of brevity. The rule sequence
and the corresponding ? is shown in Fig. 46. Note that we also had to reverse the numbering of
variables, since otherwise ?(x(3), f(x(3), x(4))) would again be missing.
What is needed, though, is an approach to E–anti–unification that is able to deal with variables
rather than just constants.
Setting up the equational background theory’s tree grammar. The main problem here consists in
determining an appropriate equational background theory in the first place. In the above example,
47
Input Series:
[ f( f( f( f(?x4,?x3) ,?x2), ?x1) , f( f( x1, f(x2, f(x3, x4))) , y)) y ,
f( f( f( ?x3 ,?x2), ?x1) , f( f( x1, f(x2, x3)) , y)) y ,
f( f( ?x2, ?x1) , f( f( x1, x2) , y)) y ,
f( ?x1 , f( x1 , y)) y ]
Variables (k = 2):
v1 = ?(0, suc(0))
v2 = ?(?x2, f(?x3,?x2))
v3 = ?(x2, f(x2, x3))
v4 = ?(?x1, f(?x2,?x1))
v5 = ?(x1, (fx1, x2))
v6 = ?([ ], [f(?x1, f(x1, y)) y])
No laws found (k = 2, k = 3)
Fig. 45. Series–Guessing Approach (A) Applied to the Rule Sequence 4, 5, 9, 10
Input Series:
[ f( f( f( f(?x(1),?x(2)) ,?x(3)), ?x(4)) , f( f( x(4), f(x(3), f(x(2), x(1)))) , y))  y ,
f( f( f( ?x(2) ,?x(3)), ?x(4)) , f( f( x(4), f(x(3), x(2))) , y))  y ,
f( f( ?x(3), ?x(4)) , f( f( x(4), x(3)) , y))  y ,
f( ?x(4) , f( x(4) , y))  y ]
Variables (k = 2): Variables (k = 3):
v1 = ?(0, 1)
v2 = ?(?x(1), f(?x(1),?x(2)))
v3 = ?(x(1), f(x(2), x(1)))
v4 = ?([ ], [. . .])
v1 = ?(0, 1, 2)
v2 = ?(?x(1), f(?x(1),?x(2)), f(f(?x(1),?x(2)),?x(3)))
v3 = ?(x(1), f(x(2), x(1)), f(x(3), f(x(2), x(1))))
v4 = ?([ ], [. . .], [. . .])
Laws found (k = 2):
f(f(f(v2,?x(suc
2(v1))),?x(suc
3(v1))), f(f(x(suc
3(v1)), f(x(suc
2(v1)), v3)), y))  y
f(f(f(v2,?x(suc
2(v1))),?x(suc
3(v1))), f(f(x(suc
3(v1)), f(x(suc
2(v1)),?v2)), y))  y
f(f(f(?v3,?x(suc
2(v1))),?x(suc
3(v1))), f(f(x(suc
3(v1)), f(x(suc
2(v1)), v3)), y))  y
f(f(f(?v3,?x(suc
2(v1))),?x(suc
3(v1))), f(f(x(suc
3(v1)), f(x(suc
2(v1)),?v2)), y))  y
Laws found (k = 3):
f(f(v2,?x(suc
2(v1))), f(f(x(suc
2(v1)), v3), y))  y
f(f(v2,?x(suc
2(v1))), f(f(x(suc
2(v1)),?v2), y)) y
f(f(?v3,?x(suc
2(v1))), f(f(x(suc
2(v1)), v3), y))  y
f(f(?v3,?x(suc
2(v1))), f(f(x(suc
2(v1)),?v2), y)) y
Fig. 46. Series–Guessing Approach (B) Applied to the Rule Sequence 4, 5, 9, 10
48
X  Y
.
= X  Y
f(X,Y )
.
= f(X,Y ) | ? ? f(X, Y ) | ?f(?Y ,?X)
?f(X,Y )
.
= f(?Y,?X)
??X
.
= X
?X
.
= ?X | ? ? ?X
X
.
= X | ? ?X
Fig. 47. Tree–Grammar Scheme for Equivalence Classes in Kirchner’s Example 2.1
we simply took the theory given in [Kir89], consisting of Rules 1 and 2 from Fig. 43. In general,
though, it is not at all clear which background theory is appropriate. In Kirchner’s examples, it is
always taken from the input rules. In many other examples, it simply defines the repeated application
of certain functions; e.g., for the completion example3 in Fig. 48, it is sufficient to define bi(x) by
b0(x) = x and bs(i)(x) = b(bi(x)), and to define di(x) similarly. This is a special case of ? terms which
have been investigated to deal with infinite sets of terms occurring in Knuth–Bendix completion or
elsewhere [Com95]. It seems to be a good default measure to use a theory of appropriate ? terms as
the equational background theory.
Once the background theory itself is fixed, the next problem is how to find an appropriate regular
tree grammar for the equivalence classes modulo this theory. In the above example, this was the most
time–consuming and error–prone task. Figure 47 shows the tree–grammar scheme (cf. Sect. 9) we
eventually came up with; the rules are priorized PROLOG facts. Note that the approach of [Emm94]
mentioned in Sect. 3.1 is not applicable, since it requires a confluent and noetherian term–rewriting
system, which is precisely what the completion process itself is about to build. Except for the cases
where the background theory is based on ? terms, a satisfactory approach to automatically obtaining
a tree grammar for the equivalence classes has yet to be found.
Considering equations in anti–unifying length–annotated suffixes. A closer look at the above com-
pletion example reveals a flaw in our approach to series guessing as presented in Sect. 7.1. Consider
the variables v2 and v3 in Fig. 46. Their pre–images under ? are inverse to each other modulo the
background equational theory. Hence, it was desirable to establish the relation v2 = ?v3, and to
delete v3 from the set V of variables that may appear in a series law, thus avoiding certain redundant
series laws. In fact, the set of enumerated laws for k = 2 collapses into the singleton set
{f(f(f(v2,?x(suc
2(v1))),?x(suc
3(v1))), f(f(x(suc
3(v1)), f(x(suc
2(v1)),?v2)), y)) y}
modulo the above relation; the case is similar for k = 3. The reason for the appearance of both v2
and v3 is that we did not consider the equational background theory when anti–unifying the length–
annotated suffixes. However, by simply E–anti–unifying them using the algorithm from Sect. 3.2 / 3.3,
we would still get both v2 and v3 in the variables set V .
8.2 Hoare Invariants
When verifying imperative programs, a still unresolved problem is how to generate loop invariants
automatically. We show below that E–anti–unification could be used for this purpose.
Consider the following imperative program:
3 This example was provided by Jo?rg Denzinger, University of Kaiserslautern.
49
Ordering LPO: c ? b ? a ? d ? f ? e
Input Equations:
1 a(c(x)) x
2 c(f(x)) e(x)
3 a(e(x)) f(x)
Completion:
4 c(d(x)) b(c(x))
5 a(b(c(x))) d(x)
6 a(b(e(x))) d(f(x))
7 a(b(b(c(x)))) d(d(x))
8 a(b(b(e(x)))) d(d(f(x)))
9 a(b(b(b(c(x))))) d(d(d(x)))
10 a(b(b(b(e(x))))) d(d(d(f(x))))
11 a(b(b(b(b(c(x)))))) d(d(d(d(x))))
12 a(b(b(b(b(e(x)))))) d(d(d(d(f(x)))))
13 a(b(b(b(b(b(c(x))))))) d(d(d(d(d(x)))))
14 a(b(b(b(b(b(e(x))))))) d(d(d(d(d(f(x))))))
15 a(b(b(b(b(b(b(c(x)))))))) d(d(d(d(d(d(x))))))
16 a(b(b(b(b(b(b(e(x)))))))) d(d(d(d(d(d(f(x)))))))
. . .
Fig. 48. Divergent Completion Schematizable using ? Terms
x := 0;
for i:=0 by 1 to n
do x:=x+2*i
done
By anti–unifying sample values of ?i, x? for a couple of iterations, e.g. ?0, 0?, ?1, 1?, ?2, 4?, ?3, 9?modulo
an appropriate theory (which should define at least + and *), we obtain the candidate x = i*i for
the loop invariant. Note that 0 <= i <= n cannot be obtained since it is not an equation.
8.3 Reengineering of Functional Programs
When programming software, it is often difficult to attain an adequate level of abstraction at the
first try. Consequently, one often has different procedures that do almost — but not quite — the
same thing. E–anti–unification could potentially help in reengineering such programs by computing
a most specific generalization.
By way of an example, consider a functional program where two almost identical procedures f1(·)
and f2(·) are defined:
f1(x) := F [ x + 1 ]
f2(x) := F [ 2 ? x ]
g(x) := G[ f1(x1) , f2(x2) ]
where F [·] denotes the possibly complex body expression common to both procedures; the third line
indicates calls to f1 and f2 in the body G[·] of another procedure g. Purely syntactic anti–unification
of the procedure bodies of f1 and f2 yields F [y], leading to the following reengineered program:
50
f(x, y) := F [ y ]
g(x) := G[ f(x1, x1 + 1) , f(x2, 2 ? x2) ]
Note that the calls to + and ? have been moved outward since they are considered to have nothing
in common. Using E–anti–unification modulo the theory of + and ?, we get a more specific gener-
alization of the bodies, viz. F [a ? x + b], leading to a better factorization of the commonalities of f1
and f2:
f(x, a, b) := F [ a ? x + b ]
g(x) := G[ f(x1, 1, 1) , f(x2, 2, 0) ]
In practice, the literally identical part F [·] of two procedure bodies will usually be small, or even non–
existent. It is thus of great importance to be able to deal with commonalities that are revealed only
by applying a background theory about programming language semantics. To the extent that this
theory is an equational one and admits regular equivalence classes, our E–anti–unification approach
can be employed to detect the commonalities.
8.4 Strengthening of Induction Hypotheses
It is well known that sometimes a formula F cannot be proven by induction, while a stronger
formula G such that G ? F is provable. The reason is that a stronger formula also provides a
stronger induction hypothesis. In inductive theorem proving, it is therefore a common technique to
strengthen F if its original proof attempt failed. This is usually done by replacing some constants or
terms by variables, or by decoupling different occurrences of the same variable; in other words, by
building anti–instances of F . The main problem is not to overgeneralize F such that it is no longer
valid.
There are several heuristics known from the literature, e.g. [BM79,Hum90,BvHSI90]. Manna and
Waldinger [MW80] propose using anti–unification, based on the data acquired during the failed
original proof attempt, to find the least strengthening of F that has a chance of being proven
inductively. However, they failed to notice that their example does in fact need anti–unification
modulo an equational theory.
Consider the equational theory and the induction proof attempt shown in Fig. 49. Manna and
Waldinger suggest anti–unifying the actual goal with the induction hypothesis if simple rewriting
with it does not lead to success. This way, overgeneralization could be avoided, since anti–unification
computes the most specific anti–instance of the induction hypothesis that is just general enough to
make it applicable. Backtracking to 9., we obtain by E–anti–unification with the induction hypoth-
esis:
rev a(t, [h]) = app(rev(t), [h]) 9.
rev a(l, [ ]) = rev(l) = app(rev(l), [ ]) I.H. (7.), and l = app(l, [ ])
rev a(t?, l?) = app(rev(t?), l?) strengthened I.H.
It is well known that the proof succeeds using the strengthened induction hypothesis.
In order to do the E–anti–unification shown above, we need to define equivalence classes of non–
ground terms as regular tree languages. In our example, we get the grammar scheme shown in
Fig. 50.
In the example, it is sufficient to syntactically anti–unify the left–hand sides, and to provide the
variable set {t?, l?} where t? = ?(t, l) and l? = ?([h], [ ]) to rsgV of the right–hand sides, viz.
rsgV ({t?, l?}, app(rev(t), [h]), rev(l)).
51
1. app([ ], l) = l
2. app([h | t], l) = [h | app(t, l)]
3. rev([ ]) = [ ]
4. rev([h | t]) = app(rev(t), [h])
5. rev a([ ], l) = l
6. rev a([h | t], l) = rev a(t, [h] | l)
Equations 1. to 4. are given as background theory, defining append and reverse;
equations 5. and 6. are the usual optimized version of reverse using an accumulator.
The goal is to show the correctness of rev a, i.e. to show
7. rev a(l, [ ]) = rev(l)
We try a proof by induction on l; l = [ ] is trivial;
in case l = [h | t], we get the following goal sequence:
8. rev a([h | t], [ ]) = rev([h | t])
9. rev a(t, [h]) = app(rev(t), [h]) by 6. and 4.
10. rev a(t, [h]) = app(rev a(t, [ ]), [h]) by I.H. (7.)
Fig. 49. Failed Induction–Proof Attempt
rev(A)
.
= rev(A) | app([ ], rev(A)) | app(rev(A), [ ])
app(A,B)
.
= app(A,B) | app(app(A,B), [ ]) | app([ ], app(A,B)) | rev(rev(app(A,B)))
A
.
= A | app([ ], A) | app(A, [ ]) | rev(rev(A)) if app(. . .) 6= A 6= rev(. . .)
Fig. 50. Equivalence Classes of Non–Ground Terms mod. append, reverse
The desired solution is the one enumerated first, and it is found in 1 second user time. We list all
enumerated terms at depth level 3, which is the minimum level of the result sort:
app(rev(t?), l?), app(rev(t?), rev(l?)), app(rev(t?), app(l?, [ ])), app(rev(t?), app([ ], l?)).
Note that the second term is not a correct solution, the reason being that instances of l?, viz. [h] and
[ ], are both “trivial” values in the sense of requirement 3. from Sect. 6.3, i.e. they satisfy rev(x) = x.
The third and fourth solution are correct, but not in normal form; they would have been filtered out
by a normal form filter.
9 Dynamic Sort Generation
For many background equational theories, some of the equivalence classes follow a common schema.
For example, consider Theory (3) from Fig. 3, defining append and reverse of lists. The equivalence
class of any list [A,B] can be defined by
[A,B]
.
= [A,B] | app([A,B], [ ]) | app([A], [B]) | app([ ], [A,B]) | rev([B,A]),
irrespective of the value of A and B. We thus get a schema of sort definitions abbreviating any of
its instances. This can be implemented in PROLOG by a corresponding fact containing A and B as
PROLOG variables.
52
(0
.
= 0 | 0 + 0).
(suc(N)
.
= suc(N) | Sums) ? all sums(0, N, Sums).
all sums(I, 0, I + 0).
all sums(I, suc(J), I + suc(J) | Sums)? all sums(suc(I), J, Sums).
Fig. 51. Sort Definition Scheme for Background Theory (0) from Fig. 3
Moreover, we may even use PROLOG rules to dynamically generate sort definitions as needed. For
example, the schema shown in Fig. 51 will generate the equivalence class of each natural number
modulo the theory of (+). The predicate all sums(I, J, Sums) computes a sort disjunction
Sums = I + J | I+1 + J?1 | . . . | I+J + 0.
Similarly, the theory of (+) and (?) has been schematized, requiring a predicate that computes all
factors of a given number.
10 Depth–Bounded E–Anti–Unification
In most applications of E–anti–unification, one is interested only in the first few enumerated terms,
which are the simplest wrt. the employed depth measure. In such cases, it may be sufficient to cut
off the rsgV algorithm each time it reaches a given depth, thus avoiding the computation of larger
solutions that will subsequently be ignored anyway. This way, even large terms can be E–anti–unified.
For example, consider the series 2, 4, 16, 256. The series–prediction algorithm from Sect. 7.1 with
example count k = 2 will call rsgV ({v1, v2, v3, v4}, s16, s256), where v1 = ?(16?4, 0), v2 = ?(4?2, 0),
v3 = ?([2], [ ]), and v4 = ?(4 ? 3, 0).
The first enumerated solution should be suc4(v1) ? suc4(v1), which has depth 5, or depth 1 if suc is
not counted. In any case, it is not necessary to descend to depth 256 to obtain this solution.
In this example, however, owing to the growing length of sort definitions caused by (+), the search–
tree breadth is too large to get reasonable runtimes, even for depth 2.
53
11 Equational Theories of Finite Algebras
In this section, we show that for each finite algebra we can always generate a closed representation
of all its quantifier–free and variable–bounded theorems.
We first give some sufficient criteria for an equational theory so that the equivalence classes are
regular tree languages (Sect. 11.1). We then show that the set T Hn(A) of formal equations in up
to n variables, which are universally valid over a given finite algebra A, is always a regular tree
language. This implies a constructive way of describing T Hn(A) by a finite term–rewriting system
(Sect. 11.3). By extending the approach to typed algebras and including a type Bool, we are able
to construct an axiom set describing the set of all quantifier–free and variable–bounded theorems
of a given finite algebra with arbitrary functions, predicates, and junctors. See Fig. 56 for an axiom
system that describes T H2(?(IN mod 3), (+), (<), (=), (?), (?)?).
11.1 Criteria for Regular Equivalence Classes
Lemma 15. (Sufficient Criterion for Regular Equivalence Classes)
If for each t ? N and each f ? F only finitely many ?t1, . . . , tn? ? Nn exist
such that f(t1, . . . , tn) =E t,
then the equivalence class t of each term t ? T can be represented as a regular sort.
Proof.
For each t ? N , we may define the sorts
t
.
= f?F ,t1,...,tn?N ,f(t1,...,tn)=Et sft1...tn and
sft1...tn
.
= f(t1, . . . , tn) for each t1, . . . , tn ? N .
We use the induction principle (Thm. 6 from Sect. 2) with
Pt(t
?) :? t? =E t and
Psft1...tn (t
?) :? t? =E f(t1, . . . , tn).
– Let t? = f(t?1, . . . , t
?
n) with t
?
i ? T , then
Pt(t
?)
? t? =E t Def. P
? f(t?1, . . . , t
?
n) =E t Def. t
?
? t? =E f(t1, . . . , tn) where ti := nf(t?i)
? Psft1 ...tn (t
?) for some f ? F , t1, . . . , tn ? N with f(t1, . . . , tn) =E t
conversely:
Psft1 ...tn (t
?) for some f(t1, . . . , tn) =E t
? t? =E f(t1, . . . , tn) =E t Def. P
? Pt(t?) Def. P
– Psft1 ...tn (t
?)
? t? =E f(t1, . . . , tn) Def. P
? ?t?1, . . . , t
?
n ? T t
? = f(t?1, . . . , t
?
n) ? t
?
1 =E t1 ? . . . ? t
?
n =E t1 (?)
? ?t?1, . . . , t
?
n ? T t
? = f(t?1, . . . , t
?
n) ? Pt1(t
?
1) ? . . . ? Ptn(t
?
n)
(?): “?”: choose t?i := ti
“?”: t? =E f(t?1, . . . , t
?
n) =E f(t1, . . . , tn)
Hence, the sort t contains all term that are equivalent mod. E to t.
54
Corollary 16. (Sufficient Criterion for Regular Equivalence Classes)
Let ? be a well–founded ordering on N with a finite branching degree, and let  be its reflexive
closure.
If ti  nf(f(t1, . . . , tn)) for all f ? F , t1, . . . , tn ? N and all i ? {1, . . . , n},
then t is representable as a regular sort for all t ? T .
Proof.
Under the above assumptions, we have for fixed t ? N and f ? F :
t1, . . . , tn ? N ? f(t1, . . . , tn) =E t? ti  nf(f(t1, . . . , tn)) = t, hence
{?t1, . . . , tn? ? N
n | f(t1, . . . , tn) =E t} ? {?t1, . . . , tn? ? N
n | t1  t, . . . , tn  t},
where the latter set is finite. The conclusion follows by Lemma 15.
Corollary 17.
If T /E is finite, each equivalence class can be represented as a regular tree language.
Proof. Trivially, N has as many elements as T /E . The conclusion follows by Lemma 15.
11.2 Equational Theories in One Variable
Definition 18.
Let (:) 6? F be a symbol of arity 2; we call a term of the form t1 : t2 a (formal) equation if
t1, t2 ? T . An equation t1 : t2 is called universally valid if ?t1 =E ?t2 for every substitution ?.
Define T Hn(T /E) as the set of all formal equations in up to n variables that are universally valid
over T /E .
Definition 19.
We will assume below that T /E is finite, and hence we have only a finite number N of normal forms.
Define B := {?b1, . . . , bN ? | ?t ? T ?i ? {1, . . . , N} t =E bi} the set of all N -tuples that represent all
N normal forms. Let b := ?b1, . . . , bN? denote the equivalence class of b. In this section, let x := ?(b)
for some b ? B, and let A := {a ? (T /E)N |  L(rsgV ({x},a)) 6= {}}.
Lemma 20. Let t1, t2 ? T with vars(t1) ? vars(t2) ? {x}. The equation t1 : t2 is universally valid
iff there exists an a ? A such that t1, t2 ?  L(rsgV ({x},a)).
Proof.
“?”:
Consider the ?i from Lemma 14 in Sect. 3.4. Define ai := ?it1; then t1 ?  L(rsgV ({x},a)) by Lemma
14; similarly, ?it2 =E ?it1 = ai for all i implies t2 ?  L(rsgV ({x},a)).
“?”:
Let t1, t2 ?  L(rsgV ({x},a)); consider an arbitrary substitution {x? t}. We have
{x? t} (t1)
=E {x? bi} (t1) since t =E bi for some i ? {1, . . . , N} by Def. 19
= ?it1 by Def. of ?i and since vars(t1) ? {x}
=E ai by Lemma 14 since t1 ?  L(rsgV ({x},a))
=E {x? t} (t2) similarly
Hence, the equation t1 : t2 is universally valid.
55
Theorem 21. If T /E is finite, the set of all universally valid equations in one variable x is a regular
tree language.
Proof. Let ? be such that ?(b) = x for some b ? B. By Cor. 17, ai is a regular tree language for each
a ? T . Define svalid
.
= a?A rsgV ({x},a) : rsgV ({x},a). Let t1, t2 ? T with vars(t1) ? vars(t2) ?
{x}. Then,
t1 : t2 is universally valid
? exists a ? T N such that t1, t2 ?  L(rsgV ({x},a)) by Lemma 20
? exists a ? A such that (t1 : t2) ?  L(rsgV ({x},a) : rsgV ({x},a))
? (t1 : t2) ?  L(svalid)
Example 22.
Consider (IN mod 2) with +. We have, letting v01 = ?(0, 1), and abbreviating s0 := 0, s1 := 1, and
sij := rsgV ({v01}, si, sj):
s0
.
= 0 | s0 + s0 | s1 + s1
s1
.
= 1 | s0 + s1 | s1 + s0
s00
.
= 0 | s00 + s00 | s01 + s01 | s10 + s10 | s11 + s11
s01
.
= v01 | s00 + s01 | s01 + s00 | s10 + s11 | s11 + s10
s10
.
= s00 + s10 | s01 + s11 | s10 + s00 | s11 + s01
s11
.
= 1 | s00 + s11 | s01 + s10 | s10 + s01 | s11 + s00
svalid
.
= s00 : s00 | s01 : s01 | s10 : s10 | s11 : s11
11.3 Equational Theories in n Variables
Theorem 21 can be generalized to n variables, which we will do in this section. The definitions given
below generalize Defs. 18 and 19 to n variables.
Definition 23. Modifying Def. 19, define
B :=
?
?
?
?
?
?
?
?
?
?
?
b1,1 . . . b1,Nn
...
...
bn,1 . . . bn,Nn
?
?
?
?
?t1, . . . , tn ? T ?j ? {1, . . . , N
n} ?i ? {1, . . . , n} bi,j =E ti
?
?
?
?
?
?
?
B is non–empty since (T /E)n is finite, viz. of cardinality Nn. Intuitively, for each matrix b ? B
there is a one–to–one correspondence between its column vectors and the elements of (T /E)
n.
In this section, let x1 := ?(b1,1, . . . , b1,Nn), . . . , xn := ?(bn,1, . . . , bn,Nn) for some b ? B, and let
V := {x1, . . . , xn}. Let A := {a ? (T /E)(N
n) |  L(rsgV ({x1, . . . , xn},a)) 6= {}}.
Lemma 24. Let t1, t2 ? T with vars(t1) ? vars(t2) ? V . The equation t1 : t2 is universally valid
iff there exists an a ? A such that t1, t2 ?  L(rsgV ({x1, . . . , xn},a)).
Proof.
“?”:
Consider the ?i from Lemma 14 in Sect. 3.4. Define ai := ?it1 for i = 1, . . . , N
n;
then t1 ?  L(rsgV ({x1, . . . , xn},a)) by Lemma 14;
similarly, ?it2 =E ?it1 = ai for all i implies t2 ?  L(rsgV ({x1, . . . , xn},a)).
56
“?”:
Let t1, t2 ?  L(rsgV ({x1, . . . , xn},a)); consider an arbitrary substitution {x1 ? t
?
1, . . . , xn ? t
?
n}. We
have
?jxi
= ?j?(bi,1, . . . , bi,Nn) Def. xi
= bi,j Def. ?j
= {x1 ? b1,j , . . . , xn ? bn,j} (xi)
By induction on t, it follows that ?jt = {x1 ? b1,j , . . . , xn ? bn,j} (t) for all t ? T with vars(t) ?
{x1, . . . , xn}. Thus:
{x1 ? t?1, . . . , xn ? t
?
n} (t1)
=E {x1 ? b1,j , . . . , xn ? bn,j} (t1) since ?j ? {1, . . . , Nn} ?i ? {1, . . . , n} bi,j =E t?i by Def. 23
= ?jt1 as shown above
=E aj by Lemma 14, since t1 ?  L(rsgV ({x1, . . . , xn},a))
=E {x1 ? t
?
1, . . . , xn ? t
?
n} (t2) similarly
Hence, the equation t1 : t2 is universally valid.
Theorem 25. If T /E is finite, the set T Hn(T /E) of all universally valid equations in n variables
is a regular tree language for each n.
Proof. Let ? be such that ?(b1,1, . . . , b1,Nn) = x1, . . . , ?(bn,1, . . . , bn,Nn) = xn for some
b ? B; let V := {x1, . . . , xn}. By Cor. 17, ai is a regular tree language for each a ? T .
Define svalid
.
= a?A rsgV ({x1, . . . , xn},a) : rsgV ({x1, . . . , xn},a). Let t1, t2 ? T with
vars(t1) ? vars(t2) ? V . Then
t1 : t2 universally valid
? exists a ? A such that t1, t2 ?  L(rsgV ({x1, . . . , xn},a)) by Lemma 24
? exists a ? A such that (t1 : t2) ?  L(rsgV ({x1, . . . , xn},a) : rsgV ({x1, . . . , xn},a))
? (t1 : t2) ?  L(svalid)
Example 26. Consider again (IN mod 2) with +. Let v0011 = ?(0, 0, 1, 1), v0101 = ?(0, 1, 0, 1),
V = {v0011, v0101}, and abbreviate s0 := 0, s1 := 1, and sijkl := rsgV ({v0011, v0101}, si, sj , sk, sl).
The sort definitions are shown in Fig. 52; the sorts s0001, s0010, s0100, s0111, s1000, s1011, s1101, and
s1110 are all empty and have been omitted in the definition of svalid. For example, the commutativity
law v0011 + v0101 : v0101 + v0011 is contained in  L(s0110 : s0110).
Corollary 27. If T /E is finite, for each finite V1 ? V2 ? V and V3 ? V4 ? V , the set of all
universally valid equations t1 : t2 such that V1 ? vars(t1) ? V2 and V3 ? vars(t2) ? V4 is a regular
tree language.
Proof. Apply Thm. 25 to V := V2 ? V4; using the variable filter sorts s
V2
V1
, sV4V3 from Sect. 6.2, define
sresult
.
= a?A (rsgV (V,a) ? s
V2
V1
) : (rsgV (V,a) ? s
V4
V3
).
Corollary 28. If T /E is finite and n ? IN arbitrary, the set T Hn(T /E) of universally valid
equations in n variables can be represented as the deductive closure of finitely many equations.
Proof. Using Thm. 25, T Hn(T /E) =  L(svalid) where svalid
.
= a?A rsgV (V,a) : rsgV (V,a), and
V = {x1, . . . , xn}. For each a ? A, choose some arbitrary normal form nfa ?  L(rsgV (V,a)).
57
s0000
.
= 0 | s0000 + s0000 | s0011 + s0011 | s0101 + s0101 | s0110 + s0110
| s1001 + s1001 | s1010 + s1010 | s1100 + s1100 | s1111 + s1111
s0011
.
= v0011 | s0000 + s0011 | s0011 + s0000 | s0101 + s0110 | s0110 + s0101
| s1001 + s1010 | s1010 + s1001 | s1100 + s1111 | s1111 + s1100
s0101
.
= v0101 | s0000 + s0101 | s0011 + s0110 | s0101 + s0000 | s0110 + s0011
| s1001 + s1100 | s1010 + s1111 | s1100 + s1001 | s1111 + s1010
s0110
.
= s0000 + s0110 | s0011 + s0101 | s0101 + s0011 | s0110 + s0000
| s1001 + s1111 | s1010 + s1100 | s1100 + s1010 | s1111 + s1001
s1001
.
= s0000 + s1001 | s0011 + s1010 | s0101 + s1100 | s0110 + s1111
| s1001 + s0000 | s1010 + s0011 | s1100 + s0101 | s1111 + s0110
s1010
.
= s0000 + s1010 | s0011 + s1001 | s0101 + s1111 | s0110 + s1100
| s1001 + s0011 | s1010 + s0000 | s1100 + s0110 | s1111 + s0101
s1100
.
= s0000 + s1100 | s0011 + s1111 | s0101 + s1001 | s0110 + s1010
| s1001 + s0101 | s1010 + s0110 | s1100 + s0000 | s1111 + s0011
s1111
.
= 1 | s0000 + s1111 | s0011 + s1100 | s0101 + s1010 | s0110 + s1001
| s1001 + s0110 | s1010 + s0101 | s1100 + s0011 | s1111 + s0000
svalid
.
= s0000 : s0000 | s0011 : s0011 | s0101 : s0101 | s0110 : s0110
| s1001 : s1001 | s1010 : s1010 | s1100 : s1100 | s1111 : s1111
Fig. 52. Sort Definitions in Exm. 26
sffff
.
= f | sffff ? sffff | sfttt ? sffff | stttt ? sffff | sffff ? sfttt | sffff ? stttt | sffff ? sffff
| sffff ? sffft | sffff ? sfftt | sffff ? sftft | sffft ? sffff | sfftt ? sffff | sftft ? sffff
sffft
.
= sffff ? sffft | sffft ? sffff | sffft ? sffft | sfttt ? sffft | stttt ? sffft | sffft ? sfttt | sffft ? stttt
| sffft ? sffft | sffft ? sfftt | sffft ? sftft | sfftt ? sffft | sfftt ? sftft | sftft ? sffft | sftft ? sfftt
sfftt
.
= vfftt | sffff ? sfftt | sffft ? sfftt | sfftt ? sffff | sfftt ? sffft | sfftt ? sfftt
| sfttt ? sfftt | stttt ? sfftt | sfftt ? sfttt | sfftt ? stttt | sfftt ? sfftt
sftft
.
= vftft | sffff ? sftft | sffft ? sftft | sftft ? sffff | sftft ? sffft | sftft ? sftft
| sfttt ? sftft | stttt ? sftft | sftft ? sfttt | sftft ? stttt | sftft ? sftft
sfttt
.
= sfttt ? sfttt | sfttt ? sffff | sfttt ? sffft | sfttt ? sfftt | sfttt ? sftft | sffff ? sfttt | sffft ? sfttt
| sfftt ? sfttt | sfftt ? sftft | sftft ? sfttt | sftft ? sfftt | sfttt ? sfttt | sfttt ? stttt | stttt ? sfttt
stttt
.
= t | sfttt ? stttt | stttt ? sfttt | stttt ? stttt | stttt ? sffff | stttt ? sffft | stttt ? sfftt
| stttt ? sftft | sffff ? stttt | sffft ? stttt | sfftt ? stttt | sftft ? stttt | stttt ? stttt
Fig. 53. Sort Definitions in Exm. 29
58
f ? x : f
y ? x : x ? y
x ? y ? y : x ? y
x ? y ? (x ? y) : x ? y
f ? x : x
x ? x : x
x ? (x ? y) : x
t ? x : x
x ? x : x
x ? (x ? y) : x
y ? x : x ? y
x ? y ? y : x ? y
x ? y ? (x ? y) : x ? y
t ? x : t
Fig. 54. Equational Theory of Bool with ? and ?
By Cor. 17 and Lemma 15, the sort definition of each ai is in head normal form and refers only to
sort names corresponding to some aj . Hence, by construction of rsgV , the sort definition of each
rsgV (V,a) is in head normal form and refers only to sort names corresponding to some rsgV (V,a
?).
For a ? A, let rsgV (V,a)
.
= mi=1 fi(rsgV (V,ai1), . . . , rsgV (V,aini)) for some fi, aij .
Define THa := {fi(nfai1 , . . . , nfaini ) : nfa | i = 1, . . . ,m}. Define TH :=
?
a?A THa.
Let t ?  L(rsgV (V,a)) for some a ? A; we show by induction on t that the equation t : nfa is a
deductive consequence of TH . Consider the alternative in the sort definition of rsgV (V,a) that leads
to t:
– If t = fi(t1, . . . , tni), where tj ?  L(rsgV (V,aij)), then by induction hypothesis the equations
tj : nfaij are deductive consequences of TH . Since (fi(nfai1 , . . . , nfaini ) : nfa) ? TH , we have
finished.
– If t = fi is a constant or a variable, we immediately have (fi : nfa) ? TH .
If we now take an arbitrary equation (t1 : t2) ?  L(svalid), then t1, t2 ?  L(rsgV (V,a)) for some a ? A;
the equation is a consequence of t1 : nfa and t2 : nfa.
Remark 1. Note that no proper instances of the equations in TH are needed to derive any equation
t1 : t2 in  L(svalid). Hence, if we consider all variables in V as constants and choose nfa to be
of minimal size within  L(rsgV (V,a)), we obtain a noetherian ground–rewriting system for the set
of all universally valid equations in variables from V . Moreover, this rewriting system assigns a
unique normal form to each term t that may occur in a universally valid equation, viz. nfa if
t ?  L(rsgV (V,a)).
Of course, when permitting proper instantiations, we lose these properties, since the commuta-
tivity law, for example, could be among the universally valid equations. On the other hand, we
may delete equations that are instances of others, thus reducing the number of equations signifi-
cantly. To find such subsumed equations, an appropriate indexing technique may be used, see e.g.
[Gra92,GM93,Gra94].
Example 29. Consider Bool = {f, t} with the operations ? and ?:
59
x+x : 0
x : x
0+x : x
x+0 : x
y+(x+y) : x
x+y+y : x
y+z+1+(y+z+(x+1)) : x
y+z+(x+1)+(y+z+1) : x
x+(x+y) : y
x+1+(x+(1+y)) : y
x+y+x : y
x+z+(y+z+x) : y
x+(1+y)+(x+1) : y
x+(1+z)+(y+z+(x+1)) : y
y+z+x+(x+z) : y
y+z+(x+1)+(x+(1+z)) : y
1+(x+(1+y)) : x+y
y+x : x+y
z+(y+z+x) : x+y
1+z+(y+z+(x+1)) : x+y
x+z+(y+z) : x+y
x+(1+y)+1 : x+y
x+(1+z)+(y+z+1) : x+y
y+z+(x+z) : x+y
y+z+1+(x+(1+z)) : x+y
y+z+x+z : x+y
y+z+(x+1)+(1+z) : x+y
x+y+(y+z+x) : z
x+(1+y)+(y+z+(x+1)) : z
y+z+x+(x+y) : z
y+z+(x+1)+(x+(1+y)) : z
y+(y+z+x) : x+z
1+y+(y+z+(x+1)) : x+z
x+y+(y+z) : x+z
x+(1+y)+(y+z+1) : x+z
y+z+(x+y) : x+z
y+z+1+(x+(1+y)) : x+z
y+z+x+y : x+z
y+z+(x+1)+(1+y) : x+z
x+y+(x+z) : y+z
x+z+(x+y) : y+z
x+(1+y)+(x+(1+z)) : y+z
x+(1+z)+(x+(1+y)) : y+z
1+(y+z+(x+1)) : y+z+x
y+(x+z) : y+z+x
z+(x+y) : y+z+x
1+y+(x+(1+z)) : y+z+x
1+z+(x+(1+y)) : y+z+x
x+y+z : y+z+x
x+z+y : y+z+x
x+(1+y)+(1+z) : y+z+x
x+(1+z)+(1+y) : y+z+x
y+z+(x+1)+1 : y+z+x
1+(y+z+x) : y+z+(x+1)
x+(y+z+1) : y+z+(x+1)
y+(x+(1+z)) : y+z+(x+1)
z+(x+(1+y)) : y+z+(x+1)
1+y+(x+z) : y+z+(x+1)
1+z+(x+y) : y+z+(x+1)
x+y+(1+z) : y+z+(x+1)
x+z+(1+y) : y+z+(x+1)
x+(1+y)+z : y+z+(x+1)
x+(1+z)+y : y+z+(x+1)
y+z+1+x : y+z+(x+1)
y+z+x+1 : y+z+(x+1)
x+(y+z+(x+1)) : y+z+1
x+y+(x+(1+z)) : y+z+1
x+z+(x+(1+y)) : y+z+1
x+(1+y)+(x+z) : y+z+1
x+(1+z)+(x+y) : y+z+1
y+z+(x+1)+x : y+z+1
1+(x+z) : x+(1+z)
y+(y+z+(x+1)) : x+(1+z)
z+(x+1) : x+(1+z)
1+y+(y+z+x) : x+(1+z)
x+1+z : x+(1+z)
x+y+(y+z+1) : x+(1+z)
x+z+1 : x+(1+z)
x+(1+y)+(y+z) : x+(1+z)
y+z+(x+(1+y)) : x+(1+z)
y+z+1+(x+y) : x+(1+z)
y+z+x+(1+y) : x+(1+z)
y+z+(x+1)+y : x+(1+z)
x+y+(y+z+(x+1)) : 1+z
x+(1+y)+(y+z+x) : 1+z
y+z+x+(x+(1+y)) : 1+z
y+z+(x+1)+(x+y) : 1+z
z+(y+z+(x+1)) : x+(1+y)
1+z+(y+z+x) : x+(1+y)
x+z+(y+z+1) : x+(1+y)
x+(1+z)+(y+z) : x+(1+y)
y+z+(x+(1+z)) : x+(1+y)
y+z+1+(x+z) : x+(1+y)
y+z+x+(1+z) : x+(1+y)
y+z+(x+1)+z : x+(1+y)
x+z+(y+z+(x+1)) : 1+y
x+(1+z)+(y+z+x) : 1+y
y+z+x+(x+(1+z)) : 1+y
y+z+(x+1)+(x+z) : 1+y
y+(x+(1+y)) : x+1
x+(1+y)+y : x+1
x+y+(x+(1+y)) : 1
x+(1+y)+(x+y) : 1
y+z+x+(y+z+(x+1)) : 1
y+z+(x+1)+(y+z+x) : 1
Fig. 55. Equational Theory of (IN mod 2) with +
60
? f t
f f f
t f t
? f t
f f t
t t t
Computing svalid for n = 2 variables, we obtain the six non–empty sorts shown in Fig. 53. Proceeding
as described in the proof of Cor. 28, we obtain 76 equations in TH ; 43 of them are instances of others
and can therefore be deleted. Of the remaining 33, a further 17 have been manually deleted since
they were subsumed modulo commutativity. The remaining equations are given in Fig. 54.
Example 30. Figure 55 shows an axiom system for the equational theory of (IN mod 2) with + in 3
variables. The 105 equations have been extracted from a system of 256 sort definitions 240 of which
where empty. Only equations that were syntactically subsumed have been removed (automatically).
Remark 2. In order to estimate the complexity of computing an axiomatization of a finite alge-
bra T /E, observe the following facts. Using an appropriate caching mechanism when computing
rsgV (V,a) for all a ? AT , we can ensure that rsgV is called exactly once for each such a. If
all sort definitions are in head normal form, the cost of one rsgV call without its recursive sub-
calls is precisely the cost of its grouping algorithm. In Sect. 3.5, we estimated the latter to be
Ø(N ? ·m? · (m? +n?) · g?N
?
), where N ? denotes the number of sorts to be anti–unified simultaneously,
m? is the maximal number of alternatives of a sort definition’s right–hand side, n? is the number
of variables in V , and g? is the maximum number of disjuncts of a sort–definition’s right–hand side
that start with the same function symbol. We have N ? = Nn and n? = n, leading to an overall
complexity of Ø((N · g?)(N
n) ·Nn ·m? · (m? +n)) for computing all N (N
n) rsgV calls. Transformation
of the sort definitions into an axiom system can be done in linear time.
11.4 Typed Equational Theories in n Variables
Theorem 25 and Corollaries 27 and 28 can be generalized to typed algebras where different variables
may have different – disjoint – domains. We will do this in this section. The definitions given below
generalize Def. 23 to n typed variables.
Definition 31.
Let T Y be a finite set of types. Assume each x ? V has a fixed type type(x) ? T Y such that for
each T ? T Y there are infinitely many x ? V with type(x) = T . Assume each f ? F has a fixed
signature f : T1 × . . .× Tn ? T where T1, . . . , Tn, T ? T Y.
For T ? T Y, let TT be the set of well–typed terms of type T , which is defined as usual. Let T :=
?
T?T Y TT ; for t ? T define type(t) := T if t ? TT ; type(t) is uniquely determined since any f has
only one signature. A substitution {x1 ? t1, . . . , xn ? tn} is called well–typed if type(xi) = type(ti)
for i = 1, . . . , n. Consequently, we always have type(?t) = type(t) for well–typed ?, t.
We call a term of the form t1 : t2 a typed (formal) equation if t1, t2 ? TT for some T ? T Y ; in this
case we define type(t1 : t2) := T . An equation t1 : t2 is called universally valid if ?t1 =E ?t2 for
every well–typed substitution ?. For x1, . . . , xn ? V and T ? T Y , define T H
T
x1,...,xn
(T /E) as the
set of all typed formal equations of type T with variables x1, . . . , xn that are universally valid over
T /E . Define T Hx1,...,xn(T /E) :=
?
T?T Y T H
T
x1,...,xn
(T /E) as the set of all possible typed formal
equations with variables x1, . . . , xn that are universally valid over T /E . Note that not all xi must
occur in such an equation, but no other variables may occur.
We still assume that T /E is finite; hence TT /E is finite for each T ? T Y. We assume in this section
that we are given n fixed variables x1, . . . , xn of types T1, . . . , Tn, respectively, such that TTi/E is of
cardinality Ni. Let N := N1 · . . . ·Nn.
61
Definition 32. Modifying Defs. 19 and 23, define
B :=
?
?
?
?
?
?
?
?
?
?
?
b1,1 . . . b1,N
...
...
bn,1 . . . bn,N
?
?
?
?
?t1 ? TT1 , . . . , tn ? TTn ?j ? {1, . . . , N} ?i ? {1, . . . , n} bi,j =E ti
?
?
?
?
?
?
?
B is non–empty since TT1/E × . . . × TTn/E is finite, viz. of cardinality N . Intuitively, for each
matrix b ? B there is a one–to–one correspondence between its column vectors and the elements of
TT1/E × . . .× TTn/E .
In this section, let x1 = ?(b1,1, . . . , b1,N), . . . , xn = ?(bn,1, . . . , bn,N) for some b ? B, and let
V := {x1, . . . , xn}. Let AT := {a ? (TT /E)N |  L(rsgV (V,a)) 6= {}} for T ? T Y .
Lemma 33. Let t1, t2 ? TT for some T ? T Y with vars(t1) ? vars(t2) ? V .
The equation t1 : t2 is universally valid iff there exists an a ? AT such that t1, t2 ?  L(rsgV (V,a)).
Proof. The proof is similar to that of Lemma 24, with the following observations:
“?”: The ?i from Lemma 14 in Sect. 3.4 are well–typed, since type(xj) = Tj = type(bj,i).
Moreover, a ? AT , since type(ai) = type(?it1) = type(t1) = T for all i.
“?”: It is sufficient to consider an arbitrary well–typed substitution {x1 ? t?1, . . . , xn ? t
?
n} with
type(t?i) = type(xi) = Ti.
Theorem 34. If T /E is finite, the set T H
T
x1,...,xn
(T /E) of all universally valid equations between
terms of type T with variables x1, . . . , xn of types T1, . . . , Tn ? T Y is a regular tree language.
Proof. Let ? be such that ?(b1,1, . . . , b1,N) = x1, . . . , ?(bn,1, . . . , bn,N) = xn for some b ? B; let
V := {x1, . . . , xn}. By Cor. 17, ai is a regular tree language for each a ? TT , T ? T Y. Define
sTvalid
.
= a?AT rsgV (V,a) : rsgV (V,a). Let t1, t2 ? TT with vars(t1) ? vars(t2) ? V . Then,
t1 : t2 is universally valid
? exists a ? AT such that t1, t2 ?  L(rsgV (V,a)) by Lemma 33
? exists a ? AT such that (t1 : t2) ?  L(rsgV (V,a) : rsgV (V,a))
? (t1 : t2) ?  L(sTvalid)
Corollary 35. If T /E is finite and n ? IN arbitrary, the set T Hx1,...,xn(T /E) of universally valid
equations in variables x1, . . . , xn of types T1, . . . , Tn ? T Y can be represented as the deductive
closure of finitely many equations.
Proof. The proof is similar to that of Cor. 28:
Using Thm. 34, T HTx1,...,xn(T /E) =  L(s
T
valid) where s
T
valid
.
= a?AT rsgV (V,a) : rsgV (V,a). Let
svalid
.
= T?T Y s
T
valid. For each a ? AT choose some arbitrary normal form nfa ?  L(rsgV (V,a)).
For a ? AT , let rsgV (V,a)
.
= mi=1 fi(rsgV (V,ai1), . . . , rsgV (V,aini)) be in head normal form.
Define THa := {fi(nfai1 , . . . , nfaini ) : nfa | i = 1, . . . ,m}. Define THT :=
?
a?AT
THa and
TH :=
?
T?T Y THT .
By analogy with the proof of Thm. 28, we can show that, for arbitrary t ?  L(rsgV (V,a)), a ?
AT , and T ? T Y, the equation t : nfa is a deductive consequence of TH . An arbitrary equation
(t1 : t2) ?  L(svalid) follows from t1 : nfa and t2 : nfa. Note that an arbitrary equation (t1 : t2) in
62
 L(sTvalid) is generally not a deductive consequence of THT only, since rewritings on subterms, e.g. of
t1, that are not of type T may be necessary.
Corollary 36. If T /E is finite and n ? IN arbitrary, the set of universally valid quantifier–free
formulas in n variables is a regular tree language and can be represented as the deductive closure
of finitely many axioms that may use the equality predicate. The same holds if the set of admitted
junctors is arbitrarily restricted, as long as it contains logical equivalence (?).
Proof. This follows immediately from Thm. 34 and Cor. 35 by adding a type Bool to T Y, coding
each predicate as a function into Bool, and coding logical junctors as functions from Bool to Bool.
Equations (t1 : t2) of type Bool are read as logical equivalences (t1 ? t2); all other equations as
equality axioms (t1 = t2).
Example 37. Consider (IN mod 3) with function (+) and predicates (<) and (=) :
+ 0 1 2
0 0 1 2
1 1 2 0
2 2 0 1
< 0 1 2
0 f t t
1 f f t
2 f f f
= 0 1 2
0 t f f
1 f t f
2 f f t
? f t
f f f
t f t
? f t
f f t
t t t
The deductive closure of the formulas given in Fig. 56 yields the set of all valid formulas in one
variable x of type IN mod 3 and with ? and ? (and ?) as the only logical junctors. Pure ground
formulas and formulas that are instances of others have been deleted, as well as variants modulo
commutativity or idempotency of ? and ?. Equations of type (IN mod 3) are listed first, followed by
equations of type Bool. Note that the former are not redundant; for example, reducing x+1 = 1+x
to t requires the equations:
x + 1 : 1 + x and
1 + x = 1 + x : t, which has been subsumed by
x = x : t.
As another example, the formula x = 0 ? x = 1 ? x = 2 reduces to t via the equations:
(x = 0) : (x < 1),
(x = 2) : (1 < x),
(1 < x) ? (x < 1) : x + x < 2, and
(1 = x) ? (x + x < 2) : t.
Remark 3. Since (=) and (?) are required among the predicates and junctors, respectively, Cor. 36
does not apply to the set of universally valid Horn formulas.
Remark 4. By analogy with the final remark in Sect. 11.3, we can estimate the complexity of com-
puting all NN1 + . . .+N
N
n rsgV calls as Ø((N
N
1 + . . .+N
N
n ) ·g
?N ·N ·m? · (m? +n)), where m? denotes
the maximal number of alternatives of a sort definition’s right–hand side, and g? is the maximum
number of disjuncts of a sort definition’s right–hand side that start with the same function symbol.
Figure 57 shows the runtimes and result statistics for some examples (optimizations “bdgsv” used).
Column “Dom” shows the involved domains, “F” shows the functions, “P” the predicates, “J” the
junctors, and “V” the number of variables. Columns “S”, “A”, “M”, and “I” show the time for
setting–up, anti–unifying, enumerating the minimal terms, and removing the redundant instances,
63
1+x+(x+x+2) : 0
x+x+x : 0
0+x : x
1+x+2 : x
x+x+(x+x) : x
x+x+1+(x+x+2) : x
x+x+1+2 : x+x
1+x+x : x+x+1
x+x+2+2 : x+x+1
2+x+(x+x+2) : 1
x+x+1+x : 1
x+1 : 1+x
2+x+2 : 1+x
x+x+1+(x+x) : 1+x
x+x+2+(x+x+2) : 1+x
x+2 : 2+x
1+x+1 : 2+x
x+x+(x+x+2) : 2+x
x+x+1+(x+x+1) : 2+x
2+x+x : x+x+2
x+x+1+1 : x+x+2
x+x+1+(1+x) : 2
x+x+2+x : 2
(0 < x) ? (x < 1) : f
(1 < x) ? (x < 1) : f
(1 < x) ? (x < 2) : f
(1 < x) ? (1 = x) : f
(x < 1) ? (1 = x) : f
(x+x < 2) ? (1 = x) : f
(2 < x) : f
(x < 0) : f
(x < x) : f
(x = 1+x) : f
(x = 2+x) : f
(1+x = 2+x) : f
(x+x = x+x+1) : f
(x+x = x+x+2) : f
(x+x+1 = x+x+2) : f
(0 < x) ? (1 < x) : 1 < x
(0 < x) ? (x+x < 2) : 1 < x
(1 < x) ? (x+x < 2) : 1 < x
(1 < x+x+1) : 1 < x
(1+x < 1) : 1 < x
(1+x < x) : 1 < x
(1+x < x+x) : 1 < x
(1+x < x+x+1) : 1 < x
(2+x < x+x+1) : 1 < x
(x+x < x) : 1 < x
(x+x+2 < 1) : 1 < x
(x+x+2 < x) : 1 < x
(x+x+2 < 2+x) : 1 < x
(x+x+2 < x+x+1) : 1 < x
(x = 2) : 1 < x
(1+x = 0) : 1 < x
(1+x = x+x+2) : 1 < x
(2+x = 1) : 1 < x
(2+x = x+x) : 1 < x
(x+x = 1) : 1 < x
(x+x = 2+x) : 1 < x
(x+x+1 = 2) : 1 < x
(x+x+1 = x) : 1 < x
(x+x+2 = 0) : 1 < x
(0 < x) ? (x < 2) : 1 = x
(0 < x) ? (1 = x) : 1 = x
(x < 2) ? (1 = x) : 1 = x
(1 < 1+x) : 1 = x
(1 < x+x) : 1 = x
(x < x+x) : 1 = x
(2+x < 1) : 1 = x
(2+x < 1+x) : 1 = x
(2+x < x+x) : 1 = x
(2+x < x+x+2) : 1 = x
(x+x+1 < 1) : 1 = x
(x+x+1 < x) : 1 = x
(x+x+1 < 1+x) : 1 = x
(x+x+1 < x+x) : 1 = x
(x+x+2 < 1+x) : 1 = x
(x = 1) : 1 = x
(1+x = 2) : 1 = x
(1+x = x+x) : 1 = x
(2+x = 0) : 1 = x
(2+x = x+x+1) : 1 = x
(x+x = 2) : 1 = x
(x+x+1 = 0) : 1 = x
(x+x+1 = 2+x) : 1 = x
(x+x+2 = 1) : 1 = x
(x+x+2 = x) : 1 = x
(0 < x+x) : 0 < x
(2+x < 2) : 0 < x
(2+x < x) : 0 < x
(x+x+2 < 2) : 0 < x
(x+x+2 < x+x) : 0 < x
(0 < x) ? (1 < x) : 0 < x
(0 < x) ? (1 = x) : 0 < x
(1 < x) ? (1 = x) : 0 < x
(x < 1) ? (x < 2) : x < 1
(x < 1) ? (x+x < 2) : x < 1
(x < 2) ? (x+x < 2) : x < 1
(1 < 2+x) : x < 1
(1 < x+x+2) : x < 1
(x < 2+x) : x < 1
(x < x+x+1) : x < 1
(x < x+x+2) : x < 1
(1+x < x+x+2) : x < 1
(x+x < 1) : x < 1
(x+x < 1+x) : x < 1
(x+x < 2+x) : x < 1
(x+x < x+x+2) : x < 1
(x+x+1 < 2+x) : x < 1
(x = 0) : x < 1
(1+x = 1) : x < 1
(1+x = x+x+1) : x < 1
(2+x = 2) : x < 1
(2+x = x+x+2) : x < 1
(x+x = 0) : x < 1
(x+x = x) : x < 1
(x+x+1 = 1) : x < 1
(x+x+2 = 2) : x < 1
(0 < 2+x) : x+x < 2
(0 < x+x+1) : x+x < 2
(1+x < 2) : x+x < 2
(1+x < 2+x) : x+x < 2
(x+x < x+x+1) : x+x < 2
(1 < x) ? (x < 1) : x+x < 2
(1 < x) ? (x+x < 2) : x+x < 2
(x < 1) ? (x+x < 2) : x+x < 2
(0 < 1+x) : x < 2
(0 < x+x+2) : x < 2
(x < 1+x) : x < 2
(x+x+1 < 2) : x < 2
(x+x+1 < x+x+2) : x < 2
(x < 1) ? (x < 2) : x < 2
(x < 1) ? (1 = x) : x < 2
(x < 2) ? (1 = x) : x < 2
(x = x) : t
(0 < x) ? (x < 1) : t
(0 < x) ? (x < 2) : t
(0 < x) ? (x+x < 2) : t
(1 < x) ? (x < 2) : t
(x < 2) ? (x+x < 2) : t
(1 = x) ? (x+x < 2) : t
Fig. 56. Theory of IN mod 3 with +, <, =, and Bool with ? and ?
64
respectively. “> n” means running out of memory after n seconds. Column “?” shows the total
time; column “Sz” shows the number of non–redundant equations (without manual deletions).
Remark 5. The above results refer to finite algebras only, i.e. models with finite T /E. It remains
to be uninvestigated whether, given an arbitrary equational theory, we can find a finite “test set”
Ttest/E ? T /E of ground instances such that an equation is universally valid iff it holds for all
instances from the test set.
Dom F P J V S A M I ? Sz
IN mod 2 + 2 4 0 1 5 6 27
IN mod 2 + 3 0 3881 0 11 3892 105
IN mod 2 , Bool + < , = ? , ? 2 , 0 0 18 0 41 59 452
IN mod 3 , Bool + < , = ? , ? 1 , 0 0 30 1 17 48 307
IN mod 3 , Bool + < , = ? , ? 2 , 0 20 >143
Fig. 57. Axiomatization Runtimes and Results
65
References
AM91. A. Aiken and B. Murphy. Implementing regular tree expressions. In ACM Conference on Func-
tional Programming Languages and Computer Architecture, pages 427–447, August 1991.
Ave89. Jrgen Avenhaus. Transforming infinite rewrite systems into finite rewrite systems by embedding
techniques. SEKI-Report SR–89–21, Univ. Kaiserslautern, 1989.
BM79. R.S. Boyer and J.S. Moore. A Computational Logic. Academic, New York, 1979.
Bur93. Jochen Burghardt. Eine feinkrnige Sortendisziplin und ihre Anwendung in der Programmkon-
struktion. PhD thesis, Univ. Karlsruhe, 1993.
BvHSI90. Alan Bundy, Frank van Harmelen, Alan Smaill, and Andrew Ireland. Extensions to the rippling-
out tactic for guiding inductive proofs. In Proc. 10th CADE, volume 449 of LNAI, pages 132–146.
Springer, 1990.
Com90. Hubert Comon. Equational formulas in order-sorted algebras. In Proc. ICALP, 1990.
Com95. Hubert Comon. On unification of terms with integer exponents. Math. Systems Theory, 28:67–88,
1995.
Emm94. Helmut Emmelmann. Codeselektion mit regulr gesteuerter Termersetzung. PhD thesis, University
Karlsruhe, 1994.
GM93. Peter Graf and Christoph Meyer. Extended path-indexing. Technical Report MPI-I-93-253, Max-
Planck-Institut fr Informatik, Saarbrcken, Dec 1993.
Gra92. Peter Graf. Path indexing for term retrieval. Technical Report MPI-I-92-237, Max-Planck-Institut
fr Informatik, Saarbrcken, April 1992.
Gra94. Peter Graf. Substitution tree indexing. Technical Report MPI-I-94-251, Max-Planck-Institut fr
Informatik, Saarbrcken, Oct 1994.
Hei94. Birgit Heinz. Lemma discovery by anti-unification of regular sorts. Technical Report 94–21, TU
Berlin, 1994.
Hei95. Birgit Heinz. Anti-Unifikation modulo Gleichungstheorie und deren Anwendung zur Lemmagener-
ierung. PhD thesis, TU Berlin, Dec 1995.
HH94. Dieter Hofbauer and Maria Huber. Linearizing term rewriting systems using test sets. J. Symbolic
Computation, 17:91–129, 1994.
Hum90. B. Hummel. Generierung von Induktionsformeln und Generalisierung beim automatischen Be-
weisen mit vollstndiger Induktion. PhD thesis, University Karlsruhe, May 1990.
Kir87. H. Kirchner. Schematization of infinite sets of rewrite rules. Application to the divergence of
completion processes. In Proc. Conf. on Rewriting Techniques and Applications, volume 256 of
LNCS, pages 180–191. Springer, May 1987.
Kir89. He?le?ne Kirchner. Schematization of infinite sets of rewrite rules generated by divergent completion
processes. Theoretical Computer Science, 67:303–332, 1989.
MW80. Zohar Manna and Richard Waldinger. A deductive approach to program synthesis. ACM Trans-
actions on Programming Languages and Systems, 2:90–121, Jan 1980.
Plo70. Gordon D. Plotkin. A note on inductive generalization. Machine Intelligence, 5:153–163, 1970.
Plo71. Gordon D. Plotkin. A further note on inductive generalization. Machine Intelligence, 6:101–124,
1971.
Rey70. John C. Reynolds. Transformational systems and the algebraic structure of atomic formulas.
Machine Intelligence, 5:135–151, 1970.
66
Appendix
A PROLOG Source Code
:-
op(910,xfx,:=), % substitution
op(831,xfx,sortdef), % user sort definition
op(831,xfx,sortdf), % system sort definition
op(831,xfx,inf), % sort infimum
op(831,yfx,\), % sort difference
op(831,fx,def), % defining equation
op(812,xfx,->), % series rewrite rule
op(810,yfx,!), % sort disjunction
op(700,xfy,:). % user equal
:-
assert((Sort sortdef SortDef :- Sort sortdf SortDef)).
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %
% %%%%% functional dependency detection %%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %
find_dependency(Eqns,AuL:Dep) :-
eval_term_list(Eqns,EqnsE),
strip_common_constructor(EqnsE,(:),[Lhss,Rhss]),
equiv_class_list(Rhss,RhssC),
abolish(origin_v,2),
sg(Lhss,AuL),
setof((Ss,var,V),origin_v(Ss,V),OccL),
rgbv([/*inf*/999999],RhssC,OccL,AuR),
write(generalized(AuR)), nl,
%init_red,
%normalforms_sort(NfS),
%inf(AuR,NfS,AuR1),
%write(filtered(AuR1)), nl,
abolish(redices,1),
assert(redices([])),
!,
find_rhs(AuR,[],Dep).
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %
% %%%%% lemma generation %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %
% given term Lhs, generate a rhs candidate Rhs
%<*backtrackable*>
generate_lemma(Lhs,Rhs) :-
read_instances(Lhs,Eqns),
write(’normalized:’), nl,
beautify_output(Eqns,EqnsB),
write_list(EqnsB), nl,
strip_common_constructor(Eqns,(:),[Lhss,Rhss]),
abolish(origin_v,2),
sg(Lhss,AuL),
setof((Ss,var,V),origin_v(Ss,V),OccL),
rsgv(/*inf*/999999,Rhss,OccL,AuR),
write(’generalized: ’),
beautify_output(AuL:AuR,AuLAuRB),
write(AuLAuRB), nl,
init_red,
normalforms_sort(NfS),
inf(AuR,NfS,AuR1),
abolish(redices,1),
assert(redices([])),
!,
find_rhs(AuR1,[],Rhs).
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %
% %%%%% series guessing %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %
guess_series_b(N,M,Series,LawB,PrognoseB) :-
guess_series(N,Series,Law),
prognose_series(Series,Law,M,Prognose),
beautify_output(Law,LawB),
beautify_output(Prognose,PrognoseB).
% given the list Series and the example count N,
% generate a construction law candidate term LawL->LawR
%<*backtrackable*>
guess_series(N,Series,LawL->LawR) :-
eval_term_list(Series,SeriesN),
%: [s(s(s(s(0)))),s(0),0]
bagof(Suffix,suffix(Suffix,SeriesN),Suffixes),
%: [[s(s(s(s(0)))),s(0),0],[s(0),0],[0],[]]
reverse(Suffixes,[[]|SuffixesR]),
%: [[s(0),0],[s(s(s(s(0)))),s(0),0]]
merge_lists(Heads,(.),Tails,SuffixesR),
%: Heads = [s(0),s(s(s(s(0))))]
%: Tails = [[0], [s(0),0]]
equiv_class_list(Heads,HeadsE),
%: HeadsE = [s1,s4]
length(HeadsE,Lgth),
make_0s_list_of_length(Lgth,Index),
merge_lists(Index,(.),Tails,TailsI),
%: TailsI = [[s(0),0], [s(s(0)),s(0),0]]
make_varlist_of_length(N,TailsS),
make_varlist_of_length(N,HeadsS),
suffix(TailsS,TailsI),
suffix(HeadsS,HeadsE),
beautify_output(TailsS:HeadsS,TailsSHeadsSB),
write(’anti-unifying: ’), write(TailsSHeadsSB), nl,
abolish(origin_v,2),
sg(TailsS,LawL),
setof((Ss,var,V),origin_v(Ss,V),OccT),
rsgv(/*inf*/999999,HeadsS,OccT,AuH),
beautify_output(LawL:AuH,LawLAuHB),
write(’generalized: ’), write(LawLAuHB), nl,
init_red,
normalforms_sort(NfS),
inf(AuH,NfS,AuH1),
abolish(redices,1),
assert(redices([])),
!,
find_rhs(AuH1,[],LawR).
prognose_series(Series,Law,Lgth,Prognose) :-
length(Series,Index),
eval_term_t([Index|Series],SeriesE),
prognose_series1(SeriesE,Law,Lgth,[_IndexP|Prognose]), !.
prognose_series1(Series,_Law,0,Series) :- !.
prognose_series1([Index|Series],LawL->LawR,Lgth,Prog) :-
try_rewrite([Index|Series],LawL,LawR,P),
eval_term_t(P,PE),
Lgth1 is Lgth - 1,
prognose_series1([s(Index),PE|Series],LawL->LawR,Lgth1,Prog), !.
prognose_series1([Index|Series],LawL->LawR,Lgth,[in|prognose_failed]) :-
beautify_output(LawL->LawR,LawB),
beautify_output([Index|Series],SeriesB),
write(prognose_failed(SeriesB,LawB,Lgth)), nl, !.
prognose_series1(A,B,C,D) :-
dont_backtrack(prognose_series1(A,B,C,D)).
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %
% %%%%% theory computation for finite algebras %%%%%%%%%%%%%%%%%%%%%%% %
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %
% given the list of lists Eqcss of equivalence classes
% and the list Ns of variable numbers,
% print an axiom system for the corresponding finite algebra,
% Consts gives the constants forbidden in the result
%: compute_theory([[s0,s1,s2],[st,sf]],[2,0],[[0,1,2],[t,f]])
%: where s0,s1,s2 denote the equivalence class of 0,1,2, respectively
%: in N mod 3,
%: st,sf denote the class of true,false in Bool, respectively
compute_theory(Eqcss,Ns,Constss) :-
trace_write(prof,set_up),
calc_sort_depths,
first_groundterms_t_list_list(Eqcss,Nfss),
% generate variables
extend_to_length_list(vv,Ns,VVs1),
new_name_list_list(VVs1,VVs),
extend_to_same_length_list(0,VVs,Nulls),
merge_lists_list(VVs,arity,Nulls,Arities),
assert_list_list(Arities),
make_varlist_of_same_length_list(VVs,VSorts),
merge_lists_list(VVs,is_variable,VSorts,IsVariables),
assert_list_list(IsVariables),
% generate variable assignments
setof(Map,(
mapping_list12(VVs,Nfss,Map)
),Maps),
transpose(Maps,Maps1),
merge_lists_list(_VNsg,(:=),VSss,Maps1),
extend_to_same_length_list(var,VVs,Vars),
merge_lists_list(Vars,(’,’),VVs,VVs2),
append_list(VVs2,VVs3),
merge_lists(VSss,(’,’),VVs3,OccL),
% generate rsgv input sorts
OccL = [(Dom1,var,_V)|_],
length(Dom1,DomLg),
make_natlist_of_length(DomLg,Dom),
bagof(Matrix,Eqcs^Col^Places^Map^(
member(Eqcs,Eqcss),
setof(Col,Places^Map^(
mapping(Dom,Eqcs,Map),
merge_lists(Places,(:=),Col,Map)
),Matrix)
),Matrixes),
% anti-unify
trace_write(prof,anti_unify),
rsgv_list_list(/*inf*/999999,Matrixes,OccL,Auss1),
trace_write(prof,transform_to_axioms),
remove_constants_list_list12(Auss1,Constss),
calc_sort_depths,
append_list(Auss1,Aus1),
remove_empty_sorts(Aus1,Aus),
first_groundterms_t_list(Aus,MinTerms),
merge_lists(Aus,(:),MinTerms,SMinL),
trace_write(prof,min_terms),
write_list(SMinL),
conv_list_to_bbt(SMinL,SMinBBT),
min_eqns_t_list(Aus,SMinBBT,Eqns),
trace_write(prof,remove_instances),
remove_instances([],Eqns,Eqns1),
beautify_output(Eqns1,EqnsB),
nl, write_list(EqnsB), nl, !.
% remove all constants in definition of Sort that are in Consts
remove_constants(Sort,Consts) :-
retract(Sort sortdf Def),
flatten_op(Def,(!),DefF),
list_trisection(DefF,Consts,DefRF,_,_),
{ unflatten_op(DefRF,(!),DefR)
; DefR = bottom
},
assert(Sort sortdf DefR), !.
remove_constants(A,B) :-
dont_backtrack(remove_constants(A,B)).
remove_constants_list([Sort|Sorts],Consts) :-
remove_constants(Sort,Consts),
remove_constants_list(Sorts,Consts), !.
remove_constants_list([],_Consts) :- !.
remove_constants_list_list12([Sorts|Sortss],[Consts|Constss]) :-
remove_constants_list(Sorts,Consts),
remove_constants_list_list12(Sortss,Constss), !.
remove_constants_list_list12([],[]) :- !.
% remove all equations from EqnsNew that are subsumed by others in
% EqnsNew or EqnsOld, yielding EqnsR
remove_instances(EqnsOld,[LN:RN|EqnsNew],EqnsR) :-
try_delete_from_list(LO:RO,EqnsOld,EqnsOld1),
( is_instance_118(RN:LN,RO:LO,_Subst),
remove_instances(EqnsOld,EqnsNew,EqnsR)
; is_instance_118(RO:LO,RN:LN,_Subst),
remove_instances(EqnsOld1,[LN:RN|EqnsNew],EqnsR)
), !.
remove_instances(EqnsOld,[LN:RN|EqnsNew],EqnsR) :-
remove_instances([LN:RN|EqnsOld],EqnsNew,EqnsR), !.
remove_instances(EqnsOld,[],EqnsR) :-
reverse(EqnsOld,EqnsR), !.
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %
% %%%%% syntactic anti-unification %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %
% calc the sort Au of anti-unifiers of all ground terms in Ss
sg_t(Ss,Au) :-
trace_enter(sg,sg(Ss)),
sg(Ss,Au),
trace_leave(sg,sg(Ss) = Au).
%- decompose common constructor
sg(Ss,Au) :-
strip_common_constructor(Ss,Cr,SsArgs),
make_varlist_of_same_length(SsArgs,AuArgs),
Au =.. [Cr|AuArgs],
sg_list(SsArgs,AuArgs), !.
%- different constructors, return old variable
sg(Ss,Au) :-
origin_v(Ss,Au), !.
%- different constructors, return new variable
sg(Ss,Au) :-
new_name(v,Au),
assert(origin_v(Ss,Au)),
assert(is_variable(Au,top)),
assert(arity(Au,0)), !.
sg_list([Ss|Sss],[Au|Aus]) :-
sg_t(Ss,Au),
sg_list(Sss,Aus), !.
sg_list([],[]) :- !.
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %
% %%%%% simple sort anti-unification %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %
% calc the sort Au of anti-unifiers of all sorts in Ss,
% defining new sorts recursively as needed
hsg(Ss,Au) :-
hsg_t(Ss,Au0,nil,OccBT),
conv_bbtlist_to_list([OccBT],Occ),
postprocess_hsg(Au0,Au1,Occ,SortDefs1,VarSubst),
extract_defs_from_occ(SortDefs1,SortDefs2,xxx,_Memo),
apply_subst_sc([Au1,SortDefs2],VarSubst,[Au2,SortDefs3]),
simplify_variables([Au2,SortDefs3],[Au,SortDefs4]),
assert_list(SortDefs4), !.
%- calc the NameAu of anti-unifiers of all sorts in Ss,
%- OccIn, OccOut is the binary tree of triples (Ss,AuSs,NameAu)
%- for which hsg already has been called,
%- AuSs may be uninstantiated until the completion of the call,
%- the meaning of a triple is: NameAu sortdef AuSs, hsg(Ss) = NameAu
hsg_t(Ss,Au,OccIn,OccOut) :-
trace_enter(hsg,hsg(Ss)),
hsg(Ss,Au,OccIn,OccOut),
trace_leave(hsg,hsg(Ss) = Au).
%- loop check
hsg(Ss,NameAu,OccIn,OccIn) :-
member_bbt((Ss,_DefAu,NameAu),OccIn),
{ nonvar(NameAu)
; new_name(sort,NameAu),
assert(origin_s(NameAu,Ss))
}, !.
%- replace sort names by definitions,
%- then distribute "!"
hsg(Ss,Au,OccIn,OccOut) :-
replace_defs(Ss,SsDef,OccIn,Occ1,DefAu,NameAu,true),
{ member(_!_,SsDef),
%: [0!s0+s0!s0*top!top*s0,s(s0)!s1+s0!s0+s1!s1*s1]
flatten_op_list1(SsDef,(!),Ss1),
%: [[0,s0+s0,s0*top,top*s0],[s(s0),s1+s0,s0+s1,s1*s1]]
sort_list(Ss1,Ss2),
%: [[0,s0*top,top*s0,s0+s0],[s(s0),s1*s1,s0+s1,s1+s0]]
group_cr_sorts(Ss2,[],Groups),
%: [[s0*top,s1*s1],[top*s0,s1*s1],
%: [s0+s0,s0+s1],[s0+s0,s1+s0]]
hsg_list(Groups,Aus,Occ1,Occ2),
{ origin_v(Ss,V),
OccOut = Occ2,
unflatten_op([V|Aus],(!),DefAu)
; new_name(v,V),
assert(origin_v(Ss,V)),
assert(is_variable(V,top)),
assert(arity(V,0)),
enter_into_bbt((Ss,var,V),Occ2,OccOut),
% same sort pairs get same variable
% necessary for calculating var intersections
unflatten_op([V|Aus],(!),DefAu)
}
; hsg_t(SsDef,DefAu,Occ1,OccOut)
},
{ var(NameAu),
Au = DefAu
; Au = NameAu
}, !.
%- decompose common constructor
hsg(Ss,Au,OccIn,OccOut) :-
strip_common_constructor(Ss,Cr,SsArgs),
make_varlist_of_same_length(SsArgs,AuArgs),
Au =.. [Cr|AuArgs],
hsg_list(SsArgs,AuArgs,OccIn,OccOut), !.
%- different constructors, return new variable
hsg(Ss,Au,OccIn,OccOut) :-
new_name(v,Au),
assert(origin_v(Ss,Au)),
assert(is_variable(Au,top)),
assert(arity(Au,0)),
enter_into_bbt((Ss,var,Au),OccIn,OccOut), !.
hsg_list([Ss|Sss],[Au|Aus],OccIn,OccOut) :-
hsg_t(Ss,Au,OccIn,Occ1),
hsg_list(Sss,Aus,Occ1,OccOut), !.
hsg_list([],[],OccIn,OccIn) :- !.
% set up variable substitution to consider sort intersections
postprocess_hsg(Au,AuS,Occ,SortDefs,VarSubst) :-
split_sort_var_defs(Occ,SortDefs1,VarDefs1),
simplify_sorts_and_defs([Au],[AuS],SortDefs1,SortDefs),
calc_sort_infs(VarDefs1,Infs),
conv_list_to_bbt(Infs,InfsBT),
calc_inf2s(VarDefs1,[],L2,InfsBT),
calc_varcnt(L2,VarCnt1),
sort(VarCnt1,VarCnt2),
sort(VarDefs1,VarDefs1S),
collect_varcnt([’XXX’:0|VarCnt2],VarDefs1S,VarCnt),
conv_list_to_bbt(VarCnt,VarCntBT),
conv_list_to_bbt(L2,BT2),
calc_infs_list(L2,VarCnt,VarCntBT,BT2,[],VarDefs2),
calc_var_subst(VarDefs2,VarSubst), !.
% calculate all nonempty intersections of two occurring sort names
calc_sort_infs(VarDefs,Infs) :-
calc_sort_infs1(VarDefs,Sorts),
sort(Sorts,Sorts1),
calc_sort_infs2(Sorts1,Infs), !.
% collect all sorts
%: calc_sort_infs1([([v8],v8,[s0,s1]),([v4],v4,[s0,s2])],[s0,s1,s0,s2])
calc_sort_infs1([(_R,_V,Ss)|List],Sorts) :-
calc_sort_infs1(List,Sorts2),
append(Ss,Sorts2,Sorts), !.
calc_sort_infs1([],[]) :- !.
% calculate all nonempty intersections of any two sorts in Sorts
%: calc_sort_infs2([s0,s1,s2,top],[(s0,top,s0),(s1,top,s1),(s2,top,s2)])
calc_sort_infs2([Sort|Sorts],Infs) :-
calc_sort_infs3(Sort,Sorts,Infs1),
calc_sort_infs2(Sorts,Infs2),
append(Infs1,Infs2,Infs), !.
calc_sort_infs2([],[]) :- !.
% calc all nonempty intersections of Sort with each element in Sorts
%- intersection of Sort and Sort0 is nonempty
calc_sort_infs3(Sort,[Sort0|Sorts0],[(Sort,Sort0,Sort1)|Infs]) :-
inf(Sort,Sort0,Sort1),
inh(Sort1),
calc_sort_infs3(Sort,Sorts0,Infs), !.
%- intersection of Sort and Sort0 is empty
calc_sort_infs3(Sort,[_Sort0|Sorts0],Infs) :-
calc_sort_infs3(Sort,Sorts0,Infs), !.
calc_sort_infs3(_Sort,[],[]) :- !.
% calculate all nonempty intersections of two variables,
% InfsBT is a binary tree with an entry (S,S0,S1) for each pair of
% sort names S,S0 with non-empty intersection S1
calc_inf2s([([V],V,Ss)|List],In,Out,InfsBT) :-
calc_inf2s1([V],V,Ss,List,In,Mid,InfsBT),
calc_inf2s(List,Mid,Out,InfsBT), !.
calc_inf2s([],In,In,_InfsBT) :- !.
% calculate all nonempty intersections of V with each element in List
%- intersection of V and V0 is nonempty
calc_inf2s1([V],V,Ss,[([V0],V0,S0s)|List],In,Out,InfsBT) :-
calc_inf2s2(Ss,S0s,S2s,InfsBT),
{ origin_v(S2s,V2)
; new_name(v,V2),
assert(origin_v(S2s,V2)),
assert(is_variable(V2,top)),
assert(arity(V2,0))
},
sort([V,V0],R2),
calc_inf2s1([V],V,Ss,List,[(R2,V2,S2s)|In],Out,InfsBT), !.
%- intersection of V0 and V1 is empty
calc_inf2s1([V],V,Ss,[([V0],V0,_S0s)|List],In,Out,InfsBT) :-
calc_inf2s1([V],V,Ss,List,In,Out,InfsBT), !.
calc_inf2s1([V],V,_Ss,[],In,In,_InfsBT) :- !.
% test all intersections S1s of Ss with S0s
calc_inf2s2([S|Ss],[S|S0s],[S|S1s],InfsBT) :-
!,
calc_inf2s2(Ss,S0s,S1s,InfsBT), !.
calc_inf2s2([S|Ss],[S0|S0s],[S1|S1s],InfsBT) :-
member_bbt((S,S0,S1),InfsBT),
!,
calc_inf2s2(Ss,S0s,S1s,InfsBT), !.
calc_inf2s2([S|Ss],[S0|S0s],[S1|S1s],InfsBT) :-
member_bbt((S0,S,S1),InfsBT),
!,
calc_inf2s2(Ss,S0s,S1s,InfsBT), !.
calc_inf2s2([],[],[],_InfsBT) :- !.
% calculate all possible intersection lists containing R0
calc_infs_list([(R0,V0,S0s)|List2],List,ListBT,BT2,In,Out) :-
length(R0,LgR0),
calc_infs_list_H1(R0,LgR0,ListBT),
calc_infs(R0,V0,S0s,List,[],BT2,In,Mid),
calc_infs_list(List2,List,ListBT,BT2,Mid,Out), !.
calc_infs_list([(R0,V0,S0s)|List2],List,ListBT,BT2,In,Out) :-
calc_infs_list(List2,List,ListBT,BT2,[(R0,V0,S0s)|In],Out), !.
calc_infs_list([],_List,_ListBT,_BT2,In,In) :- !.
calc_infs_list_H1([V|Vs],Lg,ListBT) :-
member_bbt(([V],V,_Ss):Cnt,ListBT),
Cnt >= Lg,
!,
calc_infs_list_H1(Vs,Lg,ListBT), !.
calc_infs_list_H1([],_Lg,_ListBT) :- !.
%- V is already in R0, ignore
calc_infs(R0,V0,S0s,[([V],V,_Ss):_Cnt|List],Lsusp,BT2,In,Out) :-
member(V,R0),
calc_infs(R0,V0,S0s,List,Lsusp,BT2,In,Out), !.
%- V does not occur often enough, ignore
calc_infs(R0,V0,S0s,[([V],V,_Ss):Cnt|List],Lsusp,BT2,In,Out) :-
length(R0,LgR0),
Cnt < LgR0,
calc_infs(R0,V0,S0s,List,Lsusp,BT2,In,Out), !.
%- [V|R0] has 2 element sublist with empty intersection, ignore
calc_infs(R0,V0,S0s,[([V],V,_Ss):_Cnt|List],Lsusp,BT2,In,Out) :-
member(VR0,R0),
sort([VR0,V],VR0V),
not member_bbt((VR0V,_,_),BT2),
calc_infs(R0,V0,S0s,List,Lsusp,BT2,In,Out), !.
%- [V|R0] is sublist of a nonempty intersection list, suspend V
calc_infs(R0,V0,S0s,[([V],V,Ss):Cnt|List],Lsusp,BT2,In,Out) :-
sort([V|R0],R2),
member((RR,_VV,_SSs),In),
is_sublist(R2,RR),
calc_infs(R0,V0,S0s,List,[([V],V,Ss):Cnt|Lsusp],BT2,In,Out), !.
%- [V|R0] has nonempty intersection
calc_infs(R0,V0,S0s,[([V],V,Ss):_Cnt|List],Lsusp,BT2,In,Out) :-
sort([V|R0],R2),
calc_infs2(S0s,Ss,S1s,OccsS),
calc_infs3(S1s,OccsS,S2s),
{ origin_v(S2s,V2)
; new_name(v,V2),
assert(origin_v(S2s,V2)),
assert(is_variable(V2,top)),
assert(arity(V2,0))
},
append(List,Lsusp,List1),
calc_infs(R2,V2,S2s,List1,[],BT2,In,Mid),
calc_infs(R0,V0,S0s,List1,[],BT2,Mid,Out), !.
%- [V|R0] has empty intersection, ignore
calc_infs(R0,V0,S0s,[([V],V,_Ss):_Cnt|List],Lsusp,BT2,In,Out) :-
calc_infs(R0,V0,S0s,List,Lsusp,BT2,In,Out), !.
%- maximal intersection list subsumed, ignore
calc_infs(R0,_V0,_S0s,[],[],_BT2,In,In) :-
member((RR,_VV,_SSs),In),
is_sublist(R0,RR), !.
%- maximal intersection list, report
calc_infs(R0,V0,S0s,[],[],_BT2,In,[(R0,V0,S0s)|In]) :- !.
%- maximal intersection list subsumed, ignore
calc_infs(_R0,_V0,_S0s,[],_Lsusp,_BT2,In,In) :- !.
% test all intersections of Ss with S0s
%<*may fail*>
calc_infs2([S|Ss],[S0|S0s],[S1|S1s],[OccS|OccsS]) :-
inf_t(S,S0,S1,nil,OccSBT),
conv_bbtlist_to_list([OccSBT],OccS),
inh_t(S1,[],OccS),
calc_infs2(Ss,S0s,S1s,OccsS), !.
calc_infs2([],[],[],[]) :- !.
% simplify all intersections S1s
calc_infs3([S1|S1s],[OccS|OccsS],[S2|S2s]) :-
simplify_sort1(OccS,OccSs),
simplify_sort4(S1,S2),
extract_defs_from_occ(OccSs,DefsS,memo_inf,Memo),
assert_list(DefsS),
assert_list(Memo),
calc_infs3(S1s,OccsS,S2s), !.
calc_infs3([],[],[]) :- !.
%: calc_v([([a,b],_,_),([a,c],_,_)],[a:[a,b],b:[a,b],a:[a,c],c:[a,c]])
calc_varcnt([(R0,_V0,_S0s)|List2],VarCnts) :-
calc_varcnt1(R0,R0,VarCnts1),
calc_varcnt(List2,VarCnts2),
append(VarCnts1,VarCnts2,VarCnts), !.
calc_varcnt([],[]) :- !.
%: calc_varcnt1([a,b],[a,b],[a:[a,b],b:[a,b]])
calc_varcnt1([V|Vs],R0,[V:R0|VarCnts]) :-
calc_varcnt1(Vs,R0,VarCnts), !.
calc_varcnt1([],_R0,[]) :- !.
%: collect_varcnt([’XXX’:0,a:[a,b],a:[a,c],b:[a,b],c:[a,c]],
% [([a],a,s1),([b],b,s2),([c],c,s3)],
% [([a],a,s1):2,([b],b,s2):1,([c],c,s3):1])
%- collect multiple occurrences of V
collect_varcnt([V:Cnt,V:_R|Vars],Group,VarCnts) :-
Cnt1 is Cnt + 1,
collect_varcnt([V:Cnt1|Vars],Group,VarCnts), !.
%- V1 in Vars and in Group, join
collect_varcnt([V1:Cnt1,V2:_R2|Vars],[([V1],V1,S1)|Group],
[([V1],V1,S1):Cnt1|VarCnts]) :-
collect_varcnt([V2:1|Vars],Group,VarCnts), !.
%- V1 not in Group, ignore
collect_varcnt([V1:_Cnt1,V2:_R2|Vars],[([V3],V3,S3)|Group],VarCnts) :-
V1 @< V3,
collect_varcnt([V2:1|Vars],[([V3],V3,S3)|Group],VarCnts), !.
%- V3 not in Vars, ignore
collect_varcnt([V1:Cnt1,V2:_R2|Vars],[([V3],V3,_S3)|Group],VarCnts) :-
V3 @< V1,
collect_varcnt([V1:Cnt1,V2:1|Vars],Group,VarCnts), !.
%- V in Vars and in Group, join
collect_varcnt([V:Cnt],[([V],V,S)|_Group],[([V],V,S):Cnt]) :- !.
%- V1 not in Group, ignore
collect_varcnt([V1:_Cnt1],[([V3],V3,_S3)|_Group],[]) :-
V1 @< V3, !.
%- V3 not in Vars, ignore
collect_varcnt([V1:Cnt1],[([V3],V3,_S3)|Group],VarCnt) :-
V3 @< V1,
collect_varcnt([V1:Cnt1],Group,VarCnt), !.
collect_varcnt([],_Group,[]) :- !.
collect_varcnt(_Vars,[],[]) :- !.
% build variable substitution from intersection list
calc_var_subst(VarDefs,VarSubst) :-
calc_var_subst1(VarDefs,[],VarSubst1),
sort(VarSubst1,VarSubst2),
calc_var_subst3(VarSubst2,xxx:=xxx,[xxx:=xxx|VarSubst3]),
conv_list_to_bbt(VarSubst3,VarSubst), !.
calc_var_subst1([(Vs,Vnew,_Ss)|VarDefs],VarSubstIn,VarSubstOut) :-
calc_var_subst2(Vnew,Vs,VarSubstIn,VarSubst1),
calc_var_subst1(VarDefs,VarSubst1,VarSubstOut), !.
calc_var_subst1([],VarSubstIn,VarSubstIn) :- !.
calc_var_subst2(Vnew,[V|Vs],VarSubstIn,VarSubstOut) :-
calc_var_subst2(Vnew,Vs,[V:=Vnew|VarSubstIn],VarSubstOut), !.
calc_var_subst2(_Vnew,[],VarSubstIn,VarSubstIn) :- !.
calc_var_subst3([V:=Vnew1|VarSubst],V:=Vnew,VarSubstO) :-
calc_var_subst3(VarSubst,V:=Vnew!Vnew1,VarSubstO), !.
calc_var_subst3([V1:=Vnew1|VarSubst],V:=Vnew,[V:=Vnew|VarSubstO]) :-
calc_var_subst3(VarSubst,V1:=V1!Vnew1,VarSubstO), !.
calc_var_subst3([],V:=Vnew,[V:=Vnew]) :- !.
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %
% %%%%% variable-restricted sort anti-unification %%%%%%%%%%%%%%%%%%%% %
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %
:-
assert(origin_s_bbt([],nil)).
% calc the sort Au of anti-unifiers of all sorts in Ss,
% proceed breadth-first,
% defining new sorts recursively as needed,
% OccVL is a list containing all admitted variables
% <*backtrackable*>
rgbv(Par,Ss,OccVL,Au) :-
sort(OccVL,OccVL1),
{ origin_s_bbt(OccVL1,BTin)
; BTin = nil
},
( member_bbt((Ss,_Def,_Depth,Au),BTin)
; build_occ_var_trie(OccVL1,[],OcVT),
new_name(sort,Au),
{ retract(origin_s_bbt(OccVL1,BTin))
; BTin = nil
},
enter_into_bbt((Ss,_DefAu,Dp,Au),BTin,BT1),
rgbv_t([Dp,[[Ss:Dp:DEx:Au]]|Par],[Ss:Dp:DEx:Au,layer:0],OccVL1,OcVT,BT1,BTo),
( assert(origin_s_bbt(OccVL1,BTo))
; retract(origin_s_bbt(OccVL1,_BT)),
fail
)
).
rgbv_list(Par,[Ss|Sss],Occ,[Au|Aus]) :-
rgbv(Par,Ss,Occ,Au),
rgbv_list(Par,Sss,Occ,Aus), !.
rgbv_list(_Par,[],_Occ,[]) :- !.
rgbv_list_list(Par,[Sss|Ssss],Occ,[Aus|Auss]) :-
rgbv_list(Par,Sss,Occ,Aus),
rgbv_list_list(Par,Ssss,Occ,Auss), !.
rgbv_list_list(_Par,[],_Occ,[]) :- !.
simp_sort_depths_list([Layer|Layers],[LayerS|LayersS]) :-
simp_sort_depths_t(Layer,LayerS,Chg),
{ Chg = no,
LayersS = Layers
; simp_sort_depths_list(Layers,LayersS)
}, !.
simp_sort_depths_list([],[]) :- !.
simp_sort_depths_t(Layer,LayerS,Chg) :-
trace_enter(sd,simp(Layer)),
simp_sort_depths(Layer,LayerS,Chg),
trace_leave(sd,simp(Chg,LayerS)), !.
simp_sort_depths([Ss:Dp:DpDjs:Au|SssA],[Ss:Dp:DpDjs:Au|SssA1],yes) :-
nonvar(Dp),
{ sort_depth(Au,_DpAu)
; assert(sort_depth(Au,Dp)),
trace_write(sd1,assd(Au,Dp))
},
simp_sort_depths(SssA,SssA1,_Chg), !.
simp_sort_depths([Ss:Dp:DpDjs:Au|SssA],[Ss:Dp:DpDjs:Au|SssA1],Chg) :-
var(DpDjs),
simp_sort_depths(SssA,SssA1,Chg), !.
simp_sort_depths([Ss:Dp:DpDjs:Au|SssA],[Ss:Dp:DpDjs1:Au|SssA1],Chg) :-
simp_sort_depths1(DpDjs,DpDjs1,DpDisjs2),
trace_write(sd1,smp1(Au,DpDjs,DpDisjs2)),
{ DpDisjs2 = [],
Chg = Chg1
; sort_depth(Au,_DpAu),
Chg = Chg1
; unflatten_op(DpDisjs2,(min),DpI),
Dp is DpI + 1,
assert(sort_depth(Au,Dp)),
trace_write(sd1,assd(Au,Dp,DpDjs1)),
Chg = yes
},
simp_sort_depths(SssA,SssA1,Chg1), !.
simp_sort_depths([],[],no) :- !.
simp_sort_depths1([DisjI|DisjsI],[[Max]|DisjsO],[Max|Maxs]) :-
ground(DisjI),
unflatten_op(DisjI,(max),DisjMax1),
Max is DisjMax1,
simp_sort_depths1(DisjsI,DisjsO,Maxs), !.
simp_sort_depths1([DisjI|DisjsI],[DisjI|DisjsO],Maxs) :-
simp_sort_depths1(DisjsI,DisjsO,Maxs), !.
simp_sort_depths1([],[],[]) :- !.
% Par = [DpExOrig,OldLayers,MaxDepth,MinSolutions]
%- calc the NameAu of anti-unifiers of all sorts in Ss,
%- OccIn, OccOut is the binary tree of triples (Ss,AuSs,NameAu)
%- for which hsg already has been called,
%- AuSs may be uninstantiated until the completion of the call,
%- the meaning of a triple is: NameAu sortdef AuSs, rgbv(Ss) = NameAu,
rgbv_t(Par,SssAus,OccVL,OccVT,OccIn,OccOut) :-
trace_write(hsg,rgbv(SssAus)),
rgbv(Par,SssAus,OccVL,OccVT,OccIn,OccOut),
trace_write(hsg,rgbv_exit(SssAus)).
%- no new tasks, terminate
rgbv(_Par,[layer:_L],_OccVL,_OccVT,OccIn,OccIn) :- !.
%- layer border, re-sort
%<*backtrackable*>
rgbv([DpOrig,OldLys|Par],[layer:L|SssAus],OccVL,OccVT,OccI,OccO) :-
sort(SssAus,SssAus1),
join_unifiables(SssAus1,SssAus2),
OldLys1 = [SssAus2|OldLys],
simp_sort_depths_list(OldLys1,OldLys2),
L1 is L + 1,
append(SssAus2,[layer:L1],SssAus3),
trace_write(layer,layer(DpOrig,L1)),
( ground(DpOrig),
OccO = OccI
; rgbv_t([DpOrig,OldLys2|Par],SssAus3,OccVL,OccVT,OccI,OccO)
).
%- loop check
rgbv(Par,[_Ss:_Dp:_DpEx:NameAu|SssAus],OccVL,OccVT,OccIn,OccOut) :-
NameAu sortdef _DefAu,
!,
rgbv_t(Par,SssAus,OccVL,OccVT,OccIn,OccOut).
%- replace sort names by definitions,
%- then distribute "!"
rgbv(Par,[Ss:Dp:DpEx:Au|SssAus],OccVL,OccVT,OccIn,OccOut) :-
replace_defs_star(Ss,SsDef,nil,_Occ,DefAu,_NameAu,true),
% ..._star necessary if sorts are not in head nf
( member(_!_,SsDef),
%: [0!s0+s0!s0*top!top*s0,s(s0)!s1+s0!s0+s1!s1*s1]
flatten_op_list1(SsDef,(!),Ss1),
%: [[0,s0+s0,s0*top,top*s0],[s(s0),s1+s0,s0+s1,s1*s1]]
sort_list(Ss1,Ss2),
%: [[0,s0*top,top*s0,s0+s0],[s(s0),s1*s1,s0+s1,s1+s0]]
group_cr_sorts(Ss2,OccVT,Groups),
%: OccVL = [([0,s(0)],var,v1),([s(0),0],var,v2)]
%: Groups = [[0,s(s0)],[s0*top,s1*s1],[top*s0,s1*s1],
%: [s0+s0,s0+s1],[s0+s0,s1+s0]]
rgbv_H1_list(Groups,DefL,SssAus1,Dp,DpDjs,OccVL,OccIn,Occ1),
{ unflatten_op(DefL,(!),DefAu)
; DefAu = bottom
},
{ member([],DpDjs),
DpEx = [[]],
Dp = 1
; sort_list(DpDjs,DpDjs1),
sort(DpDjs1,DpEx)
},
assert(Au sortdf DefAu),
append(SssAus,SssAus1,SssAus2),
rgbv_t(Par,SssAus2,OccVL,OccVT,Occ1,OccOut)
; not member(_!_,SsDef), %% ???
append(SssAus,[SsDef:DefAu],SssAus1), %% ???
rgbv_t(Par,SssAus1,OccVL,OccVT,Occ1,OccOut) %% ???
).
%- no tasks, terminate
rgbv_t(_Par,[],_OccVL,_OccVT,OccIn,OccIn) :- !.
rgbv_H1_list([Ss|Sss],Defs,SssO,Dp,DpDjs,OccVL,OccIn,OccOut) :-
rgbv_H1(Ss,Defs1,SssO1,DpDj,OccVL,OccIn,Occ1),
rgbv_H1_list(Sss,Defs2,SssO2,Dp,DpDjs1,OccVL,Occ1,OccOut),
append(Defs1,Defs2,Defs),
append(SssO1,SssO2,SssO),
{ member(Dp1,DpDj),
Dp1 == Dp, %% skip direct recursive sort
DpDjs = DpDjs1
; member(Dp1,DpDj),
Dp1 >= /*inf*/999000, %% skip empty sort
DpDjs = DpDjs1
; DpDjs = [DpDj|DpDjs1]
}, !.
rgbv_H1_list([],[],[],_Dp,[],_OccVL,OccIn,OccIn) :- !.
%- decompose common constructor
rgbv_H1(Ss,[Def],SssO,DpCjs,_OccVL,OccIn,OccOut) :-
%: Ss = [s0*top,s1*s1]
strip_common_constructor(Ss,Cr,SsArgs),
%: Cr = (*)
%: SsArgs = [[s0,s1],[top,s1]]
assign_sort_name_list(SsArgs,Names,SssO,DpCjs,OccIn,OccOut),
%: SssO = [[s0,s1]:A:_:sort6,[top,s1]:B:_:sort7]
%: DpCjs = [A,B]
%: Names = [sort6,sort7]
Def =.. [Cr|Names], !.
%- different constructors,
%- return a disjunction of all admitted variables whose terms are in Ss
rgbv_H1(Ss,Vs,[],[],OccVL,OccIn,OccIn) :-
bagof(V,VTs^(
member((VTs,var,V),OccVL),
inhm_list(Ss,VTs)
),Vs), !.
%- different constructors,
%- no admitted variables whose terms are in Ss, return bottom
rgbv_H1(_Ss,[],[],[/*inf*/999999],_OccVL,OccIn,OccIn) :- !.
% get the sort name Name of Ss from BTin,
% or create and enter a new sort name for Ss
assign_sort_name(Ss,Name,SsO,Dp,BTin,BTout) :-
enter_into_bbt((Ss,_Def,Dp,Name),BTin,BTout),
{ nonvar(Name)
; new_name(sort,Name)
},
SsO = (Ss:Dp:_DpEx:Name), !.
assign_sort_name_list([Ss|Sss],[Nm|Nms],[SsO|SssO],[DC|DCs],BTi,BTo) :-
assign_sort_name(Ss,Nm,SsO,DC,BTi,BT1),
assign_sort_name_list(Sss,Nms,SssO,DCs,BT1,BTo), !.
assign_sort_name_list([],[],[],[],BTin,BTin) :- !.
% %- catch disjunctions (necessary if sorts are not in head normal form)
% rgbv(Par,[Ss:Au|SssAus],OccVL,OccVT,OccIn,OccOut) :- %% ???
% distribute1(Ss,SsDist,true),
% make_varlist_of_same_length(SsDist,AusDist),
% merge_lists(SsDist,(:),AusDist,SssAus2),
% %sort(SssAus2,SssAus3),
% append(SssAus,SssAus2,SssAus1),
% rgbv_t(Par,SssAus1,OccVL,OccVT,OccIn,OccOut),
% unflatten_op(AusDist,(!),Au), !.
%
% %- decompose common constructor
% rgbv(Par,[Ss:Au|SssAus],OccVL,OccVT,OccIn,OccOut) :- %% ???
% strip_common_constructor(Ss,Cr,SsArgs),
% make_varlist_of_same_length(SsArgs,AuArgs),
% Au =.. [Cr|AuArgs],
% merge_lists(SsArgs,(:),AuArgs,SssAus2),
% %sort(SssAus2,SssAus3),
% append(SssAus,SssAus2,SssAus1),
% rgbv_t(Par,SssAus1,OccVL,OccVT,OccIn,OccOut), !.
%
% %- different constructors,
% %- return a disjunction of all admitted vars whose terms are in Ss
% rgbv(Par,[Ss:Au|SssAus],OccVL,OccVT,OccIn,OccOut) :- %% ???
% bagof(V,VTs^(
% member((VTs,var,V),OccVL),
% inhm_list(Ss,VTs)
% ),Vs),
% unflatten_op(Vs,(!),Au),
% rgbv_t(Par,SssAus,OccVL,OccVT,OccIn,OccOut), !.
%
% %- different constructors,
% %- no admitted variables whose terms are in Ss, return bottom
% rgbv(Par,[_Ss:bottom|SssAus],OccVL,OccVT,OccIn,OccOut) :- %% ???
% rgbv_t(Par,SssAus,OccVL,OccVT,OccIn,OccOut), !.
% calc the sort Au of anti-unifiers of all sorts in Ss,
% defining new sorts recursively as needed,
% OccVL is a list containing all admitted variables
rsgv(MaxDepth,Ss,OccVL,Au) :-
sort(OccVL,OccVL1),
build_occ_var_trie(OccVL1,[],OccVT),
rsg_t(MaxDepth,Ss,Au1,OccVL1,OccVT,nil,OccBT),
conv_bbtlist_to_list([OccBT],Occ),
split_sort_var_defs(Occ,SortDefs1,_VarDefs1),
extract_defs_from_occ(SortDefs1,SortDefs2,xxx,_Memo),
Au = Au1,
sort(SortDefs2,SortDefs4),
trace_write(prof,au(Ss)=Au),
assert_list(SortDefs4), !.
%calc_sort_depths, !.
rsgv_list(Dp,[Ss|Sss],Occ,[Au|Aus]) :-
rsgv(Dp,Ss,Occ,Au),
rsgv_list(Dp,Sss,Occ,Aus), !.
rsgv_list(_Dp,[],_Occ,[]) :- !.
rsgv_list_list(Dp,[Sss|Ssss],Occ,[Aus|Auss]) :-
rsgv_list(Dp,Sss,Occ,Aus),
rsgv_list_list(Dp,Ssss,Occ,Auss), !.
rsgv_list_list(_Dp,[],_Occ,[]) :- !.
%- calc the NameAu of anti-unifiers of all sorts in Ss,
%- OccIn, OccOut is the binary tree of triples (Ss,AuSs,NameAu)
%- for which hsg already has been called,
%- AuSs may be uninstantiated until the completion of the call,
%- the meaning of a triple is: NameAu sortdef AuSs, rsgv(Ss) = NameAu,
rsg_t(MaxDepth,Ss,Au,OccVL,OccVT,OccIn,OccOut) :-
trace_enter(hsg,rsgv(Ss)),
rsgv(MaxDepth,Ss,Au,OccVL,OccVT,OccIn,OccOut),
trace_leave(hsg,rsgv(Ss) = Au).
%- check cache
rsgv(_MaxDepth,Ss,NameAu,OccVL,_OccVT,OccIn,OccIn) :-
origin_s(NameAu,Ss,OccVL), !.
%- depth check
rsgv(0,_Ss,bottom,_OccVL,_OccVT,OccIn,OccIn) :- !.
%- loop check
rsgv(_MaxDepth,Ss,NameAu,OccVL,_OccVT,OccIn,OccIn) :-
member_bbt((Ss,_DefAu,NameAu),OccIn),
{ nonvar(NameAu)
; new_name(sort,NameAu),
assert(origin_s(NameAu,Ss,OccVL))
}, !.
%- replace sort names by definitions,
%- then distribute "!"
rsgv(MaxDepth,Ss,Au,OccVL,OccVT,OccIn,OccOut) :-
replace_defs_star(Ss,SsDef,OccIn,Occ1,DefAu,NameAu,true),
% ..._star necessary if sorts are not in head nf
MaxDepth1 is MaxDepth - 1,
{ member(_!_,SsDef),
%: [0!s0+s0!s0*top!top*s0,s(s0)!s1+s0!s0+s1!s1*s1]
flatten_op_list1(SsDef,(!),Ss1),
%: [[0,s0+s0,s0*top,top*s0],[s(s0),s1+s0,s0+s1,s1*s1]]
sort_list(Ss1,Ss2),
%: [[0,s0*top,top*s0,s0+s0],[s(s0),s1*s1,s0+s1,s1+s0]]
group_cr_sorts(Ss2,OccVT,Groups),
%: OccVL = [([0,s(0)],var,v1),([s(0),0],var,v2)]
%: Groups = [[0,s(s0)],[s0*top,s1*s1],[top*s0,s1*s1],
%: [s0+s0,s0+s1],[s0+s0,s1+s0]]
rsgv_list(MaxDepth1,Groups,Aus,OccVL,OccVT,Occ1,OccOut),
{ unflatten_op(Aus,(!),DefAu)
; DefAu = bottom
}
; rsgv(MaxDepth1,SsDef,DefAu,OccVL,OccVT,Occ1,OccOut)
},
{ var(NameAu),
new_name(sort,NameAu),
assert(origin_s(NameAu,Ss,OccVL)),
Au = NameAu
; Au = NameAu
}, !.
%- catch disjunctions (necessary if sorts are not in head normal form)
rsgv(MaxDepth,Ss,Au,OccVL,OccVT,OccIn,OccOut) :-
distribute1(Ss,SsDist,true),
rsgv_list(MaxDepth,SsDist,Aus,OccVL,OccVT,OccIn,OccOut),
unflatten_op(Aus,(!),Au), !.
%- decompose common constructor
rsgv(MaxDepth,Ss,Au,OccVL,OccVT,OccIn,OccOut) :-
strip_common_constructor(Ss,Cr,SsArgs),
make_varlist_of_same_length(SsArgs,AuArgs),
Au =.. [Cr|AuArgs],
rsgv_list(MaxDepth,SsArgs,AuArgs,OccVL,OccVT,OccIn,OccOut), !.
%- different constructors,
%- return a disjunction of all admitted variables whose terms are in Ss
rsgv(_MaxDepth,Ss,Au,OccVL,_OccVT,OccIn,OccIn) :-
bagof(V,VTs^(
member((VTs,var,V),OccVL),
inhm_list(Ss,VTs)
),Vs),
unflatten_op(Vs,(!),Au), !.
%- different constructors,
%- no admitted variables whose terms are in Ss, return bottom
rsgv(_MaxDepth,_Ss,bottom,_OccVL,_OccVT,OccIn,OccIn) :- !.
rsgv_list(MaxDepth,[Ss|Sss],[Au|Aus],OccVL,OccVT,OccIn,OccOut) :-
rsg_t(MaxDepth,Ss,Au,OccVL,OccVT,OccIn,Occ1),
rsgv_list(MaxDepth,Sss,Aus,OccVL,OccVT,Occ1,OccOut), !.
rsgv_list(_MaxDepth,[],[],_OccVL,_OccVT,OccIn,OccIn) :- !.
% calc the infimum Inf of sorts S and T
inf(_S,bottom,bottom) :- !.
inf(bottom,_T,bottom) :- !.
inf(S,top,S) :- !.
inf(top,T,T) :- !.
%- different equivalence classes are always disjoint
inf(S,T,bottom) :-
equiv_class(SC,S),
equiv_class(TC,T),
SC \== TC, !.
%- anti-unify S and T, allowing no variables in the result sort
inf(S,T,Inf) :-
rsgv(/*inf*/999999,[S,T],[],Inf), !.
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %
% %%%%% optimized argument selection %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %
% given a list of variables with origin sorts, compute a search tree
%: build([([0,s(a)],var,v1),([0,b+c],var,v2)],[],[0:[(+):[],s:[]]])
build_occ_var_trie([(Ss,var,_V)|OccVL],OccVTIn,OccVTOut) :-
build_occ_var_trie_H1(Ss,Ss1),
enter_into_trie(Ss1,OccVTIn,OccVT1),
build_occ_var_trie(OccVL,OccVT1,OccVTOut), !.
build_occ_var_trie([],OccVTIn,OccVTIn) :- !.
%: build_occ_var_trie_H1([0,b+c],[0,+])
build_occ_var_trie_H1([S|Ss],[Cr|Crs]) :-
S =.. [Cr|_],
build_occ_var_trie_H1(Ss,Crs), !.
build_occ_var_trie_H1([],[]) :- !.
% main grouping algorithm
group_cr_sorts(Lists,VT,Groups) :-
group_cr_sorts_H1_list(Lists,Listss),
group_cr_sorts1_t(eq,[],Listss,VT,Groups1),
sort(Groups1,Groups), !.
% partition each list in Lists into sublists of terms starting with
% equal constructors
group_cr_sorts_H1_list([List|Lists],[ListP|ListsP]) :-
group_cr_sorts_H1([],List,ListP),
group_cr_sorts_H1_list(Lists,ListsP), !.
group_cr_sorts_H1_list([],[]) :- !.
%: gr([[],[0+0,1+1,2+2,3*3,s(4),s(5),[[0+0,1+1,2+2],[3*3],[s(4),s(5)]])
group_cr_sorts_H1([],[CrSort|CrSorts],ListP) :-
group_cr_sorts_H1([CrSort],CrSorts,ListP), !.
group_cr_sorts_H1([CrS|Grp],[CrSort|CrSorts],ListP) :-
CrS =.. [Cr|_],
CrSort =.. [Cr|_],
group_cr_sorts_H1([CrSort,CrS|Grp],CrSorts,ListP), !.
group_cr_sorts_H1(Grp,[CrSort|CrSorts],[GrpR|ListP]) :-
reverse(Grp,GrpR),
group_cr_sorts_H1([CrSort],CrSorts,ListP), !.
group_cr_sorts_H1(Grp,[],[GrpR]) :-
reverse(Grp,GrpR), !.
group_cr_sorts1_t(Eq,Gr,Listss,VT,GrO) :-
trace_enter(grp,grp(Gr,Listss,VT)),
group_cr_sorts1(Eq,Gr,Listss,VT,GrO),
trace_leave(grp,grp(Gr,Listss,VT) = GrO).
%- join CrSort to current group
group_cr_sorts1(eq,[CrS1s|Gr],[[CrS2s|Ls]|Lss],VT,GrO) :-
CrS1s = [CrS1|_],
CrS2s = [CrS2|_],
CrS1 =.. [Cr|_],
CrS2 =.. [Cr|_],
get_subtrie(VT,Cr,VT1),
group_cr_sorts1_t(eq,[CrS2s,CrS1s|Gr],Lss,VT1,Gr1),
group_cr_sorts1_t(eq,[CrS1s|Gr],[Ls|Lss],VT,Gr2),
append(Gr1,Gr2,GrO), !.
%- output current group
group_cr_sorts1(_Eq,Gr,[],_VT,GrO) :-
reverse(Gr,GrR),
setof(CrSs,member_list12(CrSs,GrR),GrO), !.
%- abort current group due to empty VT
group_cr_sorts1(ne,_Gr,_Listss,[],[]) :- !.
%- abort current group due to empty VT
group_cr_sorts1(eq,[[CrS1|_]|_Gr],[[[CrS2|_]|_Ls]|_Lss],[],[]) :-
CrS1 @< CrS2, !.
%- follow VT
group_cr_sorts1(Eq,[CrS1s|Gr],[[[CrS2|CrS2s]|Ls]|Lss],VT,GrO) :-
CrS2 =.. [Cr|_],
member(Cr:VT1,VT),
group_cr_sorts1_t(ne,[[CrS2|CrS2s],CrS1s|Gr],Lss,VT1,Gr1),
group_cr_sorts1_t(Eq,[CrS1s|Gr],[Ls|Lss],VT,Gr2),
append(Gr1,Gr2,GrO), !.
%- skip CrSorts
group_cr_sorts1(Eq,[CrS1s|Gr],[[_CrS2s|Ls]|Lss],VT,GrO) :-
group_cr_sorts1_t(Eq,[CrS1s|Gr],[Ls|Lss],VT,GrO), !.
%- initialize new group
group_cr_sorts1(_Eq,[],[[[CrS2|CrS2s]|Ls]|Lss],VT,GrO) :-
CrS2 =.. [Cr|_],
get_subtrie(VT,Cr,VT1),
group_cr_sorts1_t(eq,[[CrS2|CrS2s]],Lss,VT1,Gr1),
group_cr_sorts1_t(eq,[],[Ls|Lss],VT,Gr2),
append(Gr1,Gr2,GrO), !.
%- abort current group due to empty CrS2s
group_cr_sorts1(_Eq,_Pre,[[]|_Listss],_VT,[]) :- !.
% split Occ into SortDefs and VarDefs
split_sort_var_defs([(Ss,var,V)|Occ],SortDefs,[([V],V,Ss)|VarDefs]) :-
split_sort_var_defs(Occ,SortDefs,VarDefs), !.
split_sort_var_defs([(Ss,D,N)|Occ],[(Ss,D,N)|SortDefs],VarDefs) :-
split_sort_var_defs(Occ,SortDefs,VarDefs), !.
split_sort_var_defs([],[],[]) :- !.
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %
% %%%%% sort elements enumeration %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %
% enumerate all ground terms Rhs of sort Sort in depth first order,
% iteratively deepening the bound limit
%<*backtrackable*>
%- no bound limit if sort is finite
find_rhs(Sort,Red,Rhs) :-
finite(Sort),
!,
write(’--- enumerating finite ’), write(Sort), nl,
all_groundterms_t(Sort,/*inf*/999999,_,Red,Rhs).
find_rhs(Sort,Red,Rhs) :-
nl, write(’--- enumerating ’), write(Sort), nl,
{ sort_depth(Sort,Dp)
; Dp = 1
},
find_rhs1(Sort,Dp,Red,Rhs).
find_rhs1(Sort,Dp,Red,Rhs) :-
write(’--- new depth bound ’), write(Dp), nl,
all_groundterms_t(Sort,Dp,_,Red,Rhs).
find_rhs1(Sort,Dp,Red,Rhs) :-
Dp1 is Dp + 1,
find_rhs1(Sort,Dp1,Red,Rhs).
% enumerate all ground terms Term of sort Sort
% with max number MaxRepIn of replacements
% of sort names by their definitions,
% enumerate only terms that do not contain instances of any
% redex term in Red,
%<*backtrackable*>
all_groundterms_t(Sort,MaxRepIn,MaxRepOut,Red,Term) :-
trace_enter(all,Sort:MaxRepIn),
all_groundterms(Sort,MaxRepIn,MaxRepOut,Red,Term),
trace_leave(all,Sort : Term).
%- empty sort, cut
all_groundterms(bottom,_MaxRepIn,_MaxRepOut,_Red,_Term) :-
!, fail.
%- sort name, replace by definition
all_groundterms(Sort,MaxRepIn,MaxRepIn,Red,Term) :-
%% dont accumulate sort name
%% replacements on different branches
Sort sortdef SortDef,
!,
sort_depth(Sort,Depth),
MaxRepIn >= Depth,
MaxRepIn1 is MaxRepIn - 1,
all_groundterms_t(SortDef,MaxRepIn1,_MaxRepOut1,Red,Term1),
Term = Term1.
%- yet undeined sort name, ignore
all_groundterms(Sort,MaxRepIn,MaxRepIn,_Red,_Term) :-
atom(Sort),
name(Sort,[115,111,114,116|_Rest]),
!, fail.
%- sort disjunction, try all alternatives
all_groundterms(Sort1!Sort2,MaxRepIn,MaxRepOut,Red,Term) :-
!,
flatten_op(Sort1!Sort2,(!),Sorts),
all_groundterms_list_o(Sorts,MaxRepIn,MaxRepOut,Red,Term).
%- variable, output
all_groundterms(Var,MaxRepIn,MaxRepIn,_Red,Var) :-
atomic(Var),
name(Var,[118|_Nr]), !.
%- constant, output
all_groundterms(Const,MaxRepIn,MaxRepIn,Red,Const) :-
atomic(Const), !,
not member(Const,Red), !.
%- constructor sort, enumerate arguments in lexicographical order
all_groundterms(Sort,MaxRepIn,MaxRepOut,Red,Term) :-
Sort =.. [Cr|Args],
!,
length(Args,L),
check_redices(Cr,Red,Red1),
update_redices(Cr,1,L,Red1,Reds),
check_depth_list(Args,MaxRepIn),
all_groundterms_list(Args,MaxRepIn,MaxRepOut,Reds,Terms),
Term =.. [Cr|Terms].
all_groundterms_list([Sort|Sorts],MRI,MRO,[Red|Reds],[T|Ts]) :-
all_groundterms_t(Sort,MRI,MR1,Red,T),
all_groundterms_list(Sorts,MR1,MRO,Reds,Ts).
all_groundterms_list([],MRI,MRI,[],[]) :- !.
all_groundterms_list_o([Sort|_Sorts],MRI,MRO,Red,Term) :-
all_groundterms_t(Sort,MRI,MRO,Red,Term).
all_groundterms_list_o([_Sort|Sorts],MRI,MRO,Red,Term) :-
all_groundterms_list_o(Sorts,MRI,MRO,Red,Term).
% find first ground term of each sort in Sorts
first_groundterms_t_list([Sort|Sorts],[Term|Terms]) :-
sort_depth(Sort,Depth),
all_groundterms_t(Sort,Depth,_MaxRepOut,[],Term), !,
first_groundterms_t_list(Sorts,Terms), !.
first_groundterms_t_list([],[]) :- !.
first_groundterms_t_list_list([Sorts|Sortss],[Terms|Termss]) :-
first_groundterms_t_list(Sorts,Terms),
first_groundterms_t_list_list(Sortss,Termss), !.
first_groundterms_t_list_list([],[]) :- !.
% for each sort in Sorts return the set of minimal equations
min_eqns_t_list([Sort|Sorts],SMinBBT,Eqns) :-
member_bbt(Sort:MinTerm,SMinBBT),
Sort sortdf SortDef,
{ setof(Term:MinTerm,(
min_lhs_t(SortDef,SMinBBT,Term)
),Eqns1)
; Eqns1 = []
},
min_eqns_t_list(Sorts,SMinBBT,Eqns2),
append(Eqns1,Eqns2,Eqns), !.
min_eqns_t_list([],_SMinBBT,[]) :- !.
% enumerate all minimal ground terms Term of sort Sort,
% i.e., replace sort names by their minimal terms
% which are obtained from SMinBBT
%<*backtrackable*>
min_lhs_t(Sort,SMinBBT,Term) :-
trace_enter(all,Sort),
min_lhs(Sort,SMinBBT,Term),
trace_leave(all,Sort : Term).
%- sort name, return its minimal term
min_lhs(Sort,SMinBBT,Term) :-
Sort sortdef _SortDef,
!,
member_bbt(Sort:Term,SMinBBT), !.
%- sort disjunction, try all alternatives
min_lhs(Sort1!Sort2,SMinBBT,Term) :-
!,
flatten_op(Sort1!Sort2,(!),Sorts),
min_lhs_list_o(Sorts,SMinBBT,Term).
%- variable, output
min_lhs(Var,_SMinBBT,Var) :-
atomic(Var),
name(Var,[118|_Nr]), !.
%- constant, output
min_lhs(Const,_SMinBBT,Const) :-
atomic(Const), !.
%- constructor sort, enumerate arguments in lexicographical order
min_lhs(Sort,SMinBBT,Term) :-
Sort =.. [Cr|Args],
!,
min_lhs_list_a(Args,SMinBBT,Terms),
Term =.. [Cr|Terms].
% enumerate all minimal ground terms for each sort in Sorts
%<*backtrackable*>
min_lhs_list_a([Sort|Sorts],SMinBBT,[T|Ts]) :-
min_lhs_t(Sort,SMinBBT,T),
min_lhs_list_a(Sorts,SMinBBT,Ts).
min_lhs_list_a([],_SMinBBT,[]) :- !.
% enumerate a minimal ground term for some sort in Sorts
%<*backtrackable*>
min_lhs_list_o([Sort|_Sorts],SMinBBT,Term) :-
min_lhs_t(Sort,SMinBBT,Term).
min_lhs_list_o([_Sort|Sorts],SMinBBT,Term) :-
min_lhs_list_o(Sorts,SMinBBT,Term).
% succeed if each sort name in Sorts has a depth less than Depth,
% ignore proper sort expressions in Sorts
check_depth_list([Sort|Sorts],Depth) :-
check_depth(Sort,Depth),
check_depth_list(Sorts,Depth), !.
check_depth_list([],_Depth) :- !.
%- sort name, check depth
check_depth(Sort,Depth) :-
sort_depth(Sort,SortDepth),
!,
SortDepth =< Depth, !.
%- proper sort expression, ignore
check_depth(Sort,_Depth) :-
not (Sort sortdef _Def),
!.
% succeed if Cr(X1,...,Xn) is not contained in RedIn,
% return all redices of RedIn compatible with Cr as RedOut
check_redices(Cr,[R|RedIn],[R|RedOut]) :-
R =.. [Cr|Args],
!,
not var_list(Args),
check_redices(Cr,RedIn,RedOut), !.
check_redices(Cr,[_R|RedIn],RedOut) :-
check_redices(Cr,RedIn,RedOut), !.
check_redices(_Cr,[],[]) :- !.
% update RedIn corresponding to descending along Cr, yielding RedOut
update_redices(_Cr,I,L,_RedIn,[]) :-
I > L, !.
update_redices(Cr,I,L,RedIn,[RedOut|RedsOut]) :-
update_redices1(Cr,I,RedIn,RedOut1),
redices(RedOut2),
append(RedOut1,RedOut2,RedOut3),
sort(RedOut3,RedOut),
I1 is I + 1,
update_redices(Cr,I1,L,RedIn,RedsOut), !.
% get I.th argument term of each redex in RedIn, yielding RedOut,
update_redices1(Cr,I,[RI|RedIn],[RO|RedOut]) :-
RI =.. [Cr|Args],
{ get_ith_elem(Args,I,RO) },
nonvar(RO),
update_redices1(Cr,I,RedIn,RedOut), !.
update_redices1(Cr,I,[_RI|RedIn],RedOut) :-
update_redices1(Cr,I,RedIn,RedOut), !.
update_redices1(_Cr,_I,[],[]) :- !.
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %
% %%%%% sort depth %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %
% calc bottom up N times, where N is the number of sort definitions
calc_sort_depths :-
setof(NewSort:_NewDepth,NewDef^(
NewSort sortdf NewDef,
not sort_depth(NewSort,_NewDepth)
),NewSortsDepths),
{ setof(OldSort:OldDepth,OldDef^(
OldSort sortdf OldDef,
sort_depth(OldSort,OldDepth)
),OldSortsDepths)
; OldSortsDepths = []
},
append(NewSortsDepths,OldSortsDepths,SortsDepths),
conv_list_to_bbt(SortsDepths,SsDsBBT),
calc_sort_depths1_list(SsDsBBT,NewSortsDepths,ExprsN,ExprsO),
length(NewSortsDepths,MaxCycle),
calc_sort_depths5(ExprsN,2,MaxCycle,_ExprsN1,ExprsO1),
append(ExprsO,ExprsO1,ExprsO2),
merge_lists(Sorts2,(:),Depths2,ExprsO2),
merge_lists(Sorts2,(sort_depth),Depths2,ExprsO3),
sort(ExprsO3,ExprsO4),
assert_list(ExprsO4),
write_list(ExprsO4),
calc_sort_depths3(NewSortsDepths),
calc_sort_depths4(NewSortsDepths), !.
%- no new sort defs found
calc_sort_depths :- !.
% set up depth dependency expressions for all sorts in SsDs,
% ExprsO contains all new sorts that have been assigned a depth,
% they have the form Sort:Depth where Depth is ground,
% ExprsN contains the other new sorts,
% they have the form Sort:Depth:[[A,B],[C,D,E],[F]],
% meaning Depth = (A max B) min (C max D max E) min F,
% SsDsBBT contains expressions of the form Sort:Depth
% where Depth is instantiated if known
calc_sort_depths1_list(SsDsBBT,[Sort: /*inf*/999999|SsDs],ExprsN,
[Sort: /*inf*/999999|ExprsO]) :-
Sort sortdf bottom,
trace_write(sd,calc1(Sort,bottom)),
calc_sort_depths1_list(SsDsBBT,SsDs,ExprsN,ExprsO), !.
calc_sort_depths1_list(SsDsBBT,[Sort:Depth|SsDs],ExprsN,ExprsO) :-
Sort sortdf Def,
distribute1([Def],DefL1,_Success),
append_list(DefL1,DefL),
calc_sort_depth1(Sort,SsDsBBT,DefL,Expr),
sort(Expr,Expr1),
{ member([],Expr1),
trace_write(sd,calc1(Sort,const)),
Depth = 1,
ExprsN = ExprsN1,
ExprsO = [Sort:Depth|ExprsO1]
; ExprsN = [Sort:Depth:Expr1|ExprsN1],
ExprsO = ExprsO1
},
calc_sort_depths1_list(SsDsBBT,SsDs,ExprsN1,ExprsO1), !.
calc_sort_depths1_list(_SsDsBBT,[],[],[]) :- !.
calc_sort_depth1(Own,SsDsBBT,[SortExpr|SortExprs],IsExprs) :-
get_leaves(SortExpr,[],_V,_F,_C,_O,Sorts),
calc_sort_depth2(Own,SsDsBBT,Sorts,IsExpr,Rec),
{ Rec = yes,
IsExprs = IsExprs1
; IsExprs = [IsExpr|IsExprs1]
},
calc_sort_depth1(Own,SsDsBBT,SortExprs,IsExprs1), !.
calc_sort_depth1(_Own,_SsDsBBT,[],[]) :- !.
% Rec indicates whether the disjunct corresponding to Sorts is a
% recursion in sort definition, i.e. contains the sort Own,
% such disjuncts can be ignored
calc_sort_depth2(Own,_SsDsBBT,[Own|_Sorts],[],yes) :- !.
calc_sort_depth2(Own,SsDsBBT,[Sort|Sorts],[Depth|IsExpr],Rec) :-
member_bbt(Sort:Depth,SsDsBBT),
calc_sort_depth2(Own,SsDsBBT,Sorts,IsExpr,Rec), !.
%- Sort without depth is empty sort
calc_sort_depth2(_Own,_SsDsBBT,[_Sort|_Sorts],[],yes) :- !.
calc_sort_depth2(_Own,_SsDsBBT,[],[],no) :- !.
% perform Max bottom-up cycles of depth computation,
%- stop if I geq Max
calc_sort_depths5(ExprsI,Max,Max,ExprsI,[]) :- !.
calc_sort_depths5(ExprsI,I,Max,ExprsN,ExprsO) :-
calc_sort_depths6_list(ExprsI,I,Max,ExprsN1,ExprsO1,Change),
trace_write(sd,calc6list(I,Change)),
{ % stop if no change
Change = no,
ExprsN = ExprsN1,
ExprsO = ExprsO1
; I1 is I + 1,
calc_sort_depths5(ExprsN1,I1,Max,ExprsN,ExprsO2),
append(ExprsO1,ExprsO2,ExprsO)
}, !.
% perform one bottom-up cycle of depth computation
% splitting ExprsI into ExprsO, which could be assigned a depth in this
% cycle, and ExprsN, which could only be simplified somewhat,
% Chg is "yes" if at least one sort could be assigned a depth
calc_sort_depths6_list([Sort:Dp:Expr|ExprsI],I,Max,ExprsN,ExprsO,Chg) :-
calc_sort_depths6(Dp,Expr,I,Expr1),
trace_write(sd,calc6(Sort,Dp)),
{ % Dp still uninstantiated, add to incomplete
var(Dp),
ExprsN = [Sort:Dp:Expr1|ExprsN1],
ExprsO = ExprsO1,
Chg = Chg1
; % Dp instantiated, add to complete
ExprsN = ExprsN1,
ExprsO = [Sort:Dp|ExprsO1],
Chg = yes
},
calc_sort_depths6_list(ExprsI,I,Max,ExprsN1,ExprsO1,Chg1), !.
calc_sort_depths6_list([],_I,_Max,[],[],no) :- !.
% try to compute a depth from DisjsI,
% at least, simplify DisjsI to DisjsO
%- all necessary depths available, replace by their maximum
calc_sort_depths6(Dp,[DisjI|DisjsI],I,[[DisjMax]|DisjsO]) :-
ground(DisjI),
unflatten_op(DisjI,(max),DisjMax1),
DisjMax is DisjMax1,
{ % minimum depth in current disjunct, stop search
I is DisjMax + 1,
Dp = I,
DisjsO = []
; % continue search
calc_sort_depths6(Dp,DisjsI,I,DisjsO)
}, !.
%- not all necessary depths available, skip
calc_sort_depths6(Dp,[DisjI|DisjsI],I,[DisjI|DisjsO]) :-
calc_sort_depths6(Dp,DisjsI,I,DisjsO), !.
calc_sort_depths6(_Dp,[],_I,[]) :- !.
% all sorts that still dont have assigned a depth are empty
%- dont change the definition of bottom itself
calc_sort_depths3([bottom:_Depth|SortsDepths]) :-
calc_sort_depths3(SortsDepths), !.
calc_sort_depths3([Sort:Depth|SortsDepths]) :-
var(Depth),
retract(Sort sortdf _SortDef),
assert(Sort sortdf bottom),
assert(sort_depth(Sort,/*inf*/999999)),
calc_sort_depths3(SortsDepths), !.
calc_sort_depths3([_Sort:_Depth|SortsDepths]) :-
calc_sort_depths3(SortsDepths), !.
calc_sort_depths3([]) :- !.
% delete occurrences of empty sorts from other sort defs
%- dont change the definition of bottom
calc_sort_depths4([bottom:_Depth|SortsDepths]) :-
calc_sort_depths4(SortsDepths), !.
calc_sort_depths4([Sort:_Depth|SortsDepths]) :-
Sort sortdf SortDef,
calc_sort_depths4_H1(SortDef,SortDefO),
SortDefO \== SortDef,
retract(Sort sortdf SortDef),
assert(Sort sortdf SortDefO),
calc_sort_depths4(SortsDepths), !.
calc_sort_depths4([_Sort:_Depth|SortsDepths]) :-
calc_sort_depths4(SortsDepths), !.
calc_sort_depths4([]) :- !.
calc_sort_depths4_H1(Var,Var) :-
var(Var), !.
calc_sort_depths4_H1(Sort1!Sort2,SortO) :-
flatten_op(Sort1!Sort2,(!),SortL),
calc_sort_depths4_H1_list(SortL,SortLO),
sort(SortLO,SortLO1),
list_trisection(SortLO1,[bottom],SortLO2,_,_),
{ unflatten_op(SortLO2,(!),SortO)
; SortO = bottom
}, !.
calc_sort_depths4_H1(Sort,bottom) :-
Sort sortdf bottom, !.
calc_sort_depths4_H1(Sort,SortO) :-
Sort =.. [Cr|Args],
calc_sort_depths4_H1_list(Args,ArgsO),
{ member(Bottom,ArgsO),
Bottom == bottom,
SortO = bottom
; SortO =.. [Cr|ArgsO]
}, !.
calc_sort_depths4_H1_list([Sort|Sorts],[SortO|SortsO]) :-
calc_sort_depths4_H1(Sort,SortO),
calc_sort_depths4_H1_list(Sorts,SortsO), !.
calc_sort_depths4_H1_list([],[]) :- !.
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %
% %%%%% sort difference %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %
% calc the difference Diff (= S\T) of sorts S and T,
% defining new sorts recursively as needed
diff(S,T,Diff) :-
flatten_op(T,(!),Ts),
sort(Ts,Ts1),
diff_t(S,Ts1,STs,nil,OccBT),
conv_bbtlist_to_list([OccBT],Occ),
Diff = STs,
OccS = Occ,
extract_defs_from_occ(OccS,DefsS,memo_diff,Memo),
assert_list(DefsS),
calc_sort_depths,
assert_list(Memo), !.
%- calc the difference NameSTs of sorts S and Ts,
%- OccIn, OccOut is the bin tree of triples ([S|Ts],DiffSTs,NameSTs)
%- for which diff already has been called,
%- DiffST may be uninstantiated until the completion of the call,
%- the meaning of a triple is: NameSTs sortdef DiffSTs,
%- S\(T1!...!Tn) = NameSTs, where Ts = [T1,...,Tn] is a sorted list
diff_t(S,Ts,STs,OccIn,OccOut) :-
trace_enter(diff,S\Ts),
diff(S,Ts,STs,OccIn,OccOut),
trace_leave(diff,S\Ts=STs).
%- no difference
diff(S,[],S,OccIn,OccIn) :- !.
diff(S,Ts,STs,OccIn,OccIn) :-
memo_diff(S,Ts,STs), !.
%- loop check
diff(S,Ts,NameSTs,OccIn,OccIn) :-
member_bbt(([S|Ts],_DefSTs,NameSTs),OccIn),
{ nonvar(NameSTs)
; new_name(sort,NameSTs)
}, !.
%- sort disjunction
diff(S1!S2,Ts,STs,OccIn,OccOut) :-
flatten_op(S1!S2,(!),SL),
diff_list2(SL,Ts,STsL,OccIn,OccOut),
unflatten_op(STsL,(!),STs), !.
%- T subsumes S
diff(S,Ts,bottom,OccIn,OccIn) :-
member(S,Ts), !.
%- T is top
diff(_S,Ts,bottom,OccIn,OccIn) :-
member(top,Ts), !.
%- replace sort definitions
diff(S,Ts,STs,OccIn,OccOut) :-
replace_defs([S|Ts],[SDf|TsDf],OccIn,Occ1,DefSTs,NameSTs,true),
!,
flatten_op_list(TsDf,(!),TsDf1),
sort(TsDf1,TsDf2),
diff_t(SDf,TsDf2,DefSTs,Occ1,OccOut),
{ var(NameSTs),
STs = DefSTs
; STs = NameSTs
}, !.
%- constructor sorts
diff(S,Ts,STs,OccIn,OccOut) :-
diff_H1([S],Ts,DiffList),
optimize_diff_list(DiffList,DiffList1),
diff_list(DiffList1,STsL,OccIn,OccOut),
{ unflatten_op(STsL,(!),STs)
; STs = bottom
}, !.
% set up diff calls for constructor case
%: d_H1([a+b],[c+d,e+f],[(a\c\e)+b,(a\c)+(b\f),(a\e)+(b\d),a+(b\d\f)])
diff_H1(Ss,[T|Ts],DiffList) :-
diff_H2(Ss,T,SsT),
diff_H1(SsT,Ts,DiffList), !.
diff_H1(Ss,[],Ss) :- !.
%: diff_H2([a+b],c+d,[(a\c)+b,a+(b\d)])
diff_H2([S|Ss],T,DiffList) :-
diff_H3(S,T,ST),
diff_H2(Ss,T,SsT),
append(ST,SsT,DiffList), !.
diff_H2([],_T,[]) :- !.
%: diff_H3(a+b,c+d,[(a\c)+b,a+(b\d)])
diff_H3(S,T,ST) :-
S =.. [Cr|SArgs],
T =.. [Cr|TArgs],
diff_H4(1,SArgs,TArgs,Cr,ST), !.
%: diff_H3(a+b,c*d,[a+b])
diff_H3(S,_T,[S]) :- !.
%: diff_H4([a,b],[c,d],(+),[(a\c)+b,a+(b\d)])
diff_H4(I,SArgs,[TArgI|TArgs],Cr,[CrI|ST]) :-
get_ith_elem(SArgs,I,SArgI),
replace_ith_elem(SArgs,I,SArgI\TArgI,SArgsI),
CrI =.. [Cr|SArgsI],
I1 is I + 1,
diff_H4(I1,SArgs,TArgs,Cr,ST), !.
diff_H4(_I,_SArgs,[],_Cr,[]) :- !.
% perform optimizations on the diff list
optimize_diff_list(DiffList,DiffListO) :-
optimize_diff_list1(DiffList,DiffList1),
sort(DiffList1,DiffList2),
optimize_diff_list2(DiffList2,[],DiffListO), !.
% apply a\b\b=a\b
%: optimize_diff_lst1([bottom,(a\top)+c,(a\b\c\b)+c],[(a\[b,c])+(c\[])])
optimize_diff_list1([bottom|DiffList],DiffList1) :-
optimize_diff_list1(DiffList,DiffList1), !.
optimize_diff_list1([SCr|DiffList],[SCrO|DiffList1]) :-
SCr =.. [Cr|Args],
optimize_diff_list1_H1(Args,ArgsO),
SCrO =.. [Cr|ArgsO],
optimize_diff_list1(DiffList,DiffList1), !.
%- optimize_diff_list1_H1 failed
optimize_diff_list1([_SCr|DiffList],DiffList1) :-
optimize_diff_list1(DiffList,DiffList1), !.
optimize_diff_list1([],[]) :- !.
% apply a\b\b=a\b, flatten 2nd argument of \
% fail on a\b\a, a\b\top
%: optimize_diff_list1_H1([a\b\c\b,c],[a\[b,c],c\[]])
optimize_diff_list1_H1([Arg|Args],[S\Ts1|ArgsO]) :-
flatten_op(Arg,(\),[S|Ts]),
sort(Ts,Ts1),
not member(S,Ts1),
not member(top,Ts1),
optimize_diff_list1_H1(Args,ArgsO), !.
optimize_diff_list1_H1([],[]) :- !.
% remove elements that are subsumed by others
%: optimize_diff_list2([(a\[b,c])+(c\[]),(a\[b])+(c\[])],[],[(a\b)+c])
optimize_diff_list2([SCr|DfListIn],DfListMax,DfListOut) :-
SCr =.. [Cr|Args],
diff_subsumed(Cr,Args,DfListMax),
optimize_diff_list2(DfListIn,DfListMax,DfListOut), !.
optimize_diff_list2([SCr|DfListIn],DfListMax,DfListOut) :-
SCr =.. [Cr|Args],
diff_subsumed(Cr,Args,DfListIn),
optimize_diff_list2(DfListIn,DfListMax,DfListOut), !.
optimize_diff_list2([SCr|DfListIn],DfListMax,DfListOut) :-
optimize_diff_list2(DfListIn,[SCr|DfListMax],DfListOut), !.
optimize_diff_list2([],DfListMax,DfListMax) :- !.
% succeed if Cr(Args) is subsumed by an element of DfList
diff_subsumed(Cr,Args,DfList) :-
member(DfM,DfList),
DfM =.. [Cr|ArgsM],
diff_subsumed_H1(Args,ArgsM), !.
diff_subsumed_H1([S\Ts|Args],[S\TsM|ArgsM]) :-
is_sublist(TsM,Ts),
diff_subsumed_H1(Args,ArgsM), !.
diff_subsumed_H1([],[]) :- !.
% evaluate diff calls for constructor case
diff_list([SCr|Ss],[SCrE|SsE],OccIn,OccOut) :-
SCr =.. [Cr|SArgs],
diff_list1(SArgs,SArgsE,OccIn,Occ1),
SCrE =.. [Cr|SArgsE],
diff_list(Ss,SsE,Occ1,OccOut), !.
diff_list([],[],OccIn,OccIn) :- !.
diff_list1([S\Ts|SArgs],[STs|SArgsE],OccIn,OccOut) :-
diff_t(S,Ts,STs,OccIn,Occ1),
diff_list1(SArgs,SArgsE,Occ1,OccOut), !.
diff_list1([],[],OccIn,OccIn) :- !.
% list extension of diff for sort disjunction case
diff_list2([S|Ss],T,[ST|STs],OccIn,OccOut) :-
diff_t(S,T,ST,OccIn,Occ1),
diff_list2(Ss,T,STs,Occ1,OccOut), !.
diff_list2([],_T,[],OccIn,OccIn) :- !.
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %
% %%%%% sort inhabitance %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %
% succeed if sort T is non-empty
inh(T) :-
inh_t(T,[],[]), !.
inh_t(T,_Occ,_Defs) :-
memo_inh(T,TrueFalse),
!,
TrueFalse = true.
inh_t(T,Occ,Defs) :-
trace_enter(inh,inh(T,Occ)),
inh(T,Occ,Defs),
trace_leave(inh,inh(T,Occ)), !.
inh(bottom,_Occ,_Defs) :-
!, fail.
inh(top,_Occ,_Defs) :- !.
inh(T,Occ,_Defs) :-
member(T,Occ),
!, fail.
inh(T,Occ,Defs) :-
T sortdef TD,
!,
use(T,Defs,Used),
list_trisection([T|Occ],Used,_,OccUsed,_),
{ inh_t(TD,OccUsed,Defs),
assert(memo_inh(T,true)), !
; OccUsed = [T],
assert(memo_inh(T,false)),
fail
}.
inh(T,Occ,Defs) :-
member((_,TD,T1),Defs),
T == T1,
!,
inh_t(TD,[T|Occ],Defs), !.
inh(S ! T,Occ,Defs) :-
!,
flatten_op(S!T,(!),ST1),
sort(ST1,ST),
inh_list_o(ST,Occ,Defs), !.
inh(T,Occ,Defs) :-
!,
T =.. [_Cr|Sorts1],
sort(Sorts1,Sorts),
inh_list(Sorts,Occ,Defs), !.
inh_list([T|Ts],Occ,Defs) :-
inh_t(T,Occ,Defs),
inh_list(Ts,Occ,Defs), !.
inh_list([],_Occ,_Defs) :- !.
inh_list_o([T|_Ts],Occ,Defs) :-
inh_t(T,Occ,Defs), !.
inh_list_o([_T|Ts],Occ,Defs) :-
inh_list_o(Ts,Occ,Defs), !.
% succeed if term I is member of sort T
inhm_t(T,I) :-
trace_enter(inhm,inhm(T,I)),
inhm(T,I),
trace_leave(inhm,inhm(T,I)).
inhm(bottom,_I) :-
!, fail.
inhm(top,_I) :- !.
inhm(T,I) :-
T sortdef TD,
!,
{ memo_inhm(T,I,YN),
!,
YN = yes
; inhm_t(TD,I),
assert(memo_inhm(T,I,yes))
; assert(memo_inhm(T,I,no)),
!, fail
}.
inhm(S!T,I) :-
!,
flatten_op(S!T,(!),ST1),
sort(ST1,ST),
inhm_list_o(ST,I), !.
inhm(T,I) :-
!,
T =.. [Cr|Sorts],
I =.. [Cr|Is],
inhm_list(Sorts,Is), !.
inhm_list([T|Ts],[I|Is]) :-
inhm_t(T,I), !,
inhm_list(Ts,Is), !.
inhm_list([],[]) :- !.
inhm_list_o([T|_Ts],I) :-
inhm_t(T,I), !.
inhm_list_o([_T|Ts],I) :-
inhm_list_o(Ts,I), !.
% succeed if sort S contains no definition cycles,
% i.e., is finite,
% assuming that empty sorts have been replaced by "bottom"
finite(S) :-
finite(S,nil), !.
finite(bottom,_Occ) :- !.
finite(top,_Occ) :-
!, fail.
finite(S ! T,Occ) :-
!,
flatten_op(S!T,(!),ST1),
sort(ST1,ST),
finite_list(ST,Occ), !.
finite(S,Occ) :-
member_bbt(S,Occ),
!, fail.
finite(S,Occ) :-
S sortdef SD,
!,
enter_into_bbt(S,Occ,Occ1),
finite(SD,Occ1), !.
finite(S,Occ) :-
!,
S =.. [_Cr|Ss1],
sort(Ss1,Ss),
finite_list(Ss,Occ), !.
finite_list([S|Ss],Occ) :-
finite(S,Occ), !,
finite_list(Ss,Occ), !.
finite_list([],_Occ) :- !.
% compute the set UsedSet of all sorts that occur directly or
% indirectly in the definition of Sort
use(Sort,_Defs,UsedSet) :-
memo_use(Sort,UsedSet), !.
use(Sort,Defs,UsedSet) :-
use_t(Sort,[],Defs,UsedSet),
assert(memo_use(Sort,UsedSet)), !.
use_list([Sort|Sorts],Defs,[UsedSet|UsedSets]) :-
use(Sort,Defs,UsedSet),
use_list(Sorts,Defs,UsedSets), !.
use_list([],_Defs,[]) :- !.
use_t(Sort,Occ,Defs,UsedSet) :-
trace_enter(use,use(Sort,Occ)),
use(Sort,Occ,Defs,UsedSet),
trace_leave(use,use(Sort,Occ)=UsedSet), !.
use(Sort,Occ,_Defs,UsedSet) :-
member(Sort,Occ),
sort(Occ,UsedSet), !.
use(Sort,Occ,Defs,UsedSet) :-
atom(Sort),
Sort sortdef SortDef,
use_t(SortDef,[Sort|Occ],Defs,UsedSet), !.
use(Sort,Occ,Defs,UsedSet) :-
atom(Sort),
member((_,SortDef,Sort),Defs),
use_t(SortDef,[Sort|Occ],Defs,UsedSet), !.
use(Sort,Occ,_Defs,Occ) :-
atomic(Sort), !.
use(Sort,Occ,Defs,UsedSet) :-
get_leaves(Sort,Defs,_Vars,_Wars,_Consts,Sorts),
list_trisection(Sorts,Occ,NewSorts,_,_),
use_list(NewSorts,Occ,Defs,UsedSet), !.
use_list([Sort|Sorts],Occ,Defs,UsedSet) :-
use_t(Sort,Occ,Defs,UsedSet1),
use_list(Sorts,UsedSet1,Defs,UsedSet), !.
use_list([],Occ,_Defs,Occ) :- !.
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %
% %%%%% constructor dependent sort generation %%%%%%%%%%%%%%%%%%%%%%%% %
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %
% build the top sort, the sort of reducible terms,
% and the sort of irreducible terms wrt. redices_f,
% all redices have to be linear
init_red :-
calc_top_sort(TopS),
redices_f(Red),
calc_reducible_terms_sort(Red,TopS,RedS),
diff(TopS,RedS,NfS),
calc_sort_depths,
abolish(top_sort,1),
abolish(redices_sort,1),
abolish(normalforms_sort,1),
assert(top_sort(TopS)),
assert(redices_sort(RedS)),
assert(normalforms_sort(NfS)), !.
% build the top sort Sort, considering all variables etc.
calc_top_sort(Sort) :-
new_name(sort,Sort),
setof(Cr/Ar,(
arity(Cr,Ar)
),CrArs),
calc_top_sort1(Sort,CrArs,SortDefL),
sort(SortDefL,SortDefL1),
unflatten_op(SortDefL1,(!),SortDef),
assert(Sort sortdf SortDef), !.
%: calc_top_sort1(top,[+/2,s/1,0/0],[top+top,s(top),0])
calc_top_sort1(Sort,[Cr/Ar|CrArs],[SortExpr|SortExprs]) :-
extend_to_length(Sort,Ar,Sorts),
SortExpr =.. [Cr|Sorts],
calc_top_sort1(Sort,CrArs,SortExprs), !.
calc_top_sort1(_Sort,[],[]) :- !.
% build the sort Sort of all terms reducible wrt. Redices,
% Redices may contain only linear terms
calc_reducible_terms_sort(Redices,Top,Sort) :-
new_name(sort,Sort),
calc_reducible_terms_sort1_list(Redices,Top,SortDefL1),
setof(Cr/Ar,(
arity(Cr,Ar)
),CrArs),
calc_reducible_terms_sort2_list(Sort,Top,CrArs,SortDefL2),
append(SortDefL1,SortDefL2,SortDefL),
unflatten_op(SortDefL,(!),SortDef),
assert(Sort sortdf SortDef), !.
% replace each prolog variable by the sort top,
% redices are assumed to be linear terms
calc_reducible_terms_sort1_list([Red|Reds],Top,[SortExpr|SortExprs]) :-
calc_reducible_terms_sort1(Red,Top,SortExpr),
calc_reducible_terms_sort1_list(Reds,Top,SortExprs), !.
calc_reducible_terms_sort1_list([],_Top,[]) :- !.
%: calc_reducible_terms_sort1(X+s(Y),top,top+s(top))
calc_reducible_terms_sort1(Var,Top,Top) :-
var(Var), !.
calc_reducible_terms_sort1(Redex,Top,SortExpr) :-
Redex =.. [Optr|Opnds],
calc_reducible_terms_sort1_list(Opnds,Top,SortExprs),
SortExpr =.. [Optr|SortExprs], !.
%: calc(red,top,[+/2,s/1,0/0],[red+top,top+red,s(red)])
calc_reducible_terms_sort2_list(Sort,Top,[_Cr/0|CrArs],SortExprs) :-
calc_reducible_terms_sort2_list(Sort,Top,CrArs,SortExprs), !.
calc_reducible_terms_sort2_list(Sort,Top,[Cr/Ar|CrArs],SortExprs) :-
extend_to_length(Top,Ar,Tops),
calc_reducible_terms_sort2(Sort,Tops,Cr,1,Ar,SortExprs1),
calc_reducible_terms_sort2_list(Sort,Top,CrArs,SortExprs2),
append(SortExprs1,SortExprs2,SortExprs), !.
calc_reducible_terms_sort2_list(_Sort,_Top,[],[]) :- !.
%: calc_reducible_terms_sort2(red,[top,top],(+),1,2,[red+top,top+red])
calc_reducible_terms_sort2(Sort,Tops,Cr,Ar,Ar,[SortExpr]) :-
replace_ith_elem(Tops,Ar,Sort,TopsS),
SortExpr =.. [Cr|TopsS], !.
calc_reducible_terms_sort2(Sort,Tops,Cr,I,Ar,[SortExpr|SortExprs]) :-
replace_ith_elem(Tops,I,Sort,TopsS),
SortExpr =.. [Cr|TopsS],
I1 is I + 1,
calc_reducible_terms_sort2(Sort,Tops,Cr,I1,Ar,SortExprs), !.
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %
% %%%%% variable sorts %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %
% generate the sort of all terms t with Min subset vars(t) subset Max
generate_var_sort(Min,Max,Sort) :-
var_sort_name(Min,Max,Sort), !.
generate_var_sort([],Max,Sort) :-
new_name(sort,Sort),
assert(var_sort_name([],Max,Sort)),
setof(is_cr(Cr,Ar),arity(Cr,Ar),AllCrs),
generate_var_sort_H1(AllCrs,Sort,CrSorts),
append(Max,CrSorts,SortDef1),
sort(SortDef1,SortDef2),
unflatten_op(SortDef2,(!),SortDef),
assert(Sort sortdef SortDef), !.
generate_var_sort([V],Max,Sort) :-
new_name(sort,Sort),
assert(var_sort_name([V],Max,Sort)),
setof(Ar,Cr^(
arity(Cr,Ar),
Ar > 0
),Arities),
setof(CrSort,Ar^Part^Parts^Cr^CrArgs^(
member(Ar,Arities),
all_set_partitions([V],Ar,Parts),
member(Part,Parts),
arity(Cr,Ar),
generate_var_sort_list1(Part,Max,CrArgs),
CrSort =.. [Cr|CrArgs]
),CrSorts),
sort([V|CrSorts],SortDef1), % <---- include V
unflatten_op(SortDef1,(!),SortDef),
assert(Sort sortdef SortDef), !.
generate_var_sort(Min,Max,Sort) :-
new_name(sort,Sort),
assert(var_sort_name(Min,Max,Sort)),
setof(Ar,Cr^(
arity(Cr,Ar),
Ar > 0
),Arities),
setof(CrSort,Ar^Part^Parts^Cr^CrArgs^(
member(Ar,Arities),
all_set_partitions(Min,Ar,Parts),
member(Part,Parts),
arity(Cr,Ar),
generate_var_sort_list1(Part,Max,CrArgs),
CrSort =.. [Cr|CrArgs]
),CrSorts),
sort(CrSorts,SortDef1), % <----
unflatten_op(SortDef1,(!),SortDef),
assert(Sort sortdef SortDef), !.
generate_var_sort_list1([Min|Mins],Max,[Sort|Sorts]) :-
generate_var_sort(Min,Max,Sort),
generate_var_sort_list1(Mins,Max,Sorts), !.
generate_var_sort_list1([],_Max,[]) :- !.
%- dont include variables
generate_var_sort_H1([is_cr(Cr,0)|AllCrs],Sort,CrSorts) :-
{ name(Cr,[118|_]) % "v"
; name(Cr,[119|_]) % "w"
},
generate_var_sort_H1(AllCrs,Sort,CrSorts), !.
generate_var_sort_H1([is_cr(Cr,Ar)|AllCrs],Sort,[CrSort|CrSorts]) :-
extend_to_length(Sort,Ar,Args),
CrSort =.. [Cr|Args],
generate_var_sort_H1(AllCrs,Sort,CrSorts), !.
generate_var_sort_H1([],_Sort,[]) :- !.
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %
% %%%%% term evaluation %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %
% evaluate Term according to the equations for non-constructor-functions
%- pure constructor term
eval_term_t(Term,Term) :-
get_leaves(Term,[],_V,[],_C,_O,_S), !.
eval_term_t(Term,TermE) :-
trace_enter(eval,Term),
eval_term(Term,TermE),
trace_leave(eval,TermE), !.
%- non-constructor function at top
eval_term(Term,TermE) :-
Term =.. [F|Args],
is_function(F),
eval_term_list(Args,Args1),
Term1 =.. [F|Args1],
{ def Lhs=Rhs,
try_rewrite(Term1,Lhs,Rhs,Term2),
eval_term_t(Term2,TermE)
; TermE = Term1
}, !.
%- constructor at top
eval_term(Term,TermE) :-
Term =.. [Cr|Args],
eval_term_list(Args,ArgsE),
TermE =.. [Cr|ArgsE], !.
eval_term_list([Term|Terms],[TermE|TermsE]) :-
eval_term_t(Term,TermE),
eval_term_list(Terms,TermsE), !.
eval_term_list([],[]) :- !.
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %
% %%%%% sort simplification %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %
% simplify a list Sorts of sorts and a list TOcc of sort definitions
% TOcc is a list of triples (_,TDef,T)
simplify_sorts_and_defs(Sorts,SortsS,TOcc,TOccS) :-
contract_sortdef_cycles(Sorts,Sorts0,TOcc,TOcc0),
simplify_sort1(TOcc0,TOcc1),
simplify_sort2([],TOcc1,TOcc2),
simplify_sort3_list(Sorts0,Sorts3,TOcc2),
simplify_sort4_list(Sorts3,Sorts4),
Use = not_needed,
simplify_sort5(Use,[],TOcc2,TOcc5),
simplify_sort6_list(TOcc5,Sorts4,Sorts6),
SortsS = Sorts6,
TOccS = TOcc5, !.
% contract dead cycles in sort definitions
contract_sortdef_cycles(Sorts,SortsC,TOcc,TOccC) :-
split_contains_vars(Sorts,Sorts1,Sorts2),
split_contains_vars(TOcc,TOcc1,TOcc2),
contract_sortdef_cycles1(TOcc2,TOcc3,Subst),
apply_subst_c(Sorts2,Subst,Sorts3),
append(Sorts1,Sorts3,SortsC),
append(TOcc1,TOcc3,TOccC), !.
contract_sortdef_cycles1(TOcc,TOccC,Subst) :-
find_sortdef_cycle(TOcc,Cycle),
contract_sortdef_cycle2(TOcc,Cycle,Cycle,NewDef1),
contract_sortdef_cycle3(TOcc,Cycle,Subst1),
{ NewDef1 = [],
NewDef2 = bottom
; sort(NewDef1,NewDef2),
unflatten_op(NewDef2,(!),NewDef3)
},
apply_subst_c(NewDef3,Subst1,NewDef),
contract_sortdef_cycle4(TOcc,Cycle,Subst1,NewDef,TOcc1),
contract_sortdef_cycles1(TOcc1,TOccC,Subst2),
append(Subst2,Subst1,Subst), !.
contract_sortdef_cycles1(TOcc,TOcc,[]) :- !.
% find a dead sortdef cycle in TOcc,
% return a list Cycle of its member sort names
find_sortdef_cycle(TOcc,Cycle) :-
member((_,_TDef,T),TOcc),
find_sortdef_cycle1(T,TOcc,[],Cycle), !.
find_sortdef_cycle1(T,_TOcc,CycleIn,CycleOut) :-
try_get_prefix_to(CycleIn,T,CycleOut), !.
find_sortdef_cycle1(T,TOcc,CycleIn,CycleOut) :-
member((_,TDef,T),TOcc),
flatten_op(TDef,(!),TDefF),
member(T1,TDefF),
find_sortdef_cycle1(T1,TOcc,[T|CycleIn],CycleOut), !.
% set up the contracted new sort definition for the cycle
contract_sortdef_cycle2(TOcc,[TName|TNames],Cycle,NewDef) :-
member((_,TDef,TName),TOcc),
flatten_op(TDef,(!),TDefF),
contract_sortdef_cycle2_H1(TDefF,Cycle,NewDef1),
contract_sortdef_cycle2(TOcc,TNames,Cycle,NewDef2),
append(NewDef1,NewDef2,NewDef), !.
contract_sortdef_cycle2(_TOcc,[],_Cycle,[]) :- !.
contract_sortdef_cycle2_H1([TExpr|TDefF],Cycle,NewDef) :-
member(TExpr,Cycle),
contract_sortdef_cycle2_H1(TDefF,Cycle,NewDef), !.
contract_sortdef_cycle2_H1([TExpr|TDefF],Cycle,[TExpr|NewDef]) :-
contract_sortdef_cycle2_H1(TDefF,Cycle,NewDef), !.
contract_sortdef_cycle2_H1([],_Cycle,[]) :- !.
% set up the contracting substitution for the cycle
contract_sortdef_cycle3(_TOcc,[NewSort|Cycle],Subst) :-
extend_to_same_length(NewSort,Cycle,Range),
merge_lists(Cycle,(:=),Range,Subst), !.
% do the contracting replacement
% TD=TDef, TN=TName, ND=NewDef, NN=NewName, TO=TOcc, Cy=Cycle, Sb=Subst
contract_sortdef_cycle4([(X,_TD,NN)|TO],[NN|Cy],Sb,ND,[(X,ND,NN)|TOC]):-
contract_sortdef_cycle4(TO,[NN|Cy],Sb,ND,TOC), !.
contract_sortdef_cycle4([(X,_TD,TN)|TO],[NN|Cy],Sb,ND,[(X,NN,TN)|TOC]):-
member(TN,Cy),
contract_sortdef_cycle4(TO,[NN|Cy],Sb,ND,TOC), !.
contract_sortdef_cycle4([(X,TD,TN)|TO],[NN|Cy],Sb,ND,[(X,TDC,TN)|TOC]):-
apply_subst_c(TD,Sb,TDC),
contract_sortdef_cycle4(TO,[NN|Cy],Sb,ND,TOC), !.
contract_sortdef_cycle4([],[_NN|_Cy],_Sb,_ND,[]) :- !.
% apply simplifies-laws in defs
simplify_sort1([(X,D,T)|TOs],[(X,DS,T)|TOsS]) :-
simplify_sort4(D,DS),
simplify_sort1(TOs,TOsS), !.
simplify_sort1([],[]) :- !.
% unfold trivial defs (bottom,SortName,Constant) in defs
simplify_sort2(TOccL,[(X,TD,T)|TOccR],TOccS) :-
atomic(TD),
nonvar(T),
apply_subst_c(TOccL,[T := TD],TOccL1),
apply_subst_c(TOccR,[T := TD],TOccR1),
simplify_sort2([(X,TD,T)|TOccL1],TOccR1,TOccS), !.
simplify_sort2(TOccL,[(X,TD,T)|TOccR],TOccS) :-
simplify_sort2([(X,TD,T)|TOccL],TOccR,TOccS), !.
simplify_sort2(TOccL,[],TOccL) :- !.
% unfold trivial defs in sorts
simplify_sort3_list(Sorts,SortsS,[(_,TD,T)|TOcc]) :-
atomic(TD),
nonvar(T),
apply_subst_c(Sorts,[T := TD],Sorts1),
simplify_sort3_list(Sorts1,SortsS,TOcc), !.
simplify_sort3_list(Sorts,SortsS,[_|TOcc]) :-
simplify_sort3_list(Sorts,SortsS,TOcc), !.
simplify_sort3_list(Sorts,Sorts,[]) :- !.
simplify_sort4(Sort,SortS) :-
simplify_sort4_H1(Sort,SortS), !.
simplify_sort4_list([Sort|Sorts],[SortS|SortsS]) :-
simplify_sort4(Sort,SortS),
simplify_sort4_list(Sorts,SortsS), !.
simplify_sort4_list([],[]) :- !.
simplify_sort4_H1(Sort1!Sort2,SortS) :-
flatten_op(Sort1!Sort2,(!),SortF),
simplify_sort4_list(SortF,SortF1),
sort(SortF1,SortF2),
simplify_sort4_H2(SortF2,SortF3),
{ unflatten_op(SortF3,(!),SortS)
; SortS = bottom
}, !.
simplify_sort4_H1(Sort,SortS) :-
Sort =.. [Optr|Opnds],
simplify_sort4_H1_list(Opnds,OpndsS),
Sort1 =.. [Optr|OpndsS],
{ simplifies_sort(Sort1,SortS)
; SortS = Sort1
}, !.
simplify_sort4_H1(Sort,Sort) :- !.
simplify_sort4_H1_list([Sort|Sorts],[SortS|SortsS]) :-
simplify_sort4_H1(Sort,SortS),
simplify_sort4_H1_list(Sorts,SortsS), !.
simplify_sort4_H1_list([],[]) :- !.
simplify_sort4_H2([bottom|Sorts],SortsS) :-
simplify_sort4_H2(Sorts,SortsS), !.
simplify_sort4_H2([Sort|Sorts],[Sort|SortsS]) :-
simplify_sort4_H2(Sorts,SortsS), !.
simplify_sort4_H2([],[]) :- !.
simplifies_sort(Fbottom,bottom) :-
Fbottom =.. [_F|Args],
member(bottom,Args), !.
% fold defs in defs
simplify_sort5(Use,TOccL,[(X,TD,T)|TOccR],TOccS) :-
( member((_,SortDefFold,SortFold),TOccL)
; member((_,SortDefFold,SortFold),TOccR)
),
nonvar(SortDefFold),
nonvar(SortFold),
not atomic(SortDefFold),
apply_subst_c(TD,[SortDefFold:=SortFold],TD1),
TD \== TD1,
reverse(TOccL,TOccL1),
append(TOccL1,TOccR,TOcc),
simplify_sort5(Use,[],[(X,TD1,T)|TOcc],TOccS), !.
simplify_sort5(Use,TOccL,[(X,TD,T)|TOccR],TOccS) :-
simplify_sort5(Use,[(X,TD,T)|TOccL],TOccR,TOccS), !.
simplify_sort5(_Use,TOccL,[],TOccL) :- !.
% fold defs in sorts
simplify_sort6_list(SortOcc,[Sort|Sorts],[SortS|SortsS]) :-
member((_,SortDefFold,SortFold),SortOcc),
nonvar(SortDefFold),
nonvar(SortFold),
not atomic(SortDefFold),
apply_subst_c(Sort,[SortDefFold:=SortFold],Sort1),
Sort \== Sort1,
simplify_sort6_list(SortOcc,[Sort1|Sorts],[SortS|SortsS]), !.
simplify_sort6_list(SortOcc,[Sort|Sorts],[Sort|SortsS]) :-
simplify_sort6_list(SortOcc,Sorts,SortsS), !.
simplify_sort6_list(_SortOcc,[],[]) :- !.
% eliminate each variable that occurs at exactly the same places
% or a subset of another one
%: simplify_variables(v1!v2!(v3!v4)*s9*(v3!v4),v1!v3*s9*v3)
simplify_variables(Sort,SortS) :-
simplify_variables_H1(1,_O,Sort,Classes),
sort(Classes,Classes1),
simplify_variables_H3(Classes1,xxx,[],Classes2),
sort(Classes2,[[]:xxx|Classes3]),
simplify_variables_H4(Classes3,_Classes4,ElimVars1),
ElimVars = ElimVars1,
simplify_variables_H5(Sort,ElimVars,SortS), !.
% get classes of variables that occur simultaneously,
% i.e. connected by "!", in Sort
%: si(1,4,(v1!v2!(v3!v4)*s9*(v3!v4))+[],[v1:1,v2:1,v3:2,v4:2,v3:3,v4:3])
simplify_variables_H1(I,O,Sort1 ! Sort2,Classes) :-
flatten_op(Sort1!Sort2,(!),SortF),
sort(SortF,SortF1),
simplify_variables_H2(I,SortF1,VarsF1,ExprsF1),
I1 is I + 1,
simplify_variables_H1_list(I1,O,ExprsF1,Classes1),
append(VarsF1,Classes1,Classes), !.
simplify_variables_H1(I,O,Sort,Classes) :-
Sort =.. [_Optr|Opnds],
simplify_variables_H1_list(I,O,Opnds,Classes), !.
simplify_variables_H1_list(I,O,[Sort|Sorts],Classes) :-
simplify_variables_H1(I,M,Sort,Classes1),
simplify_variables_H1_list(M,O,Sorts,Classes2),
append(Classes1,Classes2,Classes), !.
simplify_variables_H1_list(I,I,[],[]) :- !.
% separate Sorts into Vars and Exprs, all Vars beginning with "v"
simplify_variables_H2(I,[Var|Sorts],[Var:I|Vars],Exprs) :-
atom(Var),
name(Var,[118|_Nr]),
simplify_variables_H2(I,Sorts,Vars,Exprs), !.
simplify_variables_H2(I,[Expr|Sorts],Vars,[Expr|Exprs]) :-
simplify_variables_H2(I,Sorts,Vars,Exprs), !.
simplify_variables_H2(_I,[],[],[]) :- !.
% collect classes of occurrences of each variable
%: simplify_variables_H3([v1:1,v2:1,v3:2,v3:3,v4:2,v4:3],xxx,[],
%: [[]:xxx,[1]:v1,[1]:v2,[2,3]:v3,[2,3]:v4])
simplify_variables_H3([V:C|Rel],V,Class,Classes) :-
simplify_variables_H3(Rel,V,[C|Class],Classes), !.
simplify_variables_H3([V1:C|Rel],V2,Class,[ClassS:V2|Classes]) :-
sort(Class,ClassS),
simplify_variables_H3(Rel,V1,[C],Classes), !.
simplify_variables_H3([],V,Class,[ClassS:V]) :-
sort(Class,ClassS), !.
% calculate all variables whose occurrences are equal to that
% of another, calculate the reduces occurrence list with lengths
%: si([[1]:v1,[1]:v2,[2,3]:v3,[2,3]:v4],[1:[1]:v1,2:[2,3]:v3],[v2,v4])
simplify_variables_H4([C:V1,C:V2|Classes],ClassesR,[V2|ElimVars]) :-
simplify_variables_H4([C:V1|Classes],ClassesR,ElimVars), !.
simplify_variables_H4([C1:V1,C2:V2|Cl],[L1:C1:V1|ClR],ElimVars) :-
length(C1,L1),
simplify_variables_H4([C2:V2|Cl],ClR,ElimVars), !.
simplify_variables_H4([C:V],[L:C:V],[]) :-
length(C,L), !.
simplify_variables_H4([],[],[]) :- !.
% group variable occurrences in classes by their length
%: si([1:[1]:v1,2:[1,2]:v3],1,[[0]:v0],[[[1]:v1,[0]:v0],[[1,2]:v3]])
simplify_variables_H6([L:C:V|ClIn],L,Cl,ClOut) :-
simplify_variables_H6(ClIn,L,[C:V|Cl],ClOut), !.
simplify_variables_H6([L1:C:V|ClIn],_L2,Cl,[Cl|ClOut]) :-
simplify_variables_H6(ClIn,L1,[C:V],ClOut), !.
simplify_variables_H6([],_L,Cl,[Cl]) :- !.
% calculate all variables whose occurrences form a subset of another,
% occurrences are ordered in classes by their length
%: simplify_variables_H7([[[1]:v1,[0]:v0],[[1,2]:v3]],[v1])
simplify_variables_H7([[C1:V1|Cl1]|Classes],[V1|ElimVars]) :-
member(Cl2,Classes),
member(C2:_V2,Cl2),
is_sublist(C1,C2),
simplify_variables_H7([Cl1|Classes],ElimVars), !.
simplify_variables_H7([[_C1:_V1|Cl1]|Classes],ElimVars) :-
simplify_variables_H7([Cl1|Classes],ElimVars), !.
simplify_variables_H7([[]|Classes],ElimVars) :-
simplify_variables_H7(Classes,ElimVars), !.
simplify_variables_H7([],[]) :- !.
% do the elimination
%: si((v1!v2!(v3!v4)*s9*(v3!v4))+[],[v2,v4],(v1!v3*s9*v3)+[])
simplify_variables_H5(Sort1!Sort2,ElimVars,SortS) :-
flatten_op(Sort1!Sort2,(!),SortF),
list_trisection(SortF,ElimVars,SortF1,_,_),
simplify_variables_H5_list(SortF1,ElimVars,SortF2),
unflatten_op(SortF2,(!),SortS), !.
simplify_variables_H5(Sort,ElimVars,SortS) :-
Sort =.. [Optr|Opnds],
simplify_variables_H5_list(Opnds,ElimVars,OpndsS),
SortS =.. [Optr|OpndsS], !.
simplify_variables_H5_list([Sort|Sorts],ElimVars,[SortS|SortsS]) :-
simplify_variables_H5(Sort,ElimVars,SortS),
simplify_variables_H5_list(Sorts,ElimVars,SortsS), !.
simplify_variables_H5_list([],_ElimVars,[]) :- !.
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %
% %%%%% administration %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %
% remove all empty sorts from Sorts, yielding SortsR
remove_empty_sorts([bottom|Sorts],SortsR) :-
remove_empty_sorts(Sorts,SortsR), !.
remove_empty_sorts([Empty|Sorts],SortsR) :-
Empty sortdf bottom,
remove_empty_sorts(Sorts,SortsR), !.
remove_empty_sorts([Sort|Sorts],[Sort|SortsR]) :-
remove_empty_sorts(Sorts,SortsR), !.
remove_empty_sorts([],[]) :- !.
% replace all sort names in Ss by their definitions as long as not each
% disjunct starts with a constructor
replace_defs_star(Ss,SsDef,OccI,OccO,Def,Name,true) :-
%% link all Def’s and Name’s together
replace_defs(Ss,SsD1,OccI,Occ1,Def,Name,true),
replace_defs_star(SsD1,SsDef,Occ1,OccO,Def,Name,_Succ1), !.
replace_defs_star(Ss,Ss,OccI,OccI,_Def,_Name,false) :- !.
% replace all sort names in Ss by their definitions, yielding SsDef,
% update OccO from OccI,
% Success is true when any definition was actually replaced,
replace_defs(Ss,SsDef,OccI,OccO,Def,Name,true) :-
replace_defs2(Ss,SsDef,SsN,true),
enter_into_bbt((SsN,Def,Name),OccI,OccO), !.
replace_defs(Ss,Ss,OccIn,OccIn,_Def,_Name,false) :- !.
replace_defs2([Sa!Sb|Ss],[SDef|SsDef],[SN|SsN],Success) :-
flatten_op(Sa!Sb,(!),S1),
sort(S1,S2),
unflatten_op(S2,(!),SN),
replace_defs1(S2,S3,Success1),
unflatten_op(S3,(!),SDef),
replace_defs2(Ss,SsDef,SsN,Success2),
calc_or(Success1,Success2,Success), !.
replace_defs2([S|Ss],[SDef|SsDef],[S|SsN],Success) :-
replace_defs1([S],[SDef],Success1),
replace_defs2(Ss,SsDef,SsN,Success2),
calc_or(Success1,Success2,Success), !.
replace_defs2([],[],[],false) :- !.
replace_defs1([T|Ts],[TDef|TDefs],true) :-
T sortdef TDef,
replace_defs1(Ts,TDefs,_Success), !.
replace_defs1([T|Ts],[T|TDefs],Success) :-
replace_defs1(Ts,TDefs,Success), !.
replace_defs1([],[],false) :- !.
% extract sort definitions from occurrence list in range,inf,diff
extract_defs_from_occ([(A,D,N)|Occ],[N sortdf D|Dfs],MName,[Mm|Mms]) :-
nonvar(N),
append(A,[N],AN),
Mm =.. [MName|AN],
extract_defs_from_occ(Occ,Dfs,MName,Mms), !.
extract_defs_from_occ([(_,_D,_N)|Occ],Defs,MName,Memos) :-
extract_defs_from_occ(Occ,Defs,MName,Memos), !.
extract_defs_from_occ([],[],_MName,[]) :- !.
% merge List1 and List2, using Optr, into List
% modes: (>List1,>Optr,>List2,List>), (List1>,Optr>,List2>,>List)
merge_lists([Elem1|List1],Optr,[Elem2|List2],[Elem|List]) :-
Elem =.. [Optr,Elem1,Elem2],
merge_lists(List1,Optr,List2,List), !.
merge_lists([],_Optr,[],[]) :- !.
merge_lists_list([List1|Lists1],Optr,[List2|Lists2],[List|Lists]) :-
merge_lists(List1,Optr,List2,List),
merge_lists_list(Lists1,Optr,Lists2,Lists), !.
merge_lists_list([],_Optr,[],[]) :- !.
%: distribute1(f(a!b,g(c!d)),[f(a,g(c)),f(a,g(d)),f(b,g(c)),f(b,g(d))])
distribute1(S,[S],false) :-
var(S), !.
distribute1(S,SD,true) :-
S = (_S1 ! _S2),
flatten_op(S,(!),SF),
distribute1_list_a(SF,SD,_Success), !.
distribute1(S,SD,Success) :-
S =.. [F|Args],
distribute1_list_c(Args,ArgsD,Success),
distribute1_H1(F,ArgsD,SD), !.
%: distribute1_list_a([a,b,h(c!d)],[a,b,h(c),h(d)])
distribute1_list_a([S|Ss],SSsD,Success) :-
distribute1(S,SD,Success1),
distribute1_list_a(Ss,SsD,Success2),
append(SD,SsD,SSsD),
calc_or(Success1,Success2,Success), !.
distribute1_list_a([],[],false) :- !.
%: distribute1_lst_c([a!b,g(c!d)],[[a,g(c)],[a,g(d)],[b,g(c)],[b,g(d)]])
distribute1_list_c([S|Ss],SSsD,Success) :-
distribute1(S,SD,Success1),
distribute1_list_c(Ss,SsD,Success2),
combine(SD,SsD,SSsD),
calc_or(Success1,Success2,Success), !.
distribute1_list_c([],[[]],false) :- !.
%: distribute1_H1(f,[[a,g(c)],[a,g(d)]],[f(a,g(c)),f(a,g(d))])
distribute1_H1(F,[Args|Argss],[Term|Terms]) :-
Term =.. [F|Args],
distribute1_H1(F,Argss,Terms), !.
distribute1_H1(_F,[],[]) :- !.
%: co([a,b,c],[[1,2],[3]],[[a,1,2],[a,3],[b,1,2],[b,3],[c,1,2],[c,3]])
combine([H1|T1],LL2,L1LL2) :-
combine1(H1,LL2,H1LL2),
combine(T1,LL2,T1LL2),
append(H1LL2,T1LL2,L1LL2), !.
combine([],_LL2,[]) :- !.
%: combine1(a,[[1,2],[3]],[[a,1,2],[a,3]])
combine1(H1,[HL2|TL2],[[H1|HL2]|H1TL2]) :-
combine1(H1,TL2,H1TL2), !.
combine1(_H1,[],[]) :- !.
% read some example instances of Term and return the equations that
% normalize them
%: read_instances(v1+v2,[0+s(0):s(0),s(s(0))+s(0):s(s(s(0)))])
%: input:
%: [0,s(0)].
%: [s(s(0)),s(0)].
%. end.
read_instances(Term,Eqns) :-
get_leaves(Term,[],Vars,_F,_C,_O,_S),
read_subst_list(Vars,Substs),
apply_subst_c_list2(Term,Substs,GndTerms),
eval_term_list(GndTerms,NormalForms),
equiv_class_list(NormalForms,EqClasses),
merge_lists(GndTerms,(:),EqClasses,Eqns), !.
% for each term in Terms, return its equivalence class sort
equiv_class_list([Term|Terms],[EqClass|EqClasses]) :-
equiv_class(Term,EqClass),
equiv_class_list(Terms,EqClasses), !.
equiv_class_list([Term|_Terms],_EqClasses) :-
nl, write(’+++++ cant find equivalence class for ’),
write(Term), nl,
!, abort.
equiv_class_list([],[]) :- !.
% succeed if a variant of Subj is an instance of Pattern
is_instance_118(Subj,Pattern,Subst) :-
is_instance1_118(Subj,Pattern,Subst1),
sort(Subst1,Subst),
is_valid_substitution(Subst), !.
is_instance1_118(Subj,Var,[Var:=Subj]) :-
atomic(Var),
name(Var,[118|_]), !.
is_instance1_118(Subj,Pattern,Subst) :-
Subj =.. [Optr|OpndsS],
Pattern =.. [Optr|OpndsP],
is_instance1_118_list(OpndsS,OpndsP,Subst), !.
is_instance1_118_list([Subj|Subjs],[Pattern|Patterns],Subst) :-
is_instance1_118(Subj,Pattern,Subst1),
is_instance1_118_list(Subjs,Patterns,Subst2),
append(Subst1,Subst2,Subst), !.
is_instance1_118_list([],[],[]) :- !.
% succeed if Subst does not assign different image terms
% to the same variable
is_valid_substitution(Subst) :-
sort(Subst,Subst1),
is_valid_substitution1(Subst1), !.
is_valid_substitution1([X:=_T1,X:=_T2|_Subst]) :-
!, fail.
is_valid_substitution1([_X:=_T1,Y:=T2|Subst]) :-
is_valid_substitution1([Y:=T2|Subst]), !.
is_valid_substitution1([_X:=_T1]) :- !.
is_valid_substitution1([]) :- !.
% succeed if Subj is an instance of Pattern via Subst,
% variables are atoms declared by "is_variable/2"
root_match(Subj,Var,Subst) :-
root_match1(Subj,Var,Subst,SubjVars),
merge_lists(SubstVars,:=,_SubstTerms,Subst),
list_trisection(SubstVars,SubjVars,_,[],_), !.
root_match1(Subj,_Pattern,_,_) :-
var(Subj),
!, fail.
root_match1(Var,Var,[],[Var]) :-
is_variable(Var,_), !.
root_match1(Const,Const,[],[]) :-
atomic(Const), !.
root_match1(Subj,Var,[Var:=Subj],SubjVars) :-
is_variable(Var,_),
get_variables(Subj,SubjVars), !.
root_match1(Subj,Pattern,Subst,SubjVars) :-
Pattern =.. [Optr|PatList],
Subj =.. [Optr|SubjList],
root_match1_list(SubjList,PatList,[],Subst,SubjVars), !.
root_match1_list([Subj|Subjs],[Pat|Pats],SubstI,SubstO,SubjVars) :-
apply_subst(Pat,SubstI,PatSI),
root_match1(Subj,PatSI,SubstA,SubjVarsA),
append(SubstI,SubstA,SubstIA),
root_match1_list(Subjs,Pats,SubstIA,SubstO,SubsjVarsB),
append(SubjVarsA,SubsjVarsB,SubjVars), !.
root_match1_list([],[],SubstI,SubstI,[]) :- ! .
% apply the list of elementary substitutions SubstL to Term,
% yielding TermS,
% SubstL = [S1,...,Sn] denotes Sn * ... * S1,
% does not handle bound variables correctly
% leaves prolog variables unchanged,
% variables are atoms declared by "is_variable/2"
apply_subst(Term,[Subst|SubstL],TermS) :-
apply_subst1(Term,Subst,Term1),
apply_subst(Term1,SubstL,TermS), !.
apply_subst(Term,[],Term) :- !.
%- apply the elementary substitution Subst to Term, yielding TermS
apply_subst1(PrologVar,_Subst,PrologVar) :-
var(PrologVar), !.
apply_subst1(UserVar,(UserVar:=Term),Term) :-
is_variable(UserVar,_), !.
apply_subst1(Atom,_Subst,Atom) :-
atomic(Atom), !.
apply_subst1(Term,Subst,TermS) :-
Term =.. [Optr|TermL],
apply_subst1_list(TermL,Subst,TermSL),
TermS =.. [Optr|TermSL], !.
apply_subst1_list([Term|TermL],Subst,[TermS|TermSL]) :-
apply_subst1(Term,Subst,TermS),
apply_subst1_list(TermL,Subst,TermSL), !.
apply_subst1_list([],_Subst,[]) :- !.
% succeed if the rule Lhs***>Rhs is applicable to Old, yielding New
try_rewrite(Old,Lhs,Rhs,New) :-
root_match(Old,Lhs,Subst),
apply_subst(Rhs,Subst,New), !.
% like apply_subst, but substitute also constants
apply_subst_c(Term,_SubstL,Term) :-
contains_vars(Term), !.
apply_subst_c(Term,SubstL,Term) :-
contains_vars(SubstL), !.
apply_subst_c(Term,SubstL,TermS) :-
apply_subst_c1(Term,SubstL,TermS), !.
apply_subst_c1(Term,[Subst|SubstL],TermS) :-
apply_subst_c2(Term,Subst,Term1),
apply_subst_c1(Term1,SubstL,TermS), !.
apply_subst_c1(Term,[],Term) :- !.
%- apply the elementary substitution Subst to Term, yielding TermS
apply_subst_c2(Lhs,(Lhs:=Rhs),Rhs) :- !.
apply_subst_c2(Term,Subst,TermS) :-
Term =.. [Optr|TermL],
apply_subst_c2_list(TermL,Subst,TermSL),
TermS =.. [Optr|TermSL], !.
apply_subst_c2_list([Term|TermL],Subst,[TermS|TermSL]) :-
apply_subst_c2(Term,Subst,TermS),
apply_subst_c2_list(TermL,Subst,TermSL), !.
apply_subst_c2_list([],_Subst,[]) :- !.
apply_subst_c_list2(Term,[Subst|Substs],[TermS|TermsS]) :-
apply_subst_c(Term,Subst,TermS),
apply_subst_c_list2(Term,Substs,TermsS), !.
apply_subst_c_list2(_Term,[],[]) :- !.
% apply the substitution SubstS in set form to Term, yielding TermS,
% substitute also constants, but not composite terms
apply_subst_sc(Lhs,Subst,Rhs) :-
atomic(Lhs),
member_bbt(Lhs:=Rhs,Subst), !.
apply_subst_sc(Term,Subst,TermS) :-
Term =.. [Optr|TermL],
apply_subst_sc_list(TermL,Subst,TermSL),
TermS =.. [Optr|TermSL], !.
apply_subst_sc_list([Term|TermL],Subst,[TermS|TermSL]) :-
apply_subst_sc(Term,Subst,TermS),
apply_subst_sc_list(TermL,Subst,TermSL), !.
apply_subst_sc_list([],_Subst,[]) :- !.
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %
% %%%%% basic functions %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %
% find a list Parts of all partitions of of Set into L disjoint subsets
all_set_partitions(Set,L,Parts) :-
make_nat_list_of_length(L,Ran),
extend_to_length([],L,Init),
setof(Part,Map^Part1^(
mapping(Set,Ran,Map),
partition_from_mapping(Map,Init,Part1),
sort_list(Part1,Part)
),Parts), !.
% append all lists in Lists, yielding ListsA
append_list(Lists,ListsA) :-
append_list1(Lists,[],ListsA), !.
append_list1([List|Lists],CollectIn,CollectOut) :-
append(CollectIn,List,Collect1),
append_list1(Lists,Collect1,CollectOut), !.
append_list1([],Collect,Collect) :- !.
assert_list([H|T]) :-
assert(H),
assert_list(T), !.
assert_list([]) :- !.
assert_list_list([List|Lists]) :-
assert_list(List),
assert_list_list(Lists), !.
assert_list_list([]) :- !.
%: beautify_output(s(s(s(0)))+s(s(v1)),3+s2(v1))
beautify_output(s(Term),TermB) :-
beautify_output(Term,Term1),
{ integer(Term1), !,
TermB is Term1 + 1
; Term1 = s(Opnd), !,
TermB = s2(Opnd)
; Term1 =.. [S|Opnd],
name(S,[115|ExpN]),
name(Exp,ExpN),
integer(Exp),
Exp1 is Exp + 1,
name(Exp1,Exp1N),
name(S1,[115|Exp1N]),
TermB =.. [S1|Opnd]
; TermB = s(Term1)
}, !.
beautify_output(Term,TermB) :-
Term =.. [Optr|Opnds],
beautify_output_list(Opnds,OpndsB),
TermB =.. [Optr|OpndsB], !.
beautify_output_list([Term|Terms],[TermB|TermsB]) :-
beautify_output(Term,TermB),
beautify_output_list(Terms,TermsB), !.
beautify_output_list([],[]) :- !.
% calculate the or junctor
calc_or(false,false,false).
calc_or(true,_,true).
calc_or(_,true,true).
% calculate the and junctor
calc_and(true,true,true).
calc_and(false,_,false).
calc_and(_,false,false).
% cons each element of L with the corresponding list of LList,
% yielding LLList
cons_list12([H|L],[HList|LList],[[H|HList]|LLList]) :-
cons_list12(L,LList,LLList), !.
cons_list12([],[],[]) :- !.
% succeed if Term contains prolog variables
% dont instantiate anyone of them
contains_vars(Term) :-
var(Term), !.
contains_vars(Term) :-
Term =.. [_Optr|Opnds],
contains_vars_list(Opnds), !.
contains_vars_list([Term|_Terms]) :-
contains_vars(Term), !.
contains_vars_list([_Term|Terms]) :-
contains_vars_list(Terms), !.
% convert each balanced binary tree in BBTs to list form,
% append the lists
conv_bbtlist_to_list([f(L,_Lh,E,_Rh,R)|BBTs],List) :-
conv_bbtlist_to_list([L,[E],R|BBTs],List), !.
conv_bbtlist_to_list([nil|BBTs],List) :-
conv_bbtlist_to_list(BBTs,List), !.
conv_bbtlist_to_list([[E]|BBTs],[E|List]) :-
conv_bbtlist_to_list(BBTs,List), !.
conv_bbtlist_to_list([],[]) :- !.
% convert List to balanced binary tree BBTree
% nodes: f(Left,LeftHg,Val,RightHg,Right), nil
conv_list_to_bbt(List,BBTree) :-
sort(List,ListS),
length(ListS,Lg),
conv_list_to_bbt1(ListS,Lg,BBTree,_Hg), !.
conv_list_to_bbt1([E1],1,f(nil,0,E1,0,nil),1) :- !.
conv_list_to_bbt1([],0,nil,0) :- !.
conv_list_to_bbt1(List,Lg,f(BBTreeL,HgL,V,HgR,BBTreeR),Hg) :-
LgL is Lg // 2,
LgR is Lg - LgL - 1,
conv_list_to_bt2(List,LgL,ListL,V,ListR),
conv_list_to_bbt1(ListL,LgL,BBTreeL,HgL),
conv_list_to_bbt1(ListR,LgR,BBTreeR,HgR),
Hg is max(HgL,HgR) + 1, !.
conv_list_to_bt2([H|T],0,[],H,T) :- !.
conv_list_to_bt2([H|T],LgL,[H|ListL],V,ListR) :-
Lg1 is LgL - 1,
conv_list_to_bt2(T,Lg1,ListL,V,ListR), !.
% enter Elem into balanced binary tree BBT
%- Elem already in BBT
enter_into_bbt(Elem,f(L,Lh,Elem,Rh,R),f(L,Lh,Elem,Rh,R)) :- !.
%- enter into left subtree
enter_into_bbt(Elem,f(L,_Lh,E,Rh,R),BBT1) :-
Elem @< E,
enter_into_bbt(Elem,L,f(LL,LLh,LE,LRh,LR)),
{ LLh > Rh,
Rh1 is max(LRh,Rh) + 1,
BBT1 = f(LL,LLh,LE,Rh1,f(LR,LRh,E,Rh,R))
; LRh > Rh,
LR = f(LRL,LRLh,LRE,LRRh,LRR),
Lh1 is max(LLh,LRLh) + 1,
Rh1 is max(LRRh,Rh) + 1,
BBT1 = f(f(LL,LLh,LE,LRLh,LRL),Lh1,LRE,Rh1,f(LRR,LRRh,E,Rh,R))
; Lh1 is max(LLh,LRh) + 1,
BBT1 = f(f(LL,LLh,LE,LRh,LR),Lh1,E,Rh,R)
}, !.
%- enter into right subtree
enter_into_bbt(Elem,f(L,Lh,E,_Rh,R),BBT1) :-
E @< Elem,
enter_into_bbt(Elem,R,f(RL,RLh,RE,RRh,RR)),
{ RRh > Lh,
Lh1 is max(Lh,RLh) + 1,
BBT1 = f(f(L,Lh,E,RLh,RL),Lh1,RE,RRh,RR)
; RLh > Lh,
RL = f(RLL,RLLh,RLE,RLRh,RLR),
Lh1 is max(Lh,RLLh) + 1,
Rh1 is max(RLRh,RRh) + 1,
BBT1 = f(f(L,Lh,E,RLLh,RLL),Rh1,RLE,Lh1,f(RLR,RLRh,RE,RRh,RR))
; Rh1 is max(RLh,RRh) + 1,
BBT1 = f(L,Lh,E,Rh1,f(RL,RLh,RE,RRh,RR))
}, !.
%- enter into empty tree
enter_into_bbt(Elem,nil,f(nil,0,Elem,0,nil)) :- !.
enter_into_bbt(A,B,C) :-
dont_backtrack(enter_into_bbt(A,B,C)).
%: enter([a,b,d], [a:[b:[c:[]]],b:[]], [a:[b:[c:[],d:[]]],b:[]])
enter_into_trie(List,TrieIn,TrieOut) :-
enter_into_trie1(List,[],TrieIn,TrieOut), !.
enter_into_trie1([V|Vs],TrieInL,[V:TrieV|TrieInR],TrieOut) :-
enter_into_trie1(Vs,[],TrieV,TrieV1),
reverse(TrieInL,TrieInL1),
append(TrieInL1,[V:TrieV1|TrieInR],TrieOut), !.
enter_into_trie1([V1|Vs],TrieInL,[V2:TrieV2|TrieInR],TrieO) :-
V2 @< V1,
enter_into_trie1([V1|Vs],[V2:TrieV2|TrieInL],TrieInR,TrieO), !.
enter_into_trie1([V1|Vs],TrieInL,[V2:TrieV2|TrieInR],TrieOut) :-
V1 @< V2,
enter_into_trie1(Vs,[],[],TrieV1),
reverse(TrieInL,TrieInL1),
append(TrieInL1,[V1:TrieV1,V2:TrieV2|TrieInR],TrieOut), !.
enter_into_trie1([V1|Vs],TrieInL,[],TrieOut) :-
enter_into_trie1(Vs,[],[],TrieV1),
reverse(TrieInL,TrieInL1),
append(TrieInL1,[V1:TrieV1],TrieOut), !.
enter_into_trie1([],[],TrieInR,TrieInR) :- !.
% build a list List2 of length I, each element being Elem
extend_to_length(_Elem,0,[]) :- !.
extend_to_length(Elem,I,[Elem|List]) :-
I1 is I - 1,
extend_to_length(Elem,I1,List), !.
extend_to_length_list(Elem,[Length|Lengths],[List|Lists]) :-
extend_to_length(Elem,Length,List),
extend_to_length_list(Elem,Lengths,Lists), !.
extend_to_length_list(_Elem,[],[]) :- !.
% build a list List2 of same length as List1, each element being Elem
extend_to_same_length(Elem,[_Head1|Tail1],[Elem|Tail2]) :-
extend_to_same_length(Elem,Tail1,Tail2), !.
extend_to_same_length(_Elem,[],[]) :- !.
extend_to_same_length_list(Elem,[List1|Lists1],[List2|Lists2]) :-
extend_to_same_length(Elem,List1,List2),
extend_to_same_length_list(Elem,Lists1,Lists2), !.
extend_to_same_length_list(_Elem,[],[]) :- !.
% operator Op is associative and commutative,
% enter all its top level operands in Tree into List
flatten_op(Tree,Op,List) :-
Tree =.. [Op|Opnds],
flatten_op_list(Opnds,Op,List), !.
flatten_op(Tree,_Op,[Tree]) :- !.
flatten_op_list([Head|Tail],Op,List) :-
flatten_op(Head,Op,HeadList),
flatten_op_list(Tail,Op,TailList),
append(HeadList,TailList,List), !.
flatten_op_list([],_Op,[]) :- ! .
% flatten each tree in Trees, yielding Lists
flatten_op_list1([Tree|Trees],Op,[List|Lists]) :-
flatten_op(Tree,Op,List),
flatten_op_list1(Trees,Op,Lists), !.
flatten_op_list1([],_Op,[]) :- !.
% return the I’th element of List
get_ith_elem([Head|_Tail],1,Head) :- !.
get_ith_elem([_Head|Tail],I,Elem) :-
I1 is I - 1,
get_ith_elem(Tail,I1,Elem), !.
% calculate a list Vars of all variables in Term starting with "v",
% Fcts of non-constructor functions, Crs of constructors,
% and a list Optrs of all other symbols except sort names
get_leaves(Term,Defs,Vars,Fcts,Crs,Optrs,Sorts) :-
get_leaves1(Term,Defs,Vars1,Fcts1,Crs1,Optrs1,Sorts1),
sort(Vars1,Vars),
sort(Fcts1,Fcts),
sort(Crs1,Crs),
sort(Optrs1,Optrs),
sort(Sorts1,Sorts), !.
get_leaves1(Var,_Defs,[],[],[],[],[]) :-
var(Var), !.
get_leaves1(Var,_Defs,[Var],[],[],[],[]) :-
atom(Var),
name(Var,[118|_Nr]), !.
get_leaves1(Sort,_Defs,[],[],[],[],[Sort]) :-
atomic(Sort),
Sort sortdef _SortDef, !.
get_leaves1(Sort,Defs,[],[],[],[],[Sort]) :-
atomic(Sort),
member((_,_SortDef,Sort),Defs), !.
get_leaves1(Term,Defs,Vars,[Fct|Fcts],Crs,Optrs,Sorts) :-
Term =.. [Fct|Opnds],
is_function(Fct),
get_leaves1_list(Opnds,Defs,Vars,Fcts,Crs,Optrs,Sorts), !.
get_leaves1(Term,Defs,Vars,Fcts,[Cr|Crs],Optrs,Sorts) :-
Term =.. [Cr|Opnds],
arity(Cr,_Ar),
get_leaves1_list(Opnds,Defs,Vars,Fcts,Crs,Optrs,Sorts), !.
get_leaves1(Term,Defs,Vars,Fcts,Crs,[Optr|Optrs],Sorts) :-
Term =.. [Optr|Opnds],
get_leaves1_list(Opnds,Defs,Vars,Fcts,Crs,Optrs,Sorts), !.
get_leaves1_list([Term|Terms],Defs,Vars,Fcts,Crs,Optrs,Sorts) :-
get_leaves1(Term,Defs,Vars1,Fcts1,Crs1,Optrs1,Sorts1),
get_leaves1_list(Terms,Defs,Vars2,Fcts2,Crs2,Optrs2,Sorts2),
append(Vars1,Vars2,Vars),
append(Fcts1,Fcts2,Fcts),
append(Crs1,Crs2,Crs),
append(Optrs1,Optrs2,Optrs),
append(Sorts1,Sorts2,Sorts), !.
get_leaves1_list([],_Defs,[],[],[],[],[]) :- !.
get_max(Int1,Int2,Int1) :-
Int1 >= Int2, !.
get_max(_Int1,Int2,Int2) :- !.
get_min(Int1,Int2,Int1) :-
Int1 =< Int2, !.
get_min(_Int1,Int2,Int2) :- !.
get_subtrie(Trie,E,TrieE) :-
member(E:TrieE,Trie), !.
get_subtrie(_Trie,_E,[]) :- !.
% calculate a list Vars of all variables in Term
% declared by "is_variable/2",
get_variables(Term,Vars) :-
get_variables1(Term,Vars1),
sort(Vars1,Vars), !.
get_variables1(Var,[Var]) :-
atom(Var),
is_variable(Var,_), !.
get_variables1(Term,Vars) :-
Term =.. [_|Opnds],
get_variables1_list(Opnds,Vars), !.
get_variables1_list([Term|Terms],Vars) :-
get_variables1(Term,Vars1),
get_variables1_list(Terms,Vars2),
append(Vars1,Vars2,Vars), !.
get_variables1_list([],[]) :- !.
% succeed if each element of List1 is contained in List2
is_sublist([Elem|List1],[Elem|List2]) :-
is_sublist(List1,List2), !.
is_sublist([Elem1|List1],[Elem2|List2]) :-
Elem2 @< Elem1,
is_sublist([Elem1|List1],List2), !.
is_sublist([],_List2) :- !.
% list L is sorted, join all succeeding unifiable terms together,
% yielding LJ
join_unifiables([H,H|T],LJ) :-
join_unifiables([H|T],LJ), !.
join_unifiables([H1,H2|T],[H1|LJ]) :-
join_unifiables([H2|T],LJ), !.
join_unifiables([H],[H]) :- !.
join_unifiables([],[]) :- !.
% calculate intersection and both differences of List1 and List2
list_trisection(List1,List2,Only1,Both,Only2) :-
sort(List1,List1s),
sort(List2,List2s),
list_trisection1(List1s,List2s,Only1,Both,Only2), !.
list_trisection1([E12|List1],[E12|List2],Only1,[E12|Both],Only2) :-
list_trisection1(List1,List2,Only1,Both,Only2), !.
list_trisection1([E1|List1],[E2|List2],[E1|Only1],Both,Only2) :-
E1 @< E2,
list_trisection1(List1,[E2|List2],Only1,Both,Only2), !.
list_trisection1([E1|List1],[E2|List2],Only1,Both,[E2|Only2]) :-
E2 @< E1,
list_trisection1([E1|List1],List2,Only1,Both,Only2), !.
list_trisection1(List1,[],List1,[],[]) :- !.
list_trisection1([],List2,[],[],List2) :- !.
%: make_0s_list_of_length(3,[0,s(0),s(s(0))])
make_0s_list_of_length(0,[]) :- !.
make_0s_list_of_length(I,[0|List]) :-
I1 is I - 1,
make_0s_list_of_length(I1,List1),
make_0s_list_of_length_H1(List1,List), !.
make_0s_list_of_length_H1([N|Ns],[s(N)|SNs]) :-
make_0s_list_of_length_H1(Ns,SNs), !.
make_0s_list_of_length_H1([],[]) :- !.
%: make_natlist_of_length(5,[1,2,3,4,5])
make_natlist_of_length(0,[]) :- !.
make_natlist_of_length(N,List) :-
make_natlist_of_length1(1,N,List), !.
make_natlist_of_length1(N,N,[N]) :- !.
make_natlist_of_length1(I,N,[I|List]) :-
I1 is I + 1,
make_natlist_of_length1(I1,N,List), !.
make_natlist_of_length_list([Length|Lengths],[List|Lists]) :-
make_natlist_of_length(Length,List),
make_natlist_of_length_list(Lengths,Lists), !.
make_natlist_of_length_list([],[]) :- !.
%: make_varlist_of_length(5,[A,B,C,D,E])
make_varlist_of_length(0,[]) :- !.
make_varlist_of_length(I,[_|List]) :-
I1 is I - 1,
make_varlist_of_length(I1,List), !.
% generate a list V with the same length as L
% but consisting entirely of different prolog variables
make_varlist_of_same_length([_E|L],[_|V]) :-
make_varlist_of_same_length(L,V), !.
make_varlist_of_same_length([],[]) :- !.
make_varlist_of_same_length_list([List1|Lists1],[List2|Lists2]) :-
make_varlist_of_same_length(List1,List2),
make_varlist_of_same_length_list(Lists1,Lists2), !.
make_varlist_of_same_length_list([],[]) :- !.
% succeed if Map is a mapping from the bag Dom to the bag Ran
%<*backtrackable*>
mapping([X|Dom],Ran,[X:=Y|Map]) :-
member(Y,Ran),
mapping(Dom,Ran,Map).
mapping([],_Ran,[]) :- !.
% succeed if Map maps each Dom in Doms to the respective Ran in Rans
%<*backtrackable*>
mapping_list12([Dom|Doms],[Ran|Rans],Map) :-
mapping(Dom,Ran,Map1),
mapping_list12(Doms,Rans,Map2),
{ append(Map1,Map2,Map)
}.
mapping_list12([],[],[]) :- !.
% succeed if E is a member of the balanced binary tree BBT
member_bbt(E,f(_L,_Lh,E,_Rh,_R)) :- !.
member_bbt(E,f(L,_Lh,V,_Rh,_R)) :-
E @< V,
!,
member_bbt(E,L), !.
member_bbt(E,f(_L,_Lh,V,_Rh,R)) :-
V @< E,
!,
member_bbt(E,R), !.
% succeed if each term in Elems is a member of the corresponding
% list in Lists
member_list12([Elem|Elems],[List|Lists]) :-
member(Elem,List),
member_list12(Elems,Lists).
member_list12([],[]) :- !.
merge_lists_list([List1|Lists1],Optr,[List2|Lists2],[List|Lists]) :-
merge_lists(List1,Optr,List2,List),
merge_lists_list(Lists1,Optr,Lists2,Lists), !.
merge_lists_list([],_Optr,[],[]) :- !.
:-
abolish(cur_name_no,1),
assert(cur_name_no(1)).
% create a new name with the prefix Prefix
new_name(Prefix,NewName) :-
name(Prefix,PrefixL),
retract(cur_name_no(CurNo)),
NewNo is CurNo + 1,
assert(cur_name_no(NewNo)),
name(CurNo,CurNoL),
append(PrefixL,CurNoL,NewNameL),
name(NewName,NewNameL), !.
new_name_list([Prefix|Prefixes],[NewName|NewNames]) :-
new_name(Prefix,NewName),
new_name_list(Prefixes,NewNames), !.
new_name_list([],[]) :- !.
new_name_list_list([Prefixes|Prefixess],[NewNames|NewNamess]) :-
new_name_list(Prefixes,NewNames),
new_name_list_list(Prefixess,NewNamess), !.
new_name_list_list([],[]) :- !.
% return the partition induced on the domain set by the mapping Map
partition_from_mapping([X:=I|Map],In,Out) :-
partition_from_mapping_H1(X,I,In,In1),
partition_from_mapping(Map,In1,Out), !.
partition_from_mapping([],In,In) :- !.
partition_from_mapping_H1(X,1,[Part|Parts],[[X|Part]|Parts]) :- !.
partition_from_mapping_H1(X,I,[Part|Parts],[Part|PartsX]) :-
I1 is I - 1,
partition_from_mapping_H1(X,I1,Parts,PartsX), !.
% succeed once for each atom that is read in, stop if ’end’ is entered
read_list(Elem) :-
repeat,
read(Elem),
{ Elem == end,
!,
fail
; true
}.
read_subst_list(Vars,Substs) :-
bagof(Subst,SubstRanges^(
read_list(SubstRanges),
merge_lists(Vars,(:=),SubstRanges,Subst)
),Substs), !.
% replace the I’th element of List by NewElem, yielding ListR
replace_ith_elem([_Head|Tail],1,NewElem,[NewElem|Tail]) :- !.
replace_ith_elem([Head|Tail],I,NewElem,[Head|ListR]) :-
I1 is I - 1,
replace_ith_elem(Tail,I1,NewElem,ListR), !.
% reverse List, yielding ListR
reverse(List,ListR) :-
reverse1(List,[],ListR), !.
reverse1([Elem1|List1],List2,ListR) :-
reverse1(List1,[Elem1|List2],ListR), !.
reverse1([],List2,List2) :- !.
sort_list([H|T],[Hs|Ts]) :-
sort(H,Hs),
sort_list(T,Ts), !.
sort_list([],[]).
% split List into ListV and ListNV, such that each element in ListV
% contains prolog variables, and none in ListNV does
split_contains_vars([Elem|List],[Elem|ListV],ListNV) :-
contains_vars(Elem),
split_contains_vars(List,ListV,ListNV), !.
split_contains_vars([Elem|List],ListV,[Elem|ListNV]) :-
split_contains_vars(List,ListV,ListNV), !.
split_contains_vars([],[],[]) :- !.
%: strip_common_constructor([c(a,b),c(d,e),c(f,g)],c,[[a,d,f],[b,e,g]])
strip_common_constructor([S],Cr,SsArgs) :-
S =.. [Cr|SArgs],
extend_to_same_length([],SArgs,Nils),
cons_list12(SArgs,Nils,SsArgs), !.
strip_common_constructor([S|Ss],Cr,SsArgs) :-
S =.. [Cr|SArgs],
strip_common_constructor(Ss,Cr,SsArgs1),
cons_list12(SArgs,SsArgs1,SsArgs), !.
strip_common_constructor_list([Ss|Sss],[Cr|Crs],[SsArgs|SssArgs]) :-
strip_common_constructor(Ss,Cr,SsArgs),
strip_common_constructor_list(Sss,Crs,SssArgs), !.
strip_common_constructor_list([],[],[]) :- !.
% succeed if Suffix is a suffix of List
%<*backtrackable*>
suffix(List,List).
suffix(Suffix,[_Head|Tail]) :-
suffix(Suffix,Tail).
%: transpose([[a,b,c],[d,e,f]],[[a,d],[b,e],[c,f]])
transpose(Rows,[Col|Cols]) :-
cons_list12(Col,Rows1,Rows),
transpose(Rows1,Cols), !.
transpose(_Rows,[]) :- !.
% succeed if Elem is in List and remove it from List, yielding ListD
%<*backtrackable*>
try_delete_from_list(Elem,[Elem|List],List).
try_delete_from_list(Elem,[Other|List],[Other|ListD]) :-
try_delete_from_list(Elem,List,ListD).
% succeed if Elem is member of List,
% return the prefix of List, upto, and including Elem
try_get_prefix_to([Elem|_List],Elem,[Elem]) :- !.
try_get_prefix_to([Head|List],Elem,[Head|Prefix]) :-
try_get_prefix_to(List,Elem,Prefix), !.
% connect all elements of List by Op yielding Term
% eg. unflatten_op([a,b,c],(&),(a&b)&c).
unflatten_op([Term],_Op,Term) :- ! .
unflatten_op([Term1,Term2|List],Op,Term) :-
NewTerm =.. [Op,Term1,Term2],
unflatten_op([NewTerm|List],Op,Term), !.
% succeed if List is a list of prolog variables
var_list([H|T]) :-
var(H),
!,
var_list(T), !.
var_list([]) :- !.
write_list([H|T]) :-
write(H), nl,
write_list(T), !.
write_list([]) :-
nl, !.
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %
% %%%%% debugging functions %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %
% report clause call / fail
trace_enter(Event,Value) :-
% call
{ trace_wanted(Event),
{ retract(trace_tab(TabL))
; TabL = []
},
assert(trace_tab([32,32|TabL])),
name(Tab,TabL),
write(Tab), write(Value),
trace_break(Event,call,Ctrl),
!, Ctrl \== fail
; !
}
;
% fail
{ trace_wanted(Event),
retract(trace_tab([32,32|TabL])),
assert(trace_tab(TabL)),
name(Tab,TabL),
write(Tab), write(Value), write(’ FAILED’), nl
}, !, fail.
% report clause exit / back to
trace_leave(Event,Value) :-
% exit
{ trace_wanted(Event),
retract(trace_tab([32,32|TabL])),
assert(trace_tab(TabL)),
name(Tab,TabL),
write(Tab), write(Value), nl
; !
}
;
% back to
{ trace_wanted(Event),
retract(trace_tab(TabL)),
assert(trace_tab([32,32|TabL])),
name(Tab,TabL),
write(Tab), write(Value), write(’ RETRY’),
trace_break(Event,retry,_Ctrl)
}, !, fail.
trace_break(Event,Port,Ctrl) :-
trace_break_wanted(Event,Port),
write(’ ’),
get0(P),
{ P = 10
; get0(_),
{ [P] = "a", abolish(trace_tab,1),
assert(trace_tab([])), abort
; [P] = "b", retract(trace_break_wanted(Event,Port))
; [P] = "B", ( retract(trace_break_wanted(Event,_Any)),
fail
; true
)
; [P] = "f", Ctrl = fail
; [P] = "n", retract(trace_wanted(Event)),
{ retract(trace_tab([32,32|TabL])),
assert(trace_tab(TabL))
; !
}
; [P] = "t", trace
}
}, !
; nl, !.
% provide a means for additional information
trace_write(Event,Value) :-
trace_wanted(Event),
trace_tab(TabL),
name(Tab,TabL),
write(Tab), write(Value),
trace_break(Event,write,Ctrl),
!, Ctrl \== fail
; !.
% report unwanted backtracking
dont_backtrack(Predicate) :-
nl, write(’+++++ unwanted backtrack occurred (’),
write(Predicate), write(’) +++++’), nl,
trace, nl, nl, stop, !.
:-
abolish(trace_tab,1),
assert(trace_tab([])),
abolish(trace_wanted,1),
abolish(trace_break_wanted,2),
assert(trace_wanted(hsg)),
assert(trace_wanted(layer)),
assert(trace_wanted(prof)),
assert(trace_wanted(sd)),
assert(trace_wanted(sd1)),
assert(trace_break_wanted(hsg,call)),
assert(trace_break_wanted(hsg,write)),
assert(trace_break_wanted(hsg,retry)),
assert(trace_break_wanted(layer,call)),
assert(trace_break_wanted(layer,write)),
assert(trace_break_wanted(layer,retry)),
assert(trace_break_wanted(prof,call)),
assert(trace_break_wanted(prof,write)),
assert(trace_break_wanted(prof,retry)),
assert(trace_break_wanted(sd,call)),
assert(trace_break_wanted(sd,write)),
assert(trace_break_wanted(sd,retry)),
assert(trace_break_wanted(sd1,call)),
assert(trace_break_wanted(sd1,write)),
assert(trace_break_wanted(sd1,retry)).
