Hand Gestured Real Time Paint Tool - Box
Vandit Gajjar
Department of Electronics and Communication Engineering
L. D. College of Engineering
Ahmedabad, India
gajjarvandit@gmail.com
Viraj Mavani
Department of Electronics and Communication Engineering
L. D. College of Engineering
Ahmedabad, India
mavani.viraj.604@ldce.ac.in
Abstract - The paper suggests about with using of real time
color segmentation, filtration and feature selection process to
draw the patterns with major use of image processing i.e.,
Drawing the different shapes using the double tap of fingers,
open the hand and change the color of given shape.so basically
Vision-based human–computer connection could be achieved
by determining separated primary color areas. Still, one of the
challenges of this hand gesture target following is that color
distribution would be change in small lighting objects and so
the hand recognition is typical to detect.This paper presents
analyses and real time example of color-based image
segmentation, color based image filtration, feature selection,
hand recognition and using all this draw the different shapes in
real time world in front of the screen. The observations show
that RGB are the default color used for segmentation
proceeding.Meanwhile Real time video is captured from the
camera and the video is transformed into number of real time
frame images.This algorithm should monitor and process
every frame image from the real-time video and it will detect
the hand gesture and according to those hand gesture, different
shapes are drawn. Camera is used as an input. In the coding
area here image processing is done through Open-CV and
python for feature selection and feature recognition.
Keywords—Dynamic Image Processing; Image Recognition;
Image Analysis; Feature Extraction; Image Segmentation; Open-
CV; Python
I. INTRODUCTION
Many real-world applications want real-time image
processing like for object recognition, feature selection and
image segmentation. Performance of an object recognition,
feature selection and image segmentation system should be
fast accurately so that moving object in the video can be
dignified and further refined in real time. Once motion area in
a video is identified, object recognition, feature selection,
object tracking, image data mining, and other video and image
processing algorithms and techniques can be performed.
Image segmentation has acknowledged an important towards
computer vision due to the wide area of applications
containing video surveillance, bio-metric recognition, and face
indexing in multimedia contents. Due to a real time process it
gets an input as several frames and processing it at the same
time. Now in this process we actually identify our hand using
the image segmentation, color filtration, feature extraction
process essential colors are separated from the input RGB
frame and so we can accurately detect our hand. Then with
this process using real time video streaming we can draw,
erase, cut, copy, paste and even we can take pictures from that,
for just we have to identify some hand gesture using
segmented color and feature extraction. Therefore, the hand
gestured paint tool-box is major process. It requires some of
the fast GPU and processor to make it easier, and also two
major components used which are Open-CV and Python, with
these both we can make our process faster, and there brief
introduction is given below.
II. INTRODUCTION TO OPEN-CV & PYTHON
A. Open-CV
Open-CV (Open Source Computer Vision) is a
programmable library which is focuses basically on real time
applications. It’s written in C++ and the interface is in C++,
but it still retains less comprehensive though through older C
interface. There are bindings in Java and MATLAB/OCTAVE.
The API for these interfaces can be found in the online
database. All the major developments and algorithms in Open-
CV are now also developed in the C++ interface Open-CV is
an open source computer vision library which is now widely
use in dynamic image processing and real-time image
processing.
B. Python
Python is used as high-level programming
language for general-purpose programming.The language
provides constructs intended to enable writing clear programs
on both a small and large scale.Python features a dynamic
type system and automatic memory management and supports
multiple programming paradigms, including object-
oriented, imperative, functional programming,
and procedural styles.It has a large and
comprehensive standard library. In python sci kit-
image (formerly scikits.image) is an open source image
processing library. It includes algorithms for segmentation,
geometric transformations, color space manipulation, analysis,
filtering, morphology, feature detection, and many more. It is
designed to inter-operate with the Python numerical and
scientific libraries NumPy and SciPy.
III. COLOR SEGMENTATION
The color targets were designed with an idiosyncratic
combination of color organize in a particular configuration. A
series of elementary and very expeditious tests performed on
an input image will immediately encounter and localize the
color target. The tests accomplishment in-variants based on
color gradients that we have derived analytically under a
collection of indoor and outdoor lighting conditions for our
color pattern. While the decisive color gradients among the
three-color patches vary depending on brightness and noise,
some facet of the gradient are highly certain and generate a
nearly exclusive signature of the target. Four subsequent color
gradient tests satisfy to rule out all but a small portion of the
image pixels that do not lie on a color target. These tests are
based on the following gradient components: the blue channel
gradient component across the blue-green and blue-red
boundaries and the green channel gradient component across
the red-green and green-blue boundaries. The gradients are
predicted by figure out differences in RGB channels between
neighboring pixels. Color barriers between contiguous regions
are hardly sharp in real images because of effects such as color
draining, motion blurring and pixel projection. So, we
determine these gradient characteristics across several pixels
rather than between nearby pixels. We designate this
separation to be as large as possible, dependable with the
prerequisite that the samples used to compute the gradients all
fit within the target place. (The minimal scale of the target in
the image -- which is inversely commensurate to the utmost
distance it can be determine from the camera thus regulate the
utmost admissible distance between samples.)
Figure 1. Color Segmentation
IV. FEATURE SELECTION
Feature selection is the procedure of selecting a subset of
those features (variables, predictors) which are use in the
algorithms and model construction.A feature selection
algorithm could be seen as the combination of a search
technique for describing some new feature subsets, along with
an evaluation measure which scores the different feature
subsets. The simplest algorithm is to test each possible subset
of features finding the one which minimizes the error rate.The
feature selection methods are typically presented in three
classes based on how they combine the selection algorithm
and the model building.
V. BLOCK DIAGRAM
The block diagram symbolizes the distribution of
elementary color from a real-time video input. At initial
camera device is acting as input device, it gives input of RGB
images to our algorithm. It accommodates numerous numbers
of color images in motion. It provides the various color frame
into the given development and the essential color are
disjointed. Now due to the feature selection process, we can
identify our hand using the contours. Then the selection of the
different tools will be done by our hand-gestures i.e. joint the
double fingers to select the dot, line and eraser tool, Open the
hand to select the R,G & B color. Now this RGB output will
be use for the hand recognition, and this recognition will be
help to draw those lines and mainly the contours are take
major part in recognition of gestures. Following is the block
diagram shown.
Figure 2. Block Diagram
A. Gray Conversion:
It is the proceeding of alteration from color images into
gray scale image. Color image consist of 24 bits per pixel; it is
shortened to 8 bits per pixel. Most frequently levels perform
the interval number of quantization in gray scale image alter.
At right now, the best generally used repository method is 8-
bit storage. There are 256 gray levels in an 8-bit gray range
image, and the magnitude of each pixel can have from 0 to
255.
B. Subtraction:
The RGB image enclose 24 bits, each of three colors
having 8 bits per pixel. At side-by-side RGB is isolating into
each 8 bit colors. The color subtraction is the operation of
subtracting the color amount between the two colors. Here
every three colors are replaced with the gray image which
transformed from the original RGB image.
C. Binary Conversion:
Binary conversion is the procedure of transforming any
considerate of image into a binary (1, 0) image. Essentially
binary image two bits image, it consists of only 1 and 0. Here
1 will be shown as white and 0 will be shown as black. Hence,
it’s named as black and white image. The determination of
transformation is to calculate the black and white pixels in the
image. Every detached color is transformed as black and other
colors are converted as white.
D. Multiplication:
Image multiplication is the process of amplification of
pixel amount between more than images; here this
development is used to multiply binary images with breached
color images. Subsequently this action we can get every
elementary color that having above 300 PPI. The range consist
of below 300 PPI does not treated as color. After the
multiplication, this proceeding having three disjointed colors
that having 300 PPI. By bringing together these three colors
we can get the anecdotal color image that consist of only
elementary colors. From the given technique, the RGB color
area can be disjointed like subsequent diagram.
E. Color Filtration:
Color Filtration is the technique of disjointing the colors
and analyzing the disjointed colors. It is the one of the human
to computer interplay. Here the colors are substituting in a role
as amalgamate between human and computer. At introductory
elementary color modal is used for a recognition technique, it
only recognizing elementary colors in each color images,
elementary colors are disjointed and disjointed colors are
recognized to determine its name like blue, green, red. It gives
the recognized color as an output by utilizing two ways, that is
composition text on the output screen and playing audio(.wav)
files which having the names of the elementary colors. The
pixels of each three colors are check in order after disjointed it.
At whatever time, it gets above 300 PPI of these three colors
(RGB) it should identify that the given colors are establish or
formed. That we set that below 300 PPI are not any
phenomenon found there. It may be a emission from luminous.
So, that it should not recognize the colors below 300 PPI of
the elementary colors. Also, the other colors are also
undervalued. These are the core technique of color
identification. In the real-time proceeding, real time signals
are refined by convinced algorithms, for this project real time
input signal is uninterrupted motion of image signal like video
signal. It does not have any restricted duration, algorithm
observing for each frame and converting by the given
algorithm. The given technique displays input and refined
window. The input window has live video from the camera
object and the refined window has sanctioned colors as an
output.
Figure 3. Output Image
F. Feature Selection
For the given output now, we use contours to identify our
hand and basically it divided into two parts like, Gloves based
& Vision Based.The glove-based approach employs sensors
(mechanical or optical) attached to a glove that acts as
transducer of finger flexing into electrical signals to determine
hand posture.The second approach, vision based analysis, is
based on how humans perceive information about their
surroundings. Edges are basic image features that carry useful
information regarding the object boundaries, so using canny
edge detection we can make the boundaries around our hand
using gray values.Thus, an edge is defined by a discontinuity
in gray level values.Ideally, an edge is caused by changes in
color or texture or by the specific lighting conditions present
during the image acquisition process.Hand gesture recognition
process involves several techniques and algorithms that fall
under the areas of image processing.The first phase deals with
problems related to image processing, such as reducing noise
by using filters, scaling, and break down the image into
meaningful regions using segmentation techniques such as
thresholding and edge detection methods. So now with
recognition of our hand using contours and edge detection
methods now we can detect those hand gestures of taping two
fingers to select tool, open our hand to change the color
value.The following figure shows the hand detection and
feature selection, and basically we have imported the different
shapes i.e. Dot, Line, RGB Color.
Figure 4. Hand Detection
Figure 5. Tool Selection
Figure 6. Drawing line with Hand Gesture.
VI. CONCLUSION
Computer vision algorithms support encouraging ways to
human–computer through perceptive elementary colors from
visual data. A substantial step to accomplish this goal is the
prosperous and precise disjointing of elementary colors.Now
this elementary things are used for the different technologies
for sixth sense, virtual reality.Nevertheless, littered
backgrounds, obscure luminous circumstances and diversified
affecting objects make this tasks dispute. This paper mainly
robust on hand gestured paint tool box with color-based image
segmentation and vision located color identification by
marking these predicaments.
VII. FUTURE WORK
We can create a graphical user interface software for these
utilization and can amalgamate that graphical user interface
with an extraneous camera module which will be in the saddle
of an machine learning robot, and can be adequate to latch on
to the video and the further refining of the video will take
position with the help of the advanced graphical user interface.
Then this Autonomous Robot can be used for to teach the
children about various activities and these concept can also be
used for virtual reality and augmented reality. Also these
application is used for games like snakes etc. In which with
using of hand gestures you can play it.
VIII.ACKNOWLEDGMENTS
I am thankful to Prof. Usha Neelakantan, Head of
Department, Electronics and Communication Engineering, L.
D. College of Engineering, Ahmedabad and Prof. (Dr.)
Dwight Day, Associate Professor, Electrical Engineering,
Kansas State University, Kansas for their expert guidance and
reviews throughout the research work.
IX. REFERENCES
[1] “Fusion of Geometry and Color Information for Scene
Segmentation” Carlo Dal Mutto, Student Member, IEEE.
[2] Meyer, Fernand. "Color image segmentation." In Image
Processing and its Applications, 1992., International
Conference on, pp. 303-306. IET, 1992.
[3] "Display tube with color selective filtration." U.S. Patent
3,873,868, issued March 25, 1975.
[4] Viola, Paul, and Michael Jones. "Rapid object detection
using a boosted cascade of simple features." In Computer
Vision and Pattern Recognition, 2001. CVPR 2001.
Proceedings of the 2001 IEEE Computer Society
Conference on, vol. 1, pp. I-I. IEEE, 2001.
[5] Papageorgiou, Constantine P., Michael Oren, and Tomaso
Poggio. "A general framework for object detection."
In Computer vision, 1998. sixth international conference
on, pp. 555-562. IEEE, 1998.
[6] Comaniciu, Dorin, Visvanathan Ramesh, and Peter Meer.
"Kernel-based object tracking." IEEE Transactions on
pattern analysis and machine intelligence 25, no. 5 (2003):
564-577.
[7] Babenko, Boris, Ming-Hsuan Yang, and Serge Belongie.
"Robust object tracking with online multiple instance
learning." IEEE transactions on pattern analysis and
machine intelligence 33, no. 8 (2011): 1619-1632.
[8] P. Mistry, P. Maes. SixthSense – “A Wearable Gestural
Interface.” In the Proceedings of SIGGRAPH Asia 2009,
Emerging Technologies. Yokohama, Japan. 2009
