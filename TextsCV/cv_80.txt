ar
X
iv
:1
70
9.
00
04
2v
1 
 [
cs
.C
V
] 
 3
1 
A
ug
 2
01
7
Multi-task Dictionary Learning based Convolutional Neural Network for
Computer aided Diagnosis with Longitudinal Images
Jie Zhang1, Qingyang Li1, Richard J. Caselli2, Jieping Ye3, Yalin Wang1
1School of Computing, Informatics, and Decision Systems Engineering, Arizona State University,
Tempe, AZ, 2Department of Neurology, Mayo Clinic, Scottsdale, AZ,
3Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, MI
{JieZhang.Joena, Qingyang.Li, Yalin.Wang}@asu.edu, jpye@umich.edu, caselli.richard@mayo.edu
Abstract
Algorithmic image-based diagnosis and prognosis of
neurodegenerative diseases on longitudinal data has drawn
great interest from computer vision researchers. The cur-
rent state-of-the-art models for many image classification
tasks are based on the Convolutional Neural Networks
(CNN). However, a key challenge in applying CNN to bio-
logical problems is that the available labeled training sam-
ples are very limited. Another issue for CNN to be applied
in computer aided diagnosis applications is that to achieve
better diagnosis and prognosis accuracy, one usually has
to deal with the longitudinal dataset, i.e., the dataset of im-
ages scanned at different time points. Here we argue that an
enhanced CNN model with transfer learning for the joint
analysis of tasks from multiple time points or regions of
interests may have a potential to improve the accuracy of
computer aided diagnosis. To reach this goal, we innovate
a CNN based deep learning multi-task dictionary learning
framework to address the above challenges. Firstly, we pre-
train CNN on the ImageNet dataset and transfer the knowl-
edge from the pre-trained model to the medical imaging pro-
gression representation, generating the features for differ-
ent tasks. Then, we propose a novel unsupervised learning
method, termed Multi-task Stochastic Coordinate Coding
(MSCC), for learning different tasks by using shared and
individual dictionaries and generating the sparse features
required to predict the future cognitive clinical scores. We
apply our new model in a publicly available neuroimaging
cohort to predict clinical measures with two different fea-
ture sets and compare them with seven other state-of-the-
art methods. The experimental results show our proposed
method achieved superior results.
1. Introduction
Deep learning models [27, 35, 43] are capable of learn-
ing the hierarchical structure of features extracted from real-
Figure 1: This figure shows three promising anatomical fea-
tures of the brain structural MR images used for clinical di-
agnosis of Alzheimer’s Disease.
world images. Convolutional Neural Networks (CNNs) are
a class of multi-layer, fully trainable models that are able
to capture highly nonlinear mappings between inputs and
outputs [20]. Recently, CNNs have been successfully ap-
plied to a variety of applications, including image classifica-
tion [19], segmentation [30], and biological problems [15].
Feature learning with deep learning model typically re-
quires a large amount of training data. Thus, feature learn-
ing for domains with scarce data is not feasible. However,
a key challenge in applying CNNs to biological problems is
that the available labeled training samples are very limited.
Transfer learning [2, 25, 37] is one of the approaches to
address this problem and help feature learning in the data-
scarce target domain by transferring knowledge from data-
rich source domain. In this study, we aim to explore whether
the nice transfer learning property of CNN can be help ap-
ply CNN to general biological image researches.
In fact, even when we are able to transfer knowledge
from the large amounts of image data to some other domain,
employing transfer learning with deep model on longitudi-
nal or multiple brain region of interests (ROIs) data is still
1
Figure 2: The streamline of our proposed framework. We pre-train the deep CNN model on the Imagenet dataset and use the
pre-trained model as a feature extractor for the ADNI dataset. We employ the extracted features from three time points or
ROIs to conduct the multi-task dictionary learning for AD progression prediction, generating the sparse features for different
time points or ROIs. Finally, we use Lasso regression on the learnt features to predict future MMSE and ADAS-Cog scores.
challenging. Fig. 1 depicts three most promising imaging
ROIs associated with brain image analysis [13]. Usually the
large number of longitudinal or multiple ROI features mea-
sured from limited number of subjects makes it necessary
to reduce feature dimensions. Dictionary learning [23, 21]
has been proposed to use a small number of basis vectors
termed dictionary to represent local features effectively and
concisely [11] and help image content analysis. However,
most existing works on dictionary learning focus on the pre-
diction of target at a single time point [23] or on a single
ROI [40, 41]. Here, we propose a novel approach that em-
ploys dictionary learning to identify important and concise
features, i.e. the knowledge learned from the large amount
of natural images by developing a universal representation
for medical images through a deep CNN model, which is
expected to improve the performance of computer aided di-
agnosis and prognosis.
Recently, Multi-Task Learning (MTL) [32, 36, 44, 31]
has been successfully used on regression under the differ-
ent time slots. Collobert et al. [8] proposed a deep neural
network with MTL to solve the grammatical and semanti-
cal problems on Natural Language Processing. Zhang et
al. [43] integrated transfer learning with MTL on CNN for
biological image analysis. Maurer et al. [24] proposed a
sparse coding model for MTL and transfer learning based
on the generative methods, but it is not associated with deep
learning model. The common issue for the medical imaging
research is that the longitudinal features of patients among
different time points or features from different ROIs will
always be beneficial to study together. To further improve
our dictionary learning CNN model, we propose multi-task
Stochastic Coordinate Coding (MSCC) algorithm to parti-
tion the dictionaries into the common and individual parts,
considering the variance of subjects from multiply time
points or multiple ROIs. In this study, we focus on the longi-
tudinal dataset of a real world application, predicting future
clinical scores in Alzheimers disease (AD). For the same
subject, it may have different representations at different
time points. For the traditional CNN application, it is rela-
tively challenging to explore that the similarity and variance
of subject features among different time points. We propose
MSCC to learn these different tasks simultaneously and uti-
lize both shared and individual dictionaries to encode such
consistent and changing imaging features systematically.
Our main contributions can be summarized as follows:
• We employ transfer learning and CNN to explore
whether the transfer learning property of CNN can
be enhanced to generate features from geometry mesh
of biological images since the current bottleneck for
CNNs to be applied to many biological problems is
the limited amount of available labeled training data.
We pre-train the deep neural network on the ImageNet
data and transfer the knowledge of natural images to
generate the neuroimaging features for the real world
application.
• We considered the variance of subjects from differ-
ent time points or ROIs and proposed a novel unsu-
pervised dictionary learning method, termed Multi-
task Stochastic Coordinate Coding (MSCC), learning
the different tasks simultaneously and utilizing shared
and individual dictionary to encode both consistent and
changing imaging features. To the best of our knowl-
edge, it is the first deep model to integrate multi-task
learning with dictionary learning research for brain
imaging analysis.
• We tested our hypothesis on two different feature sets
(three time points and three brain areas) to better pre-
dict the future clinical cognitive scores. Specifically,
we used the multiple time points features as multiple
tasks input to predict future cognitive scores. We also
use multiple ROIs as multiple tasks input to predict
three future time points clinical scores. Our new ap-
proach outperforms seven other state-of-the-art meth-
ods and is able to boost the performance of diagnoses
ranging from cognitively unimpaired to AD.
2. Multi-task Dictionary Learning based Con-
volutional Neural Network
Our first goal here is to explore whether this transfer
learning framework of CNN can be generalized to biologi-
cal image studies. Specifically, we pre-train the CNN model
using ImageNet [10] data, containing millions of labeled
natural images with thousands of categories to obtain initial
parameters and subsequently generate the features on the
longitudinal data for each tasks. In the experiments, we ap-
ply Alexnet [19], which contains 7 layers, including convo-
lutional layers with fixed filter sizes and different numbers
of feature maps. We employ rectified non-linearity, max-
pooling on each layer in our CNN model. We pretrain the
CNN model on the ImageNet dataset, then remove the last
fully-connected layer (this layer’s outputs are the 1000 class
scores for a different task like ImageNet). Finally, we treat
the rest of the CNN as a fixed feature extractor for the pub-
licly available Alzheimer’s Disease Neuroimaging Initiative
(ADNI) database [17].
We further propose to use multi-task learning strategy to
boost the future clinical score regression accuracy. The en-
tire pipeline of our method is illustrated in Fig. 2. To be spe-
cific, we train the deep CNN model on the Imagenet dataset
firstly. Then we employ the pretrained network as a feature
extractor for the ADNI dataset from multiple time points or
multiple brain ROIs. The AlexNet has a seven layer struc-
ture deep neural network. As a result, we generate seven
deep output features for each time point. We further em-
ploy MSCC to conduct the multi-task learning simultane-
ously, generating the sparse features and dictionaries from
the deep features of different time points or different brain
ROIs. In MSCC, we utilize shared and individual dictio-
naries to encode both consistent and changing imaging fea-
tures along longitudinal time points. In the end, we em-
ploy the sparse codes generated from MSCC to perform the
Figure 3: Illustration of the learning process of MSCC.
Lasso [29] and predict the future AD progression. MSCC
is one kind of online learning methods and the advantage of
online learning method is to solve the cases that the size of
the input data might be too large (sample size up to 2867562
in this paper) to fit into memory or the input data comes in
a form of a stream.
3. Multi-task Stochastic Coordinate Coding
3.1. Dictionary Learning
Given a finite training set of signals X = (x1, ..., xn)
where X ? Rp×n. Each xi is an image patch and xi ? R
p.
Dictionary learning aims to learn a dictionaryD where D ?
R
p×l and a sparse code matrix Z , Z ? Rl×n. The original
signals X is modeled by a sparse linear combination of D
and Z as X ? DZ . Given one image patch xi, we can
formulate the following optimization problem:
min
D??,zi?Rl
f(D, zi) =
1
2
||xi ?Dzi||
2
2 + ?||zi||1, (1)
where ? = {D ? Rp×l : ?j ? 1, ..., l, ||Dj||2 ? 1}, Dj
denotes the jth column of D. ? is the positive regularization
parameter. zi is the learnt sparse codes for xi and Z =
(z1, ..., zn).
The optimization of Eq.1 can be decomposed into an al-
ternative learning process in the Online Dictionary Learn-
ing methods (ODL) [23]. Given each image patch xi, ODL
keeps the D fixed and learn zi, then keep zi fixed and learn
D. The learning process runs ? (a fixed constant) iterations
until there are no more changes on D and Z .
3.2. The Proposed Algorithm
Given features from T different tasks: {X1,X2, ..., XT },
our objective is to learn a set of sparse codes
{Z1, Z2, ..., ZT } for each task where Xt ? R
p×nt ,
Zt ? R
lt×nt and t ? {1, ..., T }. nt is the number of
subjects for Xt and lt is the dimension of each sparse
code in Zt. When employing the ODL to learn the sparse
codes Zt by Xt individually, we obtain a set of dictionary
{D1, ..., DT } but there is no correlationship between learnt
Algorithm 1 Multi-task Sparse Coordinate Coding
Require: Samples from different time points:
{X1, X2, .....XT } and for each Xt, Xt ? R
p×nt
Ensure: Dictionaries and sparse codes for each time
points: {D1, ..., DT } and {Z1, ..., ZT }
1: for k = 1 to ? do
2: for t = 1 to T do
3: for i = 1 to nt do
4: Get an image patch xt(i) from sample Xt.
5: Update D?kt : D?
k
t = ?.
6: Update zk+1t (i) and index set I
k+1
t (i) by a
few steps of CCD:
7: [zk+1t (i), I
k+1
t (i)] =
CCD(D?kt , D?
k
t , xt(i), I
k
t (i), z
k
t (i)).
8: Update the D?t and D?t by one step SGD:
9: [D?k+1t , D?
k+1
t ] =
SGD(D?kt , D?
k
t , xt(i), I
k+1
t (i), z
k+1
t (i)).
10: Normalize D?k+1t and D?
k+1
t based on the in-
dex set Ik+1t (i).
11: Update the shared dictionary?: ? = D?k+1t .
12: end for
13: end for
14: end for
dictionaries. Another solution is to construct the features
{X1, ..., XT } into one matrix X to obtain the dictionary D.
However, if there is no latent common information shared
by the same subject during different time points, only one
dictionary D is not enough to show the variation among
features from different time points. Such fact is supposed
to be easily revealed in the variance of dictionary atoms and
the sparsity of their corresponding sparse code matrices. To
address this challenge, we integrate the idea of multi-task
learning into the online dictionary learning method. We
propose a novel dictionary learning algorithm, termed as
Multi-task Stochastic Coordinate Coding (MSCC), to learn
the sparse codes of subjects from different time points.
For the subjects’ feature matrix Xt of a particular task,
MSCC learns a dictionary Dt and sparse codes Zt. Dt is
composed of two parts: Dt = [D?t, D?t] where D?t ? R
p×l?,
D?t ? R
p×l?t and l? + l?t = lt. D?t is the same among all the
learnt dictionaries {D1, ..., DT } while D?t is different from
each other and only learnt from the corresponding subjects’
feature matrix Xt. Therefore, objective function of MSCC
can be reformulated as follows:
min
D1,··· ,DT ,
Z1,··· ,ZT
T
?
t=1
1
2
||Xt ? [D?t, D?t]Zt||
2
F + ?
T
?
t=1
||Zt||1 :
subject to D?1 = · · · = D?T and Dt ? ?t (2)
where ?t = {Dt ? R
p×lt : ?j ? 1, ..., lt, ||[Dt]j ||2 ? 1}
and [Dt]j is the jth column of Dt.
Fig. 3 illustrates the framework of MSCC with features
Algorithm 2 Updating sparse codes zk+1t (i)
Require: The image patch xt(i), dictionaries D?
k
t and D?
k
t ,
sparse codes zkt (i) and index set I
k
t (i)
Ensure: The updated sparse code zk+1t (i) and the index set
Ik+1t (i).
1: for j = 1 to lt do
2: g = [D?kt , D?
k
t ]
T
j (?([D?
k
t , D?
k
t ], z
k
t (i), I
k
t (i)) ?
xt(i))
3: zk+1t (i)j = ??(z
k
t (i)j ? g)
4: if zk+1t (i)j 6= 0 then
5: Put j into the index set Ik+1t (i).
6: end if
7: end for
8: for s = 1 to S do
9: for every element µ in the index set Ik+1t (i) do
10: g = [D?kt , D?
k
t ]
T
µ (?([D?
k
t , D?
k
t ], z
k+1
t (i), I
k+1
t (i))?
xt(i))
11: zk+1t (i)µ = ??((z
k+1
t (i)µ ? g)
12: end for
13: end for
of ADNI from three different time points, which represents
as X1, X2 and X3, respectively. Through the multi-task
learning process of MSCC, we obtain the dictionary and
sparse codes for features from each time point t: Dt and
Zt. In MSCC, a dictionary Dt is composed by a shared part
D?t and an individual part D?t, D?1 = D?2 = D?3. For the
individual part of dictionaries, MSCC learns a different D?t
only from the corresponding feature matrixXt. We vary the
number of columns l?t in D?t to introduce the variant in the
learnt sparse codes Zt. As a result, the dimensions of learnt
sparse codes matrix Zt are different from each other.
The initialization of dictionaries in MSCC is critical
to the entire learning process. We propose a random
patch method to initialize the dictionaries from different
time points. The main idea of the random patch method
is to randomly select l image patches from n subjects
{x1, x2, ..., xn} to construct D where D ? R
p×l. It is
a similar way to perform the random patch approach in
MSCC. In MSCC, the way we initialize D?t is to randomly
select l? subjects’ feature from features’ matrices across dif-
ferent time points {X1, · · · , XT } to construct it. For the
individual part of each dictionary, we randomly select l? sub-
jects’ feature from the corresponding matrixXt to construct
D?t.
After initializing dictionary Dt for each time point, we
set all the sparse code Zt to be zero at the beginning. The
key steps of MSCC are summarized in Algorithm 1.
In algorithm 1, k denotes the epoch number where k ?
[1, ?]. ? represent the shared part of each dictionary Dt
which is initialized by the random patch method. For each
subject’s feature xt(i) extracted from Xt, we learn the ith
Algorithm 3 Updating dictionaries D?k+1t and D?
k+1
t
Require: The image patch xt(i), dictionaries D?
k
t and D?
k
t ,
sparse codes zk+1t (i) and index set I
k+1
t (i).
Ensure: The updated dictionaries D?k+1t and D?
k+1
t .
1: Update the Hessian matrix Hk+1t : H
k+1
t = H
k
t +
zk+1t (i)z
k+1
t (i)
T .
2: R = ?([D?kt , D?
k
t ], z
k+1
t (i), I
k+1
t (i))? xt(i).
3: for j = 1 to p do
4: for every element µ in the index set Ik+1t (i) do
5: [D?k+1t , D?
k+1
t ]j,µ = [D?
k
t , D?
k
t ]j,µ ?
1
H
k+1
t (µ,µ)
zk+1t (i)µRj .
6: end for
7: end for
sparse code zk+1t (i) from Zt by several steps of Cyclic Co-
ordinate Descent (CCD) [5]. Then we use learnt sparse
codes zk+1t (i) to update the dictionary D?
k+1
t and D?
k+1
t
by one step Stochastic Gradient Descent (SGD)[42]. Since
zk+1t (i) is very sparse, we use the index set I
k+1
t (i) to
record the location of non-zero entries in zk+1t (i) to acceler-
ate the update of sparse codes and dictionaries. ? is updated
in the end of kth iteration to ensure D?k+1t is the same among
all the dictionaries.
3.3. Updating Sparse Codes and Dictionaries
The learning process of sparse code zk+1t (i) is shown
in algorithm 2. At first, we generate the non-zero index
set Ik+1t by one step of CCD to record the nonzero entry
of zk+1t (i). Then we perform S steps CCD to update the
sparse codes only on the non-zero entries of zk+1t (i), ac-
celerating the learning process significantly. ? is a sparse
matrix multiplication function that has three input parame-
ters. Take ?(A, b, I) as an example, A denotes a matrix, b
is a vector and I is an index set that records the locations
of non-zero entries in b. The return value of function ?
is defined as: ?(A, b, I) = Ab. When multiplying A and
b, we only manipulate the non-zero entries of b and corre-
sponding columns of A based on the index set I , speeding
up the calculation by utilizing the sparsity of b. ? is the soft
thresholding shrinkage function [9] and the definition of ?
is given by: ??(x) = sign(x)(|x| ? ?).
The procedure of updating dictionaries is shown in Al-
gorithm 3. We perform one step SGD to update the dictio-
naries: D?k+1t and D?
k+1
t . The learning rate is set to be an
approximation of the inverse of the Hessian matrix Hk+1t ,
which is updated by the sparse codes zk+1t (i) in kth itera-
tion. For the µth column of dictionary, we set the learning
rate as the inverse of the diagonal element of the Hessian
matrix, which is 1/Hk+1t (µ, µ). Since Dt ? ?t in equation
(2), it is necessary to normalize the dictionaries D?k+1t and
D?k+1t after updating them. We can perform the normal-
ization on the corresponding columns of non-zero entries
Table 1: The architecture of our CNN used in HP and ROI.
Deep Layer Function # of neurons
1 Convolutional Layer 253440
2 Pooling Layer 186624
3 Convolutional Layer 64896
4 Convolutional Layer 64896
5 Convolutional layer 43264
Pooling layer 9216
6 Fully connected layer 4096
7 Fully connected layer 4096
from zk+1t (i) because the dictionaries updating only occurs
on these columns. Utilizing the non-zero information from
Ik+1t (i) can accelerate the whole learning process.
4. Experiments
AD and its early stage, Mild Cognitive Impairment
(MCI), are becoming the most prevalent neurodegenerative
brain diseases in elderly people worldwide [4]. To this end,
there have been a lot of efforts on investigating the under-
lying biological or neurological mechanisms and also dis-
covering biomarkers for early diagnosis of AD and MCI.
We conducted experiments from ADNI dataset [17], which
has been considered as the benchmark database for per-
formance evaluation of various methods for AD diagnosis.
We evaluated our method on two different sets of structural
magnetic resonance imaging (MRI) data from the ADNI
dataset: multiple time point hippocampal surface feature
dataset (HP) [39] and multiple baseline brain ROI surface
feature dataset (ROI). Specifically, for the HP dataset, we
predicted clinical scores of patients at 24-month using their
surface features at baseline, 6-month and 12-month. For
the ROI dataset, we predicted clinical scores of patients
at 6-month, 12-month and 24-month using their baseline
hippocampal, ventricular and cortical thickness surface fea-
tures.
4.1. Experimental Setup
We built a prediction model for each of the above
datasets using multiple task geometry surface features. To
train the CNN model, patches of size 50 × 50 are extracted
from surface mesh structures. We implemented our CNN
model using the Caffe toolbox [18] and the architecture of
our CNN is shown in Tab. 1. The network was trained on a
Intel (R) Xeon (R) 48-core machine, with 2.50 GHZ proces-
sors, 256 GB of globally addressable memory and a single
Nvidia GeForce GTX TITAN black GPU. In the experimen-
tal setting of MSCC, the sparsity ? = 0.1. Also, we selected
10 epochs with a batch size of 1 in Algorithm 1 and 3 iter-
ations of CCD in Algorithm 2 (P is set to be 1 and S is
set to be 3) in all the experiments. After we get the MSCC
features, we used Max-Pooling [3] for further dimension re-
duction. Therefore, the feature dimentsion of each subject
4 5 6 7
Layer
2
2.5
3
3.5
4
4.5
5
R
o
o
t 
m
ea
n
 s
q
u
ar
e 
er
ro
r
MMSE
CNN-R
CNN-MSCC
4 5 6 7
Layer
4
4.5
5
5.5
6
6.5
7
7.5
8
R
o
o
t 
m
ea
n
 s
q
u
ar
e 
er
ro
r
ADAS-Cog
CNN-R
CNN-MSCC
Figure 4: Comparison of rMSE performance achieved by
features extracted from different layers of the deep models.
is a 1 × 2000 vector. To predict future clinical scores, we
used Lasso regression. For the parameter selection, 5-fold
cross validation is used to select model parameters in the
training data (between 10?3 and 103). We used the same
method for all seven other comparison methods.
In order to evaluate the model, we randomly split the data
into training and testing sets using an 8:2 ratio and used 10-
fold cross validation to avoid data bias. Lastly, we evaluated
the overall regression performance using normalized mean
square error (nMSE), weighted correlation coefficient (wR)
and root mean square error (rMSE) for task-specific regres-
sion performance measures. The three measures are defined
as follows:
nMSE(Y, Y? ) =
?t
i=1 ||Yi ? Y?i||
2
2/?(Yi)
?t
i=1 ni
,
wR(Y, Y? ) =
?t
i=1 Corr(Yi, Y?i)ni
?t
i=1 ni
,
rMSE(y, y?) =
?
||y ? y?||22
n
.
For nMSE and wR, Yi is the ground truth of target of task
i and Y?i is the corresponding predicted value, ?(Yi) is the
Standard deviation of Yi, Corr is the correlation coefficient
between two vectors and ni is the number of subjects of
task i. For rMSE, y is the ground truth of target at a single
task and y? is the corresponding prediction by a prediction
model. The smaller nMSE and rMSE, as well as the big-
ger wR mean the better results. We reported the mean and
standard deviation based on 40 iterations of experiments on
different splits of data.
We compared the proposed model with some state-of-
the-art methods, which are as follows:
• CNN-MSCC: Our proposed model.
• CNN-R: CNN learned surface feature without transfer
learning, followed by Lasso regression.
• MSCC-R: The proposed multi-task dictionary learning
algorithm followed by Lasso regression.
• OLSC-R: The single-task dictionary learning [23] fol-
lowed by Lasso regression.
250:1750 500:1500 1000:1000 1500:500 1750:250
Dictionary size
2.5
2.6
2.7
2.8
2.9
3
3.1
3.2
3.3
3.4
3.5
3.6
3.7
R
o
o
t 
m
ea
n
 s
q
u
ar
e 
er
ro
r
MMSE
MSCC-R
CNN-MSCC
250:1750 500:1500 1000:1000 1500:500 1750:250
Dictionary size
4
4.5
5
5.5
6
6.5
7
R
o
o
t 
m
ea
n
 s
q
u
ar
e 
er
ro
r
ADAS-Cog
MSCC-R
CNN-MSCC
Figure 5: Comparison of rMSE performance by varying the
size of common dictionary on HP dataset.
• cFSGL: A state-of-the-art multi-task algorithm called
convex fused sparse group Lasso [44].
• L21: A state-of-the-art multi-task algorithm called
L2,1 norm regularization with least square loss [1].
• Lasso: A state-of-the-art single task method called
Lasso regression [29].
• Ridge: A state-of-the-art single task method called
Ridge regression [16].
4.2. Multiply Time-slots Hippocampal Surface Fea-
ture Dataset (HP)
Hippocampus is a subcortical structure in the medial
temporal lobe of the brain [28]. Parametric shape mod-
els of the hippocampi are commonly developed for tracking
shape differences or longitudinal atrophy in brain diseases.
HP dataset consists of a total of 2246 subjects, consisting
of 837 baseline, 733 6-month and 676 12-month imaging
data. First, we used FIRST software [26] and marching
cube method [22] to automatically segment and reconstruct
hippocampal surfaces for each brain MR image. Then, we
registered and computed surface multivariate morphometry
statistics [34], which consist of surface multivariate tensor-
based morphometry and radial distances. For each sub-
ject, we obtained a 120,000 dimensional features of the hip-
pocampal surfaces and we use a 50×50 window to obtain a
collection of image patches as mentioned in Sec. 4.1. After
preprocessing the data, we have 220968, 193512, 178464
image patches for different time points, respectively. Our
goal is to predict Mini Mental State Examination (MMSE)
and Alzheimer’s Disease Assessment Scale cognitive sub-
scale (ADAS-cog) of the 24-month patients. We used 12-
month features learned by MSCC as Lasso design matrix
(since it contains the baseline, 6, 12-months surface fea-
tures) to train and test the 24-month clinical scores.
Comparison of Features from Different Layers The
deep learning model consists of multiple layers of feature
maps, whereby each layer is a different representation of
the input data. With this hierarchical representation, we se-
lected the layers which has the most discriminative power
to capture the characteristics of the input data by compar-
ing the features extracted from various layers of the deep
20 21 22 23 24 25 26 27 28 29 30 31
Actual MMSE
22
24
26
28
30
32
P
re
d
ic
te
d
 M
M
S
E
MSCC-R Results on Predicting 24-month MMSE
rMSE = 2.89, CORR = 0.73
23 24 25 26 27 28 29 30 31
Actual MMSE
22
23
24
25
26
27
28
29
30
31
P
re
d
ic
te
d
 M
M
S
E
CNN-MSCC Results on Predicting 24-month MMSE
rMSE = 2.52, CORR =
0.80
0 2 4 6 8 10 12 14 16 18 20
Actual ADAS-Cog
2
4
6
8
10
12
14
16
18
20
P
re
d
ic
te
d
 A
D
A
S
-C
o
g
MSCC-R Results on Predicting 24-month ADAS-Cog
rMSE = 5.04, CORR = 0.78
0 10 20 30 40
Actual ADAS-Cog
0
5
10
15
20
25
30
35
P
re
d
ic
te
d
 A
D
A
S
-C
o
g
CNN-MSCC Results on Predicting 24-month ADAS-Cog
rMSE = 4.47, CORR = 0.84
Figure 6: The scatter plots for MMSE and ADAS-cog of CNN-MSCC and MSCC-R on HP dataset.
6-month 12-month 24-month
Time Point
0
0.5
1
1.5
2
2.5
3
3.5
4
P
re
d
ic
te
d
 M
M
S
E
MSCC-R
MCI only
All
6-month 12-month 24-month
Time Point
0
0.5
1
1.5
2
2.5
3
3.5
4
P
re
d
ic
te
d
 M
M
S
E
CNN-MSCC
MCI only
All
6-month 12-month 24-month
Time Point
0
1
2
3
4
5
6
7
8
P
re
d
ic
te
d
 A
D
A
S
-C
o
g
MSCC-R
MCI only
All
6-month 12-month 24-month
Time Point
0
1
2
3
4
5
6
7
8
P
re
d
ic
te
d
 A
D
A
S
-C
o
g
CNN-MSCC
MCI only
All
Figure 7: Comparison of MMSE and ADAS-cog prediction models in terms of rMSE on patients using only MCI patients in
training (MCI only), and using MCI patients together with AD patients and normal controls (All) on ROI dataset.
model CNN-R and CNN-MSCC. Specifically, we used the
HP data as inputs to train the network and extracted features
from 4th, 5th, 6th and 7th layers. These features were used
to predict the MMSE and ADAS-cog of 24-month patients,
the results are given in Fig. 4. We observed that the 6th layer
features outperformed the others in terms of overall perfor-
mance in all three different deep models. The discriminative
power increases from the 4th to 6th layer, and then drops af-
terwards as the depth of network increases. One reasonable
explanation about this observation is the lower layers do not
fully capture the surface features and the higher layers cap-
tured features that are specific to the training natural image
set, and these features may not be relevant for surface fea-
tures. In this paper, we use the 6th layer’s features (4096)
as the number of rows for all the dictionaries.
The Size of Common Dictionaries in MSCC In MSCC,
the common dictionary is assumed to be shared by differ-
ent tasks. It is necessary to evaluate what is the appro-
priate size of such common dictionary. Therefore, we set
the dictionary size to be 2000 and partitioned the dictionary
by different proportions: 250:1750, 500:1500, 1000:1000,
1500:500 and 1750:250. The left one is the size of common
dictionary while the right one is the size of individual dic-
tionary for each task. We used two methods MSCC-R and
CNN-MSCC to evaluate the regression performance. Fig. 5
shows the results of rMSE of MMSE and ADAS-cog pre-
diction on HP dataset. As it shows in Fig. 5, the rMSE of
MMSE and ADAS-Cog are lowest when we split the dictio-
nary by half and a half. It means the both of common and
individual dictionaries are of equal importance during the
multi-task learning. In all experiments, we use the split of
1000:1000 as the size of common and individual dictionar-
ies and 2000 is the number of columns (dimension of each
sparse code) for all the dictionaries.
Performance Comparison. We compared the results of
CNN-MSCC with other state-of-the-art methods on predict-
ing 24-month MMSE and ADAS-cog in Table 2 and CNN-
MSCC outperformed all other methods. The results of
CNN-R and cFSGL are very close while MSCC-R methods
are superior to them. For dictionary learning models, we ob-
serve that MSCC-R obtained a lower rMSE result than tra-
ditional dictionary learning method OLSC-R since we con-
sider the correlation between different time slots for differ-
ent tasks and the relationship with different time points on
the same patient among all tasks. For the multi-task meth-
ods, we observed MSCC-R has better performance than L21
and cFSGL. Comparing with single-task methods, we no-
ticed that the dictionary learning methods have better per-
formance. We also show scatter plots of CNN-MSCC and
MSCC-R for the predicted values versus the actual values
for MMSE and ADAS-Cog on the testing data in Fig. 6, it
shows that CNN-MSCC achieved higher predictive correla-
tion on both MMSE and ADAS-Cog.
Table 2: The results of predicting 24-month MMSE and
ADAS-cog on HP dataset.
Methods MMSE rMSE ADAS-cog rMSE
CNN-MSCC 2.769±0.455 4.977±1.000
CNN-R 3.897±0.565 6.775±1.680
MSCC-R 3.033±0.747 5.860±1.135
OLSC-R 4.656±0.575 7.553±1.022
cFSGL 3.635±0.707 6.132±1.889
L21 4.323±0.834 7.910±0.719
Lasso 5.113±0.723 7.024±0.880
Ridge 4.957±0.443 7.661±0.677
Table 3: The MMSE results of 6-month, 12-month and 24-month on ROI dataset.
Methods nMSE wR M06 M12 M24
CNN-MSCC 0.274±0.051 0.751±0.083 2.198±0.062 2.211±0.459 2.290±0.601
CNN-R 0.311±0.051 0.681±0.091 2.218±0.062 2.396±0.250 2.591±0.420
MSCC-R 0.308±0.058 0.654±0.036 2.451±0.357 2.566±0.560 2.859±0.494
OLSC-R 0.337±0.112 0.692±0.074 2.578±0.319 2.954±0.746 3.706±0.711
cFSGL 0.312±0.037 0.726±0.066 2.424±0.315 2.691±0.272 2.906±0.907
L21 0.281±0.032 0.572±0.082 2.535±0.473 2.897±0.990 3.107±0.501
Lasso 0.302±0.078 0.423±0.073 2.659±0.804 2.904±0.658 3.335±0.692
Ridge 0.299±0.101 0.449±0.091 2.766±0.776 3.001±0.280 3.621±0.893
Table 4: The ADAS-cog results of 6-month, 12-month and 24-month on ROI dataset.
Methods nMSE wR M06 M12 M24
CNN-MSCC 0.762±0.012 0.862±0.045 4.322±0.269 4.930±0.192 5.521±0.816
CNN-R 0.802±0.059 0.712±0.058 5.521±0.712 5.913±0.213 6.012±0.941
MSCC-R 0.792±0.039 0.837±0.045 4.506±0.452 5.124±0.689 5.835±1.042
OLSC-R 0.828±0.079 0.681±0.052 5.080±0.589 5.860±0.608 6.179±1.001
cFSGL 0.795±0.052 0.836±0.031 4.451±0.340 5.230±0.589 6.249±0.996
L21 0.811±0.080 0.554±0.062 4.476±0.931 5.453±0.392 6.279±1.232
Lasso 0.809±0.110 0.518±0.080 5.295±0.763 5.799±1.001 6.729±0.705
Ridge 0.819±0.108 0.497±0.071 5.534±0.542 5.907±0.885 6.543±0.844
4.3. Multiple Baseline Brain ROIs Surface Features
Dataset (ROI)
In this experiment, we utilized three structural mea-
sures of brain, which are hippocampi (as we mentioned in
Sec. 4.2), lateral ventricle and cortical thickness, from the
ADNI baseline dataset (N = 837). In brief, the lateral ven-
tricles are often enlarged in disease and can provide sen-
sitive measures of disease progression [28] and the corti-
cal thickness can be used as an anatomical index for quan-
tifying cortical shape variations [7]. For the hippocampal
surface features, we used the same methods as HP dataset
while for the ventricular surface features we did the follow-
ing. First, we segmented images of the lateral ventricles to
build the ventricular structure surface models using a level-
set based topology preserving method [14]. Then we com-
puted surface registrations using the canonical holomorphic
one-form segmentation method [33]. Finally, surface multi-
variate morphometry statistics [34] were computed and ob-
tained as a 308,247 dimensional features of the ventricular
surfaces for each subject. The cortical thickness was com-
puted by FreeSurfer [12] which deforms the white surface to
pial surface and measures deforming distance as the cortical
thickness. The spherical parameter surface and weighted
spherical harmonic representation [6][38] are used to regis-
ter pial surfaces across subjects, which means each subjects
have the same dimension (161,800) cortical thickness. The
image patch size is 50× 50 as mentioned in Sec. 4.1. After
preprocessing the data, we have 220968, 2867562, 1504926
image patches for multiple input tasks, respectively.
Performance Comparison. We constructed the predic-
tion models by first forming the final baseline data from the
combined three tasks features. Then, we used Lasso to indi-
vidually predict 6-month, 12-month and 24-month MMSE
and ADAS-cog scores with 8:2 ratio on training and testing
data sets. The prediction results are reported in Table 3 and
Table 4. We can observe that the performance of predict-
ing 6-month, 12-month and 24-month scores of MMSE and
ADAS-Cog are improved by CNN-MSCC and MSCC-R for
all three time points. We can also notice that the significant
improvement of the proposed CNN-MSCC and MSCC-R
for later time points (12, 24-month). This may be due to
the data sparseness in later time points, as the proposed
sparsity-inducing models are expected to achieve better pre-
diction performance. Also, the improvement of ADAS-cog
is more significant than MMSE.
Comparing MCI vs. all Baseline Dataset. In the study
of AD, MCI patients are of particular interest because peo-
ple with MCI are at high risk of progression to dementia.
We studied the prediction performance on MCI patients and
MCI patients together with AD patients and normal controls
(CN) on ROI dataset. In the first experiment, we used only
MCI patients in both training and testing data. We random
split the MCI patients with 8:2 ratio for training and test-
ing. For another experiment, we follow the same practice
as in our previous experiments. The performance of pre-
dicting MMSE and ADAS-cog at all time points is given in
Fig. 7. We see that in most cases the prediction performance
together with AD and CN induce the performance improve-
ment. This may be due to the small sample size at later time
points, in which the information from AD and CN subjects
may be useful during the learning. Our discovery may shed
new light onto the clinical cognitive score prediction of AD.
5. Conclusions and Future Work
In this work, we proposed a deep learning model, multi-
task dictionary learning based CNN to incorporate multiple
time slots or multiple brain ROI imaging features, for pre-
dicting the AD clinical score. The proposed model is val-
idated by extensive experimental studies and shown to be
more efficient than seven other state-of-the-art methods. In
future work, we will optimize our method and investigate
its capability on brain multimodality imaging datasets.
References
[1] A. Argyriou, T. Evgeniou, and M. Pontil. Convex multi-task
feature learning. Machine Learning, 73(3):243–272, 2008. 6
[2] J. Blitzer, R. McDonald, and F. Pereira. Domain adaptation
with structural correspondence learning. In Proceedings of
the 2006 conference on empirical methods in natural lan-
guage processing, pages 120–128. Association for Compu-
tational Linguistics, 2006. 1
[3] Y.-L. Boureau, J. Ponce, and Y. LeCun. A theoretical anal-
ysis of feature pooling in visual recognition. In Proceed-
ings of the 27th international conference on machine learn-
ing (ICML-10), pages 111–118, 2010. 5
[4] R. Brookmeyer, E. Johnson, K. Ziegler-Graham, and H. M.
Arrighi. Forecasting the global burden of Alzheimer’s dis-
ease. Alzheimer’s & dementia, 3(3):186–191, 2007. 5
[5] A. A. Canutescu and R. L. Dunbrack. Cyclic coordinate de-
scent: A robotics algorithm for protein loop closure. Protein
science, 12(5):963–972, 2003. 5
[6] M. K. Chung, K. M. Dalton, and R. J. Davidson. Tensor-
based cortical surface morphometry via weighted spheri-
cal harmonic representation. IEEE Trans Med Imaging,
27(8):1143–1151, Aug 2008. 8
[7] M. K. Chung, S. Robbins, and A. C. Evans. Unified statisti-
cal approach to cortical thickness analysis. In Biennial Inter-
national Conference on Information Processing in Medical
Imaging, pages 627–638. Springer, 2005. 8
[8] R. Collobert and J. Weston. A unified architecture for natural
language processing: Deep neural networks with multitask
learning. In Proceedings of the 25th international conference
on Machine learning, pages 160–167. ACM, 2008. 2
[9] P. L. Combettes and V. R. Wajs. Signal recovery by proximal
forward-backward splitting. Multiscale Modeling & Simula-
tion, 4(4):1168–1200, 2005. 5
[10] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-
Fei. Imagenet: A large-scale hierarchical image database.
In Computer Vision and Pattern Recognition, 2009. CVPR
2009. IEEE Conference on, pages 248–255. IEEE, 2009. 3
[11] D. L. Donoho and M. Elad. Optimally sparse represen-
tation in general (nonorthogonal) dictionaries via l1 mini-
mization. Proceedings of the National Academy of Sciences,
100(5):2197–2202, 2003. 2
[12] B. Fischl. Freesurfer. Neuroimage, 62(2):774–781, 2012. 8
[13] G. B. Frisoni, N. C. Fox, C. R. Jack, P. Scheltens, and P. M.
Thompson. The clinical use of structural MRI in Alzheimer
disease. Nat Rev Neurol, 6(2):67–77, Feb 2010. 2
[14] X. Han, C. Xu, and J. L. Prince. A topology preserving
level set method for geometric deformable models. IEEE
Transactions on Pattern Analysis and Machine Intelligence,
25(6):755–768, 2003. 8
[15] H. C. Hazlett, H. Gu, B. C. Munsell, S. H. Kim, M. Styner,
J. J. Wolff, J. T. Elison, M. R. Swanson, H. Zhu, K. N. Bot-
teron, et al. Early brain development in infants at high risk
for autism spectrum disorder. Nature, 542(7641):348–351,
2017. 1
[16] A. E. Hoerl and R. W. Kennard. Ridge regression: Bi-
ased estimation for nonorthogonal problems. Technometrics,
12(1):55–67, 1970. 6
[17] C. R. Jack, M. A. Bernstein, N. C. Fox, P. Thompson,
G. Alexander, D. Harvey, B. Borowski, P. J. Britson,
J. L Whitwell, C. Ward, et al. The alzheimer’s disease neu-
roimaging initiative (adni): Mri methods. Journal of mag-
netic resonance imaging, 27(4):685–691, 2008. 3, 5
[18] Y. Jia, E. Shelhamer, J. Donahue, S. Karayev, J. Long, R. Gir-
shick, S. Guadarrama, and T. Darrell. Caffe: Convolu-
tional architecture for fast feature embedding. arXiv preprint
arXiv:1408.5093, 2014. 5
[19] A. Krizhevsky, I. Sutskever, and G. E. Hinton. Imagenet
classification with deep convolutional neural networks. In
Advances in neural information processing systems, pages
1097–1105, 2012. 1, 3
[20] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. Gradient-
based learning applied to document recognition. Proceed-
ings of the IEEE, 86(11):2278–2324, 1998. 1
[21] B. Lin, Q. Li, Q. Sun, M.-J. Lai, I. Davidson, W. Fan,
and J. Ye. Stochastic coordinate coding and its applica-
tion for drosophila gene expression pattern annotation. arXiv
preprint arXiv:1407.8147, 2014. 2
[22] W. E. Lorensen and H. E. Cline. Marching cubes: A high res-
olution 3d surface construction algorithm. In ACM siggraph
computer graphics, volume 21, pages 163–169. ACM, 1987.
6
[23] J. Mairal, F. Bach, J. Ponce, and G. Sapiro. Online dictionary
learning for sparse coding. In Proceedings of the 26th Annual
International Conference on Machine Learning, pages 689–
696. ACM, 2009. 2, 3, 6
[24] A. Maurer, M. Pontil, and B. Romera-Paredes. Sparse coding
for multitask and transfer learning. In Proceedings of the
30th International Conference on Machine Learning, ICML
2013, Atlanta, GA, USA, 16-21 June 2013, pages 343–351,
2013. 2
[25] S. J. Pan and Q. Yang. A survey on transfer learning.
IEEE Transactions on knowledge and data engineering,
22(10):1345–1359, 2010. 1
[26] B. Patenaude, S. M. Smith, D. N. Kennedy, and M. Jenkin-
son. A bayesian model of shape and appearance for subcor-
tical brain segmentation. Neuroimage, 56(3):907–922, 2011.
6
[27] A. Sharif Razavian, H. Azizpour, J. Sullivan, and S. Carls-
son. Cnn features off-the-shelf: an astounding baseline for
recognition. In Proceedings of the IEEE Conference on Com-
puter Vision and Pattern Recognition Workshops, pages 806–
813, 2014. 1
[28] P. M. Thompson, K. M. Hayashi, G. I. De Zubicaray, A. L.
Janke, S. E. Rose, J. Semple, M. S. Hong, D. H. Herman,
D. Gravano, D. M. Doddrell, et al. Mapping hippocampal
and ventricular change in alzheimer disease. Neuroimage,
22(4):1754–1766, 2004. 6, 8
[29] R. Tibshirani. Regression shrinkage and selection via the
lasso. Journal of the Royal Statistical Society. Series B
(Methodological), pages 267–288, 1996. 3, 6
[30] S. C. Turaga, J. F. Murray, V. Jain, F. Roth, M. Helmstaedter,
K. Briggman, W. Denk, and H. S. Seung. Convolutional net-
works can learn to generate affinity graphs for image seg-
mentation. Neural computation, 22(2):511–538, 2010. 1
[31] J. Wang, Q. Li, S. Yang, W. Fan, P. Wonka, and J. Ye. A
highly scalable parallel algorithm for isotropic total variation
models. In Proceedings of the 31st International Conference
on Machine Learning (ICML-14), pages 235–243, 2014. 2
[32] X. Wang, T. Zhang, T. M. Chaim, M. V. Zanetti, and
C. Davatzikos. Classification of mri under the presence of
disease heterogeneity using multi-task learning: Applica-
tion to bipolar disorder. In Medical Image Computing and
Computer-Assisted Intervention–MICCAI 2015, pages 125–
132. Springer, 2015. 2
[33] Y. Wang, T. F. Chan, A. W. Toga, and P. M. Thompson. Mul-
tivariate tensor-based brain anatomical surface morphometry
via holomorphic one-forms. In International Conference on
Medical Image Computing and Computer-Assisted Interven-
tion, pages 337–344. Springer, 2009. 8
[34] Y. Wang, Y. Song, P. Rajagopalan, T. An, K. Liu, Y. Y. Chou,
B. Gutman, A. W. Toga, and P. M. Thompson. Surface-based
TBM boosts power to detect disease effects on the brain:
an N=804 ADNI study. Neuroimage, 56(4):1993–2010, Jun
2011. 6, 8
[35] M. D. Zeiler and R. Fergus. Visualizing and understanding
convolutional networks. In European Conference on Com-
puter Vision, pages 818–833. Springer, 2014. 1
[36] D. Zhang, D. Shen, A. D. N. Initiative, et al. Multi-modal
multi-task learning for joint prediction of multiple regression
and classification variables in alzheimer’s disease. NeuroIm-
age, 59(2):895–907, 2012. 2
[37] J. Zhang. Deep transfer learning via restricted boltzmann
machine for document classification. In Machine Learning
and Applications and Workshops (ICMLA), 2011 10th Inter-
national Conference on, volume 1, pages 323–326. IEEE,
2011. 1
[38] J. Zhang, Y. Fan, Q. Li, P. M. Thompson, J. Ye, and Y. Wang.
Empowering cortical thickness measures in clinical diagno-
sis of alzheimer’s disease with spherical sparse coding. In
Biomedical Imaging (ISBI 2017), 2017 IEEE 14th Interna-
tional Symposium on, pages 446–450. IEEE, 2017. 8
[39] J. Zhang, Q. Li, R. J. Caselli, P. M. Thompson, J. Ye, and
Y. Wang. Multi-source multi-target dictionary learning for
prediction of cognitive decline. In International Conference
on Information Processing in Medical Imaging, pages 184–
197. Springer, 2017. 5
[40] J. Zhang, J. Shi, C. Stonnington, Q. Li, B. A. Gutman,
K. Chen, E. M. Reiman, R. Caselli, P. M. Thompson, J. Ye,
et al. Hyperbolic space sparse coding with its application
on prediction of alzheimers disease in mild cognitive impair-
ment. In International Conference on Medical Image Com-
puting and Computer-Assisted Intervention, pages 326–334.
Springer, 2016. 2
[41] J. Zhang, C. Stonnington, Q. Li, J. Shi, R. J. Bauer, B. A.
Gutman, K. Chen, E. M. Reiman, P. M. Thompson, J. Ye,
et al. Applying sparse coding to surface multivariate tensor-
based morphometry to predict future cognitive decline. In
Biomedical Imaging (ISBI), 2016 IEEE 13th International
Symposium on, pages 646–650. IEEE, 2016. 2
[42] T. Zhang. Solving large scale linear prediction problems us-
ing stochastic gradient descent algorithms. In Proceedings of
the twenty-first international conference on Machine learn-
ing, page 116. ACM, 2004. 5
[43] W. Zhang, R. Li, T. Zeng, Q. Sun, S. Kumar, J. Ye, and S. Ji.
Deep model based transfer and multi-task learning for bi-
ological image analysis. In Proceedings of the 21th ACM
SIGKDD International Conference on Knowledge Discovery
and Data Mining, pages 1475–1484. ACM, 2015. 1, 2
[44] J. Zhou, J. Liu, V. A. Narayan, and J. Ye. Modeling disease
progression via multi-task learning. Neuroimage, 78:233–
248, Sep 2013. 2, 6
