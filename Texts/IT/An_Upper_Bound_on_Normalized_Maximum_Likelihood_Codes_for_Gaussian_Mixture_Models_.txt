An Upper Bound on Normalized Maximum Likelihood Codes for
Gaussian Mixture Models
So Hirai and Kenji Yamanishi ?
Abstract
This paper shows that the normalized maximum likelihood (NML) code-length calculated in [1] is
an upper bound on the NML code-length strictly calculated for the Gaussian Mixture Model. We call
an upper bound on the NML code-length as uNML (upper bound on NML). When we use this uNML
code-length, we have to change the scale of data sequence to satisfy the restricted domain. However, in
the point of model selection, we find the fact that the model selection algorithm is essentially universal
regardless of scale conversion of data in Gaussian Mixture Models, and the experimental results of paper
[1] can be used as it is.
In addition to this, we correct the normalized maximum likelihood (NML) code-length for generalized
logistic distribution calculated in [1].
1 Problem Setting
In this paper, we consider the problem of model selection in which we aims to calculate the number of clusters
for Gaussian Mixture Model. Let us use the given sequence xn = (x1, · · · , xn), xi = (xi1, · · · , xim)> (i = 1, · · · , n).
Here, we use the Gaussian Model Class: N(µ, ?), µ ? Rm, ? ? Rm×m, and calculate NML code-length for
Gaussian Model. The Gaussian distribution for data sequence xn is defined as follows:
f (xn; µ, ?) = 1
(2?)mn2 · |? | n2
exp
{
? 1
2
n?
i=1
(xi ? µ)>??1(xi ? µ)
}
.
We define the NML distribution fNML relative to a model class M = { f (Xn; ?) : ? ? ?} by
fNML(xn;M)
def
=
f (xn; µ?(xn), ??(xn))?
Y
f (yn; µ?(yn), ??(yn))dyn
. (1)
Here Y is the restricted domain for xn. By using this restrict, we can calculate the NML code-length without
divergence.
The NML code-length for Gaussian Mixture Model is defined as below with latent variable zn:
LNML(xn, zn;Y,M(K))
def
= ? log fNML(xn, zn)
= ? log f (xn, zn;M(K), ??(xn, zn)) + log C(M(K), n), (2)
C(M(K), n) =
?
wn
?
Y
f (yn,wn;M(K), ??(yn,wn))dyn. (3)
Here ? = (?, µ, ?) is the set of parameters, We consider problem of model selection for Gaussian Mixture
Model with using (2) as a criterion.
?S. Hirai and K. Yamanishi are with Graduate School of Information Science and Technology, The University of Tokyo, 7-3-1
Hongo, Bunkyo-ku, Tokyo, JAPAN
E-mail: so hirai@mist.i.u-tokyo.ac.jp
E-mail: yamanishi@mist.i.u-tokyo.ac.jp
1
ar
X
iv
:1
70
9.
00
92
5v
1 
 [
cs
.I
T
] 
 4
 S
ep
 2
01
7
2 Influence of scale conversion of data on model selection
When we use the NML code-length defined by (2), we have to change the scale of data sequence to safisfy the
restricted domain Y (e.g. to multiply 1/?, etc.). In this section, we show that the model selection algorithm
is essentially universal regardless of scale conversion of data.
Let us consider the NML code-length for Gaussian Mixture Model as LNML(xn, zn;Y,M(K)), and we can
get the definition of code-length as (2). The term influenced by the scale of the data is the first term of the
formula (2). Here, in order to evaluate the influence of the first term from the scale conversion of the data,
we use the dataset xn? (= xn/?) which we calculate by multiplting xn by 1/?. We consider model selection
when each data xn or xn? is used, and evaluate the difference between them. Since it is important for model
selection to evaluate the difference between M(K1) and M(K2), we focus on the difference in the first term
of equation (2).
? log f (xn?, zn;M(K1), ??(xn?, zn)) ? (? log f (xn?, zn;M(K2), ??(xn?, zn))
= C +
K1?
k=1
m?
j=1
hk
2
log ??j(xn?) ?
K2?
k=1
m?
j=1
h?
k
2
log ???j(xn?)
= C +
K1?
k=1
m?
j=1
hk
2
{
log ??j(xn) ? 2 log ?
}
?
K2?
k=1
m?
j=1
h?
k
2
{
log ???j(xn) ? 2 log ?
}
(4)
= C +
K1?
k=1
m?
j=1
hk
2
log ??j(xn) ?
K2?
k=1
m?
j=1
h?
k
2
log ???j(xn)
= ? log f (xn, zn;M(K1), ??(xn, zn)) ? (? log f (xn, zn;M(K2), ??(xn, zn)) (5)
where we define
C def= ?
K1?
k=1
hk log ??k +
K2?
k=1
h?k log ??
?
k +
K1?
k=1
mhk
2
log 2?e ?
K2?
k=1
mh?
k
2
log 2??e
and each hk, h?k represents the number of data which belong to k under the model class M(K1),M(K2). This
shows us that the difference of code-length is not effected by scale conversion of data, and it is possible for us
to process the data so as to satisfy the restriction and use it for model selection without changing the result.
Here, in this paper, we define the restricted domain with maximum likelihood estimator (MLE) of param-
eter µ?, ?? = (??1, · · · , ??m), where each ??j is j-th eigen values of ??. These MLEs are changed by scale conversion
of data as follows:
µ?? =
1
n
n?
i=1
xi? =
1
n?
n?
i=1
xi =
1
?
µ?, (6)
??? =
1
n
n?
i=1
(xi? ? µ??)(xi? ? µ??)> =
1
n?2
n?
i=1
(xi ? µ?)(xi ? µ?)> =
1
?2
?? =
1
?2
U?U>
? ??j? =
1
?2
??j . (7)
Here the data sequence xn denotes data assigned to a cluster. This shows that the MLEs of parameters can
be converted into arbitorary size by scale conversion of data.
3 An upper bound on NML code-length
By the discussion of section 2, the model selection algorithm is essentially universal regardless of scale
conversion of data. Using this feature, we restrict the domain in order to calculate NML code-length. We
show that the code-length calculated by [1] is an upper bound on the the NML code-length strictly calculated
for the Gaussian Mixture Model, and we can use this code-length called uNML for model selection.
2
3.1 1st Change Point of [1]
We use the Shtarkov’s minmax regret with restricted domain as follows:
min
Q
max
xn ?Y(R,1,2)
{
? log Q(xn) ?min
?
(? log P(xn |?))
}
(8)
Y (R, 1, 2)
def
= {yn | | | µ?(yn)| |2 ? R, 1j ? ??j(yn) ? 2j ? 2 < 1 ( j = 1, · · · ,m),
Vol(O(m))
2m
· 
m(m?1)
2
2 ? 1, y
n ? Xn}. (9)
3.2 2nd Change Point for [1]
Using the restricted domain (9), we can calculate an upper bound on NML code-length as follows:
C(M, n) =
?
Y(R,1,2)
f (yn; µ?(yn), ??(yn)) dyn
=
?
?(µ?(xn) = µ?, ??(xn) = ??) dyn
?
| |µ? | |2?R
dµ
?
g(??) d??
=
?
| |µ? | |2?R
dµ
?
dU
?
1 j ??? j ?2 j
g(??)
?
1?i< j?m
|??i ? ??j | d?? (10)
<
?
dU · 
m(m?1)
2
2
?
| |µ? | |2?R
dµ
?
1 j ??? j ?2 j
g(??) d??
=
Vol(O(m))
2m
· 
m(m?1)
2
2 ·
2m+1R
m
2 (?mj=1 1j?m2 ??mj=1 2j?m2 )
mm+1 · ?
(
m
2
) · ( n
2e
) mn
2 1
?m( n?12 )
<
2m+1R
m
2
?m
j=1 1j
?m
2
mm+1 · ?
(
m
2
) × ( n
2e
) mn
2 1
?m( n?12 )
= B(m, R, ) ×
( n
2e
) mn
2 1
?m( n?12 )
. (11)
Here equation (11) equals to code-length calculated in [1], and represents an upper bound on NML code-
length. From this fact, we can use the uNML (11) for model selection with the data which satisfy the
restricted domain (9).
Here, we can define an upper bound on NML (uNML) code-length as follows:
LuNML(xn;Y,M)
def
= ? log fuNML(xn;M)
= ? log f (xn;M, ??(xn)) + log Cu(M, n),
Cu(M, n) = B(m, R, ) ×
( n
2e
) mn
2 1
?m( n?12 )
.
In calculating uNML code-length for Gaussian Mixture Models, we can use this definition of normalization
term in the same way as [1].
3.3 Points to be aware of when handling this code length
Using this uNML code-length, we have to change the scale of data sequence to safisfy the restricted domain
(9). From the discussion in section 2, in computation, we can use it for model selection without scale
conversion of data. In the experiments of paper [1], as we can scale artificial dataset to safisfy the restricted
domain (9), the experimental results of paper [1] can be used as it is.
3
4 Summary of modified [1]
Here, the following text quotes the sentence of the paper [1] and it is modified to describe the calculation of
an upper bound on NML code-length.
Let an observed data sequence be xn = (x1, · · · , xn) where xi = (xi1, · · · , xim)> (i = 1, · · · , n). We use a class
of Gaussian distributions: N(µ, ?), where µ ? Rm is a mean vector, ? ? Rm×m is a covariance matrix, and m
is the dimension of xi . A probability density function of x
n for the Gaussian distribution is given by
f (xn; µ, ?) = 1
(2?)mn2 · |? | n2
exp
{
? 1
2
n?
i=1
(xi ? µ)>??1(xi ? µ)
}
,
and the NML distribution based on the Gaussian distribution is defined as follows:
fNML(xn)
def
=
f (xn; µ?(xn), ??(xn))?
Y(R,1,2)
f (yn; µ?(yn), ??(yn))dyn
(12)
where µ?(xn) and ??(xn) are the MLEs of µ and ? respectively:
µ?(xn) = 1
n
n?
i=1
xi,
??(xn) = 1
n
n?
i=1
(xi ? µ?(xn))(xi ? µ?(xn))>.
For given constants R, 1, 2, we set a restricted domain as follows:
Y (R, 1, 2)
def
= {yn | | | µ?(yn)| |2 ? R, 1j ? ??j(yn) ? 2j ? 2 < 1 ( j = 1, · · · ,m),
Vol(O(m))
2m
· 
m(m?1)
2
2 ? 1, y
n ? Xn}, (13)
where ??j(yn) ( j = 1, · · · ,m) are eigen values of ??(yn). This restriction makes the calculation of an upper
bound on normalization term C(M, n) easier, as shown below.
First, by substituting MLE µ?(xn), ??(xn) into the formula (12), the numerator of Eq. (12) can be expressed
as follows:
f (xn; µ?(xn), ??(xn)) =
n?
i=1
1
(2?)m2 |??(xn)| 12
× exp
{
? 1
2
(xi ? µ?(xn))>??(xn)?1(xi ? µ?(xn))
}
(14)
= (2?e)?mn2
m?
j=1
??j(xn)?
n
2 . (15)
Next, we calculate the denominator of formula (12). Using the fact that µ?(xn) and ??(xn) are sufficient
statistics, we can calculate the normalization term as an integral with respect to µ?, ??. As MLEs are sufficient
statistics, f (xn; µ, ?) is decomposed as follows:
f (xn; µ, ?) = f (xn | µ?(xn), ??(xn)) · g1(µ?(xn); µ, ?) · g2(??(xn); ?).
where
g1(µ?(xn); µ, ?)
def
=
1
(2?/n)m2 |? | 12
exp
{
? 1
2/n (µ?(x
n) ? µ)>??1(µ?(xn) ? µ)
}
,
g2(??(xn); ?)
def
=
|??(xn)| n?m?22
2
m(n?1)
2 | 1n? |
n?1
2 ?m( n?12 )
× exp
{
? 1
2
Tr(n??1??(xn))
}
.
4
Here we define the function f (xn | µ?(xn), ??(xn)) = ?(µ?(xn) = µ?, ??(xn) = ??). We fix values µ?(xn) = µ?, ??(xn) = ??,
and let
g(??) def= g1(µ?; µ?, ??) · g2(??; ??) (16)
=
n
mn
2
2
mn
2 ?
m
2 e
mn
2 ?m( n?12 )
·
m?
j=1
??
?m
2
?1
j . (17)
Letting the normalization term of formula (12) be C(M, n), we can calculate an upper bound on it by
integrating g(??) with respect to µ?, ?? over the restricted domain as follows:
C(M, n) =
?
Y(R,1,2)
f (yn; µ?(yn), ??(yn)) dyn
=
?
?(µ?(xn) = µ?, ??(xn) = ??) dyn
?
| |µ? | |2?R
dµ
?
g(??) d??
=
?
| |µ? | |2?R
dµ
?
dU
?
1 j ??? j ?2 j
g(??)
?
1?i< j?m
|??i ? ??j | d?? (18)
<
?
dU · 
m(m?1)
2
2
?
| |µ? | |2?R
dµ
?
1 j ??? j ?2 j
g(??) d??
=
Vol(O(m))
2m
· 
m(m?1)
2
2 ·
2m+1R
m
2 (?mj=1 1j?m2 ??mj=1 2j?m2 )
mm+1 · ?
(
m
2
) · ( n
2e
) mn
2 1
?m( n?12 )
<
2m+1R
m
2
?m
j=1 1j
?m
2
mm+1 · ?
(
m
2
) × ( n
2e
) mn
2 1
?m( n?12 )
= B(m, R, ) ×
( n
2e
) mn
2 1
?m( n?12 )
. (19)
where the formula (18) owes to [2], and we define B(m, R, ) by
B(m, R, ) def=
2m+1R
m
2
?m
j=1 1j
?m
2
mm+1 · ?
(
m
2
) .
B(m, R, ) does not depend on a number of data n. Since (19) is finite, an upper bound on normalization term
C(M, n) does not diverge.
Here, we can define an upper bound on NML (uNML) code-length as follows:
LuNML(xn;Y,M)
def
= ? log fuNML(xn;M)
= ? log f (xn;M, ??(xn)) + log Cu(M, n),
Cu(M, n) = B(m, R, ) ×
( n
2e
) mn
2 1
?m( n?12 )
.
In calculating uNML code-length for Gaussian Mixture Models, we can use this definition of normalization
term in the same way as [1].
5 Correction of NML for Generalized logistic distribution
Here, the following text quotes the sentence of the paper [1] and it is modified to describe the correction of
NML for generalized logistic distribution.
5
In the paper [1], we use the generalized logistic distribution as an example of exponential family. The
density function of xn for a generalized logistic distribution with a parameter ? is defined as
f (xn; ?) =
n?
i=1
?e?xi
(1 + e?xi )?+1 .
The MLE of ? is analytically obtained as ??(xn) = n/(?ni=1 log(1+e?xi )). Thus the joint density of xn is written
as
f (xn; ?) = ?n · exp
{
?
n?
i=1
xi ?
n(? + 1)
??(xn)
}
= H(xn |??(xn)) · g(??(xn); ?),
where n/??(xn) is distributed according to the Gamma distribution with a shape parameter n and a scale
parameter 1/?.
Here, we correct the function g(??(xn); ?) and the result of NML code-length changes. First, the function
g(??(xn); ?) is written as:
g(??(xn); ?) = ?
n
(n ? 1)! ·
nn
??(xn)n+1
· exp
{
?? · n
??(xn)
}
.
Fix ??(xn) = ??. Then we have
g(??; ??) = n
n
en(n ? 1)! ·
1
??
.
Then the normalization term: C(M) is calculated by taking an integral of g(??; ??) with respect to ??. Here we
use hyper-parameters ?min, ?max to restrict the domain for the integral to be taken as follows:
Y (?min, ?max) =
{
yn |?min ? ??(yn) ? ?max
}
.
Then we have
C(M) =
?
Y(?min,?max)
g(??; ??)d??
=
nn
en(n ? 1)!
? ?max
?min
1
??
d??
=
nn
en(n ? 1)! · log
?max
?min
.
Hence we obtain an approximation of the normalization term C(M) for generalized logistic distributions in
an analytical way.
6 Acknowledgements
This work was supported by JST-CREST. We thank Professor Takeuchi at Kyushu University and Mr.
Miyaguchi at The University of Tokyo for helpful discussion.
References
[1] S. Hirai and K. Yamanishi. Efficient computation of normalized maximum likelihood codes for gaussian
mixture models with its applications to clustering. JOURNAL OF IEEE INFORMATION THEORY,
2013.
[2] Arakaparampil M Mathai. Jacobians of matrix transformations and functions of matrix arguments. World
Scientific Publishing Co Inc, 1997.
6
