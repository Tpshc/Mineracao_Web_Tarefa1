ar
X
iv
:1
70
9.
00
67
5v
1 
 [
cs
.I
T
] 
 3
 S
ep
 2
01
7
1
Two-Way Interference Channel Capacity:
How to Have the Cake and Eat it Too
Changho Suh, Jaewoong Cho and David Tse
Abstract
Two-way communication is prevalent and its fundamental limits are first studied in the point-
to-point setting by Shannon [1]. One natural extension is a two-way interference channel (IC) with
four independent messages: two associated with each direction of communication. In this work, we
explore a deterministic two-way IC which captures key properties of the wireless Gaussian channel.
Our main contribution lies in the complete capacity region characterization of the two-way IC (w.r.t. the
forward and backward sum-rate pair) via a new achievable scheme and a new converse. One surprising
consequence of this result is that not only we can get an interaction gain over the one-way non-
feedback capacities, we can sometimes get all the way to perfect feedback capacities in both directions
simultaneously. In addition, our novel outer bound characterizes channel regimes in which interaction
has no bearing on capacity.
Index Terms
Feedback Capacity, Interaction, Perfect Feedback, Two-Way Interference Channels
I. INTRODUCTION
Two-way communication, where two nodes want to communicate data to each other, is
prevalent. The first study of such two-way channels was done by Shannon [1] in the setting
of point-to-point memoryless channels. When the point-to-point channels in the two directions
are orthogonal (such as when the two directions are allocated different time slots or different
frequency bands, or when the transmitted signal can be canceled perfectly as in full-duplex
C. Suh and J. Cho are with the School of Electrical Engineering at Korea Advanced Institute of Science and Technology,
South Korea (Email: {chsuh, cjw2525}@kaist.ac.kr)
D. Tse is with the Electrical Engineering Department at Stanford University, CA, USA (Email: dntse@stanford.edu).
DRAFT
2
fwd msg 1
fwd msg 2
bwd msg 1
bwd msg 2
 
Fig. 1. Two interfering two-way communication links, consisting of two IC’s, one in each direction. The IC’s are orthogonal
to each other and do not necessarily have the same channel gains.
communication), the problem is not interesting as feedback does not increase point-to-point
capacity. Hence, communication in one direction cannot increase the capacity of the other
direction and no interaction gain is possible. One can achieve no more than the one-way capacity
in each direction.
The situation changes in network scenarios where feedback can increase capacity. In these
scenarios, communication in one direction can potentially increase the capacity of the other
direction by providing feedback in addition to communicating data. One scenario of particular
interest is the setting of the two-way interference channel (two-way IC), modeling two interfering
two-way communication links (Fig. 1). Not only is this scenario common in wireless commu-
nication networks, it has also been demonstrated that feedback provides a significant gain for
communication over (one-way) IC’s [2], [3], [4]. In particular, [3] reveals that the feedback
gain can be unbounded, i.e., the gap between the feedback and non-feedback capacities can
be arbitrarily large for certain channel parameters. This suggests the potential of significant
interaction gain in two-way IC’s. On the other hand, the feedback result [3] assumes a dedicated
infinite-capacity feedback link. In the two-way setting, any feedback needs to be transmitted
through a backward IC, which also needs to carry its own backward data traffic. The question is
when we take in consideration the competition with the backward traffic, whether there is still
any net interaction gain through feedback?
To answer this question, [5] investigated a two-way IC under the linear deterministic model [6],
which approximates a Gaussian channel. A scheme is proposed to demonstrate a net interaction
DRAFT
3
interaction 
gain
interaction 
gain
interaction 
gain
no interaction gain
interaction 
gain
perfect
feedback
perfect 
feedback
no feedback gain
no
interaction
gain
 
Fig. 2. When can one have the cake and eat it too? The plot is over two channel parameters of the deterministic model, ?
and ??, where ? is the ratio of the interference-to-noise ratio (in dB) to the signal-to-noise ratio (in dB) of the IC in the forward
direction and ?? is the corresponding quantity of the IC in the backward direction. The parameter ? is the ratio of the backward
signal-to-noise ratio (in dB) to the forward signal-to-noise ratio (in dB), and is fixed to be a value between 1 and 4. White
region: feedback does not increase capacity in either direction and thus interaction is not useful. Purple: feedback does increase
capacity but interaction cannot provide such increase. Light blue: feedback can be provided through interaction and there is a
net interaction gain. Dark blue: interaction is so efficient that one can achieve perfect feedback capacity simultaneously in both
directions. This implies that one can obtain the maximal feedback gain without any sacrifice for feedback transmission (have
the cake and eat it too).
gain, i.e., one can simultaneously achieve better than the non-feedback capacities in both direc-
tions. While an outer bound is also derived, it has a gap to the lower bound. Hence, there has
been limited understanding on the maximal gain that can be reaped by feedback. In particular,
whether or not one can get all the way to perfect feedback capacities in both directions has been
unanswered. Recently Cheng-Devroye [7] derived an outer bound, but it does not give a proper
answer as the result assumes a partial interaction scenario in which interaction is enabled only
at two nodes, while no interaction is permitted at the other two nodes.
In this work, we settle this open problem and completely characterize the capacity region of
the deterministic two-way IC via a new capacity-achieving transmission scheme as well as a
novel outer bound. For simplicity, we assume the IC in each direction is symmetrical between the
two users; however the IC’s in the two directions are not necessarily the same (for example, they
DRAFT
4
may use different frequency bands). For some channel gains, the new scheme simultaneously
achieves the perfect feedback sum-capacities of the IC’s in both directions. This occurs even
when feedback offers gains in both directions and thus feedback must be explicitly or implicitly
carried over each IC while sending the traffic in its own direction. Fig. 2 shows for what channel
gains this happens.
In the new scheme, feedback allows the exploitation of the following as side information: (i)
past received signals; (ii) users’ own messages; (iii) even the future information via retrospective
decoding (to be detailed later; see Remark 3 in particular). While the first two were already
shown to offer a feedback gain in literature, the third is newly exploited. It turns out this new
exploitation leads us to achieve the perfect feedback capacities in both directions, which can
never be done by the prior schemes [3], [4], [5].
Our new outer bound leads to the characterization of channel regimes in which interaction
provides no gain in capacity. The bound is neither cutset nor more sophisticated bounds such
as genie-aided bounds [8], [2], [3], [9], [10], [11], [14] and the generalized network sharing
bound [12]. We employ a notion called triple mutual information, also known as interaction
information [13]. In particular, we exploit one key property of the notion, commutativity, to
derive the bound.
II. MODEL
Fig. 3 describes a two-way deterministic IC where user k wants to send its own message Wk
to user k?, while user k? wishes to send its own message W?k to user k, k = 1, 2. We assume
that (W1,W2, W?1, W?2) are independent and uniformly distributed. For simplicity, we consider a
setting where both forward and backward ICs are symmetric but not necessarily the same. In the
forward IC, n and m indicate the number of signal bit levels for direct and cross links respectively.
The corresponding values in the backward IC are denoted by (n?, m?). Let Xk ? F
max(n,m)
2 be user
k’s transmitted signal and Vk ? F
m
2 be a part of Xk visible to user j?( 6= k?). Similarly let X?k be
user k?’s transmitted signal and V?k be a part of X?k visible to user j( 6= k). The deterministic model
abstracts broadcast and superposition of signals in the wireless Gaussian channel. See [6] for
explicit details. A signal bit level observed by both users is broadcasted. If multiple signal levels
arrive at the same signal level at a user, we assume modulo-2-addition. The encoded signal Xki of
user k at time i is a function of its own message and past received signals: Xki = fki(Wk, Y?
i?1
k ).
DRAFT
5
m
n
n?
m?
Y?
i?1
1
Y?
i?1
2
X2i
X1i
Y1i
Y2i
Enc 1
Enc 2
Dec 1
Dec 2
X?1i
X?2i
Y?1i
Y?2i
Dec 1?
Dec 2?
Enc 1?
Enc 2?
Y
i?1
1
Y
i?1
2
User 1
User 2
User 1
User 2
User
User
User
User
 
Fig. 3. A two-way deterministic interference channel (IC).
We define Y? i?1k := {Y?kt}
i?1
t=1 where Y?kt denotes user k’s received signal at time t, offered through
the backward IC. Similarly the encoded signal X?ki of user k? at time i is a function of its own
message and past received signals: X?ki = f?ki(W?k, Y
i?1
k ).
A rate tuple (R1, R2, R?1, R?2) is said to be achievable if there exists a family of codebooks and
encoder/decoder functions such that the decoding error probabilities go to zero as code length
N tends to infinity.
For simplicity, we focus on a sum-rate pair regarding the forward and bacward ICs: (R, R?) :=
(R1+R2, R?1+ R?2).
1 The capacity region is defined as the closure of the set of achievable sum-
rate pairs: C = closure{(R, R?) : (R1, R2, R?1, R?2) ? Chigh} where Chigh denotes the one w.r.t. the
high-dimensional rate tuple.
1The extension to the four-rate tuple case is not that challenging although it requires a complicated yet tedious analysis. Given
our results (to be presented soon) and the tradeoff w.r.t. (R1, R2) (or (R?1, R?2)) already characterized in [3], the extension does
not provide any additional insights. Hence, here we consider a simpler sum-rate pair setting.
DRAFT
6
III. MAIN RESULTS
Our main contribution lies in characterization of the capacity region of the two-way IC,
formally stated below.
Theorem 1 (Capacity region): The capacity region C of the two-way IC is the set of (R, R?)
such that
R ? max(2n?m,m) =: Cpf (1)
R? ? max(2n?? m?, m?) =: C?pf (2)
R + R? ? 2(n+ n?) (3)
R + R? ? 2max(n?m,m) + 2max(n?? m?, m?) (4)
where Cpf and C?pf indicate the perfect feedback sum-capacities of the forward and backward
IC’s, respectively [3].
Proof: The achievability proof relies on two novel transmission schemes. In particular, we
highlight key features of the second scheme - that we call retrospective decoding - which plays
a crucial role to achieve perfect feedback capacities in both directions. The first feature is that it
consists of two stages, each comprising a sufficiently large number L of time slots. The second
feature is that in the second stage, feedback-aided successive refinement w.r.t. the fresh symbols
sent in the first stage occurs in a retrospective manner: the fresh symbol sent in time i of stage I
is refined in time 2L+2? i of stage II where 1 ? i ? L. See Section IV for the detailed proof.
For the converse proof, we first note that the first two bounds (1) and (2) match the perfect-
feedback bound [3], [14], [5]. So one can prove them with a simple modification to the proof
in the references. The third bound is due to cutset: R1+ R?2 ? n+ n? and R2+ R?1 ? n+ n?. Our
contribution lies in the derivation of the last bound. See Section V-B for the proof.
We state two baselines for comparison to our main result.
Baseline 1 ([8], [15]): The capacity region Cno for the non-interactive scenario is the set of
(R, R?) such that
R ? min {2max(n?m,m),max(2n?m,m), 2n} =: Cno
R? ? min {2max(n?? m?, m?),max(2n?? m?, m?), 2n?} =: C?no.
Baseline 2 ([3]): The capacity region for the perfect feedback scenario is Cpf = {(R, R?) :
R ? Cpf , R? ? C?pf}.
DRAFT
7
With Theorem 1 and Baseline 1, one can readily see that feedback gain (in terms of capacity
region) occurs as long as (? /? [2
3
, 2], ?? /? [2
3
, 2]), where ? := m
n
and ?? := m?
n?
. A careful inspection
reveals that there are channel regimes in which one can enhance Cno (or C?no) without sacrificing
the other counterpart. This implies a net interaction gain.
Definition 1 (Interaction gain): We say that an interaction gain occurs if one can achieve
(R, R?) = (Cno + ?, C?no + ??) for some ? ? 0 and ?? ? 0 such that max(?, ??) > 0.
A tedious yet straightforward calculation with this definition leads us to identify channel regimes
which exhibit an interaction gain, marked in light blue in Fig. 2.
We also find the regimes in which feedback does increase capacity but interaction cannot
provide such increase, meaning that whenever ? > 0, ?? must be ?? and vice versa. These are
(? ? 2
3
, ?? ? 2
3
) and (? ? 2, ?? ? 2) marked in purple in Fig. 2. The cutset bound (3) proves
this for (? ? 2, ?? ? 2). The regime of (? ? 2
3
, ?? ? 2
3
) has been open as to whether both ? and
?? can be non-negative. Our novel bound (4) cracks the open regime, demonstrating that there is
no interaction gain in the regime.
Achieving perfect feedback capacities: One interesting observation is that there are channel
regimes in which both ? and ?? can be strictly positive. This is unexpected because it implies
that not only feedback does not sacrifice one transmission for the other, it can actually improve
both simultaneously. More interestingly, ? and ?? can reach up to the maximal feedback gains,
reflected in Cpf ? Cno and C?pf ? C?no. The dark blue regimes in Fig. 2 indicate such channel
regimes when 1 ? ? := n?
n
? 4. Note that such regimes depend on ?. The amount of feedback
that one can send is limited by available resources offered by the backward (or forward) IC.
Hence, the feedback gain can be saturated depending on availability of the resources, which is
affected by the channel asymmetry parameter ?. One point to note here is that for any ?, there
always exists a non-empty set of (?, ??) in which perfect feedback capacities can be achieved.
Corollary 1 stated below exhibits all of such channel regimes.
Corollary 1: Consider a case in which feedback helps in both ICs: Cpf > Cno and C?pf > C?no.
In this case, the channel regimes in which C = Cpf are:
(I) ? < 2/3, ?? > 2, Cpf ? Cno ? 2m?? C?pf , C?pf ? C?no ? 2n? Cpf ;
(II) ?? < 2/3, ? > 2, C?pf ? C?no ? 2m? Cpf , Cpf ? Cno ? 2n?? C?pf .
Proof: A tedious yet straightforward calculation with Theorem 1 completes the proof.
DRAFT
8
Remark 1 (Why the Perfect Feedback Regimes?): When ? < 2/3 and ?? > 2, 2m? indicates
the total number of resource levels at the receivers in the backward channel. Hence, one can
interpret 2m? ? C?pf as the remaining resource levels (resource holes) that can potentially be
utilized to aid forward transmission. It turns out feedback can maximize resource utilization
by filling up the resource holes under-utilized in the non-interactive case. Note that Cpf ? Cno
represents the amount of feedback that needs to be sent for achieving Cpf . Hence, the condition
Cpf ? Cno ? 2m?? C?pf (similarly C?pf ? C?no ? 2n? Cpf) in Corollary 1 implies that as long as
we have enough resource holes, we can get all the way to perfect feedback capacity. We will
later provide an intuition as to why feedback can do so while describing our achievability; see
Remark 3 in particular. 
IV. ACHIEVABILITY PROOF OF THEOREM 1
We first illustrate new transmission schemes via two toy examples in which the key ingredients
of our achievability idea are well presented. Once the description of the schemes is done via the
examples, we will then outline the proof for generalization while leaving a detailed proof for
arbitrary channel parameters in Appendix A.
A. Example 1: (n,m) = (2, 1), (n?, m?) = (1, 2)
See Fig. 4 for the channel structure of the example. The claimed rate region in this example
reads {(R, R?) : R ? Cpf = 3, R? ? C?no = 2}. This is the case in which one can achieve Cpf
while maintaining C?no. We introduce a new transmission scheme (that we call Scheme 1) to
achieve the claimed rate region.
Perfect feedback scheme: A perfect feedback scheme was presented in [3]. Here we consider
a different scheme which allows us to resolve the tension between feedback and independent
messages when translated into a two-way scenario. The scheme operates in two stages. See Fig. 4.
In stage I, four fresh symbols ((A, a) from user 1 and (B, b) from user 2) are transmitted. The
scheme in [3] feeds a?B back to user 1, so that user 1 can decode B which turns out to help
refining the corrupted symbol a in stage II. On the other hand, here we send a?B back to user
2. This way, user 2 can get a by removing its own symbol B. Similarly user 1 can get b. Now
in stage II, user 2 intends to re-send b on top, as the b is corrupted due to A in stage I. But here
a challenge arises. The challenge is that the b causes interference to user 1? at the bottom level.
DRAFT
9
User 1
User 2
User
User
User 1
User 2
User
User
stage I stage Istage II
stage II
get
get
interference 
neutralization
 
Fig. 4. A perfect feedback scheme for (n,m) = (2, 1) where Cpf = 3 (top); a nonfeedback scheme for (n?, m?) = (1, 2) where
C?pf = C?no = 2 (bottom).
But here the symbol b obtained via feedback at user 1 can play a role. The idea of interference
neutralization [16] comes into play. User 1 sending the b on bottom enables neutralizing the
interference. This then allows user 1 to transmit another fresh symbol, say A?, without being
interfered. Similarly user 2 can carry B? interference-free. This way, we send 6 symbols during
two time slots, thus achieving Cpf = 3. As for the backward IC, we employ a nonfeedback
scheme in [15]. User 1? and 2? send (A?, B?) on top levels. This yields C?no = 2.
We are now ready to illustrate our achievability. Like the perfect feedback scheme, it still
operates in two stages and the operation of stage I remains unchanged. A new idea comes in
feedback strategy. Recall that a ? B is the one that is desired to be fed back to user 2. But
the a ? B has a conflict with transmission of A?. It seems an explicit selection needs to be
made between the two competing transmissions. But it turns out the two transmissions come
without the conflict. The idea is to combine the XORing scheme introduced in network coding
literature [17] with interference neutralization [16]. See Fig. 5. User 1? simply sends the XOR of
DRAFT
10
stage 1 stage Istage II
stage II
get
get
User 1
User 2
User
User
interference alignment 
& neutralization
User 1
User 2
User
User
desired to be fed back
interference 
neutralization 
XORing
has
has
 
Fig. 5. XORing with interferene neutralization for feedback strategy; Employing interference alignment and neutralization for
refinement of the past corrupted symbols.
a?B and A? on top. User 1 can then extract A??B by using its own symbol a as side information.
But it is still interfered with by B. Here a key observation is that B is also available at user 2? -
it was received cleanly at the top level in stage I. User 2? sending the B on bottom enables user
1 to achieve interference neutralization at the bottom level, thereby decoding A? of interest. Now
consider user 2 side. User 2 can exploit B to obtain a ? A?. Note that a ? A? is not the same
as a wanted by user 2 in the perfect feedback scheme. Nonetheless a ? A? can serve the same
role as a and this will be clearer soon. Similarly, user 2? sending B? ? (b?A) on top while user
1? sending A (already delivered via the forward IC) on bottom, user 2 can decode B? of interest
and user 1 can get b? B?.
Now in stage II, we take a similar approach as in the perfect feedback case. User 2 intends
to re-send b on top. Recall in the perfect feedback scheme that user 1 sent the fedback symbol
b on bottom, in order to remove the interference caused to user 1?. But the situation is different
here. User 1 has b ? B? instead. It turns out this can also play the same role. The idea is to
DRAFT
11
use interference alignment and neutralization [18], [19], [16]. User 1 sends b ? B? on bottom.
Here B? seems to cause interference to user 1?. But this can be canceled as B? is already decoded
at user 2 - see the bottom level at user 2 in the backward channel. User 2 sending b ? B? on
top enables interference neutralization. This allows user 1 to send another fresh symbol A? on
bottom interference-free. Note that b ? B? can be viewed as the aligned interference w.r.t. A.
Similarly user 1 sending a? A? on top and user 2 sending B? ? (a? A?) on bottom, user 1? and
2? can decode a and B? respectively. This way, we achieve Cpf = 3 as in the perfect feedback
case while maintaining C?no = 2. Hence, the claimed rate region is achieved. 
Remark 2 (Exploiting Side Information): Note in Fig. 5 (bottom) that the two backward sym-
bols (A?, B?) and the two feedback signals (a?B, b?A) can be transmitted through 2-bit-capacity
backward IC. This is because each user can cancel the seemingly interfering information by
exploiting what has been received and its own symbols as side information. The side information
allows the backward IC to have an effectively larger capacity, thus yielding a gain. This gain
equalizes feedback cost, which in turn enables feedback to come for free in the end. The nature
of the gain offered by side information coincides with that of the two-way relay channel [20]
and many other examples [21], [22], [3], [23], [24]. 
B. Example 2: (n,m) = (2, 1), (n?, m?) = (0, 1)
Scheme 1 is intended for the regimes in which feedback provides a gain only in one direction,
e.g., Cpf > Cno and C?pf = C?no. For the regimes feedback helps in both directions, we develop
another transmission scheme (that we call Scheme 2) which enables us to get sometimes all the
way to perfect feedback capacities. In this section, we illustrate the scheme via Example 2 in
which (Cpf = 3 > 2 = Cno, C?pf = 1 > 0 = C?no) and one can achieve (R, R?) = (Cpf , C?pf). See
Fig. 6 for the channel structure of the example.
Our scheme operates in two stages. But one noticeable distinction is that each stage comprises
a sufficiently large number of time slots. Specifically stage I consists of L time slots, while stage
II uses L + 1 time slots. It turns out our scheme ensures transmission of 6L forward symbols
and 2L backward symbols, thus yielding:
(R, R?) =
(
6L
2L+ 1
,
2L
2L+ 1
)
?? (3, 1) = (Cpf , C?pf).
as L ? ?. Here are details.
DRAFT
12
time 1 time 1time 2 time 2
XORing
XORing desired to be fed back
User 1
User 2
User 1
User 2
User
User
User
User
time L
time L
tension
has
time i:
XORing
has
time i:
 
Fig. 6. Stage I: Employ L time slots. The operation in each time slot is similar to stage I’s operation in the perfect feedback
case. We simply forward the XOR of a feedback signal and a new independent symbol. Here we see the tension between them.
Before describing details, let us review the perfect feedback scheme of the backward IC [3]
which takes a relaying idea. User 1? delivers a backward symbol, say a?, to user 1 via the feedback-
assisted path: user 1? ? user 2 ? feedback ? user 2? ? user 1. Similarly user 2? sends b? to user
2. This yields C?pf = 1.
Stage I: We employ L time slots. In each time slot, we mimick the perfect feedback scheme
although we have the tension between feedback and independent message transmissions.
Time 1: Four fresh symbols are transmitted over the forward IC. User 1? then extracts the one
that is desired to be fed back: a1 ? B1. Next we send the XOR of a1 ? B1 and a backward
symbol, say a?1. Similarly user 2? transmits (b1?A1)? b?1. User 1 then gets b1? b?1 using its own
symbol A1. Similarly user 2 gets a1 ? a?1.
Time 2: User 1 superimposes b1 ? b?1 with another new symbol, say a2, sending the XOR on
bottom. On top is another fresh symbol A2 transmitted. Similarly user 2 sends (B2, b2?(a1?a?1)).
User 1? transmits (a2 ? b1 ? b?1 ?B2)? a?2. Similarly user 2? sends (b2 ? a1 ? a?1 ?A2)? b?2. User
1 then gets b2 ? a?1 ? b?2 by using its own signal a1 ?A2. Similarly user 2 obtains a2 ? b?1 ? a?2.
Repeating the above, one can readily verify that at time i ? {2, · · · , L}, user 1 and 2 get
bi? a?i?1? b?i?1 and ai? b?i?1? a?i?1 respectively; similarly user 1? and 2? get ai? bi?1? b?i?1?Bi
and bi ? ai?1 ? a?i?1 ? Ai on bottom, respectively. See Fig. 6.
DRAFT
13
time L+1 time L+1time L+2 time L+2time 2L+1
has
has
(from time L)(from time 1)
has
has
(from time L)
time 2L+1
interference alignment 
& neutralization
(from time L)(from time 1)
(from time 2L)
(from time 2L)
User 1
User 2
User 1
User 2
User
User
User
User
(from time L)has
 
Fig. 7. Stage II: Time L+1 aims at decoding (a?L, b?L). At time L+1+ i, given (a?L+1?i, b?L+1?i) (decoded in time L+ i),
we decode (aL+1?i, bL+1?i) which in turn helping decoding (a?L?i, b?L?i). We iterate this from i = 1 to i = L.
Stage II: We employ L+1 time slots. We perform refinement w.r.t. the fresh symbols sent in
stage I. The novel feature here is that the successive refinement occurs in a retrospective manner:
the fresh symbol sent at time i is refined at time 2L+ 2? i in stage II where 1 ? i ? L. Here
one key point to emphasize is that the refined symbol in stage II acts as side information, which
in turn helps refining other past symbols in later time. In the example, the decoding order reads:
(a?L, b?L) ? (aL, bL) ? · · · ? (a?1, b?1) ? (a1, b1). (5)
Time L+1: User 1 sends bL?a?L?1? b?L (received at time L) on bottom. It turns out this acts as
ignition for refining all the corrupted symbols in the past. Similarly user 2 sends aL? b?L?1? a?L
on bottom. User 1? can then obtain bL? b?L which would be forwarded to user 2. User 2 can then
decode b?L of interest. Similarly a?L is delivered to user 1.
Time L+ 2: The decoded symbols (a?L, b?L) turn out to play a key role to refine past forward
transmission. Remember that bL sent by user 2 at time L in stage I was corrupted. User 2 re-
transmits the bL on top as in the perfect feedback case. But here the problem is that the situation
is different from that in the perfect feedback case where bL was available at user 1 and helped
nulling interference. Note that bL is not available here. Instead user 1 has an interfered version:
bL ? b?L ? a?L?1. Nonetheless we can effectively do the same as in the perfect feedback case.
DRAFT
14
User 1 sends bL ? b?L ? a?L?1 on bottom. Clearly the neutralization is not perfect as it contains
b?L. Here the idea is to exploit the b?L as side information to enable interference alignment and
neutralization [18], [19], [16]. Note that user 2 can exploit the knowledge of b?L to construct the
aligned interference bL ? b?L. Sending the bL ? b?L on top, user 2 can completely neutralize the
interference as in the perfect feedback case. This enables user 1 to deliver A?1 interference-free
on bottom. Similarly we can deliver (aL, B
?
1). On the other hand, exploiting aL (decoded right
before) as side information, user 1? can extract bL?1 ? b?L?1 ?BL from the one received at time
L. Sending this then allows user 2 to decode b?L?1. Similarly a?L?1 can be decoded at user 1.
Time L+3 ? Time 2L+1: We repeat the same as before. At time L+1+ i where 2 ? i ? L,
exploiting (a?L+1?i, b?L+1?i) decoded in time L + i, we decode (aL+1?i, bL+1?i), which in turn
helps decoding (a?L?i, b?L?i).
Now let us compute an achievable rate. In stage I, we sent (4L, 2L) fresh forward and backward
symbols. In stage II, we sent only 2L fresh forward symbols. This yields the desired rate in the
limit of L ? ?.
Remark 3 (Exploiting Future Symbols as Side Information): Note in Fig. 6 the two types of
tension: (1) forward-symbol feedback vs. backward symbols; (2) the other counterpart. As
illustrated in Fig. 7, our scheme leads us to resolve both tensions. This then enables us to fully
utilize the remaining resource level 2m?? C?pf = 1 for sending the forward-symbol feedback of
Cpf ?Cno = 1, thereby achieving Cpf . Similarly we can fill up the resource holes 2n?Cpf = 1
with the backward-symbol feedback of C?pf ? C?no = 1. This comes from the fact that our
feedback scheme exploits the following as side information: (i) past received signals; (ii) users’
own symbols; (iii) partially decoded symbols. While the first two were already shown to be
beneficial in the prior works [3], [5] (as well as in Example 1), the third type of information is
the newly exploited one which turns out to yield the strong interaction gain. One can view this
as future information. Recall the decoding order (5). When decoding (a?L?1, b?L?1), we exploited
(aL, bL) (future symbols w.r.t. (a?L?1, b?L?1)) as side information. A conventional belief is that
feedback allows us to know only about the past. In contrast, we discover a new viewpoint on
the role of feedback. Feedback enables exploiting future information as well via retrospective
decoding. 
DRAFT
15
no feedback 
gain
(no need to consider)
 
Fig. 8. Regimes to check for achievability proof. By symmetry, it suffices to consider (R1), (R2), (R3), (R4), (R5).
C. Proof Outline
We categorize regimes depending on the values of channel parameters. Notice that C = Cno
when (? ? [2
3
, 2], ?? ? [2
3
, 2]). Also by symmetry, it suffices to consider only five regimes - see
Fig. 8:
(R1) ? > 2, ?? > 2;
(R2) ? ? (0, 2/3), ?? ? (0, 2/3);
(R3) ? > 2, ?? ? [2/3, 2];
(R4) ? ? (0, 2/3), ?? ? [2/3, 2];
(R5) ? ? (0, 2/3), ?? > 2.
As figured out in Fig. 2, (R1) and (R2) are the ones in which there is no interaction gain. The
proof builds only upon the perfect feedback scheme [3]. One thing to note here is that there are
many subcases depending on whether or not available resources offered by a channel are enough
to achieve the perfect feedback bound. Hence, a tedious yet careful analysis is required to cover
all such subcases. On the other hand, (R3) and (R4) are the ones in which there is an interaction
gain but only in one direction. So in this case, the nonfeedback scheme suffices for the backward
DRAFT
16
    
(Scheme 1) (Scheme 2)
 
 
Fig. 9. Achievaility for (n,m) = (4, 2), (n?, m?) = (1, 3) via network decomposition.
IC while a non-trivial scheme needs to be employed for the forward IC. It turns out Scheme
1 illustrated in Example 1 plays a key role in proving the claimed achievable region. (R5) is
the one in which there is an interaction gain and sometimes one can get to perfect feedback
capacities. We fully utilize the ideas presented in Scheme 1 and Scheme 2 to prove the claimed
rate region. One key feature to emphasize is that the idea of network decomposition developed
in [25] is utilized to provide a conceptually simpler proof for generalization. Here we illustrate
the network decomposition idea via Example 3, while leaving a detailed proof in Appendix A.
Example 3: (n,m) = (4, 2), (n?, m?) = (1, 3): Network decomposition relies on graph coloring.
See Fig. 9. For the forward IC, we assign a color (say green) to level 1 and the levels connected to
level 1. The green-colored graph then represents a subchannel, say (n(1), m(1)) = (2, 1), which
has no overlap with the remaining uncolored subchannel (n(2), m(2)) = (2, 1). Following the
notation in [25], we represent this by: (4, 2) ?? (2, 1)× (2, 1). Similarly the backward channel
can be decomposed as: (1, 3) ?? (1, 2)× (0, 1). We then pair up one forward-subchannel (2, 1)
and one backward-subchannel, say (1, 2), and apply Scheme 1 for the pair as in Fig. 5. This
gives (R(1), R?(1)) = (3, 2). For the remaining pair of (2, 1) and (0, 1), we perform Scheme 2
DRAFT
17
independently. This yields (R(2), R?(2)) = (3, 1). Combining these two achieves the desired rate
region: {(R, R?) : R ? Cpf = 6, R? ? C?pf = 3}. 
V. CONVERSE PROOF OF THEOREM 1
The first two (1) and (2) are the perfect-feedback bounds [3], [14], [5]. So the proof is
immediate via a slight modification. The third bound (3) is cutset: R1 + R?2 ? n + n? and
R2 + R?1 ? n + n?. The last is a new bound. For completeness, we will provide detailed proof
for the cutset and perfect feedback bounds in the subsequent section. We will then derive the
new bound in Section V-B.
A. Proof of the Cutset & Perfect Feedback Bound
Proof of (3): Starting with Fano’s inequality, we get
N(R1 + R?2 ? ?N ) ? I(W1, W?2; Y
N
1 , W?1, Y?
N
2 ,W2)
(a)
=
?
H(Y1i, Y?2i|W?1,W2, Y
i?1
1 , Y?
i?1
2 , X2i)
(b)
=
?
H(Y1i|W?1,W2, Y
i?1
1 , Y?
i?1
2 , X2i) +
?
H(Y?2i|W?1,W2, Y
i
1 , Y?
i?1
2 , X2i, X?1i)
(c)
?
?
H(Y1i|X2i) +
?
H(Y?2i|X?1i)
(d)
? N(n + n?)
where (a) follows from the fact that (W1, W?2) is independent of (W2, W?1), and X2i is a function
of (W2, Y?
i?1
2 ); (b) follows from the fact that X?1i is a function of (W?1, Y
i?1
1 ); (c) follows from
the fact that conditioning reduces entropy; (d) follows from the fact that the right-hand-side is
maximized when (X1, X2, X?1, X?2) are uniformly distributed and independent. Similarly one can
show N(R2 + R?1? ?N) ? N(n+ n?). If (R1, R2, R?1, R?2) is achievable, then ?N ? 0 as N tends
to infinity. Therefore, we get the desired bound.
DRAFT
18
Proof of (1): Starting with Fano’s inequality, we get
N(R1 +R2 ? ?N )
(a)
? I(W1; Y
N
1 |W?1,W2, W?2) + I(W2; Y
N
2 |W?2, W?1)
= H(Y N1 |W?1,W2, W?2) +H(Y
N
2 |W?2, W?1)
?
{
H(Y N1 , Y
N
2 |W?1,W2, W?2)?H(Y
N
1 |W?1, W?2,W2, Y
N
2 )
}
= H(Y N1 |W?1, W?2,W2, Y
N
2 )?H(Y
N
2 |W?1,W2, W?2, Y
N
1 ) +H(Y
N
2 |W?2, W?1)
? H(Y N1 |W?1, W?2,W2, Y
N
2 ) +H(Y
N
2 |W?2, W?1)
(b)
=
?
H(Y1i|W?1, W?2,W2, Y
N
2 , Y
i?1
1 , X?
i
1, X?2i, Y?
i
2 , X2i, V1i) +H(Y
N
2 |W?2, W?1)
(c)
?
?
H(Y1i|V1i, X2i) +
?
H(Y2i)
? N
{
(n?m)+ +max(n,m)
}
= N max(2n?m,m)
where (a) follows from the independence of (W1,W2, W?1, W?2); (b) follows from the fact that X?
i
1
is a function of (W?1, Y
i?1
1 ), X2i is a function of (W2, Y?
i?1
2 ), and V1i is a function of (X2i, Y2i);
(c) follows from the fact that conditioning reduces entropy. This completes the proof.
B. Proof of a Novel Outer Bound
The proof hinges upon several lemmas stated below. The proof is streamlined with the help of
a key notion, called triple mutual information (or interaction information [13]), which is defined
as
I(X ; Y ;Z) := I(X ; Y )? I(X ; Y |Z). (6)
It turns out that the commutative property of the notion plays a crucial role in deriving several
key steps in the proof:
I(X ; Y ;Z) = I(X ;Z; Y ) = · · · = I(Z; Y ;X). (7)
DRAFT
19
Using this notion and starting with Fano’s inequality, we get
N(R1 +R2 ? ?N ) ? I(W1; Y
N
1 , W?1) + I(W2; Y
N
2 , W?2)
? I(W1; Y
N
1 , V
N
1 |W?1) + I(W2; Y
N
2 , V
N
2 |W?2)
=
?
{
I(W1; Y1i, V1i|W?1, Y
i?1
1 , V
i?1
1 ) + I(W2; Y2i, V2i|W?2, Y
i?1
2 , V
i?1
2 )
}
=
?
{
I(V1i;W1|W?1, Y
i?1
1 , V
i?1
1 ) + I(Y1i;W1|W?1, Y
i?1
1 , V
i
1 )
+I(V2i;W2|W?2, Y
i?1
2 , V
i?1
2 ) + I(Y2i;W2|W?2, Y
i?1
2 , V
i
2 )
}
(a)
=
?
{
I(Y1i;W1,W2, W?2|W?1, Y
i?1
1 , V
i
1 ) + I(Y2i;W2,W1, W?1|W?2, Y
i?1
2 , V
i
2 )
+I(V1i;W1|W?1, Y
i?1
1 , V
i?1
1 )? I(Y1i;W2, W?2|W1, W?1, Y
i?1
1 , V
i
1 )
+I(V2i;W2|W?2, Y
i?1
2 , V
i?1
2 )? I(Y2i;W1, W?1|W2, W?2, Y
i?1
2 , V
i
2 )
}
?
?
{H(Y1i|V1i) +H(Y2i|V2i)
+I(V1i;W1|W?1, Y
i?1
1 , V
i?1
1 )? I(Y1i;W2, W?2|W1, W?1, Y
i?1
1 , V
i
1 )
+I(V2i;W2|W?2, Y
i?1
2 , V
i?1
2 )? I(Y2i;W1, W?1|W2, W?2, Y
i?1
2 , V
i
2 )
}
where (a) follows from a chain rule. By symmetry, we get:
N(R?1 + R?2 ? ?N ) ?
?
{
H(Y?1i|V?1i) +H(Y?2i|V?2i)
+I(V?1i; W?1|W1, Y?
i?1
1 , V?
i?1
1 )? I(Y?1i;W2, W?2|W1, W?1, Y?
i?1
1 , V?
i
1 )
+I(V?2i; W?2|W2, Y?
i?1
2 , V?
i?1
2 )? I(Y?2i;W1, W?1|W2, W?2, Y?
i?1
2 , V?
i
2 )
}
.
Now adding the above two and using Lemma 1 stated below, we get:
N(R1 +R2 + R?1 + R?2 ? ?N )
?
?
{
H(Y1i|V1i) +H(Y2i|V2i) +H(Y?1i|V?1i) +H(Y?2i|V?2i)
}
? 2N max(n?m,m) + 2N max(n?? m?, m?).
Hence, we get the desired bound.
DRAFT
20
Lemma 1:
?
{
I(V1i;W1|W?1, Y
i?1
1 , V
i?1
1 )? I(Y1i;W2, W?2|W1, W?1, Y
i?1
1 , V
i
1 )
+I(V2i;W2|W?2, Y
i?1
2 , V
i?1
2 )? I(Y2i;W1, W?1|W2, W?2, Y
i?1
2 , V
i
2 )
+I(V?1i; W?1|W1, Y?
i?1
1 , V?
i?1
1 )? I(Y?1i; W?2,W2|W?1,W1, Y?
i?1
1 , V?
i
1 )
+I(V?2i; W?2|W2, Y?
i?1
2 , V?
i?1
2 )? I(Y?2i; W?1,W1|W?2,W2, Y?
i?1
2 , V?
i
2 )
}
? 0
C. Proof of Lemma 1
First consider:
(1st and 2nd terms in summation of LHS)
(a)
=
?
{
I(V1i;W1|W?1, Y
i?1
1 , V
i?1
1 )? I(Y1i;W2, W?2, Y?
i
1 |W1, W?1, Y
i?1
1 , V
i
1 )
(b)
=
?
{
I(V1i, V?1i;W1|W?1, Y
i?1
1 , V
i?1
1 , V?
i?1
1 )
?I(Y1i; Y?
i
1 |W1, W?1, Y
i?1
1 , V
i
1 , V?
i
1 )? I(Y1i;W2, W?2|W1, W?1, Y?
i
1 , Y
i?1
1 )
}
(c)
=
?
{
I(V1i, V?1i;W1|W?1, V
i?1
1 , V?
i?1
1 )? I(V1i, V?1i;W1; Y
i?1
1 |W?1, V
i?1
1 , V?
i?1
1 )
?I(Y1i; Y?
i
1 |W1, W?1, Y
i?1
1 , V
i
1 , V?
i
1 )? I(Y1i;W2, W?2|W1, W?1, Y?
i
1 , Y
i?1
1 )
}
where (a) follows from the fact that Y? i1 is a function of (W1, W?1,W2, W?2); (b) follows from
the fact that V? i1 is a function of (W?1, Y
i?1
1 ); and (c) is due to the definition of triple mutual
information (6).
Using Lemma 2 stated at the end of this section, we get:
(1st and 2nd terms in summation of LHS)
?
?
{
I(V1i, V?1i;W1|W?1, V
i?1
1 , V?
i?1
1 ) + I(Y?1i; Y
i?1
1 |W1, W?1, Y?
i?1
1 , V?
i
1 )
?I(V?1i;W1, Y?
i?1
1 |W?1, V
i?1
1 , V?
i?1
1 )? I(Y1i;W2, W?2|W1, W?1, Y?
i
1 , Y
i?1
1 )
}
.
DRAFT
21
Now combining this with the 5th and 6th terms in summation of LHS gives:
(1st, 2nd, 5th and 6th terms of LHS in the claimed bound)
(a)
?
?
{
I(V1i, V?1i;W1|W?1, V
i?1
1 , V?
i?1
1 ) + I(Y?1i; Y
i?1
1 |W1, W?1, Y?
i?1
1 , V?
i
1 )
?I(V?1i;W1, Y?
i?1
1 |W?1, V
i?1
1 , V?
i?1
1 )? I(Y1i;W2, W?2|W1, W?1, Y?
i
1 , Y
i?1
1 )
}
+
?
{
I(V?1i; W?1|W1, Y?
i?1
1 , V
i?1
1 , V?
i?1
1 )? I(Y?1i; W?2,W2, Y
i?1
1 |W?1,W1, Y?
i?1
1 , V?
i
1 )
}
(b)
?
?
{
I(V1i, V?1i;W1|W?1, V
i?1
1 , V?
i?1
1 )
?I(V?1i;W1, Y?
i?1
1 |W?1, V
i?1
1 , V?
i?1
1 )? I(Y1i;W2, W?2|W1, W?1, Y?
i
1 , Y
i?1
1 )
}
+
?
{
I(V?1i; W?1,W1, Y?
i?1
1 |V
i?1
1 , V?
i?1
1 )? I(Y?1i; W?2,W2|W?1,W1, Y?
i?1
1 , Y
i?1
1 )
}
(c)
?
?
{
I(V1i, V?1i;W1|W?1, V
i?1
1 , V?
i?1
1 )
?I(Y1i, Y?1i;W2, W?2|W1, W?1, Y?
i?1
1 , Y
i?1
1 ) + I(V1i, V?1i; W?1|V
i?1
1 , V?
i?1
1 )
}
(d)
= I(V N1 , V?
N
1 ;W1, W?1)? I(Y
N
1 , Y?
N
1 , V
N
2 , V?
N
2 ;W2, W?2|W1, W?1)
? I(V N1 , V?
N
1 ;W1, W?1)? I(V
N
2 , V?
N
2 ;W2, W?2|W1, W?1)
where (a) follows from the fact that V i?11 and Y
i?1
1 are functions of (W1, Y?
i?1
1 ) and (W1,W2, W?1, W?2),
respectively; (b) follows from a chain rule (applied on the last term) and the non-negativity of
mutual information; (c) follows from a chain rule (combining the 2nd and 4th terms; also
combining the 3rd and 5th terms) and the non-negativity of mutual information; (d) follows
from a chain rule (combining the 1st and 3rd terms) and the fact that (V N2 , V?
N
2 ) is a function
of (W1, W?1, Y
N
1 , Y?
N
1 ).
Applying the same to the 3rd, 4th, 7th and 8th terms in summation of LHS, we get:
(LHS in the claimed bound)
? I(V N1 , V?
N
1 ;W1, W?1)? I(V
N
2 , V?
N
2 ;W2, W?2|W1, W?1)
+ I(V N2 , V?
N
2 ;W2, W?2)? I(V
N
1 , V?
N
1 ;W1, W?1|W2, W?2)
? I(W2, W?2, V
N
1 , V?
N
1 ;W1, W?1)? I(V
N
2 , V?
N
2 ;W2, W?2|W1, W?1)
+ I(W1, W?1, V
N
2 , V?
N
2 ;W2, W?2)? I(V
N
1 , V?
N
1 ;W1, W?1|W2, W?2) = 0.
This completes the proof.
DRAFT
22
Lemma 2:
?
?
{
I(V1i, V?1i;W1; Y
i?1
1 |W?1, V
i?1
1 , V?
i?1
1 ) + I(Y1i; Y?
i
1 |W1, W?1, Y
i?1
1 , V
i
1 , V?
i
1 )
}
?
?
{
I(Y?1i; Y
i?1
1 |W1, W?1, Y?
i?1
1 , V?
i
1 )? I(V?1i;W1, Y?
i?1
1 |W?1, V
i?1
1 , V?
i?1
1 )
}
.
Proof: See Section V-D.
D. Proof of Lemma 2
?
?
{
I(V1i, V?1i;W1; Y
i?1
1 |W?1, V
i?1
1 , V?
i?1
1 ) + I(Y1i; Y?
i
1 |W1, W?1, Y
i?1
1 , V
i
1 , V?
i
1 )
}
(a)
=
?
{
I(V1i, V?1i; Y
i?1
1 |W1, W?1, V
i?1
1 , V?
i?1
1 )
?I(V1i, V?1i; Y
i?1
1 |W?1, V
i?1
1 , V?
i?1
1 )? I(Y1i; Y?
i
1 |W1, W?1, Y
i?1
1 , V
i
1 , V?
i
1 )
}
(b)
?
?
{
I(V1i, V?1i; Y
i?1
1 |W1, W?1, V
i?1
1 , V?
i?1
1 )
?I(V?1i; Y
i?1
1 |W?1, V
i?1
1 , V?
i?1
1 )? I(Y1i; Y?
i
1 |W1, W?1, Y
i?1
1 , V
i
1 , V?
i
1 )
}
(c)
=
?
{
I(Y? i1 , V?1i; Y
i?1
1 |W1, W?1, V
i?1
1 , V?
i?1
1 )? I(Y?
i
1 ; Y
i?1
1 |W1, W?1, V
i
1 , V?
i
1 )
?I(V?1i; Y
i?1
1 |W?1, V
i?1
1 , V?
i?1
1 )? I(Y1i; Y?
i
1 |W1, W?1, Y
i?1
1 , V
i
1 , V?
i
1 )
}
(d)
=
?
{
I(Y? i1 , V?1i; Y
i?1
1 |W1, W?1, V
i?1
1 , V?
i?1
1 )
?I(Y? i1 ; Y
i
1 |W1, W?1, V
i
1 , V?
i
1 )? I(V?1i; Y
i?1
1 |W?1, V
i?1
1 , V?
i?1
1 )
}
(e)
=
?
{
I(Y?1i, V?1i; Y
i?1
1 |W1, W?1, Y?
i?1
1 , V
i?1
1 , V?
i?1
1 ) + I(Y?
i?1
1 ; Y
i?1
1 |W1, W?1, V
i?1
1 , V?
i?1
1 )
?I(Y? i1 ; Y
i
1 |W1, W?1, V
i
1 , V?
i
1 )? I(V?1i; Y
i?1
1 |W?1, V
i?1
1 , V?
i?1
1 )
}
(f)
?
?
{
I(Y?1i, V?1i; Y
i?1
1 |W1, W?1, Y?
i?1
1 , V
i?1
1 , V?
i?1
1 )? I(V?1i; Y
i?1
1 |W?1, V
i?1
1 , V?
i?1
1 )
}
(g)
=
?
{
I(Y?1i; Y
i?1
1 |W1, W?1, Y?
i?1
1 , V
i?1
1 , V?
i
1 )? I(V?1i; Y
i?1
1 ;W1, Y?
i?1
1 |W?1, V
i?1
1 , V?
i?1
1 )
}
(h)
=
?
{
I(Y?1i; Y
i?1
1 |W1, W?1, Y?
i?1
1 , V?
i
1 )? I(V?1i;W1, Y?
i?1
1 |W?1, V
i?1
1 , V?
i?1
1 )
}
where (a) follows from the definition of triple mutual information (6); (b) follows from the
non-negativity of mutual information; (c) follows from a chain rule and the fact that V1i is a
DRAFT
23
    
…
…
User 1
User 2
User 1
User 2
User 1
User 2
User 1
User 2
User 1
User 2
User 1
User 2
User 1
User 2
User 1?
User 2?
User 1
User 2
User 1?
User 2?
User 1?
User 2?
User 1?
User 2?
User 1?
User 2?
User 1?
User 2?
User 1?
User 2?
User 1?
User 2?
 
 
Fig. 10. Two-way parallel ICs. The rich diversity on channel gains across many parallel subchannels can often occur in
broadband systems.
function of (W1, Y?
i
1 ) (see below)
?
I(V1i, V?1i; Y
i?1
1 |W1, W?1, V
i?1
1 , V?
i?1
1 )
=
?
I(V1i, Y?
i
1 , V?1i; Y
i?1
1 |W1, W?1, V
i?1
1 , V?
i?1
1 )?
?
I(Y? i1 ; Y
i?1
1 |W1, W?1, V
i
1 , V?
i
1 )
=
?
I(Y? i1 , V?1i; Y
i?1
1 |W1, W?1, V
i?1
1 , V?
i?1
1 )?
?
I(Y? i1 ; Y
i?1
1 |W1, W?1, V
i
1 , V?
i
1 );
(d) follows from a chain rule (combining the 2nd and 4th terms); (e) follow from a chain rule
(applying to the 1st term); (f) follows from
N
?
i=1
I(Y? i?11 ; Y
i?1
1 |W1, W?1, V
i?1
1 , V?
i?1
1 )
=
N?1
?
i=0
I(Y? i1 ; Y
i
1 |W1, W?1, V
i
1 , V?
i
1 ) ?
N
?
i=1
I(Y? i1 ; Y
i
1 |W1, W?1, V
i
1 , V?
i
1 );
(g) follows from a chain rule and the definition of triple mutual information; (h) follows from
the fact that V i?11 and V?1i are a function of (W1, Y?
i?2
1 ) and (W?1, Y
i?1
1 ), respectively.
VI. DISCUSSION
A. System Implication
As suggested in Fig. 2, an interaction gain occurs when forward and backward ICs are
somewhat different. This asymmetry occurs naturally in FDD systems where the forward and
DRAFT
24
backward channels are on completely different bands. Even in TDD systems, the asymmetry
can occur since the forward and backward channels can be on different subcarriers or different
coherent time. Also one can create this asymmetry by opportunistically pairing subbands for the
forward and backward transmissions. While this asymmetry is not likely to occur in narrowband
systems, it can often occur in broadband systems where there are a multitude of subchannels
with a wide dynamic range of channel gains. For example, in 4G-LTE and 5G systems, one
can easily expect rich diversity on channel gains, since an operating bandwidth of the systems
is much larger than coherence bandwidth of typical wireless channels (around the order of 0.1
MHz).
Fig. 10 illustrates an example which can represent such scenario where there are a variety of
parallel subchannels. Our results suggest that pairs of (FW(1),BACK(2)) and (FW(2),BACK(1)),
for instance, can provide a significant gain with interaction. Another interesting observation is that
even though forward-and-backward parallel ICs are identical, there exist many pairs of forward-
backward subchannels that can yield capacity improvements. In tomorrow’s communication
systems, a broader system bandwidth is expected to support a variety of multimedia services.
Hence, it is believed that our results will provide detailed guidelines as to how to design future
communication systems.
In this paper, we investigate the benefit of interaction for a full duplex system. This is only for
illustrative purpose. As suggested in Remarks 2 and 3, the nature of the interaction gain comes
from exploiting the past received signals, partially decoded symbols and users’ own information
as side information. This nature is not limited to the full duplex system. So one can readily
see that the interaction gain carries over to the half duplex system. While the detailed capacity
region of the half-duplex system is distinct, the channel regimes in which feedback offers a gain
remain unchanged. In other words, we have the same picture as in Fig. 2.
B. Translation to the Gaussian Channel
The deterministic-channel achievability proposed in this work gives insights into an achievable
scheme in the Gaussian channel. This is inspired by several observations that can be made from
Scheme 1 (see Example 1 in Fig. 5) and Scheme 2 (see Example 2 in Figs. 6 and 7).
(Extracting feedback signals ? quantize-&-binning): Note in Fig. 5 that the fedback signal
a?B at user 1? can be interpreted as a quantized version of the received signal (A, a?B) at the
DRAFT
25
level below the clean signal A. This motivates the use of quantize-and-binning [6], [26] in the
Gaussian channel. There are two points to make. The first is that the binning scheme [27] can
be employed solely without quantization in this example. Binning the received signal (A, a?B)
may construct a linear combination of the two components: a?B ?A. The distinction is then
user 1? feeds back A?? (a?B?A) instead. Nonetheless, user 1 can still get A? of interest, as A
is also known. On the other hand, user 2 obtains a?A? A? instead of a? A?. This is not an issue
either. We can still achieve interference alignment and neutralization in forward transmission at
stage II. User 1 sending a ? A ? A? on top (with the help of the decoded symbol A?) and user
2 sending B? ? (a ? A ? A?), user 2? can still obtain B? interference-free. Also user 1? can get
a with the help of A which has already been received in stage I. The second point to note is
that the binning-only approach might not work properly for other channel parameter regimes.
This is because mixing all the equations may include some undesirable symbols that prevent
the optimal transmission. In that case, both quantization and binning are desired to be employed
with a careful choice of a quantization level, set to exclude undesirable symbols.
(XORing with interference neutralization ? superposition with dirty paper coding): Observe
in Fig. 5 that the fedback signal a ? B is XORed with a backward symbol A?. This motivates
the use of superposition coding in the Gaussian channel. On the other hand, user 2? sends B on
bottom for interference neutralization. To this end, we employ quantization scheme for extracting
B from the received signal (B, b?A) and utilize dirty paper coding [28] for nulling.
(Interference alignment and neutralization ? structured coding): Note at the second stage in
Fig. 5 that user 2 computes the XOR of b (its own symbol) and B? (decoded from the received
signal in backward transmission) and then sends the XOR on a proper level (the top level) for
nulling. This motivates the use of structured coding [29], as computation needs to be made
across appropriate symbols and the computed signal should be placed in a structured location
for nulling.
(Retrospective decoding): To be the best of our knowledge, this is a novel feature that has never
been introduced in network information theory literature. Hence, it requires a new achievability
technique which includes a careful decoding order as well as sets proper symbols to decode
for each time slot. Also note that decoded symbols in an intermediate time slot are part of the
entire symbols. See Fig. 7 for instance. Here aL (a decoded symbol in time L + 2) is part of
the entire symbols (AL, aL) sent in time L. Hence, this scheme needs to be properly combined
DRAFT
26
with Han-Kobayashi message splitting [30].
C. Unified Achievability
The noisy network coding [26] together with Han-Kobayashi message splitting is a fairly
generic scheme that yields reasonably good performances for a variety of multi-user channels.
It implements many achievablility techniques such as quantize-and-binning and superposition
coding. However, it has a room for improvement as it does not incorporate dirty paper coding and
structured coding. An effort has been made by Nazer-Gastpar [29] for implementing structured
codes.
But this approach still has a room for improvement, as it does not allow for the key operation
that appears in our achievability: retrospective decoding. As suggested in Example 2, the key
operation seems required for achieving the optimal performance. There seems no way to achieve
the perfect feedback bound without an intermediate decoding of partial symbols which admits
a carefully-designed backward ordering. One future work of interest is to develop a generic
achievable scheme that can be applied to general discrete memoryless networks as well as
unifies all of the techniques mentioned earlier: (1) quantize-and-binning; (2) superposition coding
(or block Markov coding); (3) structured coding; (4) Han-Kobayashi message-splitting; (5)
retrospective decoding. This development is expected to open the door to characterizing and/or
approximating many of interesting interference networks.
D. Unified Converse
In this work, we develop a new converse technique which well captures the tension between
feedback and independent message transmissions. Hence, unlike the prior upper bounds such as
cutset [27], genie-aided bounds [8], [2], [3], [9], [10], [11], [14], generalized network sharing
bounds [12], it gives rise to the tight capacity characterization of interactive multi-user channels
like the two-way IC. Encouragingly, our novel bound (4) subsumes the following bounds as
special cases: the nonfeedback-case counterpart R1 +R2 ? H(Y1|V1) +H(Y2|V2) [8]; the rate-
limited-feedback-case counterpart R1+R2 ? H(Y1|V1)+H(Y2|V2)+C
bitpipe
FB1 +C
bitpipe
FB2 [4]. Here
CbitpipeFBi denotes the capacity of the bit-piped feedback link that connects user i? to user i. One
future work of interest is to extend this bound to arbitrary discrete memoryless networks in
which many nodes interact with each other.
DRAFT
27
E. Role of Interaction in General Networks
This work focuses on an interference channel setting in which each user wishes to deliver
its own message to its counterpart. As mentioned earlier, the nature of interaction gain is not
limited to this particular setting. So it would be interesting to explore the role of interaction for
a variety of different settings. While initial efforts along this research direction have been made
for a multicast channel setting [31], function computation settings [32], [33], and multi-hop
network settings [34], an explicit comparison between non-interactive vs interactive scenarios
was not made yet. One research direction of interest is to investigate the capacity regions of such
channels, thereby discovering two-way scenarios in which one can achieve a huge interaction
gain.
VII. CONCLUSION
We characterized the capacity region of the two-way deterministic IC. As a consequence,
we discovered an interesting fact that one can even get to perfect feedback capacities in both
directions. In the process of obtaining this result, we found a new role of feedback: Feedback
enables exploiting even the future information as side information via retrospective decoding.
Our future work includes: (1) Translating to the Gaussian channel; (2) Discovering other two-
way scenarios in which one can achieve a huge interaction gain; (3) Generalizing our new
achievability to broader network contexts.
DRAFT
28
APPENDIX A
ACHIEVABILITY PROOF OF THEOREM 1: GENERALIZATION TO ARBITRARY (n,m, n?, m?)
One key idea for generalization is to use the network decomposition in [25] (also illustrated
via Example 3 in Fig. 9). The idea provides a conceptually simpler proof by decomposing a
general (n,m) (or (n?, m?)) channel into multiple elementary subchannels and taking a proper
matching across forward and backward subchannels. See Theorem 2 (stated below) for the
identified elementary subchannels, which we will use to complete the proof in the subsequent
subsections.
Theorem 2 (Network Decomposition [25]): For an arbitrary (n,m) channel, the following
network decomposition holds:
(n,m) ?? (1, 0)n?2m × (2, 1)m, ? ? [0, 1/2]; (8)
(n,m) ?? (2, 1)2n?3m × (3, 2)2m?n, ? ? [1/2, 2/3]; (9)
(n,m) ?? (0, 1)m?2n × (1, 2)n, ? ? 2. (10)
Here the symbol × indicates the concatenation of orthogonal channels and (i, j)? denotes the
?-fold concatenation of the (i, j) channel.
A. Proof of (R1) ? > 2, ?? > 2 & (R2) ? ? (0, 2
3
), ?? ? (0, 2
3
)
The following achievability w.r.t. the elementary subchannels identified in Theorem 2 forms
the basis of the proof for the regimes of (R1) and (R2).
Lemma 3: The following rates are achievable:
(i) For the pair of (n,m) = (0, 1)i and (n?, m?) = (1, 2)j where i ? 2j: (R, R?) = (i, 2j ? i);
(ii) For the pair of (n,m) = (2, 1)i and (n?, m?) = (1, 0)j × (2, 1)k where i ? 2j + 2k:
(R, R?) = (3i, 2j + 2k ? i);
(iii) For the pair of (n,m) = (2, 1)i and (n?, m?) = (2, 1)j × (3, 2)k where i ? 2j + 4k:
(R, R?) = (3i, 2j + 4k ? i).
Proof: The proof builds upon the perfect feedback scheme in [3]. See Appendix B for the
detailed proof.
For the considered regimes, the claimed achievable rate region reads:
{(R, R?) : R ? Cpf , R? ? C?pf , R + R? ? Cno + C?no}.
DRAFT
29
    
 
 
Fig. 11. Four types of shapes of an achievable rate region for the regimes of (R1) ? > 2, ?? > 2 and (R2) ? < 2
3
, ?? < 2
3
.
We see that there is no feedback gain in sum capacity. This means that one bit of a capacity
increase due to feedback costs exactly one bit. Depending on whether or not Cpf (or C?pf) exceeds
Cno + C?no, we have four subcases, each of which forms a different shape of the region. See
Fig. 11.
(I) (Cpf ? Cno ? C?no), (C?pf ? C?no ? Cno): The first case is the one in which the amount of
feedback for maximal improvement, reflected in Cpf ? Cno (or C?pf ? C?no), is smaller than the
available resources offered by the backward IC (or the forward IC). In other words, in this case,
we have a sufficient amount of resources such that one can achieve the perfect feedback bound
in one direction. By symmetry, it suffices to focus on one corner point that favors the rate of
forward transmission: (R, R?) = (Cpf , C?no ? (Cpf ? Cno)).
(R1) ? > 2, ?? > 2 : For this regime, the network decomposition (10) yields:
(n,m) ??(0, 1)Cpf?Cno × (1, 2)n,
(n?, m?) ??(0, 1)m??2n? × (1, 2)n?.
Here we use the fact that Cpf?Cno = m?2n in the considered case. We now apply Lemma 3-(i)
for the pair of (0, 1)Cpf?Cno and (1, 2)n?. Note that the condition in Lemma 3-(i) holds: Cpf?Cno ?
C?no = 2n?. This then gives: R
(1) = Cpf ? Cno; R?
(1) = 2n? ? (Cpf ? Cno). For the remaining
DRAFT
30
subchannels, we apply the nonfeedback scheme, yielding: R(2) = 2n; R?(2) = 0. Aggregating
these two, we achieve the claimed corner point:
R = Cpf ? Cno + 2n = Cpf ? Cno + Cno = Cpf ,
R? = 2n?? (Cpf ? Cno) = C?no ? (Cpf ? Cno).
(R2) ? ? (0, 2
3
), ?? ? (0, 2
3
) : Applying the network decompositions (8) and (9) to this regime,
we get:
(n,m) ??
?
?
?
(1, 0)n?2m × (2, 1)Cpf?Cno , ? ? (0, 1/2];
(2, 1)Cpf?Cno × (3, 2)2m?n, ? ? (1/2, 2/3);
(n?, m?) ??
?
?
?
(1, 0)n??2m? × (2, 1)m?, ? ? (0, 1/2];
(2, 1)2n??3m? × (3, 2)2m??n?, ? ? (1/2, 2/3).
Here we use the fact that Cpf ? Cno = m for ? ? (0,
1
2
] and takes 2n ? 3m for ? ? (1
2
, 2
3
).
When ? ? (0, 1
2
] and ?? ? (0, 1
2
], we apply Lemma 3-(ii) for the pair of (2, 1)Cpf?Cno and
(1, 0)n??2m? × (2, 1)m?, yielding R(1) = 3(Cpf ? Cno) = 3m and R?
(1) = 2(n? ? 2m?) + 2m? ? m.
Notice that the condition in Lemma 3-(ii) is satisfied: Cpf ?Cpf ? C?no = 2(n?? 2m?) + 2m?. For
the rest, we apply the nonfeedback scheme to achieve R(2) = 2(n? 2m). This then gives:
R = 3m+ 2(n? 2m) = 2n?m = Cpf ,
R? = 2(n?? 2m?) + 2m??m = 2(n?? m?)?m = C?no ? (Cpf ? Cno).
When ? ? (0, 1
2
] and ?? ? (1
2
, 2
3
), we apply Lemma 3-(iii) for the pair of (2, 1)Cpf?Cno and
(2, 1)2n??3m? × (3, 2)2m??n?, yielding R(1) = 3(Cpf ?Cno) = 3m and R?
(1) = 2(2n?? 3m?) + 4(2m??
n?)?m. Note that the associated condition holds: Cpf ? Cpf ? C?no = 2(2n?? 3m?) + 4(m?? n?).
For the remaining subchannels, we apply the nonfeedback scheme to achieve R(2) = 2(n?2m).
This then gives:
R = 3m+ 2(n? 2m) = 2n?m = Cpf ,
R? = 2(2n?? 3m?) + 4(2m?? n?)?m = 2m??m = C?no ? (Cpf ? Cno).
The proof for the other regimes of [? ? (1
2
, 2
3
), ?? ? (0, 2
3
)] and [? ? (1
2
, 2
3
), ?? ? (1
2
, 2
3
)] follows
similarly.
DRAFT
31
As seen from all the cases above, one key observation to make is that the capacity increase
due to feedback Cpf?Cno plus the backward transmission rate is always C?no, meaning that there
is one-to-one tradeoff between feedback and independent message transmissions, i.e., one bit of
feedback costs one bit.
(II) Cpf ? Cno ? C?no, C?pf ? C?no ? Cno: Also in this case, one can readily prove the same
one-to-one tradeoff relationship in achieving one corner point (R, R?) = (Cpf , C?no?(Cpf ?Cno)).
Hence, we omit the detailed proof. On the other hand, there is a limitation in achieving the
other counterpart. Note that the maximal feedback gain C?pf ? C?no for backward transmission
does exceed the resource limit Cno offered by the forward channel. This leads the maximal
achievable rate for backward transmission to be saturated by R? ? C?no+Cno. So the other corner
point reads (R, R?) = (0, C?no + Cno) instead. For completeness, we will show this is indeed the
case as below. By symmetry, we omit the case of (II’).
(R1) ? > 2, ?? > 2 : For this regime,
(n,m) ??(0, 1)m?2n × (1, 2)
Cno
2
(n?, m?) ??(0, 1)Cno × (0, 1)(C?pf?C?no)?Cno × (1, 2)n?.
Here we use the fact that C?pf ? C?no = m? ? 2n? and
Cno
2
= n in the considered case. We
now apply a symmetric version of Lemma 3-(i) for the pair of (1, 2)
Cno
2 and (0, 1)Cno . This
then gives: R(1) = 2Cno
2
? Cno = 0; R?
(1) = Cno. For the rest, we apply the nonfeedback
scheme to achieve: R(2) = 0; R?(2) = 2n? = 2C?no. Hence, we achieve the claimed corner point:
(R, R?) = (0, C?no + Cno).
(R2) ? ? (0, 2
3
), ?? ? (0, 2
3
) : For this regime, the network decompositions (8) and (9) yield:
(n,m) ??
?
?
?
(1, 0)n?2m × (2, 1)m, ? ? (0, 1/2];
(2, 1)2n?3m × (3, 2)2m?n, ? ?
(
1
2
, 2
3
)
;
(n?, m?) ??
?
?
?
(1, 0)n??2m? × (2, 1)Cno × (2, 1)C?pf?C?no?Cno , ? ? (0, 1/2];
(2, 1)Cno × (2, 1)C?pf?C?no?Cno × (3, 2)2m??n?, ? ?
(
1
2
, 2
3
)
.
Here we use the fact that C?pf ? C?no = m? for ?? ? (0,
1
2
] and takes 2n? ? 3m? for ?? ? (1
2
, 2
3
).
When ? ? (0, 1
2
] and ?? ? (0, 1
2
], we apply a symmetric version of Lemma 3-(ii) for the pair of
(1, 0)n?2m × (2, 1)m and (2, 1)Cno . So we get: R(1) = 2(n? 2m) + 2m?Cno = 0; R?
(1) = 3Cno.
DRAFT
32
For the rest, we apply the nonfeedback scheme to achieve: R(2) = 0; R?(2) = 2(n??2m?)+2(C?pf?
C?no ? Cno) = 2n?? 2m?? 2Cno = C?no ? 2Cno. Hence we achieve: (R, R?) = (0, C?no + Cno).
When ? ? (1
2
, 2
3
) and ?? ? (0, 1
2
], we apply a symmetric version of Lemma 3-(iii) for the pair of
(2, 1)2n?3m × (3, 2)2m?n and (2, 1)Cno , thus giving: R(1) = 2(2n? 3m) + 4(2m? n)?Cno = 0;
R?(1) = 3Cno. For the rest, we apply the nonfeedback scheme to achieve: R
(2) = 0; R?(2) =
2(C?pf ? C?no ? Cno) + 4(2m?? n?) = 2m?? 2Cno. Hence we prove: (R, R?) = (0, C?no +Cno). The
proof of the other regimes [? ? (1
2
, 2
3
), ?? ? (0, 2
3
)] and [? ? (1
2
, 2
3
), ?? ? (1
2
, 2
3
)] follows similarly.
(III) Cpf ? Cno ? C?no, C?pf ? C?no ? Cno: This is the case in which there are limitations now
in achieving both R = Cpf and R? = C?pf . Due to the same argument as above, what we can
maximally achieve for R (or R?) in exchange of the other channel is Cno + C?no which implies
(R, R?) = (Cno + C?no, 0) or (0, Cno + C?no). The proof follows exactly the same as above; hence,
we omit it.
B. Proof of (R3) ? > 2, ?? ? [2
3
, 2]
A tedious yet straightforward computation demonstrates that the claimed achievable rate region
evaluated in the regime (R3) is:
{(R, R?) : R ? Cpf , R? ? C?no, R + R? ? Cno + 2n?}.
Unlike the (R1) and (R2) regimes, there is an interaction gain. Note that the sum-rate bound
exceeds Cno + C?no in the regime. The backward IC has no feedback gain. The network decom-
position (3) together with the fact that Cpf ? Cno = m? 2n in the regime gives:
(n,m) ?? (0, 1)Cpf?Cno × (1, 2)n.
We find that the shape of the region depends on where Cpf ?Cno lies in between 2n?? C?no and
2n?. See Fig. 12.
(I) Cpf ? Cno ? 2n? ? C?no: The first case is the one in which the amount of feedback for
maximal improvement, reflected in Cpf ?Cno, is small enough to achieve the maximal feedback
gain without degrading the performance of backward transmission. Now let us prove how to
achieve (R, R?) = (Cpf , C?no).
The decomposition idea is to pair up (0, 1)Cpf?Cno and (n?, m?) while applying the nonfeedback
scheme for the remaining forward subchannel (1, 2)n. To give an achievability idea for the first
pair, let us consider a simple example of (n,m) = (0, 1) and (n?, m?) = (3, 2). See Fig. 13.
DRAFT
33
    
 
 
Fig. 12. Three types of shapes of an achievable rate region for the regime (R3) ? > 2, ?? ? [ 2
3
, 2].
In each time, user 1 sends its own symbol ai. Unlike the previous regimes (R1) and (R2), an
interesting observation is made in feedback transmission. In the backward IC, C?no = max(2n??
m?, m?) (= 4 in this example) levels are utilized to send the backward symbols. For feedback, user
2? sends user 1’s received symbols ai’s back to user 2 through the remaining direct-link level.
Here one can make two key observations. The first is that such feedback signal ai is interfered
with by user 1?’s transmission but it turns out the interference does not cause any problem. Notice
in the example that a feedback signal, say a1, is mixed with A?1 and hence user 2 receives a1?A?1
instead of a1 which is desired to be fed back. Nonetheless user 2 sending the a1? A?1 in time 2,
user 1? can decode a1 of interest with the help of its own symbol A?1. This implies that feedback
and independent backward message transmissions do not interfere with each other and thus one
can maximally utilize available resource levels: the total number of direct-link levels 2n?. So the
2n?? C?no levels can be exploited for feedback. In the general case of (0, 1)
Cpf?Cno , the maximal
feedback gain Cpf ?Cno does not exceed the limit on the exploitable levels 2n?? C?no under the
considered regime. Hence, we achieve R(1) = Cpf ?Cno. Now the second observation is that the
feedback transmission of ai’s does not cause any interference to user 1. This ensures R?
(1) = C?no.
On the other hand, for the remaining suchanneles (1, 2)n, we apply the nonfeedback scheme to
DRAFT
34    
time 1 time 1time 2 time 2
desired to be fed back
User 1
User 1
User 2
User
User
time 3 time 3
User
UserUser 2
 
 
Fig. 13. Illustration of achievability for the (R3) regime via an example of (n,m) = (0, 1), (n?, m?) = (3, 2). This is an
instance in which we have a sufficient amount of resources that enables achieving the perfect feedback bound in the forward
IC: Cpf ? Cno = 1 ? 2 = 2n?? C?no. Hence, we achieve (R, R?) = (Cpf , C?no) = (1, 4).
achieve R(2) = 2n. Combining all of the above, we get:
R = Cpf ? Cno + 2n = Cpf ? Cno + Cno = Cpf
R? = C?no.
(II) Cpf?Cno ? 2n?: In this case, we do not have a sufficient amount of resources for achieving
R = Cpf . The maximally achievable forward rate is saturated by Cno+2n? and this occurs when
R? = 0. On the other hand, under the constraint of R? = C?no, what one can achieve for R is
Cno + (2n?? C?no).
(III) 2n?? C?no < Cpf ? Cno < 2n?: This is the case in which we have a sufficient amount of
resources for achieving R = Cpf , but not enough to achieve R? = C?no simultaneously. Hence,
aiming at R = Cpf , R? is saturated by 2n?? (Cpf ? Cno).
DRAFT
35
C. Proof of (R4) ? ? (0, 2
3
], ?? ? [2
3
, 2]
For the regime of (R4), the claimed achievable rate region is:
{(R, R?) : R ? Cpf , R? ? C?no, R + R? ? Cno + 2m?}.
This rate region is almost the same as that of (R3). The only difference is that the sum-rate
bound now reads Cno + 2m? instead of Cno + 2n?. Hence, the shape of the region depends now
on where Cpf ? Cno lies in between 2m?? C?no and 2m?. See Fig. 14. Here we will describe the
proof for the case (I) Cpf ?Cno ? 2m?? C?no in which we have a sufficient amount of resources
in achieving (R, R?) = (Cpf , C?no). For the other cases of (II) and (III), one can make the same
arguments as those in the (R3) regime; hence, we omit them.
Here what we need to demonstrate are two-folded. First, feedback and independent backward
message transmissions do not interfere with each other. Second, the maximum number of resource
levels utilized for sending feedback and independent backward symbols is limited by the total
number of cross-link levels: 2m?. The idea for feedback strategy is to employ Scheme 1 that we
illustrated via Example 1 in Section IV-A. We will show that the above two indeed hold when
we use this idea.
Note in Fig. 5 the tension between forward-symbol feedback and backward symbols, e.g.,
a?B vs. A?. Scheme 1 based on XORing with interference neutralization leads us to completely
resolve the tension. Observe that user 1 could decode A? of interest since user 2? transmitted B
through the second cross-link level to neutralize the inference B at the bottom level at user 1.
This contributes one bit (the number of the second cross-link level) to the backward symbol rate
(w.r.t. A?). At the same time, user 2 could obtain a ? A? (which would be used for the purpose
of refinement in stage II) through the first cross-link level. This contributes one bit (the number
of the first cross-link level) to the feedback rate (w.r.t. a ? A?). Similarly b ? A and B? were
successfully transmitted to user 1 and 2 respectively, and the contributed 2 bits correspond to
the number of the remaining cross-link levels. We can now see that feedback and independent
backward symbols do not cause any interference to each other and the total transmission rate
is limited by the total number of cross link levels: 2m?. Since the maximal amount of feedback
Cpf ? Cno plus the backward symbol rate C?no does not exceed 2m? in the considered case, we
can indeed achieve (R, R?) = (Cpf , C?no).
DRAFT
36
    
 
Fig. 14. Three types of shapes of an achievable rate region for the regime (R4) ? ? (0, 2
3
], ?? ? [ 2
3
, 2].
D. Proof of (R5) ? ? (0, 2
3
), ?? > 2
For the regime of (R5), the claimed achievable rate region is:
{(R, R?) : R ? Cpf , R? ? C?pf , R + R? ? 2n+ C?no, R+ R? ? Cno + 2m?}.
Remember that Cpf ? Cno indicates the maximum amount of feedback w.r.t. forward symbols
and we interpret 2m? ? C?pf as the remaining resource levels that can potentially be utilized to
aid forward transmission. Whether or not Cpf ?Cno ? 2m?? C?pf (i.e., we have enough resource
levels to achieve R = Cpf), the shape of the above claimed region is changed. Note that the last
inequality in the rate region becomes inactive when Cpf ? Cno ? 2m?? C?pf . Similarly the third
inequality is inactive when C?pf ? C?no ? 2n?Cpf (i.e., we have enough resources for achieving
R? = C?pf). One can readily verify that Cpf ?Cno > 2m?? C?pf and C?pf ? C?no > 2n? Cpf do not
hold simultaneously. Hence, it suffices to consider the following three cases:
(I) Cpf ? Cno ? 2m?? C?pf , C?pf ? C?no ? 2n? Cpf ;
(II) Cpf ? Cno ? 2m?? C?pf , C?pf ? C?no > 2n? Cpf ;
(III) Cpf ? Cno > 2m?? C?pf , C?pf ? C?no ? 2n? Cpf .
As mentioned earlier in Example 3, the key idea for the proof is to use the network de-
composition. Specifically, the following lemma that describes achievability for the elementary
subchannels in the considered regime forms the basis of the proof.
DRAFT
37
Lemma 4: The following rates are achievable:
(i) For the pair of (n,m) = (2, 1) and (n?, m?) = (0, 1): (R, R?) = (3, 1);
(ii) For the pair of (n,m) = (2, 1)i and (n?, m?) = (1, 2)j where i ? 2j: (R, R?) = (3i, 2j);
(iii) For the pair of (n,m) = (3, 2)i and (n?, m?) = (0, 1)j where 2i ? j: (R, R?) = (4i, j);
(iv) For the pair of (n,m) = (2, 1) and (n?, m?) = (0, 1)2: (R, R?) = (2, 2);
(v) For the pair of (n,m) = (2, 1)2 and (n?, m?) = (0, 1): (R, R?) = (6, 0).
Proof: See Appendix C.
(I) Cpf ? Cno ? 2m? ? C?pf , C?pf ? C?no ? 2n ? Cpf : In this case, the rate region claims that
we can get all the way to perfect feedback capacities: (R, R?) = (Cpf , C?pf). First consider the
regime of ? ? (0, 1
2
] in which the network decompositions (8) and (10) yield:
(n,m) ??(2, 1)C?pf?C?no × (2, 1)Cpf?Cno?(C?pf?C?no) × (1, 0)n?2m;
(n?, m?) ??(0, 1)C?pf?C?no × (1, 2)n?.
Here we use the fact that Cpf ? Cno = m and that C?pf ? C?no ? Cpf ? Cno = 2n ? Cpf in the
considered regime. We now apply Lemma 4-(i) for the pair of (2, 1)C?pf?C?no and (0, 1)C?pf?C?no .
Also we apply Lemma 4-(ii) for the pair of (2, 1)Cpf?Cno?(C?pf?C?no) and (1, 2)n?. Note that Cpf ?
Cno ? (C?pf ? C?no) ? 2n? in the considered regime: Cpf ? Cno ? 2m?? C?pf . Lastly we apply the
nonfeedback scheme for the remaining subchannel (1, 0)n?2m. This yields:
R = 3× (C?pf ? C?no) + 3× {Cpf ? Cno ? (C?pf ? C?no)}+ 2× (n? 2m) = 2n?m = Cpf ,
R? = 1× (C?pf ? C?no) + 2× n? = m? = C?pf .
Next consider the regime of ? ? [1
2
, 2
3
]. In this regime, there are two subcases depending on
whether or not Cpf ? Cno ? C?pf ? C?no. When Cpf ? Cno ? C?pf ? C?no,
(n,m) ??(2, 1)C?pf?C?no × (2, 1)Cpf?Cno?(C?pf?C?no) × (3, 2)2m?n;
(n?, m?) ??(0, 1)C?pf?C?no × (1, 2)n?.
We apply Lemma 4-(i) for the pair of (2, 1)C?pf?C?no and (0, 1)C?pf?C?no ; apply Lemma 4-(ii) for
the pair of (2, 1)Cpf?Cno?(C?pf?C?no) and (1, 2)n? (note that Cpf ? Cno ? (C?pf ? C?no) ? 2n? in the
considered regime Cpf ? Cno ? 2m?? C?pf); apply the nonfeedback scheme for (3, 2)
2m?n. This
DRAFT
38
gives:
R = 3× (C?pf ? C?no) + 3× {Cpf ? Cno ? (C?pf ? C?no)}+ 4× (2m? n) = 2n?m = Cpf ,
R? = 1× (C?pf ? C?no) + 2× n? = m? = C?pf .
For the other case Cpf ? Cno < C?pf ? C?no,
(n,m) ?? (2, 1)Cpf?Cno × (3, 2)2m?n,
(n?, m?) ?? (0, 1)Cpf?Cno × (0, 1)C?pf?C?no?(Cpf?Cno) × (1, 2)n?.
Using Lemma 4 and making similar arguments as earlier, one can show that
R = 3× (Cpf ? Cno) + 4× (2m? n) = 2n?m = Cpf ,
R? = 1× (Cpf ? Cno) + 1× {C?pf ? C?no ? (Cpf ? Cno)}+ 2× n? = m? = C?pf .
(II) Cpf ? Cno ? 2m? ? C?pf , C?pf ? C?no > 2n ? Cpf : In this case, there are two corner points
to achieve. The first corner point is (R, R?) = (Cpf , C?no + 2n ? Cpf). The second corner point
depends on where C?pf ? C?no lies in between 2n ? Cno, 2n and beyond. See Fig. 15. For the
cases of (II-1) and (II-2), the corner point reads (R, R?) = (2n ? (C?pf ? C?no), C?pf), while for
(II-3), (R, R?) = (0, C?no + 2n).
Let us first prove (R, R?) = (Cpf , C?no + 2n? Cpf). For the regime ? ? (0,
1
2
],
(n,m) ??(2, 1)Cpf?Cno × (1, 0)n?2m,
(n?, m?) ??(0, 1)Cpf?Cno × (0, 1)C?pf?C?no?(Cpf?Cno) × (1, 2)n?.
Note that C?pf ? C?no > Cpf ? Cno in the considered regime C?pf ? C?no > 2n ? Cpf . We apply
Lemma 4-(i) for the pair of (2, 1)Cpf?Cno and (0, 1)Cpf?Cno ; apply the nonfeedback scheme for
the rest. This yields:
R = 3× (Cpf ? Cno) + 2× (n? 2m) = 2n?m = Cpf ,
R? = 1× (Cpf ? Cno) + 2× n? = C?no + 2n? Cpf .
For the regime ? ? [1
2
, 2
3
],
(n,m) ??(2, 1)Cpf?Cno × (3, 2)2m?n,
(n?, m?) ??(0, 1)Cpf?Cno × (0, 1)2(2m?n) × (0, 1)C?pf?C?no?(Cpf?Cno)?2(2m?n) × (1, 2)n?.
DRAFT
39
    
 
 
Fig. 15. Three types of shapes of an achievable rate region for the regime (R5) ? ? (0, 2
3
], ?? > 2 and the case (II)
Cpf ? Cno ? 2m?? C?pf , C?pf ? C?no > 2n? Cpf .
Note that C?pf ? C?no > Cpf ?Cno + 2(2m? n) in the considered regime C?pf ? C?no > 2n?Cpf .
We apply Lemma 4-(i) for the pair of (2, 1)Cpf?Cno and (0, 1)Cpf?Cno ; apply Lemma 4-(iii) for the
pair of (3, 2)2m?n and (0, 1)2(2m?n); apply the nonfeedback scheme for the rest. This yields:
R = 3× (Cpf ? Cno) + 4(2m? n) = 2n?m = Cpf ,
R? = 1× (Cpf ? Cno) + 1× 2(2m? n) + 2n? = C?no + 2n? Cpf .
We are now ready to prove the second corner point which favors R?. Depending on the quantity
of C?pf ? C?no, we have three subcases.
(II-1) 2n? Cpf < C?pf ? C?no ? 2n? Cno: For the regime ? ? (0,
1
2
],
(n,m) ??(2, 1)2n?Cno?(C?pf?C?no) × (2, 1)C?pf?C?no?(2n?Cpf ) × (1, 0)n?2m,
(n?, m?) ??(0, 1)2n?Cno?(C?pf?C?no) × (0, 1)2{C?pf?C?no?(2n?Cpf)} × (1, 2)n?.
We apply Lemma 4-(i) for the pair of (2, 1)2n?Cno?(C?pf?C?no) and (0, 1)2n?Cno?(C?pf?C?no); apply
Lemma 4-(iv) for the pair of (2, 1)C?pf?C?no?(2n?Cpf ) and (0, 1)2{C?pf?C?no?(2n?Cpf )}; apply the non-
feedback scheme for the rest. This then gives:
R = 3{2n? Cno ? (C?pf ? C?no)}+ 2{C?pf ? C?no ? (2n? Cpf)}+ 2(n? 2m) = 2n? (C?pf ? C?no),
R? = {2n? Cno ? (C?pf ? C?no)}+ 2{C?pf ? C?no ? (2n? Cpf)}+ 2n? = C?pf .
DRAFT
40
For the regime ? ? [1
2
, 2
3
],
(n,m) ??(2, 1)2n?Cno?(C?pf?C?no) × (2, 1)C?pf?C?no?(2n?Cpf ) × (3, 2)2m?n,
(n?, m?) ??(0, 1)2n?Cno?(C?pf?C?no) × (0, 1)2{C?pf?C?no?(2n?Cpf )} × (0, 1)2(2m?n) × (1, 2)n?.
We apply Lemma 4-(i) for the pair of (2, 1)2n?Cno?(C?pf?C?no) and (0, 1)2n?Cno?(C?pf?C?no); apply
Lemma 4-(iv) for the pair of (2, 1)C?pf?C?no?(2n?Cpf) and (0, 1)2{C?pf?C?no?(2n?Cpf )}; apply Lemma 4-
(iii) for the pair of (3, 2)2m?n and (0, 1)2(2m?n); apply the nonfeedback scheme for the rest. This
then gives:
R = 3{2n? Cno ? (C?pf ? C?no)}+ 2{C?pf ? C?no ? (2n? Cpf)}+ 4(2m? n) = 2n? (C?pf ? C?no),
R? = {2n? Cno ? (C?pf ? C?no)}+ 2{C?pf ? C?no ? (2n? Cpf)}+ 12(2m? n) + 2n? = C?pf .
(II-2) 2n ? Cno < C?pf ? C?no ? 2n: It turns out in this case proving achievability only
via the network decomposition is a bit involved. So for illustrative purpose, we will first show
achievability for one point that lies on the 45-degree line connecting the two corner points. Later
we will slightly perturb the scheme to prove achievability for the second corner point that we
intend to achieve.
First consider the regime ? ? (0, 1
2
]. In this case,
(n,m) ??(2, 1)Cpf?Cno × (1, 0)n?2m,
(n?, m?) ??(0, 1)2(Cpf?Cno) × (0, 1)C?pf?C?no?2(Cpf?Cno) × (1, 2)n?.
Note that C?pf ? C?no > 2(Cpf ?Cno) in the considered regime C?pf ? C?no > 2n?Cno. We apply
Lemma 4-(iv) for the pair of (2, 1)Cpf?Cno and (0, 1)2(Cpf?Cno); apply the nonfeedback scheme for
the rest. This then yields:
R = 2× (Cpf ? Cno) + 2× (n? 2m),
R? = 2× (Cpf ? Cno) + 2× n?.
As mentioned earlier, this is an intermediate point that lies on the 45-degree line connecting the
two corner points. Now we tune the scheme which yields the above rate to prove the achievability
of the second corner point. We use part of the forward channel for aiding backward transmission
instead of sending its own traffic. Specifically we utilize C?pf ? C?no ? 2(Cpf ? Cno) number of
bottom levels in the forward channel in an effort to relay backward-symbol feedback. This naive
DRAFT
41
change incurs one-to-one tradeoff between feedback and independent message transmission, thus
yielding:
R = 2× (Cpf ? Cno) + 2× (n? 2m)? {C?pf ? C?no ? 2(Cpf ? Cno)} = 2n? (C?pf ? C?no),
R? = 2× (Cpf ? Cno) + 2× n?+ {C?pf ? C?no ? 2(Cpf ? Cno)} = C?pf .
For the regime ? ? [1
2
, 2
3
],
(n,m) ??(2, 1)Cpf?Cno × (3, 2)2m?n,
(n?, m?) ??(0, 1)2(Cpf?Cno) × (0, 1)2(2m?n) × (0, 1)C?pf?C?no?2(Cpf?Cno)?2(2m?n) × (1, 2)n?.
We apply Lemma 4-(iv) for the pair of (2, 1)Cpf?Cno and (0, 1)2(Cpf?Cno); apply Lemma 4-(iii) for
the pair of (3, 2)2m?n and (0, 1)2(2m?n); apply the nonfeedback scheme for the rest. This then
gives:
R = 2× (Cpf ? Cno) + 4× (2m? n),
R? = 2× (Cpf ? Cno) + 1× 2(2m? n) + 2n?.
This is an intermediate point that lies on the 45-degree line connecting the two corner points.
Now sacrificing C?pf ? C?no?2(Cpf ?Cno)?2(2m?n) number of resource levels in the forward
channel for aiding backward transmission, we achieve:
R = 2(Cpf ? Cno) + 4(2m? n)? {C?pf ? C?no ? 2(Cpf ? Cno)? 2(2m? n)} = 2n? (C?pf ? C?no),
R? = 2(Cpf ? Cno) + 2(2m? n) + 2n?+ {C?pf ? C?no ? 2(Cpf ? Cno)? 2(2m? n)} = C?pf .
(II-3) C?pf?C?no > 2n: In this case, we sacrifice all of the 2n direct links in the forward channel
only for the purpose of helping backward transmission. This then gives: (R, R?) = (0, C?no+2n).
(III) Cpf ? Cno > 2m?? C?pf , C?pf ? C?no ? 2n? Cpf : Similarly this case requires the proof of
two corner points. The first corner point is: (R, R?) = (Cno +2m?? C?pf , C?pf). The second corner
point depends on where Cpf ?Cno lies in. See Fig. 16. While the proof is similar to that in the
previous case, we provide details for completeness.
First focus on the proof of the first corner point (R, R?) = (Cno + 2m?? C?pf , C?pf). Notice that
for the regime ? ? (0, 1
2
], ?? > 2, we encounter a contradiction as follows:
Cpf ? Cno > 2m?? C?pf ? Cpf ? Cno > C?pf ? C?no;
C?pf ? C?no ? 2n? Cpf ? Cpf ? Cno ? C?pf ? C?no.
DRAFT
42
  
 
 
Fig. 16. Three types of shapes of an achievable rate region for the regime (R5) ? ? (0, 2
3
], ?? > 2 and the case (III)
Cpf ? Cno > 2m?? C?pf , C?pf ? C?no ? 2n? Cpf .
Hence, we will not consider this regime. For the regime ? ? [1
2
, 2
3
],
(n,m) ??(2, 1)C?pf?C?no × (2, 1)2n? × (2, 1)Cpf?Cno?(C?pf?C?no)?2n? × (3, 2)2m?n,
(n?, m?) ??(0, 1)C?pf?C?no × (1, 2)n?.
Note that Cpf ? Cno > C?pf ? C?no + 2n? in the considered regime Cpf ? Cno > 2m? ? C?pf . We
now apply Lemma 4-(i) for the pair of (2, 1)C?pf?C?no and (0, 1)C?pf?C?no ; apply Lemma 4-(ii) for
the pair of (2, 1)2n? and (1, 2)n?; apply the nonfeedback scheme for the rest. This gives:
R = 3(C?pf ? C?no) + 3 · 2n?+ 2{Cpf ? Cno ? (C?pf ? C?no)? 2n?}+ 4(2m? n) = Cno + 2m?? C?pf ,
R? = (C?pf ? C?no) + 2n? = C?pf .
Let us now prove the second corner point which favours R. As mentioned earlier, we have
three subcases depending on the quantity of Cpf ? Cno.
(III-1) 2m?? C?pf < Cpf ? Cno ? 2m?? C?no: In this case, we have:
(n,m) ??(2, 1)2m??C?no?(Cpf?Cno) × (2, 1)2{Cpf?Cno?(2m??C?pf )} × (2, 1)2n? × (3, 2)2m?n,
(n?, m?) ??(0, 1)2m??C?no?(Cpf?Cno) × (0, 1)Cpf?Cno?(2m??C?pf ) × (1, 2)n?.
DRAFT
43
We now apply Lemma 4-(i) for the pair of (2, 1)2m??C?no?(Cpf?Cno) and (0, 1)2m??C?no?(Cpf?Cno);
apply Lemma 4-(v) for the pair of (2, 1)2{Cpf?Cno?(2m??C?pf )} and (0, 1)Cpf?Cno?(2m??C?pf ); apply the
nonfeedback scheme for the rest. This then yields:
R = 3{2m?? C?no ? (Cpf ? Cno)}+ 3 · 2{Cpf ? Cno ? (2m?? C?pf)}+ 3 · 2n?+ 4(2m? n) = Cpf ,
R? = {2m?? C?no ? (Cpf ? Cno)}+ 2n? = 2m?? (Cpf ? Cno).
(III-2) 2m? ? C?no < Cpf ? Cno ? 2m?: In this case, we will take the two-step approach: first
obtaining an intermediate point that lies on the 45-degree line and then perturbing the scheme
to prove achievability of the second corner point of interest.
In the considered regime, we have:
(n,m) ??(2, 1)2(C?pf?C?no) × (2, 1)2n? × (2, 1)Cpf?Cno?2×(C?pf?C?no)?2n? × (3, 2)2m?n,
(n?, m?) ??(0, 1)C?pf?C?no × (1, 2)n?.
Here we use the fact that Cpf ? Cno > 2(C?pf ? C?no) + 2n? due to Cpf ? Cno > 2m? ? C?no. We
now apply Lemma 4-(v) for the pair of (2, 1)2(C?pf?C?no) and (0, 1)C?pf?C?no ; apply Lemma 4-(ii) for
the pair of (2, 1)2n? and (1, 2)n?; apply the nonfeedback scheme for the rest. This gives:
R = 3× 2(C?pf ? C?no) + 3× 2n?+ 2× {Cpf ? Cno ? 2× (C?pf ? C?no)? 2n?}+ 4× (2m? n),
R? = 2n?.
We now change the scheme that achieves the above rate pair to prove achievability of the second
corner point. Specifically we utilize Cpf ?Cno ? 2× (C?pf ? C?no)? 2n? number of cross links in
the backward channel to help forward transmission. This way, we can achieve:
R = 3× 2(C?pf ? C?no) + 3× 2n? + 2× {Cpf ? Cno ? 2× (C?pf ? C?no)? 2n?}+ 4× (2m? n)
+ {Cpf ? Cno ? 2× (C?pf ? C?no)? 2n?} = 2n?m = Cpf ,
R? = 2n?? {Cpf ? Cno ? 2× (C?pf ? C?no)? 2n?} = 2m?? (Cpf ? Cno).
(III-3) Cpf ?Cno > 2m?: In this case, all of the 2m? cross-link levels in the backward channel
are used solely for aiding forward transmission. So we can achieve: (R, R?) = (Cno + 2m?, 0).
DRAFT
44    
time 1 time 1time 2 time 2
desired to be fed back
User 1
User 2
User 1
User 2
User
User
time 3 time 3
User
User
 
 
Fig. 17. For the pair of (n,m) = (0, 1), (n?, m?) = (1, 2), one can achieve (R, R?) = (1, 1).
APPENDIX B
PROOF OF LEMMA 3
(i): We will illustrate achievability via the simplest example in which (i, j) = (1, 1). See
Fig. 17. In the forward channel (0, 1), only one user (say user 1) intends to send one symbol
(say ai) every time slot. User 2? then feeds the symbol back to user 2 using the top level in the
backward channel. Next user 2 delivers the fed back symbol to user 1?. This way, we achieve
R = 1. Now for (n,m) = (0, 1)i and (n?, m?) = (1, 2)j , consider sending i number of feedback
symbols from user 2? to user 2. Since the total number of resource levels at user 2 in the backward
channel is 2j, one can ensure R = i as long as i ? 2j. On the other hand, the remaining 2j ? i
resource levels at user 2 are used for backward traffic. In the example, 2j?i = 1, so one backward
symbol A?i is transmitted per time. Notice that this transmission also occupies a resource level
at user 1. This prevents from squeezing more backward symbols, thus yielding R? = 2j ? i.
Here one key observation to make is that feedback for increasing R by one bit incurs one bit of
degradation w.r.t. R?, meaning that there is one-to-one tradeoff between feedback and backward
message transmissions, as demonstrated in [3].
DRAFT
45
    
time 1 time 1time 2 time 2
desired to be fed back
time 3 time 3
User 1
User 2
User
User
User 1
User 2
User
User
 
 
Fig. 18. For the pair of (n,m) = (2, 1), (n?, m?) = (1, 0), one can achieve (R, R?) = (3, 1).
(ii): We will describe achievability via a special case of (i, j, k) = (1, 1, 0): (n,m) = (2, 1)
and (n?, m?) = (1, 0). See Fig. 18. In the forward channel (2, 1), user 1 sends two symbols (ai, Ai)
per time, while user 2 sends only one symbol Bi on bottom. The symbol Bi is interfered with
ai. User 2? then sends the interfered signal ai ? Bi back to user 2, which in turn enables user
2 to decode ai. User 2 forwarding the ai through the top level in the next time allows user 2?
to refine the corrupted symbol. For instance, at time 2, user 2? can decode B1 by subtracting a1
from a1 ? B1. This way, we achieve R =
3N?1
N
? 3 as code length N tends to infinity. Now
for (n,m) = (2, 1)i and (n?, m?) = (1, 0)j , consider sending i number of feedback symbols either
from user 2? to user 2 (as in the example) or from user 1? to user 1 (this is the case in which
user 2 sends more compared to user 1). Then, we can achieve R = 3i as long as i does not
exceed the total number 2j of resource levels in the backward channel which corresponds to
the nonfeedback sum-rate. For the remaining resource levels 2j? i, we employ the nonfeedback
scheme to achieve R? = 2j? i. As in the previous case (i), we see one-to-one tradeoff. One can
apply the same argument for (n,m) = (2, 1)i and (n?, m?) = (2, 1)k to observe the same one-to-
one tradeoff relationship. The only distinction is that in this case, the nonfeedback sum-rate of
the backward channel is 2k. Hence, we achieve (R, R?) = (3i, 2k? i) under i ? 2k. Now for the
DRAFT
46
general (i, j, k) case, combining the above two, we get (R, R?) = (3i, 2j+2k? i) if i ? 2j+2k.
(iii): For (n,m) = (2, 1)i and (n?, m?) = (2, 1)j, the proof in the (ii) case yields (R, R?) =
(3i, 2j ? i) under i ? 2j. For (n,m) = (2, 1)i and (n?, m?) = (3, 2)k, using the same argument
and the fact that the nonfeedback sum-rate of the backward channel is 4k, one can show that
(R, R?) = (3i, 4k? i) under i ? 4k. Now for the general (i, j, k) case, combining the above two,
we can achieve (R, R?) = (3i, 2j + 4k ? i) as long as i ? 2j + 4k. This completes the proof.
APPENDIX C
PROOF OF LEMMA 4
(i): See Scheme 2 in Section IV.
(ii): Obviously (n,m) = (2, 1)i = (2i, i) and (n?, m?) = (1, 2)j = (j, 2j). Note in this case that
Cpf = 3i > 2i = Cno and C?no = 2j and hence the channel belongs to the (R4) regime. Since the
condition i ? 2j corresponds to Cpf ? Cno ? 2m? ? C?no, the achievability for the (R4) regime
yields (R, R?) = (Cpf , C?no).
(iii): Obviously (n,m) = (3, 2)i = (3i, 2i) and (n?, m?) = (0, 1)j = (0, j). Note in this case
that Cno = 4i and C?pf = j > 0 = C?no and hence the channel belongs to the (R3’) regime (the
symmetric counterpart of (R3)). Since the condition 2i ? j corresponds to C?pf?C?no ? 2n?Cno,
the achievability for the (R3’) regime yields (R, R?) = (Cno, C?pf).
(iv): In the forward channel, each user sends one bit on bottom every time, while the upper
level is utilized to relay backward-symbol feedback. See Fig. 19. Here the backward-symbol
feedback, say b?1, does not cause any interference to user 2? as it is already known. Hence, two
feedback symbols can be delivered every time and this yields (R, R?) = (2, 2).
(v): The backward channel is used solely for feeding back forward-symbol feeddback. One
can easily verify that this enables us to achieve R = Cpf = 2× 3 = 6.
REFERENCES
[1] C. E. Shannon, “Two-way communication channels,” 4th Berkeley Symp. Math. Stat. Prob., pp. 611–644, June 1961.
[2] G. Kramer, “Feedback strategies for white Gaussian interference networks,” IEEE Transactions on Information Theory,
vol. 48, pp. 1423–1438, June 2002.
[3] C. Suh and D. Tse, “Feedback capacity of the Gaussian interference channel to within 2 bits,” IEEE Transactions on
Information Theory, vol. 57, pp. 2667–2685, May 2011.
[4] A. Vahid, C. Suh, and A. S. Avestimehr, “Interference channels with rate-limited feedback,” IEEE Transactions on
Information Theory, vol. 58, pp. 2788–2812, May 2012.
DRAFT
47
    
User 1
User 2
User
User
User 1
User 2
User
User
time 1time 2time 3
time 1 time 2 time 3
 
 
Fig. 19. For the pair of (n,m) = (2, 1) and (n?, m?) = (0, 1)2, one can achieve (R, R?) = (2, 2).
[5] C. Suh, I.-H. Wang, and D. Tse, “Two-way interference channels,” IEEE International Symposium on Information Theory,
2012.
[6] S. Avestimehr, S. Diggavi, and D. Tse, “Wireless network information flow: A deterministic approach,” IEEE Transactions
on Information Theory, vol. 57, pp. 1872–1905, Apr. 2011.
[7] Z. Cheng and N. Devroye, “Two-way neworks: When adapation is useless,” IEEE Transactions on Information Theory,
vol. 60, pp. 1793–1813, Mar. 2014.
[8] A. El-Gamal and M. H. Costa, “The capacity region of a class of deterministic interference channels,” IEEE Transactions
on Information Theory, vol. 28, pp. 343–346, Mar. 1982.
[9] S. Rini, D. Tuninetti, and N. Devroye, “New inner and outer bounds for the memoryless cognitive interference channel
and some new capacity results,” IEEE Transactions on Information Theory, vol. 57, pp. 4087–4109, July 2011.
[10] I.-H. Wang and D. Tse, “Interference mitigation through limited receiver cooperation,” IEEE Transactions on Information
Theory, vol. 57, pp. 2913–2940, May 2011.
[11] V. M. Prabhakaran and P. Viswanath, “Interference channels with source cooperation,” IEEE Transactions on Information
Theory, vol. 57, pp. 156–186, Jan. 2011.
[12] S. Kamath and Y.-H. Kim, “Chop and roll: Improving the cutset bound,” Allerton Conference on Communicaiton, Control,
and Computing, Oct. 2014.
[13] W. J. McGill, “Multivariate information transmission,” Psychometrika, vol. 19, pp. 97–116, 1954.
[14] A. Sahai, V. Aggarwal, M. Yuksel, and A. Sabharwal, “On channel output feedback in deterministic interference channels,”
Information Theory Workshop, pp. 298–302, Oct. 2009.
[15] G. Bresler and D. Tse, “The two-user Gaussian interference channel: a deterministic view,” European Transactions on
Telecommunications, vol. 19, pp. 333–354, Apr. 2008.
DRAFT
48
[16] S. Mohajer, S. Diggavi, C. Fragouli, and D. Tse, “Approximate capacity of a class of Gaussian interferene-relay networks,”
IEEE Transactions on Information Theory, vol. 57, pp. 2837–2864, May 2011.
[17] R. Ahlswede, N. Cai, S.-Y. R. Li, and R. W. Yeung, “Network information flow,” IEEE Transactions on Information
Theory, vol. 46, pp. 1204–1216, July 2000.
[18] M. A. Maddah-Ali, A. S. Motahari, and A. K. Khandani, “Communication over MIMO X channels: Interference alignment,
decomposition, and performance analysis,” IEEE Transactions on Information Theory, vol. 54, pp. 3457–3470, Aug. 2008.
[19] V. R. Cadambe and S. A. Jafar, “Interference alignment and degrees of freedom of the k-user interference channel,” IEEE
Transactions on Information Theory, vol. 54, pp. 3425–3441, Aug. 2008.
[20] Y. Wu, P. A. Chou, and S. Y. Kung, “Information exchange in wireless networks with network coding and physical-layer
broadcast,” CISS 39th Annual Conference, Mar. 2005.
[21] S. Katti, H. Rahul, W. Hu, D. Katabi, M. Medard, and J. Crowcroft, “XORs in the air: Practical wireless network coding,”
ACM SIGCOMM Computer Communication Review, vol. 36, pp. 243–254, Oct. 2006.
[22] Z. Bar-Yossef, Y. Birk, T.S.Jayram, and T. Kol, “Index coding with side information,” Foundations of Computer Science
(FOCS), pp. 197–206, Oct. 2006.
[23] M. Maddah-Ali and D. Tse, “Completely stale transmitter channel state information is still very useful,” IEEE Transactions
on Informatoin Theory, vol. 58, pp. 4418–4431, July 2012.
[24] M. A. Maddah-Ali and U. Niesen, “Fundamental limits of caching,” IEEE Transactions on Information Theory, vol. 60,
pp. 2856–2867, May 2014.
[25] C. Suh, N. Goela, and M. Gastpar, “Computation in multicast networks: Function alignment and converse theorems,” IEEE
Transactions on Information Theory, vol. 62, pp. 1866–1877, Apr. 2016.
[26] S. H. Lim, Y.-H. Kim, A. E. Gamal, and S.-Y. Chung, “Noisy network coding,” IEEE Transactions on Information Theory,
vol. 57, pp. 3132–3152, May 2011.
[27] A. E. Gamal and Y.-H. Kim, Network Information Theory. Cambridge, 1th ed., 2011.
[28] M. H. M. Costa, “Writing on dirty paper,” IEEE Transactions on Information Theory, vol. 29, pp. 439–441, May 1983.
[29] B. Nazer and M. Gastpar, “Compute-and-forward: Harnessing interference through structured codes,” IEEE Transactions
on Information Theory, vol. 57, pp. 6463–6486, Oct. 2011.
[30] T. S. Han and K. Kobayashi, “A new achievable rate region for the interference channel,” IEEE Transactions on Information
Theory, vol. 27, pp. 49–60, Jan. 1981.
[31] C. Suh, N. Goela, and M. Gastpar, “Approximate feedback capacity of the Gaussian multicast channel,” IEEE International
Symposium on Information Theory, July 2012.
[32] C. Suh and M. Gastpar, “Interactive function computation,” IEEE International Symposium on Information Theory, July
2013.
[33] S. Shin and C. Suh, “Two-way function computation,” Proceedings of Allerton Conference on Communication, Control,
and Computing, Oct. 2014.
[34] J. Chen, A. Ozgur, and S. Diggavi, “Feedback through overhearing,” Proceedings of Allerton Conference on Communication,
Control, and Computing, Oct. 2014.
DRAFT
