ar
X
iv
:1
70
9.
00
95
7v
1 
 [
cs
.N
I]
  4
 S
ep
 2
01
7
1
Edge Caching in Dense Heterogeneous
Cellular Networks with Massive MIMO
Aided Self-backhaul
Lifeng Wang, Member, IEEE, Kai-Kit Wong, Fellow, IEEE, Sangarapillai
Lambotharan, Senior Member, IEEE, Arumugam Nallanathan, Fellow, IEEE,
and Maged Elkashlan, Member, IEEE
Abstract
This paper studies edge caching in dense heterogeneous cellular networks, in which small
base stations (SBSs) with limited cache size store the popular contents, and massive multiple-
input multiple-output (MIMO) aided macro base stations provide wireless self-backhaul when SBSs
require the non-cached contents. We address the effects of cell load and hit probability on the
successful content delivery (SCD), and evaluate the minimum required base station density for
avoiding the access overload in a small cell and backhaul overload in a macrocell. We demonstrate
that hit probability needs to be appropriately selected, in order to achieve SCD. We derive the massive
MIMO backhaul achievable rate without downlink channel estimation, to calculate the backhaul time.
We provide important insights on the interplay between cache size and SCD, and analyze the latency
in such networks. We demonstrate that when non-cached contents are requested, the average delay
of the non-cached content delivery could be comparable to the cached content delivery with the
help of massive MIMO aided self-backhaul, if the average access rate of cached content delivery
is lower than that of self-backhauled content delivery. Simulation results are presented to validate
our analysis.
Index Terms
Edge caching, dense small cell, massive MIMO, self-backhaul.
L. Wang and K.-K. Wong are with the Department of Electronic and Electrical Engineering, University College London,
London, UK (Email: {lifeng.wang, kai-kit.wong}@ucl.ac.uk).
S. Lambotharan is with School of Electronic, Electrical and System Engineering, Loughborough University, Loughborough
Leicestershire, UK (Email: {s.lambotharan}@lboro.ac.uk)
A. Nallanathan and M. Elkashlan are with the School of Electronic Engineering and Computer Science, Queen Mary
University of London, London, UK. (Email: {arumugam.nallanathan,maged.elkashlan}@qmul.ac.uk)
2
I. INTRODUCTION
A. Motivation and Background
New findings from Cisco [1] indicate that mobile video traffic accounts for the majority
of mobile data traffic. To offload the traffic of the core networks and reduce the backhaul
cost and latency, caching the popular contents at the edge of wireless networks becomes a
promising solution [2–4]. The latest 3GPP standard has required that the fifth generation (5G)
system shall support content caching applications and operators need to place the content
caches close to mobile terminals [5]. In addition, the emerging radio-access technologies and
wireless network architectures provide edge caching with new opportunities [6].
Recent works have focused on the caching design and analysis in various scenarios. In [7],
a probabilistic caching model was considered in single-tier cellular networks and the optimal
content placement was designed to maximize the total hit probability. In [8], a stochastic
content multicast scheduling problem was formulated to jointly minimize the average network
delay and power costs in heterogeneous cellular networks (HetNets), and a structure-aware
optimal algorithm was proposed to solve this problem. Caching cooperation in multi-tier
HetNets was studied in [9], where a low-complexity suboptimal solution was developed to
maximize the capacity in such networks. Caching in device-to-device (D2D) networks was
investigated in the literature such as [10, 11]. In [10], a holistic design on D2D caching at
multi-frequency band including sub-6 GHz and millimeter wave (mmWave) was presented. In
[11], the performance difference between maximizing hit probability and maximizing cache-
aided throughput in D2D caching networks was evaluated. The work of [12] showed that
in multi-hop relaying systems, the efficiency of caching could be further improved by using
collaborative cache-enabled relaying. Joint design of cloud and edge caching in fog radio
access networks were introduced in [13, 14], where the popular contents were cached at
the remote radio heads. However, prior works [7–13] did not present design and insights
involving edge caching in the future dense/ultra-dense cellular networks (e.g., 5G) with
backhaul concerns, where wireless self-backhauling shall be supported [4].
Cache-enabled small cell networks with stochastic models have been investigated in the
literature such as [15–19]. Cluster-centric caching with base station (BS) cooperation was
studied in [15], where the tradeoff between transmission diversity and content diversity was
revealed. In [16], two cache-enabled BS modes were considered, i.e., always-on and dynamic
on-off, and it was assumed that the intensity of BSs is much larger than the intensity of
mobile terminals. The work of [17–19] concentrated on the cache-enabled multi-tier HetNets.
3
Specifically, [17] and [18] studied optimal content placement under probabilistic caching
strategy, and [19] considered the joint BS caching and cooperation, in contrast to the single-
tier case in [15]. However, [15–19] only aimed to maximize the probability that the requested
content is not only cached but also successfully delivered. In realistic networks, when users’
requested contents are not cached at their associated BSs, they will obtain their requested
contents from the core networks via wired/wireless backhaul, which also needs to be studied
in cache-enabled cellular networks.
In fact, existing contributions such as [20–22] have studied the effects of backhaul on
content delivery in cache-enabled networks. The work of [20] considered that non-cached
contents were obtained via backhaul, and designed a downlink content-centric sparse multicast
beamforming in the cache-enabled cloud radio access network (Cloud-RAN) architecture,
to minimize the weighted sum of backhaul cost and transmit power. In [21], the network
successful content delivery consisting of cached content delivery and backhauled content
delivery was studied, and the optimization problem was formulated to minimize the cache
size under quality-of-service constraint. The work of [22] analyzed the capacity scaling law
when there are limited number of wired backhaul in single-tier networks, and showed that
cache size needs to be large enough to achieve linear capacity scaling. However, none of
[20–22] has studied the cache-enabled cellular networks with specified wireless backhaul
transmission, such as massive multiple-input multiple-output (MIMO) aided self-backhaul.
B. Novelty and Contributions
In this paper, we focus on the edge caching in dense HetNets with massive MIMO aided
self-backhaul, which has not been understood yet. Considering massive MIMO aided self-
backhaul is motivated by the fact that it is challenging to let each backhaul link be fiber-optic
in such networks and massive MIMO can support high-speed transmissions thanks to large
array gains [4]. Our contributions are summarized as follows:
• In contrast to the prior works such as [15–22], we consider cache-enabled HetNets, in
which randomly located small BSs (SBSs) cache finite popular contents, and macro BSs
(MBSs) equipped with massive MIMO antennas provide wireless backhaul to deliver
the non-cached requested contents to the SBSs. Moreover, we also consider the resource
allocation when multiple users request the contents from the same SBS, which has not
been studied in a cache-enabled stochastic model.
• We first derive the successful content delivery probability when the requested content is
cached at the SBS. The maximum small cell load is calculated, and the minimum required
4
Marco base staion (MBS)
Small  base staion (SBS)
Cache
User equipment (UE)
Backhaul link
Access  link
Fig. 1. An illustration of cache-enabled heterogeneous cellular network with massive MIMO backhaul.
density of SBSs for avoiding access overload is obtained. We show that hit probability
needs to be lower than a certain value, to guarantee successful cached content delivery.
• We derive the successful content delivery probability when the requested content is not
cached and has to be obtained via massive MIMO backhaul. We analyze the massive
MIMO backhaul achievable rate when downlink channel estimation is not available,
to evaluate the backhaul time. The minimum required density of MBSs for avoiding
backhaul overload is obtained. We show that hit probability needs to be higher than a
certain value, to guarantee successful self-backhauled content delivery.
• We analyze the effects of cache size on the successful content delivery, and provide
important insights on the interplay between time-frequency resource allocation and cache
size from the perspective of successful content delivery probability. We characterize the
latency in terms of average delay in such networks, and confirm that when the requested
contents are not cached, the average delay of the non-cached content delivery could
be comparable to the cached content delivery with the assistance of massive MIMO
backhaul, if the average access rate of cached content delivery is lower than that of
self-backhauled content delivery.
II. NETWORK MODEL
As shown in Fig. 1, we consider a two-tier self-backhauled HetNet, in which each single-
antenna SBS with finite cache size can store popular contents to serve user equipment (UEs),
5
and each massive MIMO aided MBS equipped with N antennas accesses to the core networks
via optical fiber and delivers the non-cached contents to the SBSs via wireless backhaul. UEs,
SBSs, and MBSs are assumed to be distributed following independent homogeneous Poisson
point processes (HPPPs) denoted by ?U with the density ?U, ?S with the density ?S, and ?M
with the density ?M, respectively. It is assumed that UEs are associated with the SBSs that can
provide the maximum average received power, which is also utilized in 4G networks [6]. In
addition, each channel undergoes independent and identically distributed (i.i.d.) quasi-static
Rayleigh fading.
A. Content Placement
Content placement mechanism is mainly designed based on content popularity [4]. We
assume that there is a finite content library denoted as F := {f1, . . . , fj, . . . , fJ}, where fj
is the j-th most popular content and the number of contents is J . The request probability
for the j-th most popular content is commonly-modeled by following the Zipf distribution,
which is expressed as [23]
aj = j
??/
?J
m=1
m?? , (1)
where ? is the Zipf exponent to represent the popularity skewness [23]. Each content is
assumed to be unit size and each SBS can only cache L (L ? J) contents. We employ
the probabilistic caching strategy [7], i.e., the probability that the content j is cached at an
arbitrary SBS is qj(0 ? qj ? 1), and
J?
j=1
qj?L.
B. Self-backhaul Load
We assume that the access and backhaul links orthogonally share the sub-6 GHz spectrum,
and the bandwidths allocated to the access and backhaul links are ?W and (1? ?)W ,
respectively, where ? is the fraction factor and W is the system bandwidth. The number
of UEs that is associated with an SBS is denoted as K, and UEs in the same small cell are
time-dividedly served with equal-time sharing. Thus, the fraction of time-frequency resources
allocated to each access link is ?W/K during the cached content delivery. When an associated
SBS does not cache the requested content, it has to be connected to an MBS that provides the
strongest wireless backhaul link such that the requested content can be obtained from core
networks. Let Sj (N ? Sj) denote the number of SBSs served by the j-th MBS (j ? ?M)
for wireless backhaul.
6
Since the hit probability that UE’s requested content file is stored at an SBS is qhit =
J?
j=1
ajqj , the set of SBSs can be partitioned into two independent HPPPs ?
a
S and ?
b
S based
on the thinning theorem [24], where ?aS with the density ?Sqhit denotes the point process of
SBSs with access links, and ?bS with the density ?S (1? qhit) denotes the point process of
SBSs with backhaul links. Let ?b = ?S (1? qhit) /?M represent the average number of SBSs
served by an MBS for wireless backhaul.
C. Resource Allocation Model
We consider the saturated traffic condition, i.e., all the SBSs keep active to serve their
associated UEs.
1) Access: When the requested content is stored at a typical SBS, the rate for a typical
access link is given by
Ra =
?W
K
log2
(
1 +
PahoL (|Xo|)
?
i??aS\{o}
PahiL (|Xo,i|)
? ?? ?
Ia
+?2a
)
, (2)
where Ia denotes the total interference power from other SBSs, Pa is the SBS’s transmit
power, L (|X|) = ? (|X|)??a denotes the path loss with frequency dependent constant value
?, distance |X| and path loss exponent ?a, ho ? exp(1) and |Xo| are the small-scale fading
channel power gain and distance between the typical UE and its associated SBS respectively,
hi ? exp(1) and |Xo,i| are the small-scale fading interfering channel power gain and distance
between the typical UE and the interfering SBS i ? ?aS\ {o} (except the typical SBS o)
respectively, and ?2a is the noise power at the typical UE.
2) Self-Backhaul: When the requested content is not stored at SBSs, it is obtained through
massive MIMO backhaul. For massive MIMO backhaul link, we consider that massive MIMO
enabled MBS adopts zero-forcing beamforming with equal power allocation [25]. In such
a massive MIMO self-backhauled network, SBSs will not perform any channel estimation,
and we adopt an achievable backhaul transmission rate as confirmed in [26, 27]. Therefore,
given a typical distance |Yo| between the typical SBS and its associated MBS, the rate for a
typical massive MIMO backhaul link is given by
Rb = (1? ?)W log2 (1 + SINRb) (3)
7
with
SINRb =
Pb
So
(
E
{?
go
})2
L (|Yo|)
Pb
So
(?
go ? E
{?
go
})2
L (|Yo|) +
?
j??M\{o}
Pb
Sj
gjL (|Yo,j |)
? ?? ?
Ib
+?2b
,
where E {·} is the expectation operator, Ib denotes the total interference power from other
MBSs, Pb is the MBS’s transmit power, L (|Y |) = ? (|Y |)??b denotes the path loss with
the distance |Y | and path loss exponent ?b, go ? ? (N ? So + 1, 1) is the small-scale fading
channel power gain between the typical SBS and its associated MBS, gj ? ? (Sj, 1)1 and
|Yo,j | are the small-scale fading interfering channel power gain and distance between the
typical SBS and interfering MBS j, respectively, and ?2b is the noise power at the typical
SBS.
After obtaining the requested content via backhaul, the associated SBS delivers it to the
corresponding UE. In this case, the corresponding access-link rate is expressed as
Ra? =
(1? ?)W
K
×
log2
(
1 +
PahoL (|Xo|)
?
i
???bS\{o}
Pahi?L
(?
?Xo,i?
?
?
)
? ?? ?
I
a
?
+?2
a
?
)
, (4)
where Ia? is the total interference power, hi? ? exp(1) and L
(?
?Xo,i?
?
?
)
= ?
(?
?Xo,i?
?
?
)??a
are the small-scale fading channel power gain and pathloss between the typical SBS and
interfering SBS i
? ? ?bS\ {o}, respectively, and ?2a? is the noise power at the typical UE.
From (3) and (4), we see that to cut latency, massive MIMO backhaul link needs to be of
high-speed, which can be achieved by using large array gains and large bandwidths via carrier
aggregations (CA). In the following section, we will further examine how much backhaul
time is needed at an achievable backhaul rate.
III. CONTENT DELIVERY EFFICIENCY
In this paper, there are two cases for successful content delivery (SCD), i.e., 1) when the
associated BS has cached the requested content, SCD occurs if the time for successfully
delivering Q bits will not exceed the threshold Tth; and 2) when the requested content is not
cached at the associated BS and needs to be obtained via massive MIMO backhaul, SCD
occurs if the total time for successfully delivering Q bits to the UE is less than Tth.
1? (·, ·) is the upper incomplete gamma function [28, (8.350)].
8
A. Cached Content Delivery
Different from [15, 16, 18] where it is assumed that each small cell has only one active
UE, we evaluate SCD probability by considering multiple UEs served by an SBS in practice,
and analyze the effect of resource allocation on SCD probability. We first have the following
important theorem.
Theorem 1: When a requested content is stored at the typical SBS, the SCD probability
is derived as
?aSCD (Q, Tth) =
Kamax?
k=1
P?U
?S
(k) , (5)
where P?U
?S
(k) is the probability mass function (PMF) that there are other k?1 UEs (except
typical UE) served by the typical SBS, and is given by P?U
?S
(k) = ?
?
(k?1)!
?(k+?)
?(?)
(
?U
?S
)k?1
(
?+
?U
?S
)k+?
with ? = 3.5 [29]. In (5), K = Kamax is the maximum load in a typical small cell, and can
be quickly obtained by using Algorithm 1 to solve the following equation
2
KamaxQ
?WTth
+1 ? 2
?a ? 2
?ak (K
a
max) =
1? ?
qhit?
, (6)
where ?ak (K
a
max) = 2F1
[
1, 1? 2
?a
, 2? 2
?a
, 1? 2
KamaxQ
?WTth
]
, 2F1 [·, ·; ·; ·] is the Gauss hypergeo-
metric function [28, (9.142)], and ? is the predefined threshold, i.e., SCD occurs when the
probability that Ra is larger than
Q
Tth
is above ?.
Proof 1: See Appendix A.
It is implied from Theorem 1 that in the dense small cell networks (i.e., interference-
limited)2, the SCD probability depends on the ratio of UE density to SBS density and hit
probability given the time-frequency resource allocation. Based on Theorem 1, we have
Corollary 1: From (6), we see that to achieve the load K = Kamax ? 1 in a small cell, the
hit probability should satisfy
qhit ? min
{
?a
1? ?
?
, 1
}
, (7)
where ?a =
(
2
Q
?WTth
+1
?2
?a?2
?ak (1)
)?1
.
It is indicated from (7) that there is an upper-bound on the hit probability, which can be
explained by the fact that when more UEs can obtain their requested contents from their
associated SBSs in dense cellular networks with large hit probability, there will also be more
interference from nearby SBSs that degrades the cached content delivery.
2The near-field pathloss exponent is assumed to be larger than 2 [4].
9
Algorithm 1 One-dimension Search
1: if t = 0
2: Initialize ? = 1??
qhit?
, kl = 1, kh = 10× ?U
?S
, and calculate
F l = 2
klQ
?WTth
+1
?2
?a?2
2F1
[
1, 1? 2
?a
, 2? 2
?a
, 1? 2
klQ
?WTth
]
and
F h = 2
khQ
?WTth
+1
?2
?a?2
2F1
[
1, 1? 2
?a
, 2? 2
?a
, 1? 2
khQ
?WTth
]
3: else
4: While F l 6= ? and F h 6= ?
5: Let k = k
l+kh
2
, and compute Fk.
6: if Fk = ?
7: The optimal k? is obtained, i.e., Kamax = round (k
?).
8: break
9: elseif Fk < ?
10: kl = k.
11: else Fk > ?
12: kh = k.
13: end if
14: end while
15: end if
In realistic networks, there may be overload issues when the scale of small cells is not
adequate to support large level of connectivity, which needs to be addressed. Therefore, given
a specified scale of UEs ?U, we evaluate the minimum required scale of small cells as follows.
Corollary 2: To mitigate the harm of overloading, the minimum required SBS density
needs to satisfy
?S =
?
??
??
?U
Kamax+1
, if P?U
?S
=Kamax+1
(k = Kamax + 1) ? ?,
?U
µa
, if P?U
?S
=Kamax+1
(k = Kamax + 1) > ?,
(8)
where µa ?
(
0, K
a
max?
?+1
]
is the solution of P?U
?S
=µa
(k = Kamax + 1) = ? with arbitrary small
? > 0, and can be easily obtained via one-dimension search, similar to Algorithm 1. Such
network deployment given in (8) can guarantee P?U
?S
(k) ? ?, ?k > Kamax.
Proof 2: See Appendix B.
From (8), we see that the minimum required density of SBSs only depends on the maximum
load of a small cell and the density of UEs in dense cache-enabled cellular networks.
10
B. Self-backhauled Content Delivery
1) Massive MIMO Backhaul: When the required content is not stored at the typical SBS,
SBS has to obtain it from the core networks via massive MIMO backhaul. Therefore, we need
to evaluate the backhaul time for delivering the requested content to the typical SBS. Given
the load So in a typical macrocell, the achievable transmission rate for a typical backhaul
link is given by
Rb (So) = (1? ?)W
? ?
rb
Cb (y)
2??My exp (???My2)
exp (???Mr2b)
dy, (9)
where Cb (y) = log2
(
1 +
Pb
So
?1(y)
Pb
So
?2(y)+?3(y)+?2b
)
with ?1 (y) = L (y)
(
?(N?So+ 32)
?(N?So+1)
)2
, ?2 (y) =
(N ? So + 1)L (y) ? ?1, and ?3 (y) = Pb2??M? y
2??b
?b?2
, and rb is the minimum distance
between the typical MBS and its associated SBS. A detailed derivation of (9) is provided
in Appendix C. Therefore, the time for delivering Q bits to the typical SBS via wireless
backhaul is T1 =
Q
Rb
. When the number of antennas at the MBS grows large, we have the
following corollary.
Corollary 3: For large N , the achievable transmission rate for a typical backhaul link is
tightly lower-bounded as
R
Low
b (So) = (1? ?)W log2
(
1 + Pb?
N ? So + 12
So
e?1??2
)
, (10)
where ?
????????
???
????
?1 = ??be??Mr
2
b
(
? Ei
(
? r2b??M
)
2
+ e?r
2
b??M ln rb
)
,
?2 =
? ?
rb
ln
(
Pb?
2So
y?rb + Pb2??M?
y2??b
?b ? 2
+ ?2b
)
× 2??My
exp (???Mr2b)
exp
(
???My2
)
dy,
in which Ei (z) is the exponential integral given by Ei (z) = ?
??
?z
e?t
t
dt [28]. Based on
(10), the typical MBS’s required time for delivering Q bits to its associated SBS satisfies
T1 ?
Q(1? ?)?1W?1
log2
(
1 + Pb?
(N?So+ 12)
So
e?1??2
) . (11)
Proof 3: See Appendix D.
It is explicitly shown from Corollary 3 that large number of antennas and bandwidths are
required, in order to significantly cut the wireless backhaul time. From (11), we see that the
backhaul time can at least be cut proportionally to 1/ lnN .
In the self-backhauled networks, the number of SBSs being simultaneously served by
an MBS for wireless backhaul should not exceed the maximum value denoted by Smax,
11
i.e., So ? Smax; otherwise high-speed massive MIMO aided backhaul transmission cannot
be guaranteed. Hence, given the minimum required backhaul transmission rate Rminb , the
maximum backhaul load of a typical massive MIMO MBS is the solution of Rb (Smax) =
Rminb , which can be quickly obtained by using one-dimension search since Rb (So) is a
decreasing function of So for large N , as suggested in Appendix D. After obtaining Smax,
we can obtain the minimum number of massive MIMO aided MBSs that needs to be deployed,
in order to mitigate the backhaul overload.
Corollary 4: Similar to Corollary 2, the minimum required density of MBSs is given by
?M =
?
?
?
?S(1?qhit)
Smax+1
, if P?b=Smax+1 (? = Smax + 1) ? ?,
?S(1?qhit)
µb
, if P?b=Smax+1 (? = Smax + 1) > ?,
(12)
where P?b (?) = ?
?
(??1)!
?(?+?)
?(?)
(?b)
??1
(?+?b)
?+? , µb ?
(
0, Smax?
?+1
]
is the solution of P?b=µb (? = Smax + 1) =
? with arbitrary small ? > 0, and can be easily obtained via one-dimension search.
It is explicitly shown in (12) that higher hit probability can significantly reduce the scale
of MBSs because of less backhaul.
2) Access: After obtaining the required content via backhaul, the typical SBS transmits it
to the associated UE. Thus, we have the following important theorem.
Theorem 2: When the required content is not stored at the typical SBS and has to be
obtained via massive MIMO self-backhaul, the SCD probability is derived as
?bSCD (Q, Tth) =
Kbmax?
k=1
P?U
?S
(k) , (13)
where Kbmax is the maximum number of UEs that a typical small cell can serve when the
typical UE’s content needs to be attained via backhaul, and Kbmax can be obtained by solving
the following equation3
2
KbmaxQ
(1??)W(Tth?T1)
+1 ? 2
?a ? 2
?bk
(
Kbmax
)
=
1? ?
(1? qhit) ?
(14)
with ?bk
(
Kbmax
)
= 2F1
[
1, ?a?2
?a
, 2?a?2
?a
, 1? 2
KbmaxQ
(1??)W(Tth?T1)
]
, and the minimum required SBS
density for mitigating overload is given from (8) by interchanging Kamax ? Kbmax.
Proof 4: See Appendix E.
It is indicated from (14) that when a typical UE’s requested content is not stored at the
typical SBS, the number of UEs that can be served by the typical SBS decreases with
increasing backhaul time. Based on Theorem 2, we have the following corollary
3It can be solved by following Algorithm 1.
12
Corollary 5: From (14), we see that to achieve the load K = Kbmax ? 1 in a small cell,
the hit probability should satisfy
qhit ?
[
1? ?b
1? ?
?
]+
, (15)
where ?b =
(
2
Q
(1??)W(Tth?T1)
+1
?2
?a?2
?bk (1)
)?1
, and [x]+ = max {x, 0}.
From (15), we see that there is a lower-bound on the hit probability, i.e., minimum cache
capacity is demanded at the SBS, since more backhaul results in more interference, which
will degrade the self-backhauled content delivery.
Corollary 6: After obtaining the maximum load Kbmax, we can calculate the minimum
required SBS density given from (8) by interchanging Kamax ? Kbmax, to overcome overload.
Based on Theorem 1 and Theorem 2, the SCD probability in dense cellular networks
with massive MIMO self-backhaul for a typical UE is calculated as
?SCD (Q, Tth) = qhit?
a
SCD (Q, Tth) + (1? qhit)?bSCD (Q, Tth)
=
?
????
????
???????
?
Kbmax?
k=1
P?U
?S
(k) + qhit
Kamax?
k=Kbmax+1
P?U
?S
(k) , Kamax ? Kbmax,
Kamax?
k=1
P?U
?S
(k) + (1? qhit)
×
Kbmax?
k=Kamax+1
P?U
?S
(k) , Kamax < K
b
max,
(16)
where Kamax and K
b
max are given by (6) and (14), respectively.
The SCD probability given in (16) can be intuitively understood based on the fact that
when the small cell load is light, UEs’ requested contents can be successfully delivered
whether they are cached or obtained from the core networks via massive MIMO backhaul.
However, after a critical value of cell load, UEs can only obtain their requested contents that
are cached by the SBSs or via backhaul, which depends on the maximum cell load in cached
content delivery and self-backhauled content delivery cases.
IV. CONTENT PLACEMENT, CACHE SIZE AND LATENCY
In this section, we study the effects of content placement and cache size on the content
delivery performance. Then, we evaluate the latency in such networks.
A. Content Placement and Cache Size
As shown in (16), hit probability plays an important role in content delivery. Since hit
probability depends on the cache size and content placement, SBSs with large storage capacity
13
can cache more popular contents, to avoid frequent backhaul and cut backhaul cost and
latency. Therefore, higher hit probability is meaningful to cut the network’s operational
and capital expenditures (OPEX, CAPEX). Given the SBS’s cache size, different content
placement strategies may result in various hit probability, and caching the most popular
contents (MPC) can achieve the highest hit probability, which is commonly-considered in
the literature involving edge caching such as [13, 30]. Therefore, we consider MPC caching
and analyze the appropriate cache size in such networks. Considering the fact that for large
J with MPC caching, qhit =
?L
j=1 aj ?
(
L
J
)1??
, we have
Corollary 7: Given Tth?T1
Tth
? ?
1??
(i.e., more time-frequency resources are allocated to the
cached content delivery), the SCD probability is
?SCD (Q, Tth) =
Kbmax?
k=1
P?U
?S
(k) , (17)
and it is an increasing function of the cache size, if the cache size L ?
[
J
([
1? ?b 1???
]+
) 1
1??
, J
(
1
2
) 1
1??
]
and the minimum SBS density satisfies the condition given in Corollary 6; Given Tth?T1
Tth
>
?
1??
, the SCD probability is
?SCD (Q, Tth) =
Kamax?
k=1
P?U
?S
(k) , (18)
if L ?
[
J
(
1
2
) 1
1?? ,
(
min
{
?a
1??
?
, 1
}) 1
1??
]
, and the minimum SBS density satisfies the condi-
tion given in Corollary 4.
Proof 5: See Appendix F.
The above corollary provides some important insights into the interplay between time-
frequency resource allocation and cache size in cache-enabled dense cellular networks with
massive MIMO backhaul, which plays a key role in the content delivery performance.
B. Latency
To evaluate the latency in such networks, we consider the average delay for successfully
obtaining the requested content in such networks. It should be noted that when the small
cells are overloaded, UEs may suffer longer delay. There are many approaches to solve the
overload issue such as deploying enough small cells following the rule of Corollary 2 and
Corollary 6 or advanced multi-antenna techniques. Moreover, it may be more lightly loaded
in realistic small cell networks [31]. For tractability, we assume that the load of a small
14
cell will not exceed its maximum load Kmax. As suggested in [32], the average delay for
requesting a content from a typical small cell can be expressed as
D =
Kmax?
k=1
P?U
?S
(k)
(
qhit
Q
E {Ra}
+ (1? qhit)
(
T1 +
Q
E {Ra?}
))
, (19)
where T1 is the massive MIMO backhaul time detailed in Section III-B, and E {Ra} and
E {Ra?} are the average access rate of the cached and self-backhauled content delivery,
respectively, which are given by
?
?
?
E {Ra} =
??
0
? (x, qhit, ?)dx,
E {Ra?} =
??
0
? (x, 1? qhit, 1? ?)dx,
(20)
where ? (x, ?1, ?2) =
(
1 + ?1
2
kx
?2W
+1
?2
?a?2
? (k)
)?1
with ? (k) = 2F1
[
1, 1? 2
?a
, 2? 2
?a
, 1? 2
kx
?2W
]
is the complementary cumulative distribution function of the Ra or Ra? , respectively, which
is obtained by using the approach in Appendix A.
Given the hit probability, i.e., the cache size is fixed, the spectrum fraction ? = ?o for
meeting E {Ra} = E {Ra?} can be easily obtained by using one-dimension search, considering
the fact that E {Ra} ? E {Ra?} is an increasing function of ?.
Corollary 8: When ? < ?o, the average delay of self-backhauled content delivery could
be lower than cached content delivery if massive MIMO antennas meet
N ?
(
2?(?o) ? 1
Pb?e??1???2
+ 1
)
So ?
1
2
(21)
with ? (?o) =
(1??o)
?1W?1E{Ra}E{R
a
?}
E{R
a
?}?E{Ra} , for a specified typical backhaul load So.
The proof of Corollary 8 can be easily obtained by considering T1 ? QE{Ra} ?
Q
E{R
a
?} for
? < ?o and Corollary 3. It is implied from Corollary 8 that for the case of requesting non-
cached contents, the average delay of the non-cached content delivery via massive MIMO
backhaul could be comparable to the cached content delivery, if the average access rate of
cached content delivery is lower than that of self-backhauled content delivery.
V. SIMULATION RESULTS
In this section, simulation results are presented to validate the prior analysis and further
shed light on the effects of key system parameters including cell load, cache size, BS density,
and massive MIMO antennas on the performance. The basic simulation parameters are shown
in Table I.
15
TABLE I
SIMULATION PARAMETERS
Parameter Symbol Value
Pathloss exponent to UE ?a 3.0
Pathloss exponent to SBS ?b 2.6
Transmit power of MBS Pb 46 dBm
Transmit power of SBS Pa 30 dBm
Carrier frequency fc 3.5 GHz
Frequency dependent constant value ?
(
3×108
4?fc
)2
System bandwidth W 100 MHz
Noise power ?2a , ?
2
b, ?
2
a
? ?174+10× log10(Bandwidth)
dBm
Content library size J 105
Zipf exponent ? 0.7
A. Cached Content Delivery
In this subsection, we illustrate the cell load, SCD probability, and minimum required SBS
density when the requested content is cached at the associated SBS.
1 2 4 6 7 8 9 10 12 14 16 18 20
Number of UEs served in a small cell
0.84
0.86
0.88
0.9
0.92
0.94
0.96
0.98
1
C
C
D
F 
( P
r(
R
a
>Q
/T
th
)
Monte Carlo Simulation
Analytical
K
a
max=2, ?=0.98
K
a
max=4, ?=0.96
K
a
max=7, ?=0.94
K
a
max=12, ?=0.90
K
a
max=9, ?=0.92
Fig. 2. The complementary cumulative distribution function (CCDF) of the Ra:
Q
Tth
= 1 Mbps, ?U = 3 × 10
?4 m?2,
?S = 10
?4 m?2, ? = 0.5, and Cache Size= 3× 103.
Fig. 2 shows the complementary cumulative distribution function (CCDF) of the rate Ra
16
for different number of UEs served in a small cell. The analytical maximum cell load Kamax
for different CCDF thresholds are obtained from (6), which has a precise match with the
Monte Carlo simulations. The CCDF is a decreasing function of number of UEs served in a
small cell, since resources allocated to each UE become less when serving more UEs.
Fig. 3 shows the SCD probability when the requested content is cached at the associated
SBS, based on Theorem 1 and Fig. 2. We see that for fixed cache size, the SCD probability
decreases when the system requires higher SCD threshold ?, since higher ? reduces the level of
maximum allowable cell load, as suggested in Fig. 2. Moreover, given ?, the SCD probability
decreases with increasing the cache size. The reason is that hit probability increases with
increasing the cache size, i.e., UEs are more likely to obtain the requested contents cached
by their associated SBSs, which results in more interference at the same frequency band and
reduces the maximum allowable cell load.
0.9 0.92 0.94 0.96 0.98 1
SCD Threshold (?)
0
0.2
0.4
0.6
0.8
1
S
C
D
 p
ro
ba
bi
lit
y
Cache Size=3×103
Cache Size=6×103
Fig. 3. The SCD probability: Q
Tth
= 1 Mbps, ?U = 3× 10
?4 m?2, ?S = 10
?4 m?2, and ? = 0.5.
Fig. 4 shows the minimum required SBS density to avoid the overload issue given the UE
density ?U. Without loss of generality, we assume that the maximum allowable load of a
small cell is Kamax = 5 in this figure (Note that for specified system performance requirement,
the maximum small cell load is obtained from (6), as illustrated in Fig. 2.). The numerical
result has a precise match with the analysis shown in Corollary 2. We see that when the
probability that more than Kamax UEs need to be served in a small cell is not larger than
17
0 1 2 3 4 5 6 7
?
U
/?
S
0
0.01
0.02
0.04
0.06
0.08
0.1
0.12
P
ro
ba
bi
lit
y 
m
as
s 
fu
nc
tio
n
Numerical
Analytical, Corollary 2
?=0.01, ?U/?S=0.8744
?=0.05, ?U/?S=1.6377
?=0.1, ?U/?S=K
a
max+1
?U/?S=K
a
max? / (?+1)
Fig. 4. The minimum required SBS density for avoiding overloading.
? = 0.1, the minimum required SBS density satisfies ?U
?S
= Kamax + 1 = 6, as confirmed in
(8). When the system requires lower ? = 0.1 (i.e., lower overload probability.), the density
ratio ?U
?S
in such networks decreases, which means that more SBSs need to be deployed.
B. Massive MIMO Backhaul Transmission
In this subsection, we focus on the massive MIMO backhaul achievable rate, which
determines the amount of backhaul time when an SBS obtains the requested content from its
associated MBS. Note that the macrocell load and minimum required MBS density have been
studied in Section III-B, which are similar to Theorem 1 and Corollary 2, and numerical
results can be easily obtained by following Figs. 2 and 4.
Fig. 5 shows the backhaul achievable rate for different macrocell load and massive MIMO
antennas. The analytical exact and lower-bound curves are obtained from (9) and (10),
respectively, which tightly matches with the simulated exact curves. We see that the back-
haul achievable rate decreases when macrocell load increases, since each SBS will obtain
less transmit power and array gains. Adding more massive MIMO antennas improves the
achievable rate because of larger array gains.
18
1 3 5 7 9 10
Number of SBSs served in a macrocell
1
1.5
2
2.5
3
3.5
B
ac
kh
au
l a
ch
ie
va
bl
e 
ra
te
 (
bp
s)
×108
Monte Carlo Simulation, Eaxct
Analytical, Exact
Analytical, Lower Bound
N=256
N=128
Fig. 5. Backhaul achievable rate: ?M = 10
?5 m?2, ? = 0.5 and rb = 5 m.
C. Latency
In this subsection, we evaluate the average delay in two scenarios, i.e., 1) the requested
content is cached at the associated SBS; and 2) the requested content is not cached and needs
to be obtained via massive MIMO backhaul.
Fig. 6 shows the average delay for different cache size. The analytical curves are obtained
based on the average rate given by (20). We see that the average delay for cached content
delivery is lower than self-backhualed content delivery. The average delay for cached content
delivery increases with increasing the cache size. In contrast, the average delay for self-
backhauled content delivery decreases with increasing the cache size. The reason is that
larger cache size results in higher hit probability, and more SBSs can provide cached content
delivery, which results in more inter-SBS interference over the frequency band allocated to
the cached content delivery, and less inter-SBS interference over the frequency band allocated
to the self-backhauled content delivery. In addition, the backhaul time T1 is much lower than
the access when using massive MIMO backhaul.
VI. CONCLUSION
In this paper, we have studied the content delivery in cache-enabled HetNets with massive
MIMO backhaul. We derived the successful content delivery probability involving cached
19
1000 2000 3000 4000 5000 6000 7000 8000
Cache size
40
45
50
55
60
65
70
A
ve
ra
ge
 d
el
ay
 (
s)
Monte Carlo Simulation
Analytical, Cached Content Delivery
Analytical, Self-backhauled Content Delivery
T1=6.1976 s
Fig. 6. Average delay: Q = 1 Gbit, ?U = 3 × 10
?4 m?2, ?S = 10
?4 m?2, ?M = 10
?5 m?2, N = 128, So = 10,
K = 5, ? = 0.45, and rb = 5 m.
content delivery and non-cached content delivery via massive MIMO backhaul in such
networks. We addressed the effects of hit probability, UE and SBS densities on the perfor-
mance. Particularly, we provided the minimum required SBS and MBS densities for avoiding
overloading. We demonstrated that hit probability needs to be properly determined, in order
to achieve successful content delivery. We showed the interplay between cache size and time-
frequency resource allocations from the perspective of successful content delivery probability.
We characterized the latency in terms of average delay in this networks, and showed that
when UEs request non-cached contents, the average delay of the non-cached content delivery
could be comparable to the cached content delivery with the help of massive MIMO aided
self-backhaul in some cases.
20
APPENDIX A: PROOF OF THEOREM 1
Based on (2), SCD probability is calculated as
?aSCD (Q, Tth) = Pr
(
Ra ?
Q
Tth
)
= EK
{
Pr
(
Ra ?
Q
Tth
|K = k
)
? ?? ?
?(k)
}
=
?
k=1
P?U
?S
(k) ? (k) , (A.1)
where P?U
?S
(k) is the probability mass function (PMF) of the number of other k ? 1 UEs
(except typical UE) served by the typical SBS, and ?ak is the conditional SCD probability
given K = k. According to [33], P?U
?S
(k) can be calculated as
P?U
?S
(k) =
??
(k ? 1)!
? (k + ?)
? (?)
(
?U
?S
)k?1
(
? + ?U
?S
)k+?
, (A.2)
where ? = 3.5 [29]. Given K = k, ? (k) is calculated as
? (k) = Pr
(
Ra ?
Q
Tth
)
= E|Xo|
{
Pr
(
PahoL (|Xo|)
Ia + ?2a
?2
kQ
?WTth ? 1
)}
=
? ?
0
Pr
(
PahoL (x)
Ia + ?2a
?2
kQ
?WTth ? 1
)
? ?? ?
?1(x)
f|Xo| (x) dx, (A.3)
where f|Xo| (x) = 2??Sx exp (???Sx2) is the probability density function (PDF) of the
distance between the typical UE and its associated SBS, and ?1 (x) is the conditional SCD
probability given K = k and |Xo| = x. Considering the fact that dense cellular network is
interference-limited in practice, the effect of noise power on the performance is negligible.
As such, we can evaluate ?1 (x) as
?1 (x) = E?aS
{
exp
(
?2
kQ
?WTth ? 1
PaL (x)
Ia
)}
(a)
= exp
?
??2??Sqhit
? ?
x
(
2
kQ
?WTth ? 1
)
x?ar1??a
1 +
(
2
kQ
?WTth ? 1
)
x?ar??a
dr
?
?
= exp
(
? 2??Sqhit
x2
?a ? 2
(
2
kQ
?WTth ? 1
)
×
2F1
[
1, 1? 2
?a
, 2? 2
?a
, 1? 2
kQ
?WTth
])
(A.4)
21
where step (a) is obtained by using the generating functional of the PPP [34]. By substituting
(A.4) into (A.3), ? (k) can be derived in closed-form as
? (k) =
1
1 + qhit
2
kQ
?WTth
+1
?2
?a?2
?ak (k)
, (A.5)
where ?ak (k) = 2F1
[
1, 1? 2
?a
, 2? 2
?a
, 1? 2
kQ
?WTth
]
. Based on (A.5), the maximum load Kamax
of a typical small cell is given by
? (k)|k=Kamax = ?, (A.6)
where ? is the threshold that SCD occurs when ? (k) ? ?. Although the closed-form solution
with respect to (w.r.t.) k = Kamax of (A.6) is unfeasible, it can be quickly obtained by using
one-dimension search as detailed in Algorithm 1 due to the fact that ? (k) is a decreasing
function of k. The SCD probability in (A.1) is rewritten as
?aSCD (Q, Tth) =
Kamax?
k=1
P?U
?S
(k), (A.7)
where P?U
?S
(k) and Kamax are defined by (A.2) and (A.6), respectively, and the proof of
Theorem 1 is completed.
APPENDIX B: PROOF OF COROLLARY 2
After obtaining Kamax, we can find out how many small cells are sufficient to serve a
specified scale of UEs ?U, since serving larger than K
a
max UEs in a small cell cannot achieve
SCD. Assuming that P?U
?S
(k = Kamax + 1) = ? with arbitrary small ? > 0, we need to
guarantee P?U
?S
(k) ? ?, ?k > Kamax, in order to avoid content delivery failure resulting from
overloading. Let
P?U
?S
(k + 1)
P?U
?S
(k)
=
(
1 +
?
k
) ?U
?S
? + ?U
?S
? 1, k ? Kamax + 1. (B.1)
We can intuitively interpret (B.1) based on the fact that given the maximum load Kamax, the
probability that serving more than Kamax UEs should be lower when adding more UEs. From
(B.1), we get ?U
?S
? Kamax + 1 such that P?U
?S
(k) ? ?, ?k > Kamax. Then, we need to solve
P?U
?S
(k = Kamax + 1) = ? w.r.t.
?U
?S
under the constraint ?U
?S
? Kamax+1. The first-order partial
derivative of P?U
?S
(k) w.r.t. ?U
?S
is
?P?U
?S
(k)
? ?U
?S
=
??? (k + ?)
(k ? 1)!? (?)
(
?U
?S
)k?2(
? +
?U
?S
)?(k+?+1)
×
(
(k ? 1) ? ? (? + 1) ?U
?S
)
. (B.2)
22
From (B.2), we see that for k = Kamax + 1,
?P?U
?S
?
?U
?S
? 0 as ?U
?S
?
(
0, K
a
max?
?+1
]
, and
?P?U
?S
?
?U
?S
< 0 as
?U
?S
?
(
Kamax?
?+1
, Kamax + 1
]
. Therefore, the minimum required density of SBSs satisfies
?U
?S
=
?
??
??
(Kamax + 1) , if P?U
?S
=Kamax+1
(k = Kamax + 1) ? ?,
µa, if P?U
?S
=Kamax+1
(k = Kamax + 1) > ?,
(B.3)
where µa ?
(
0, K
a
max?
?+1
]
is the solution of P?U
?S
=µa
(k = Kamax + 1) = ?, and can be easily
obtained by using one-dimension search approach, since P?U
?S
=µa
(k = Kamax + 1) is an in-
creasing function of µa as µa ?
(
0, K
a
max?
?+1
]
. Thus, we obtain the minimum required SBS
density, in order to avoid overloading.
APPENDIX C: DETAILED DERIVATION OF (9)
Since the typical SBS is associated with the nearest MBS, the PDF of the typical commu-
nication distance is
f|Yo| (y) =
2??My
exp (???Mr2b)
exp
(
???My2
)
, y ? rb, (C.1)
where rb is the minimum distance between the typical MBS and its associated SBS. According
to (3) and [26, 27], the achievable transmission rate can be written as
Rb = (1? ?)WE|Yo|
{
log2
(
1 +
Pb
So
?1
Pb
So
?2 + ?3 + ?2b
)}
= (1? ?)W
? ?
rb
Cb (y) f|Yo| (y)dy, (C.2)
where Cb (y) = log2
(
1 +
Pb
So
?1(y)
Pb
So
?2(y)+?3(y)+?2b
)
with ?1(y) = L (y)
(
E
{?
go
})2
, ?2 (y) =
L (y) var
{?
go
}
,4 and ?3 (y) = E|Yo|=y {Ib}.
We first calculate ?1 as
?1 (y) = L (y)
(? ?
0
?
x
xN?Soe?x
? (N ? So + 1)
dx
)2
= L (y)
(
?
(
N ? So + 32
)
? (N ? So + 1)
)2
. (C.3)
Then, ?2 is given by
?2 (y) = L (y)E {go} ? ?1 = (N ? S + 1)L (y)? ?1. (C.4)
4var {·} is the variance operator.
23
By using the Campbell’s theorem [24], ?3 is obtained as
?3 (y) =
Pb
Sj
E {gj} 2??M?
? ?
y
t1??bdt
= Pb2??M?
y2??b
?b ? 2
. (C.5)
By substituting (C.3), (C.4) and (C.5) into (C.2), we obtain (9).
APPENDIX D: PROOF OF COROLLARY 3
According to the Stirling’s formula, i.e., ? (x+ 1) ?
(
x
e
)x?
2?x as x ? ?, we have
?1 (y) ? L (y)
?
?
?
(
N?So+
1
2
e
)N?So+
1
2
?
2?
(
N ? So + 12
)
(
N?S
e
)N?So
?
2? (N ? So)
?
?
?
2
? L (y) N ? So +
1
2
e
(
1 +
1
2 (N ? So)
)2(N?So)
(a)
?
(
N ? So +
1
2
)
L (y) , (D.1)
when the number of antennas at the MBS grows large. Note that step (a) is obtained by the
fact that
(
1 + 1
x
)x ? e as x ? ?. Thus, ?2 (y) = L(y)2 . By using Jensen’s inequality [35],
we derive a tight lower-bound on the achievable transmission rate (C.2) as
R
Low
b = (1? ?)W log2
(
1 +
Pb
So
e?1??2
)
, (D.2)
where ?
??
??
?1 = E|Yo| {ln ?1} ,
?2 = E|Yo|
{
ln
(
Pb
So
?2 + ?3 + ?
2
b
)}
.
(D.3)
For large N , based on (D.1), ?1 can be asymptotically derived as
?1 ? ln
(
N ? So +
1
2
)
+ E {lnL (y)}
= ln
(
N ? So +
1
2
)
+ ln (?)
? ?b
exp (???Mr2b)
(
? Ei
(
? r2b??M
)
2
+ e?r
2
b??M ln rb
)
? ?? ?
?1
, (D.4)
24
where Ei (z) is the exponential integral given by Ei (z) = ?
??
?z
e?t
t
dt. Then, ?2 can be
asymptotically calculated as
?2 =
? ?
rb
ln
(
Pb
So
?2 (y) + ?3 (y) + ?
2
b
)
f|Yo| (y) dy
?
? ?
rb
ln
(
Pb?
2So
y?rb + Pb2??M?
y2??b
?b ? 2
+ ?2b
)
× 2??My
exp (???Mr2b)
exp
(
???My2
)
dy
? ?? ?
?2
. (D.5)
Considering the fact that T1 =
Q
Rb
? Q
R
Low
b
, we obtain T1 ? Q(1??)W
(
log2
(
1 +
Pb?(N?So+ 12)
So
e?1??2
))?1
,
which confirms the Corollary 3.
APPENDIX E: PROOF OF THEOREM 2
Based on (4), SCD probability is given by
?bSCD (Q, Tth) = Pr
(
Ra? >
Q
Tth ? T1
)
=
?
k?1
P?U
?S
(k) ?bk, (E.1)
where P?U
?S
(k) is given by (A.2), and ?bk is the conditional SCD probability given K = k.
Similar to (A.3), ?bk is calculated as
?bk = Pr
(
Pa?hoL (|Xo|)
Ia? + ?
2
a?
>2
kQ
(1??)W(Tth?T1) ? 1
)
=
1
1 + (1? qhit) 2
kQ
(1??)W(Tth?T1)
+1
?2
?a?2
?bk
, (E.2)
where ?bk = 2F1
[
1, 1? 2
?a
, 2? 2
?a
, 1? 2
kQ
(1??)W(Tth?T1)
]
. Like (A.6), the maximum load Kbmax
of a typical small cell is the solution of ? (k)|k=Kbmax = ?. Then, the SCD probability is
obtained as (13).
APPENDIX F: PROOF OF COROLLARY 7
Based on (6) and (14), we see that Kamax ? Kbmax if Tth?T1Tth ?
?
1??
and qhit ? 12 . In this case,
the SCD probability in (16) reduces to (17), and the corresponding cache size is obtained by
considering Corollary 5 and qhit ? 12 . Likewise, Kamax > Kbmax if
Tth?T1
Tth
> ?
1??
and qhit >
1
2
,
and we can obtain (18) accordingly.
25
REFERENCES
[1] Cisco, “Cisco visual networking index: Global mobile data traffic forecast update, 2016–2021 white paper,” 2017.
[2] G. Paschos, E. Bastug, I. Land, G. Caire, and M. Debbah, “Wireless caching: technical misconceptions and business
barriers,” IEEE Commun. Mag., vol. 54, no. 8, pp. 16–22, Aug. 2016.
[3] W. Han, A. Liu, and V. K. N. Lau, “PHY-caching in 5G wireless networks: design and analysis,” IEEE Commun.
Mag., vol. 54, no. 8, pp. 30–36, Aug. 2016.
[4] L. Wang, K.-K. Wong, S. Jin, G. Zheng, and R. W. Heath Jr., “A new look at physical layer security, caching, and
wireless energy harvesting for heterogeneous ultra-dense networks,” arXiv preprint arXiv:1705.09647, May 2017.
[5] 3GPP TS 22.261:“Service requirements for the 5G system,” Mar. 2017.
[6] D. Liu, L. Wang, Y. Chen, M. Elkashlan, K. K. Wong, R. Schober, and L. Hanzo, “User association in 5G networks:
A survey and an outlook,” IEEE Commun. Surveys & Tutorials, vol. 18, no. 2, pp. 1018–1044, Second Quarter 2016.
[7] B. Blaszczyszyn and A. Giovanidis, “Optimal geographic caching in cellular networks,” in IEEE Int. Conf. Commun.
(ICC), 2015, pp. 3358–3363.
[8] B. Zhou, Y. Cui, and M. Tao, “Stochastic content-centric multicast scheduling for cache-enabled heterogeneous cellular
networks,” IEEE Trans. Wireless Commun., vol. 15, no. 9, pp. 6284–6297, Sept. 2016.
[9] X. Li, X. Wang, K. Li, Z. Han, and V. C. Leung, “Collaborative multi-tier caching in heterogeneous networks:
Modeling, analysis, and design,” IEEE Trans. Wireless Commun., Early Access Articles, 2017.
[10] M. Ji, G. Caire, and A. F. Molisch, “Wireless device-to-device caching networks: Basic principles and system
performance,” IEEE J. Sel. Areas Commun., vol. 34, no. 1, pp. 176–189, Jan. 2016.
[11] Z. Chen, N. Pappas, and M. Kountouris, “Probabilistic caching in wireless D2D networks: Cache hit optimal versus
throughput optimal,” IEEE Commun. Lett., vol. 21, no. 3, pp. 584–587, Mar. 2017.
[12] G. Zheng, H. A. Suraweera, and I. Krikidis, “Optimization of hybrid cache placement for collaborative relaying,”
IEEE Commun. Lett., vol. 21, no. 2, pp. 442–445, Feb. 2017.
[13] S. H. Park, O. Simeone, and S. S. Shitz, “Joint optimization of cloud and edge processing for fog radio access
networks,” IEEE Trans. Wireless Commun., vol. 15, no. 11, pp. 7621–7632, Nov. 2016.
[14] H. Zhang, Y. Qiu, X. Chu, K. Long, and V. C. Leung, “Fog radio access networks: Mobility management, interference
mitigation, and resource optimization,” arXiv preprint arXiv:1707.06892, July 2017.
[15] Z. Chen, J. Lee, T. Q. S. Quek, and M. Kountouris, “Cooperative caching and transmission design in cluster-centric
small cell networks,” IEEE Trans. Wireless Commun., vol. 16, no. 5, pp. 3401–3415, May 2017.
[16] Y. Chen, M. Ding, J. Li, Z. Lin, G. Mao, and L. Hanzo, “Probabilistic small-cell caching: Performance analysis and
optimization,” IEEE Trans. Veh. Technol., vol. 66, no. 5, pp. 4341–4354, May 2017.
[17] K. Li, C. Yang, Z. Chen, and M. Tao, “Optimization and analysis of probabilistic caching in n-tier heterogeneous
networks,” arXiv preprint arXiv:1612.04030, Dec. 2016.
[18] J. Wen, K. Huang, S. Yang, and V. O. K. Li, “Cache-enabled heterogeneous cellular networks: Optimal tier-level
content placement,” IEEE Trans. Wireless Commun., Early Access Articles 2017.
[19] W. Wen, Y. Cui, F. chun Zheng, S. Jin, and Y. Jiang, “Random caching based cooperative transmission in heterogeneous
wirelesss networks,” arXiv preprint arXiv:1701.05761, Jan. 2017.
[20] M. Tao, E. Chen, H. Zhou, and W. Yu, “Content-centric sparse multicast beamforming for cache-enabled cloud ran,”
IEEE Trans. Wireless Commun., vol. 15, no. 9, pp. 6118–6131, Sept. 2016.
[21] X. Peng, J. Zhang, S. H. Song, and K. B. Letaief, “Cache size allocation in backhaul limited wireless networks,” in
IEEE Int. Conf. Commun. (ICC), 2016, pp. 1–6.
[22] A. Liu and V. K. N. Lau, “How much cache is needed to achieve linear capacity scaling in backhaul-limited dense
wireless networks?” IEEE/ACM Trans. Netw., vol. 25, no. 1, pp. 179–188, Feb. 2017.
26
[23] L. Breslau, P. Cao, L. Fan, G. Phillips, and S. Shenker, “Web caching and zipf-like distributions: evidence and
implications,” in Proc. IEEE INFOCOM, 1999, pp. 126-134.
[24] F. Baccelli and B. Blaszczyszyn, Stochastic Geometry and Wireless Networks, Volume I: Theory. Now Publishers
Inc. Hanover, MA, USA, 2009.
[25] K. Hosseini, W. Yu, and R. S. Adve, “Large-scale MIMO versus network MIMO for multicell interference mitigation,”
IEEE J. Sel. Topics Signal Process., vol. 8, no. 5, pp. 930–941, Oct. 2014.
[26] J. Jose, A. Ashikhmin, T. L. Marzetta, and S. Vishwanath, “Pilot contamination and precoding in multi-cell TDD
systems,” IEEE Trans. Wireless Commun., vol. 10, no. 8, pp. 2640–2651, Aug. 2011.
[27] J. Hoydis, S. ten Brink, and M. Debbah, “Massive MIMO in the UL/DL of cellular networks: How many antennas
do we need?” IEEE J. Sel. Areas Commun., vol. 31, no. 2, pp. 160–171, Feb. 2013.
[28] I. S. Gradshteyn and I. M. Ryzhik, Table of Integrals, Series and Products, 7th ed. San Diego, C.A.: Academic
Press, 2007.
[29] J.-S. Ferenc and Z. Ne?da, “On the size distribution of poisson voronoi cells,” Physica A: Statistical Mechanics and
its Applications, vol. 385, no. 2, pp. 518–526, Nov. 2007.
[30] E. Bastug, M. Bennis, and M. Debbah, “Living on the edge: The role of proactive caching in 5G wireless networks,”
IEEE Commun. Mag., vol. 52, no. 8, pp. 82–89, Aug. 2014.
[31] J. G. Andrews, S. Buzzi, W. Choi, S. Hanly, A. Lozano, A. Soong, and J. Zhang, “What will 5G be?” IEEE J. Sel.
Areas Commun., vol. 32, no. 6, pp. 1065–1082, June 2014.
[32] J. Liu, B. Bai, J. Zhang, and K. B. Letaief, “Cache placement in Fog-RANs: From centralized to distributed algorithms,”
IEEE Trans. Wireless Commun., Early Access Articles 2017.
[33] S. Singh, H. S. Dhillon, and J. G. Andrews, “Offloading in heterogeneous networks: Modeling, analysis, and design
insights,” IEEE Trans. Wireless Commun., vol. 12, no. 5, pp. 2484–2497, May 2013.
[34] M. Haenggi, J. G. Andrews, F. Baccelli, O. Dousse, and M. Franceschetti, “Stochastic geometry and random graphs
for the analysis and design of wireless networks,” IEEE J. Sel. Areas Commun., vol. 27, no. 7, pp. 1029–1046, Sept.
2009.
[35] L. Wang, H. Q. Ngo, M. Elkashlan, T. Q. Duong, and K. K. Wong, “Massive MIMO in spectrum sharing networks:
Achievable rate and power efficiency,” IEEE Systems Journal, vol. 11, no. 1, pp. 20–31, Mar. 2017.
