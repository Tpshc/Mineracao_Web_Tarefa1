Michele Colledanchise and Petter O?gren
Behavior Trees in
Robotics and AI
An Introduction
ar
X
iv
:1
70
9.
00
08
4v
1 
 [
cs
.R
O
] 
 3
1 
A
ug
 2
01
7

Contents
1 What are Behavior Trees? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3
1.1 A Short History of BTs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4
1.2 What is wrong with FSMs? The Need for Reactiveness and
Modularity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4
1.3 Classical Formulation of BTs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6
1.3.1 Execution Example of a BT . . . . . . . . . . . . . . . . . . . . . . . . . . . 9
1.3.2 Control Flow Nodes with Memory . . . . . . . . . . . . . . . . . . . . . . 10
1.4 Creating a BT for Pac-Man from Scratch . . . . . . . . . . . . . . . . . . . . . . . 12
1.5 Creating a BT for a Mobile Manipulator Robot . . . . . . . . . . . . . . . . . . 14
1.6 Use of BTs in Robotics and AI . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16
1.6.1 BTs in autonomous vehicles . . . . . . . . . . . . . . . . . . . . . . . . . . . 16
1.6.2 BTs in industrial robotics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18
1.6.3 BTs in the Amazon Picking Challenge . . . . . . . . . . . . . . . . . . 20
1.6.4 BTs inside the social robot JIBO . . . . . . . . . . . . . . . . . . . . . . . 21
2 How Behavior Trees Generalize and Relate to Earlier Ideas . . . . . . . . . 23
2.1 Finite State Machines . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23
2.1.1 Advantages and disadvantages . . . . . . . . . . . . . . . . . . . . . . . . . 24
2.1.2 Hierarchical Finite State Machines . . . . . . . . . . . . . . . . . . . . . . 24
2.1.3 Creating a FSM that works like a BTs . . . . . . . . . . . . . . . . . . 29
2.1.4 Creating a BT that works like a FSM . . . . . . . . . . . . . . . . . . . 31
2.2 Subsumption Architecture . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31
2.2.1 Advantages and disadvantages . . . . . . . . . . . . . . . . . . . . . . . . . 32
2.2.2 How BTs Generalize the Subsumption Architecture . . . . . . . 33
2.3 Teleo-Reactive programs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34
2.3.1 Advantages and disadvantages . . . . . . . . . . . . . . . . . . . . . . . . . 35
2.3.2 How BTs Generalize Teleo-Reactive Programs . . . . . . . . . . . 35
2.4 Decision Trees . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35
2.4.1 Advantages and disadvantages . . . . . . . . . . . . . . . . . . . . . . . . . 36
2.4.2 How BTs Generalize Decision Trees . . . . . . . . . . . . . . . . . . . . 37
2.5 Advantages and Disadvantages of Behavior Trees . . . . . . . . . . . . . . . 38
I
II Contents
2.5.1 Advantages . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38
2.5.2 Disadvantages . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42
3 Design principles . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45
3.1 Improving Readability using Explicit Success Conditions . . . . . . . . . 45
3.2 Improving Reactivity using Implicit Sequences . . . . . . . . . . . . . . . . . . 46
3.3 Handling Different Cases using a Decision Tree Structure . . . . . . . . . 47
3.4 Improving Safety using Sequences . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47
3.5 Creating Deliberative BTs using Backchaining . . . . . . . . . . . . . . . . . . 49
3.6 Creating Un-Reactive BTs using Memory Nodes . . . . . . . . . . . . . . . . 51
3.7 Choosing the Proper Granularity of a BT . . . . . . . . . . . . . . . . . . . . . . . 52
4 Analysis of Efficiency, Safety, and Robustness . . . . . . . . . . . . . . . . . . . . . 55
4.1 Statespace Formulation of BTs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55
4.2 Efficiency and Robustness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58
4.3 Safety . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62
4.4 Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66
4.4.1 Robustness and Efficiency . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66
4.4.2 Safety . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 69
4.4.3 Complex BT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73
5 Formal Analysis of How Behavior Trees Generalize Earlier Ideas . . . . 77
5.1 How BTs Generalize Decision Trees . . . . . . . . . . . . . . . . . . . . . . . . . . 77
5.2 How BTs Generalize the Subsumption Architecture . . . . . . . . . . . . . . 79
5.3 How BTs Generalize Sequential Behavior Compositions . . . . . . . . . . 81
5.4 How BTs Generalize TRs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 82
5.4.1 Universal TRs and FT-Successful BTs . . . . . . . . . . . . . . . . . . . 84
6 Stochastic BTs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87
6.1 Stochastic BTs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 88
6.1.1 Markov Chains and Markov Processes . . . . . . . . . . . . . . . . . . 89
6.1.2 Formulation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 91
6.2 Transforming a SBT into a DTMC . . . . . . . . . . . . . . . . . . . . . . . . . . . . 96
6.2.1 Computing Transition Properties of the DTMC . . . . . . . . . . . 99
6.3 Reliability of a SBT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101
6.3.1 Average sojourn time . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101
6.3.2 Mean Time To Fail and Mean Time To Succeed . . . . . . . . . . 103
6.3.3 Probabilities Over Time . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 104
6.3.4 Stochastic Execution Times . . . . . . . . . . . . . . . . . . . . . . . . . . . . 105
6.3.5 Deterministic Execution Times . . . . . . . . . . . . . . . . . . . . . . . . . 105
6.4 Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 107
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 117
Quotes on Behavior Trees
“There are a lot of different ways to create AI’s, and I feel like I’ve tried pretty
much all of them at one point or another, but ever since I started using behavior
trees, I wouldn’t want to do it any other way. I wish I could go back in time with
this information and do some things differently.” 1
Mike Weldon
Disney, Pixar
“[...]. Sure you could build the very same behaviors with a finite state machine
(FSM). But anyone who has worked with this kind of technology in industry knows
how fragile such logic gets as it grows. A finely tuned hierarchical FSM before a
game ships is often a temperamental work of art not to be messed with!” 2
Alex J. Champandard
Editor in Chief & Founder AiGameDev.com,
Senior AI Programmer Rockstar Games
“Behavior trees offer a good balance of supporting goal-oriented behaviors and
reactivity. 3 ”
Daniel Broder
Unreal Engine developer
“The main advantage [of Behavior Trees] is that individual behaviors can easily
be reused in the context of another higher-level behavior, without needing to specify
how they relate to subsequent behaviors, [1]”.
Andrew Bagnell et al.
Carnegie Mellon University.
1 http://www.gamasutra.com/blogs/ChrisSimpson/20140717/221339/
Behavior_trees_for_AI_How_they_work.php
2 http://aigamedev.com/open/article/fsm-age-is-over/
3 https://forums.unrealengine.com/showthread.php?6016-Behavior-
Trees-What-and-Why

Chapter 1
What are Behavior Trees?
A Behavior Tree (BT) is a way to structure the switching between different tasks1
in an autonomous agent, such as a robot or a virtual entity in a computer game.
An example of a BT can be seen in Fig. 1.1a. As will be explained, BTs are a very
efficient way of creating complex systems that are both modular and reactive. These
properties are crucial in many applications, which has led to the spread of BT from
computer game programming to many branches of AI and Robotics.
In this book, we will first give an introduction to BTs, in the present chapter.
Then, in Chapter 2 we describe how BTs relate to, and in many cases generalize,
earlier switching structures. These ideas are then used as a foundation for a set
of efficient and easy to use design principles described in Chapter 3. Properties
such as safety, robustness, and efficiency are important for an autonomous system,
and in Chapter 4 we describe a set of tools for formally analyzing these using a
state space description of BTs. With the new analysis tools, we can formalize the
descriptions of how BTs generalize earlier approaches in Chapter 5. Finally, we
describe an extended set of tools to capture the behavior of Stochastic BTs, where
the outcomes of actions are described by probabilities, in Chapter 6. These tools
enable the computation of both success probabilities and time to completion.
In this chapter, we will first tell a brief history of BTs in Section 1.1, and explain
what are the core benefits of BTs, in Section 1.2, then in Section 1.3 we will describe
how a BT works. Then, we will create a simple BT for the video game Pac-Man in
Section 1.4 and a more sophisticated BT for a mobile manipulator in Section 1.5.
We finally describe the usage of BT in a number of applications in Section 1.6.
1 assuming that an activity can somehow be broken down into reusable sub-activities called tasks
sometimes also denoted actions or control modes
3
4 1 What are Behavior Trees?
1.1 A Short History of BTs
BTs were developed in the video game industry, as a tool to increase modularity
in the control structures of Non-Player Characters (NPCs) [18, 7, 19, 25, 36]. In
this billion-dollar industry, modularity is a key property that enables reuse of code,
incremental design of functionality, and efficient testing.
In games, the control structures of NPCs were often formulated in terms of Finite
State Machines (FSMs). However, just as Petri Nets [29] provide an alternative to
FSMs that supports concurrency, BTs provide an alternative view of FSMs that
supports modularity.
Following the development in the industry, BTs have now also started to receive
attention in academia [22, 30, 38, 3, 33, 23, 1, 21, 8, 12, 17, 15].
At Carnegie Mellon University, BTs have been used extensively to do robotic
manipulation [1, 12]. The fact that modularity is the key reason for using BTs is clear
from the following quote from [1]: “The main advantage is that individual behaviors
can easily be reused in the context of another higher-level behavior, without needing
to specify how they relate to subsequent behaviors”.
BTs have also been used to enable non-experts to do robot programming of pick
and place operations, due to their “modular, adaptable representation of a robotic
task” [15] and allowed “end-users to visually create programs with the same amount
of complexity and power as traditionally-written programs” [34]. Furthermore, BTs
have been proposed as a key component in brain surgery robotics due to their “flex-
ibility, reusability, and simple syntax” [17].
The advantages of BTs as compared to FSMs was the reason for extending the
so-called JADE agent Behavior Model with BTs in [3], and the benefits of using
BTs to control complex multi mission UAVs was described in [33].
The modularity of BTs was used to address the formal verification of mission
plans in [21] while the execution time of stochastic BTs was analyzed in [8]. BTs
have also been studied in machine learning applications [22, 30] and details re-
garding efficient parameter passing were investigated in [38]. Finally, a Modelica
implementation of BTs was presented in [20].
1.2 What is wrong with FSMs? The Need for
Reactiveness and Modularity
Many autonomous agents need to be both reactive and modular. By reactive we
mean the ability to quickly and efficiently react to changes. We want a robot to slow
down and avoid a collision if a human enters into its planned trajectory and we want
a virtual game character to hide, flee, or fight, if made aware of an approaching
enemy. By modular, we mean the degree to which a system’s components may be
separated into building blocks, and recombined [13]. We want the agent to be mod-
ular, to enable components to be developed, tested, and reused independently of one
1.2 What is wrong with FSMs? The Need for Reactiveness and Modularity 5
another. Since complexity grows with size, it is beneficial to be able to work with
components one at a time, rather than the combined system.
FSMs have long been the standard choice when designing a task switching struc-
ture, see e.g. [35, 26]. FSMs will be discussed in detail in Chapter 2.1, but here we
make a short description of the tradeoff between reactivity and modularity that is
inherent in FSMs. This tradeoff can be understood in terms of the classical Goto-
statement that was used in early programming languages. The Goto statement is an
example of a so-called one-way control transfer, where the execution of a program
jumps to another part of the code and continue executing from there. Instead of
one-way control transfers, modern programming languages tend to rely on two-way
control transfers embodied in e.g. function calls. Here, execution jumps to a par-
ticular part of the code, executes it, and then returns to where the function call was
made. The drawbacks of one-way control transfers were made explicit by Edsgar
Dijkstra in his paper Goto statement considered harmful [10], where he states that
“The Goto statement as it stands is just too primitive; it is too much an invitation to
make a mess of one’s program”. Looking back at the state transitions in FSMs, we
note that they are indeed one-way control transfers. This is where the tradeoff be-
tween reactivity and modularity is created. For the system to be reactive, there needs
to be many transitions between components, and many transitions means many one-
way control transfers which, just as Dijkstra noted, harms modularity by being an
“invitation to make a mess of one’s program”. If, for example, one component is
removed, every transition to that component needs to be revised. As will be seen,
BTs use two-way control transfers, governed by the internal nodes of the trees.
Using BTs instead of FSMs to implement the task switching, allows us to de-
scribe the desired behavior in modules as depicted in Figure 1.1a. Note that in the
next section we will describe how BTs work in detail, so these figures are just meant
to give a first glimpse of BTs, rather than the whole picture.
A behavior is often composed of a sequence of sub-behaviors that are task inde-
pendent, meaning that while creating a sub-behavior the designer does not need to
know which sub-behavior will be performed next. Sub-behaviors can be designed
recursively, adding more details as in Figure 1.1b. BTs are executed in a particular
way, which will be described in the following section, that allows the behavior to be
carried out reactively. For example, the BTs in Figure 1.1 execute the sub-behavior
Place Ball, but also verifies that the ball is still at a known location and securely
grasped. If, due to an external event, the ball slips out out of the grasp, then the
robot will abort the sub-behavior Place Ball and will re-execute the sub-behavior
Pick Ball or Find Ball according to the current situation.
6 1 What are Behavior Trees?
?
Find Ball Pick Ball Place Ball
(a) A high level BT carrying out a task consisting of first finding, then picking and finally placing
a ball.
?
Find Ball Place Ball
?
? ?
Ball Close Approach Ball Ball Grasped Grasp Ball
Pick Ball
(b) The action Pick Ball from the BT in Fig. 1.1a is expanded into a sub-BT. The Ball is approached
until it is considered close, and then the action grasp is executed until the ball is securely grasped.
Fig. 1.1: Illustrations of a BT carrying out a pick and place task with different degrees of detail.
The execution of a BT will be described in Section 1.3.
1.3 Classical Formulation of BTs
At the core, BTs are built from a small set of simple components, just as many other
powerful concepts, but throughout this book, we will see how this simple formalism
can be used to create very rich structures, in terms of both applications and theory.
Formally speaking, a BT is a directed rooted tree where the internal nodes are
called control flow nodes and leaf nodes are called execution nodes. For each con-
nected node we use the common terminology of parent and child. The root is the
node without parents; all other nodes have one parent. The control flow nodes have
at least one child. Graphically, the children of a node are placed below it, as shown
in Figures 1.2-1.4.
A BT starts its execution from the root node that generates signals that allow
the execution of a node called ticks with a given frequency, which are sent to its
children. A node is executed if and only if it receives ticks. The child immediately
returns running to the parent, if its execution is under way, success if it has achieved
its goal, or failure otherwise.
In the classical formulation, there exist four categories of control flow nodes
(sequence, fallback, parallel, and decorator) and two categories of execution nodes
(action and condition). They are all explained below and summarized in Table 1.1.
1.3 Classical Formulation of BTs 7
The sequence node executes Algorithm 1, which corresponds to routing the ticks
to its children from the left until it finds a child that returns either failure or running,
then it returns failure or running accordingly to its own parent. It returns success if
and only if all its children return success. Note that when a child returns running
or failure, the sequence node does not route the ticks to the next child (if any). The
symbol of the sequence node is a box containing the label “?”, shown in Figure 1.2.
?
Child 1 Child 2 · · · Child N
Fig. 1.2: Graphical representation of a sequence node with N children.
Algorithm 1: Pseudocode of a Sequence node with N children
1 for i? 1 to N do
2 childStatus? Tick(child(i))
3 if childStatus = running then
4 return running
5 else if childStatus = failure then
6 return failure
7 return success
The fallback node2 executes Algorithm 2, which corresponds to routing the ticks
to its children from the left until it finds a child that returns either success or running,
then it returns success or running accordingly to its own parent. It returns failure if
and only if all its children return failure. Note that when a child returns running
or success, the fallback node does not route the ticks to the next child (if any).
The symbol of the the fallback node is a box containing the label “?”, shown in
Figure 1.3.
The parallel node executes Algorithm 3, which corresponds to routing the ticks
to all its children and it returns success if M children return success, it returns failure
if N?M+1 children return failure, and it returns running otherwise, where N is the
number of children and M ? N is a user defined threshold. The symbol of the the
parallel node is a box containing the label “?”, shown in Figure 1.4.
2 Fallback nodes are sometimes also called selector nodes.
8 1 What are Behavior Trees?
?
Child 1 Child 2 · · · Child N
Fig. 1.3: Graphical representation of a fallback node with N children.
Algorithm 2: Pseudocode of a Fallback node with N children
1 for i? 1 to N do
2 childStatus? Tick(child(i))
3 if childStatus = running then
4 return running
5 else if childStatus = success then
6 return success
7 return failure
?
Child 1 Child 2 · · · Child N
Fig. 1.4: Graphical representation of a parallel node with N children.
Algorithm 3: Pseudocode of a Parallel node with N children and success
threshold M
1 for i? 1 to N do
2 childStatus(i)? Tick(child(i))
3 if ?i:childStatus(i)=success1?M then
4 return Success
5 else if ?i:childStatus(i)= f ailure1 > N?M then
6 return failure
7 return running
When it receives ticks, an action node executes a command. It returns success if
the action is correctly completed or failure if the action has failed. While the action
is ongoing it returns running. An action node is shown in Figure 1.5a.
When it receives ticks, a condition node checks a proposition. It returns success
or failure depending on if the proposition holds or not. Note that a condition node
never returns a status of running. A condition node is shown in Figure 1.5b.
1.3 Classical Formulation of BTs 9
Action
(a) Action node. The la-
bel describes the action per-
formed.
Condition
(b) Condition node. The label
describes the condition veri-
fied.
? Policy
Child
(c) Decorator node. The la-
bel describes the user defined
policy.
Fig. 1.5: Graphical representation of action (a), condition (b), and decorator (c) node.
The decorator node is a control flow node with a single child that manipulates
the return status of its child according to a user-defined rule and also selectively
ticks the child according to some predefined rule. For example, an invert decorator
inverts the success/failure status of the child; a max-N-tries decorator only lets its
child fail N times, then always returns failure without ticking the child; a max-T-
sec decorator lets the child run for T seconds then, if the child is still running, the
decorator returns failure without ticking the child. The symbol of the the decorator
is a rhombus, as in Figure 1.5c.
Node type Symbol Succeeds Fails Running
Fallback ? If one child succeeds If all children fail If one child returns running
Sequence ? If all children succeed If one child fails If one child returns running
Parallel ? If ?M children succeed If > N?M children fail else
Action text Upon completion If impossible to complete During completion
Condition
  text If true If false Never
Decorator ? Custom Custom Custom
Table 1.1: The node types of a BT.
1.3.1 Execution Example of a BT
Consider the BT in Figure 1.6 designed to make an agent look for a ball, approach
it, grasp it, proceed to a bin, and place the ball in the bin. This example will illustrate
the execution of the BT, including the reactivity when another (external) agent takes
the ball from the first agent, making it switch to looking for the ball and approaching
it again. When the execution starts, the ticks traverse the BT reaching the condition
node Ball Found. The agent does not know the ball position hence the condition node
returns failure and the ticks reach the action Find Ball, which returns running (see
Figure 1.7a). While executing this action, the agent sees the ball with the camera. In
10 1 What are Behavior Trees?
this new situation the agent knows the ball position. Hence the condition node Ball
Found now returns success resulting in the ticks no longer reaching the action node
Find Ball and the action is preempted. The ticks continue exploring the tree, and
reach the condition node Ball Close, which returns failure (the ball is far away) and
then reach the action node Approach Ball, which returns running (see Figure 1.7b).
Then the agent eventually reaches the ball, picks it up and goes towards the bin (see
Figure 1.7c). When an external agent moves the ball from the hand of the first agent
to the floor (where the ball is visible), the condition node Ball Found returns success
while the condition node Ball Close returns failure. In this situation the ticks no
longer reach the action Approach Bin (which is preempted) and they instead reach
the action Approach Ball (see Figure 1.7d).
?
?
Ask for
Help
?
Ball Found
Find
Ball
?
Ball Close
Approach
Ball
?
Ball Grasped
Grasp
Ball
?
Bin Close
Approach
Bin
?
Ball Placed
Place
Ball
Fig. 1.6: BT encoding the behavior of Example 2.1.
1.3.2 Control Flow Nodes with Memory
As seen in the example above, to provide reactivity the control flow nodes sequence
and fallback keep sending ticks to the children to the left of a running child, in
order to verify whether a child has to be re-executed and the current one has to be
preempted. However, sometimes the user knows that a child, once executed, does
not need to be re-executed.
Nodes with memory [25] have been introduced to enable the designer to avoid
the unwanted re-execution of some nodes. Control flow nodes with memory always
remember whether a child has returned success or failure, avoiding the re-execution
of the child until the whole sequence or fallback finishes in either success or failure.
In this book, nodes with memory are graphically represented with the addition of the
symbol “?” (e.g. a sequence node with memory is graphically represented by a box
with a “??”). The memory is cleared when the parent node returns either success or
failure, so that at the next activation all children are considered. Note however that
every execution of a control flow node with memory can be obtained with a non-
memory BT using some auxiliary conditions as shown in Figure 1.8. Hence nodes
with memory can be considered to be syntactic sugar.
Remark 1.1. Some BT implementations, such as the one described in [25], do not
include the running return status. Instead, they let each action run until it returns
1.3 Classical Formulation of BTs 11
?
?
Ask for
Help
?
Ball Found
Find
Ball
?
Ball Close
Approach
Ball
?
Ball Grasped
Grasp
Ball
?
Bin Close
Approach
Bin
?
Ball Placed
Place
Ball
FAILURE, RUNNING
RUNNING
RUNNING
RUNNING
(a) Ticks’ traversal when the robot is searching the ball.
?
?
Ask for
Help
?
Ball Found
Find
Ball
?
Ball Close
Approach
Ball
?
Ball Grasped
Grasp
Ball
?
Bin Close
Approach
Bin
?
Ball Placed
Place
Ball
SUCCESS
SUCCESS
FAILURE, RUNNING
RUNNING
RUNNING
RUNNING
(b) Ticks’ traversal while the robot is approaching the ball.
?
?
Ask for
Help
?
Ball Found
Find
Ball
?
Ball Close
Approach
Ball
?
Ball Grasped
Grasp
Ball
?
Bin Close
Approach
Bin
?
Ball Placed
Place
Ball
SUCCESS
SUCCESS
SUCCESS
SUCCESS
SUCCESS
SUCCESS
FAILURE, RUNNING
RUNNING
RUNNING
RUNNING
(c) Ticks’ traversal while the robot is approaching the bin.
?
?
Ask for
Help
?
Ball Found
Find
Ball
?
Ball Close
Approach
Ball
?
Ball Grasped
Grasp
Ball
?
Bin Close
Approach
Bin
?
Ball Placed
Place
Ball
SUCCESS
SUCCESS
FAILURE, RUNNING
RUNNING
RUNNING
RUNNING
(d) Ticks’ traversal while the robot is approaching the ball again (because it was removed from the
hand).
Fig. 1.7: Visualization of the ticks’ traversal in the different situations, as explained in Sec-
tion 1.3.1.
failure or success. We denote these BTs as non-reactive, since they do not allow
actions other than the currently active one to react to changes. This is a significant
limitation on non-reactive BTs, which was also noted in [25]. A non-reactive BT
can be seen as a BT with only memory nodes.
As reactivity is one of the key strengths of BTs, the non-reactive BTs are of
limited use.
12 1 What are Behavior Trees?
??
Action 1 Action 2
(a) Sequence composition
with memory.
?
? ?
Action 1 Done Action 1 Action 2 Done Action 2
(b) BT that emulates the execution of the sequence compo-
sition with memory using nodes without memory.
Fig. 1.8: Relation between memory and memory-less BT nodes.
1.4 Creating a BT for Pac-Man from Scratch
In this section we create a set of BTs of increasing complexity for playing the game
Pac-Man. The source code of all the examples is publicly available and editable, see
Appendix A. We use a clone of the Namco’s Pac-Man computer game depicted in
Figure 1.93.
In the testbed, a BT controls the agent, Pac-Man, through a maze containing two
ghosts, a large number of pills, including two so-called power pills. The goal of the
game is to consume all the pills, without being eaten by the ghosts. The power pills
are such that, if eaten, Pac-Man receives temporary super powers, and is able to eat
the ghosts. After a given time the effect of the power pill wears off, and the ghosts
can again eat Pac-Man. When a ghost is eaten, it returns to the center box where it
is regenerated and becomes dangerous again. Edible ghosts change color, and then
flash to signal when they are about to become dangerous again.
Fig. 1.9: The game Pac-Man for which we will design a BT. There exists maps of different com-
plexity.
3 The software was developed at UC Berkeley for educational purposes. More information avail-
able at: http://ai.berkeley.edu/project_overview.html
1.4 Creating a BT for Pac-Man from Scratch 13
The simplest behavior is to let Pac-Man ignore the ghosts and just focus on eating
pills. This is done using a greedy action Eat pills as in Figure 1.10.
Eat Pills
Fig. 1.10: BT for the simplest non-random behavior, Eat pills, which maximizes the number of
pills eaten in the next time step.
The simple behavior described above ignores the ghosts. To take them into ac-
count, we can extend the previous behavior by adding an Avoid Ghosts action to
be executed whenever the condition Ghost Close is true. This action will greedily
maximize the distance to all ghosts. The new action and condition can be added to
the BT as depicted in Fig. 1.11. The resulting BT will switch between Eat Pills and
Avoid Ghost depending on whether Ghost Close returns success or failure.
?
Eat Pills?
Avoid
Ghost
Ghost
Close
Fig. 1.11: If a Ghost is Close, the BT will execute the action Avoid Ghost, else it will run Eat Pills.
The next extension we make is to take the power pills into account. When Pac-
Man eats a Power pill, the ghosts are edible, and we would like to chase them,
instead of avoiding them. To do this we add the condition Ghost Scared and the ac-
tion Chase Ghost to the BT, as shown in Fig. 1.12. Chase Ghost greedily minimizes
the distance to the closest edible ghost. Note that we only start chasing the ghost
if it is close, otherwise we continue eating pills. Note also that all extensions are
modular, without the need to rewire the previous BT.
With this incremental design, we have created a basic AI for playing Pac-Man,
but what if we want to make a world class Pac-Man AI? You could add additional
nodes to the BT, such as moving towards the Power pills when being chased, and
stop chasing ghosts when they are blinking and soon will transform into normal
ghosts. However, much of the fine details of Pac-Man lies in considerations of the
Maze geometry, choosing paths that avoid dead ends and possible capture by mul-
tiple ghosts. Such spatial analysis is probably best done inside the actions, e.g.,
making Avoid Ghosts take dead ends and ghost positions into account. The question
14 1 What are Behavior Trees?
?
Eat Pills?
Ghost
Close
?
Avoid
Ghost
?
Chase
Ghost
Ghost
Scared
Fig. 1.12: BT for the Combative Behavior
of what functionality to address in the BT structure, and what to take care of inside
the actions is open, and must be decided on a case to case basis, as discussed in
Section 3.7.
1.5 Creating a BT for a Mobile Manipulator Robot
Fig. 1.13: The Mobile Manipulator for which we will design a BT.
1.5 Creating a BT for a Mobile Manipulator Robot 15
In this section, we create a set of BTs of increasing complexity for controlling a
mobile manipulator. The source code of all the examples is publicly available and
editable. See Appendix B. We use a custom-made testbed created in the V-REP
robot simulator depicted in Figure 1.13.
In the testbed, a BT controls a mobile manipulator robot, a youBot, on a flat
surface. In the scenario, there are several colored cubes lying on a flat surface. The
goal is to move the green cube to the goal area while avoiding the other cubes. The
youBot’s grippers are such that the robot is able to pick and place the cubes if the
robot is close enough.
The simplest possible BT is to check the goal condition Green Cube on Goal. If
this condition is satisfied (i.e. the cube is on the goal) the task is done, if it is not
satisfied the robot needs to place the cube onto the goal area. To correctly execute
the action Place Cube, two conditions need to hold: the robot is holding the green
cube and the robot is close to the goal area. The behavior described so far can be
encoded in the BT in Figure 1.14. This BT is able to place the green cube on the goal
area if and only if the robot is close to the goal area with the green cube grasped.
?
Green Cube
on Goal
?
Holding
Green Cube
Close to
Goal
Place Cube
Fig. 1.14: BT for the simple Scenario.
Now, thanks to the modularity of BTs, we can separately design the BTs needed
to satisfy the two lower conditions in Fig. 1.14, i.e., the BT needed to grasp the green
cube and the BT needed to reach the goal area. To grasp the green cube, the robot
needs to have the hand free and be close to the cube. If it is not close, it approaches
as long as a collision free trajectory exists. This behavior can be engoded is the BT
in Figure 1.15a. To reach the goal area we let the robot simply Move To the Goal as
long as a collision free trajectory exists. This behavior can be engoded is the BT in
Figure 1.15b.
Now we can extend the simple BT above by replacing the two lower conditions
in Fig. 1.14 with the two BTs in Fig. 1.15. The result can be seen in Fig. 1.16. Using
this design, the robot is able to place the green cube in the goal area as long as there
exists a collision free trajectory to the green cube and to the goal area.
We can continue to incrementally build the BT in this way to handle more sit-
uations, for instance removing obstructing objects to ensure that a collision free
trajectory exists, and dropping things in the hand to be able to pick the green cube
up.
16 1 What are Behavior Trees?
?
Holding
Green Cube
?
Hand Free Pick Cube?
Close to
Cube
?
Exists
Collision Free
Trajectory
Approach
Cube
(a) A BT that picks the green cube.
?
Close to
Goal
?
Exists
Collision Free
Trajectory
Approach
Goal
(b) A BT that reaches the goal region.
Fig. 1.15: Illustrations of a BT carrying out the subtasks of picking the green cube and reaching
the goal area
1.6 Use of BTs in Robotics and AI
In this section we describe the use of BTs in a set of real robot applications and
projects, spanning from autonomous navigation to industrial robotics.
1.6.1 BTs in autonomous vehicles
There is no standard CA for autonomous vehicles, however reviewing the CAs used
to address the DARPA Grand Challenge, a competition for autonomous vehicles,
we note that most teams employed FSMs designed and developed exactly for that
challenge [40, 41]. Some of them used a HFSM[26] decomposing the mission task
in multiple sub-tasks in a hierarchy.
1.6 Use of BTs in Robotics and AI 17
?
Green Cube
on Goal ?
Place Cube
?
Holding
Green Cube
?
Hand Free Pick Cube?
Close to
Cube
?
Exists
Collision Free
Trajectory
Approach
Cube
?
Close to
Goal
?
Exists
Collision Free
Trajectory
Approach
Goal
Fig. 1.16: Final BT resulting from the aggregation of different BTs.
Fig. 1.17: Trucks running the Scania iQmatic’s software.4
iQmatic is a Scania led project that aims at developing a fully autonomous heavy
vehicle, i.e. a truck, for goods transport; mining; and other industrial applications.
The vehicle’s software has to be reusable, maintainable and easy to develop. For
these reasons, the iQmatic’s developers chose BTs as the CA for the project. BTs
are appreciated in iQmatic for their human readability, that support the design and
4 Picture courtesy of Scania.com
18 1 What are Behavior Trees?
development of early prototypes; and their maintainability, that makes the editing
task easier. Figure 1.17 shows two trucks used in the iQmatic project.
1.6.2 BTs in industrial robotics
Industrial robots usually operate in structured environments and their CA is de-
signed for a single specific task. Hence classical CAs such as FSMs or Petri
Nets [29] have found successful applications in the last decades. However, future
generations of industrial robots, so-called cobots, will operate in less structured en-
vironments and collaborate closely with humans. Several research projects explore
this research direction.
Fig. 1.18: Experimental platform of the CoSTAR project.5
CoSTAR [34] is a project that aims at developing a software framework that con-
tains tools for industrial applications that involve human cooperation. The use cases
include non trained operators composing task plans, and training robots to perform
complex behaviors. BTs have found successful applications in this project as they
simplify the composition of sub-tasks. The order in which the sub-tasks are executed
is independent from the sub-task implementation; this enables easy composition of
trees and the iterative composition of larger and larger trees. Figure 1.18 shows one
of the robotic platforms of the project.
5 Picture courtesy of http://cpaxton.github.io/
1.6 Use of BTs in Robotics and AI 19
Fig. 1.19: Experimental platform of the SARAFun project.6
SARAFun7 is a project that aims at developing a robot-programming framework
that enables a non-expert user to program an assembly task from scratch on a robot
in less than a day. It takes advantages of state of the art techniques in sensory and
cognitive abilities, robot control, and planning.
BTs are used to execute the generic actions learned or planned. For the purpose of
this project, the CA must be human readable, enable code reuse, and modular. BTs
have created advantages also during the development stage, when the code written
by different partners had to be integrated. Figure 1.19 shows an ABB Yumi robot
used in the SARAFun testbed.
Fig. 1.20: Intera’s BT (left) and simulation environment (right).8
7 http://h2020sarafun.eu
20 1 What are Behavior Trees?
Rethink Robotics released its software platform Intera in 2017, with BTs at the
“heart of the design”. Intera claims to be a “first-of-its-kind software platform that
connects everything from a single robot controller, extending the smart, flexible
power of Rethink Robotics’ Sawyer to the entire work cell and simplifying automa-
tion with unparalleled ease of deployment.”9 It is designed with the goal of creating
the world’s fastest-to-deploy robot and fundamentally changing the concepts of in-
tegration, making it drastically easier and affordable.
Intera’s BT defines the sequence of tasks the robot will perform. The tree can
be created manually or trained by demonstration. Users can inspect any portion of
the BT and make adjustments. The Intera interface (see Figure 1.20) also includes a
simulated robot, so a user can run simulations while the program executes the BT.
BTs are appreciated in this context because the train-by-demonstration framework
builds a BT that is easily inspectable and modifiable.10
1.6.3 BTs in the Amazon Picking Challenge
The Amazon Picking Challenge (APC) is an international robot competition. Robots
need to autonomously retrieve a wide range of products from a shelf and put them
into a container. The challenge was conceived with the purpose of strengthening
the ties between industrial and academic robotic research, promoting shared solu-
tions to some open problems in unstructured automation. Over thirty companies and
research laboratories from different continents competed in the APC’s preliminary
phases. The best performing teams earned the right to compete at the finals and the
source codes of the finalists were made publicly available 11.
The KTH entry in the final challenge used BTs in both editions (2015 and 2016).
BTs were appreciated for their modularity and code reusability, which allowed the
integration of different functionalities developed by programmers with different
background and coding styles. In 2015, the KTH entry got the best result out of
the four teams competing with PR2 robots.
9 http://www.rethinkrobotics.com/news-item/rethink-robotics-
releases-intera-5-new-approach-automation/
9 Setup located at CERTH, Thessaloniki, Greece. Picture courtesy of Angeliki Topalidou-
Kyniazopoulou.
9 Picture courtesy of http://www.rethinkrobotics.com/intera/
10 http://twimage.net/rodney-brooks-743452002
11 https://github.com/amazon-picking-challenge
1.6 Use of BTs in Robotics and AI 21
Fig. 1.21: The KTH entry in the Amazon Picking Challenge at ICRA 2015.
1.6.4 BTs inside the social robot JIBO
JIBO is a social robot that can recognize faces and voices, tell jokes, play games and
share information. It is intended to be used in homes, providing the functionality of
a tablet, but with an interface relying on speech and video instead of a touch screen.
BTs are a fundamental part of the software architecture of JIBO12, including an
open SDK inviting external contributors to develop new skills for the robot.
12 https://developers.jibo.com/docs/behavior-trees.html
22 1 What are Behavior Trees?
Fig. 1.22: The JIBO social robot has an SDK based on BTs.
Chapter 2
How Behavior Trees Generalize and Relate to
Earlier Ideas
In this chapter we describe how BT relate to, and often generalize, a number of well
known control architectures including Finite State Machines (2.1), the Subsumption
Architecture (2.2), the Teleo-Reactive Approach (2.3) and Decision Trees (2.4). We
also present advantages and disadvantages of each approach. Finally, we list a set of
advantages and disadvantages of BTs (2.5). Some of the results of this chapter were
previously published in the journal paper [9].
2.1 Finite State Machines
A FSM is one of the most basic mathematical models of computation. The FSM
consists of a set of states, transitions and events, as illustrated in Fig. 2.1 showing an
example of a FSM designed to carry out a grab-and-throw task. Note that the discus-
sion here is valid for all CAs based on FSMs, including Mealy [27] and Moore [24]
machines.
Approach Ball Grasp Ball Move To Dest. Throw Ball
Wait for Help SuccessFailure
Ball Close Ball Grasped Dest. Reached
Help OK
Help not OK
Fault Fault Fault Fault
Fig. 2.1: Graphical representation of a FSM designed to carry out a simple grab-and-throw task.
The initial state has a thicker border, and events names are given next to the corresponding transi-
tion arrows.
23
24 2 How Behavior Trees Generalize and Relate to Earlier Ideas
2.1.1 Advantages and disadvantages
FSMs are widely used due to their three main advantages:
• Very common structure, used in many different parts of computer science.
• Intuitive and easy to understand.
• Easy to implement.
However, the drawbacks of FSMs gives rise to problems when the system mod-
elled grows in complexity and number of states, as described briefly in Section 1.2.
In particular we have the following drawbacks
• Reactivity/Modularity tradeoff. A reactive system needs many transitions, and
every transition corresponds to a goto-statement, see Section refsec:modularity.
In particular, the transitions give rise to the problems below:
– Maintainability: Adding or removing states requires to re-evaluate possibly all
the transitions and internal states of the whole FSM. This makes FSMs highly
susceptible to human design errors and makes them inefficient to be used and
generated by computer programs.
– Scalability: FSMs with many states and many transitions between them are
hard to modify, for both humans and computers.
– Reusability: The transitions between states may depend on internal variables
(like in a Hybrid Automaton), making it unpractical to encode the same task
for use in multiple projects.
2.1.2 Hierarchical Finite State Machines
Hierarchical Finite State Machines (HFSMs), also known as State Charts[16], where
developed to alleviate some of the disadvantages of FSMs. In a HFSM, a state can in
turn contain one or more sub states. A state containing two or more states is called
a super state. In a HFSM, a generalized transition is a transition between super
states. Generalized transitions can reduce the number of transitions by connecting
two super states rather than connecting a larger number of sub states individually.
Each super state has one sub state identified as the starting state, executing whenever
a transition to the super state occurs. Figure 2.2 shows an example of a HFSM for a
video game character.
2.1.2.1 Advantages and disadvantages
The main advantages of HFSMs are:
2.1 Finite State Machines 25
Go
To A
Go
To B
Go
To C
Go
To D
Patrol
Aim Shoot
Reload
Use Handgun
Aim Shoot
Reload
Use Rifle
Fig. 2.2: Example of a HFSM controlling a NPC of a combat game. Patrol, Use Rifle, and Use
Handgun are superstates.
• Increased Modularity: it is possible to separate the tasks in sub-tasks. However
these sub-tasks often still depend on each other through state-dependent transi-
tions.
• Behavior inheritance: The state nesting in HFSMs allows so-called behavior
inheritance. Behavior inheritance allows sub-states to inherit behaviors from
the superstate; for example, in the HFSM depicted in Figure 2.2, while in the
sub-states inside Use Handgun, the character holds the weapon using one hand
whereas while in the sub-states inside Use Rifle, the character holds the weapon
using two hands. Thus, there is no need for the sub states to specify this property,
instead, it is inherited from the superstate.
The main disadvantages of HFSMs are:
• Maintainability: Adding or removing states is still hard. A long sequence of ac-
tions, with the possibility of going back in the sequence and re-execute a task
that was undone by external agents (e.g. the environment), still requires a fully
connected sub-graph.
• Manually created hierarchy: Although HFSMs were conceived as a hierarchical
version of FSMs, the hierarchy has to be user defined and editing such a hierarchy
can be difficult. The hierarchy resolves some problems, but a reactive HFSM still
results in some sub graphs being fully connected with many possible transitions,
see Fig. 2.3.
26 2 How Behavior Trees Generalize and Relate to Earlier Ideas
From a theoretical standpoint, every execution described by a BT can be de-
scribed by a FSM and vice-versa [33, 23]. However, due to the number of transitions,
using a FSM as a CA is unpractical for some applications as shown in Chapter 1.
Moreover, a potential problem is that a FSM does not assume that the proposi-
tions triggering the outgoing transitions from the same state are mutually exclusive.
When implemented, the propositions are checked regularly in discrete time, hence
there exists a non-zero probability that two or more propositions hold simultane-
ously after one cycle. To solve this problem we need to redefine some transitions, as
done in the FSM in Figure 2.22, making the propositions of the outgoing transitions
mutually exclusive. A FSM of this format is impractical to design for both humans
and computers. Adding and removing behaviors by a human is prone to errors. After
adding a new state, each existing transition must be re-evaluated (possibly removed
or replaced) and new transitions from/to the new state must be evaluated as well.
A high number of transitions make any automated process to analyze or synthesize
FSMs computationally expensive.
HFSMs is the most similar CA to BTs in terms of purpose and use. To com-
pare BTs with HFSMs we use the following complex example. Consider the HFSM
shown in Figure 2.3 describing the behavior of a humanoid robot. We can describe
the same functionality using the BT shown in Figure 2.4. Note that we have used the
standard notation [16] of HFSMs to denote two activities running in parallel with a
dashed line as separation. One important difference is that, in HFSMs, each layer
in the hierarchy needs to be added explicitly, whereas in BTs every sub-tree can be
seen as a module of its own, with the same interface as an atomic action.
In the HFSM shown in Figure 2.3, a proposition needs to be given for each tran-
sition, and to improve readability we have numbered these propositions from C1 to
C10. In the top layer of the HFSM we have the sub-HFSMs of Self Protection and
Perform Activites. Inside the latter we have two parallel sub-HFSMs. One is han-
dling the user interaction, while the larger one contains a complete directed graph
handling the switching between the different activities. Finally, Play Ball Game is
yet another sub-HFSM with the ball tracking running in parallel with another com-
plete directed graph, handling the reactive switching between Approach Ball, Grasp
Ball, and Throw Ball.
It is clear from the two figures how modularity is handled by the HFSM. The
explicitly defined sub-HFSM encapsulates Self Protection, Perform Activities and
Play Ball Game. However, inside these sub-HFSMs, the transition structure is a
complete directed graph, with n(n? 1) transitions that need to be maintained (n
being the number of nodes).
2.1
Finite
State
M
achines
27
Ball Tracker
Sit Down
Ask What
to Do
Stand Up
Sit
Wave
Approach
Ball
Throw Ball
Grasp Ball
C7
not C7
C8
C7 and not C8
C8not C7
Ball Game
C4
C6
C7
C3
C6
C7
C3
C4
C7
C3
C4
C6
C2
C3
C2
C4
C2
C6
C2
C7
Say Goodbye
Bye
C8
C3
C8
C4
C8
C6
C8
C7
C8
C2
Idle
Set Current
ActivityC9
not C9
Activity Manager
Say Ouch
Back
Off 0.2m
Perform Activity
Self Protection
not C10
C10
Fig. 2.3: A HFSM description of the BT in Figure 2.4. The transition conditions are shown at the end of each arrow to indicate the direction of the
transition. Note how the complexity of the transitions within each layer of the HFSM grows with the number of nodes. The conditions labels are:
C1 = Activity Sit, C2 = Not Know What to Do, C3 = Activity Stand Up, C4 = Activity Sleep, C5 = Activity Ball Game, C6 = Ball Close, C7 = Ball Grasped,
C8 = New User Suggestion, C9 = Activity Sit, C10 = Bumper Pressed.
28
2
H
ow
B
ehaviorTrees
G
eneralize
and
R
elate
to
E
arlierIdeas
?
?
Toe Bumper
Pressed
?
Say
Ouch
Back Off
0.2m
Self Protection
?
?
?
I Know
What to Do
Ask What
to Do
User Interaction
?
New User
Suggestion
Set Current
Activity
Activity Manager
?
?
Activity Sit Sit
?
Activity
Ball Game
?
Activity
Stand Up
Stand
Up
?
Activity Say
Goodbye
?
Activity
Sleep
Go To
Sleep
?
?
?
Ball
Close
Approach
Ball
?
Ball
Grasped
Grasp
Ball
Throw
Ball
Track
Ball
Ball Game ?
Say
Goodbye
Wave
Hand
Ball Game
Fig. 2.4: A BT that combines some capabilities of the NAO robot in an interactive and modular way. Note how atomic actions can easily be replaced by more
complex sub-BTs.
2.1 Finite State Machines 29
2.1.3 Creating a FSM that works like a BTs
As described in Chapter 1, each BT returns Success, Running or Failure. Imagine
we have a state in an FSM that has 3 transitions, corresponding to these 3 return
statements. Adding a Tick source that collect the return transitions and transfer the
execution back into the state, as depicted in Figure 2.5, we have a structure that
resembles a BT.
We can now compose such FSM states using both Fallback and Sequence con-
structs. The FSM corresponding to the Fallback example in Figure 2.6 would then
look like the one shown in Figure 2.7.
Similarly, the FSM corresponding to the Sequence example in Figure 2.8 would
then look like the one shown in Figure 2.9, and a two level BT, such as the one in
Figure 2.10 would look like Figure 2.11.
A few observations can be made from the above examples. First, it is perfectly
possible to design FSMs with a structure taken from BTs. Second, considering that
a BT with 2 levels corresponds to the FSM in Figure 2.11, a BT with 5 levels, such
as the one in Figure 2.12 would correspond to a somewhat complex FSM.
Third, and more importantly, the modularity of the BT construct is illustrated in
Figures 2.5-2.11. Figure 2.11 might be complex, but that complexity is encapsu-
lated in a box with a single in-transition and three out-transitions, just as the box in
Figure 2.5.
Fourth, as was mentioned in Section 1.2, the decision of what to do after a given
sub-BT returns is always decided on the parent level of that BT. The sub-BT is
ticked, and returns Success, Running or Failure and the parent level decides whether
to tick the next child, or return something to its own parent. Thus, the BT ticking
and returning of a sub-BT is similar to a function call in a piece of source code, just
as described in Section 1.2. A function call in Java, C++ or Python moves execution
to another piece of the source code, but then returns the execution to the line right
below the function call. What to do next is decided by the piece of code that made
the function call, not the function itself. As we will see below, this is quite different
Generic BT
S
F
RIn
Atomic action 
or 
Composition 
Tick 
Source
Fig. 2.5: An FSM behaving like a BT, made up of a single normal state, three out transitions
Success (S), Running (R) and Failure (F), and a Tick source.
30 2 How Behavior Trees Generalize and Relate to Earlier Ideas
?
Enter
through
Front Door
Enter
through
Back Door
Fig. 2.6: A Fallback is used to create an Enter Building BT. The back door option is only tried if
the front door option fails. Fallbacks are denoted by a white box with a question mark and Actions
are denoted by a green box.
Fallback(Use Front Door, Use Back Door)
S
F
RIn
Use Front Door S
F
RIn
Use Back Door S
F
RIn
Fig. 2.7: A FSM corresponding to the Fallback BT in Figure 2.6. Note how the second state is only
executed if the first fails.
?
Open
Front
Door
Pass
through
Door
Fig. 2.8: A Sequence is used to to create an Enter Through Front Door BT. Passing the door is
only tried if the opening action succeeds. Sequences are denoted by a white box with an arrow.
from standard FSMs where the decision of what to do next is decided by the state
being transitioned to, in a way that resembles the Goto statement.
2.2 Subsumption Architecture 31
Sequence(Open Door, Pass Through Door)
S
F
RIn
Open Door S
F
RIn
Pass Through Door S
F
RIn
Fig. 2.9: An FSM corresponding to the Sequence BT in Figure 2.8. Note how the second state is
only executed if the first succeeds.
?
?
Open
Front
Door
Pass
through
Door
?
Open
Back
Door
Pass
through
Door
Fig. 2.10: The two BTs in Figures 2.6 and 2.8 are combined to larger BT. If e.g. the robot opens
the front door, but does not manage to pass through it, it will try the back door.
Fallback(Sequence(Open Front Door,Pass Front Door), Sequence(Open Back Door,Pass Back Door))
S
F
RIn
Sequence(Open Front Door,Pass Front Door) S
F
RIn
Open Front Door S
F
RIn
Pass Front Door S
F
RIn
Sequence(Open Back Door,Pass Back Door) S
F
RIn
Open Back Door S
F
RIn
Pass Back Door S
F
RIn
Fig. 2.11: An FSM corresponding to the BT in Figure 2.10.
2.1.4 Creating a BT that works like a FSM
If you have a FSM design and want to convert it to a BT, the most straight forward
way is to create a State Variable available to all parts of the BT and then list all
the states of the FSM and their corresponding transitions and actions as shown in
Figure 2.13.
2.2 Subsumption Architecture
The Subsumption Architecture [4] is heavily associated with the behavior-based
robotic architecture, which was very popular in the late 1980s and 90s. This archi-
32 2 How Behavior Trees Generalize and Relate to Earlier Ideas
?
? ?
?
? ?
?
Battery
Level>10%
Recharge
Now!
Do other
Task
Open
Front
Door
Pass
through
Front Door
Close
Front
Door
Pass
through
Back Door
Open Back
Door
Smash
Back Door
Fig. 2.12: Combining the BTs above and some additional Actions, we get a flexible BT for entering
a building and performing some task.
?
?
State
Variable=1
Check
Transition
conditions
in State 1
and update
State
Variable if
needed
Execute
Action
Corre-
sponding
to State 1
?
State
Variable=N
Check
Transition
conditions
in State N
and update
State
Variable if
needed
Execute
Action
Corre-
sponding
to State N
· · ·
Fig. 2.13: Example of a straightforward translation of a FSM to a BT using a global State Variable.
tecture has been widely influential in autonomous robotics and elsewhere in real-
time AI and has found a number of successful applications [5]. The basic idea of
the Subsumpion Architecture is to have several controllers, each one implementing
a task, running in parallel. Each controller is allowed to output both its actuation
commands and a binary value that signifies if it wants to control the robot or not.
The controllers are ordered according to some priority (usually user defined), and
the highest priority controller, out of the ones that want to control the robot, has the
access to the actuators. Thus, a controller with a higher priority is able to subsume
a lower level one. Figure 2.14 shows an example of a Subsumption Architecture.
2.2.1 Advantages and disadvantages
The Subsumption Architecture has many practical advantages, in particular:
2.2 Subsumption Architecture 33
Sensors Stop if Overheated
Recharge if Needed
Do Other Tasks
S
S
S Actuators
Fig. 2.14: Example of Subsumption Architecture composed by three controllers. The controller
Stop if Overheated subsumes the controller Recharge if Needed, which subsumes the controller Do
Other Tasks.
• Easy development: The Subsumption Architecture is naturally well suited for
iterative development and testing.
• Modularity: The Subsumption Architecture connects limited, task-specific ac-
tions.
• Hierarchy: The controllers are hierarchically ordered, which makes it possible to
define high priority behaviors (e.g. safety guarantees) that override others.
The main disadvantages of the Subsumption Architecture are:
• Scalability: Designing complex action selection through a distributed system of
inhibition and suppression can be hard.
• Maintainability: Due to the lack of structure, the consequences of adding or re-
moving controllers can be hard to estimate.
2.2.2 How BTs Generalize the Subsumption
Architecture
There is a straightforward mapping from a Subsumption Architecture design to a
BT using a fallback node. If each controller in the SA is turned into a BT action,
returning running if the binary output indicates that it wants to run and failure the
rest of the time, a standard fallback composition will create an equivalent BT. As an
example we see that the structure in Fig. 2.14 is represented by the BT in Fig. 2.15.
A more formal argument using a state space representation of BTs will be given in
Section 5.2.
?
Stop if Overheated Recharge if Needed Do Other Tasks
Fig. 2.15: A BT version of the subsumption example in Figure 2.14.
34 2 How Behavior Trees Generalize and Relate to Earlier Ideas
2.3 Teleo-Reactive programs
Teleo-Reactive (TR) programs were introduced by Nils Nilsson [31] at Stanford
University in 1994 to allow engineers to define the behavior of a robotics system
that had to achieve specific goals while being responsive to changes in the environ-
ment. A TR program is composed of a set of prioritized condition-action rules that
directs the agent towards a goal state (hence the term teleo) while monitoring the
environmental changes (hence the term reactive). In its simplest form, a TR program
is described by a list of condition-action rules as the following:
c1 ? a1
c2 ? a2
· · ·
cm ? am
where the ci are conditions and ai are actions. The condition-action rules list is
scanned from the top until it finds a condition that holds, then the corresponding
action is executed. In a TR program, actions are usually durative rather than dis-
crete. A durative action is one that continues indefinitely in time (e.g. the action
move forwards is a durative action, whereas the action take one step is discrete). In
a TR program, a durative action is executed as long as its corresponding condition
remains the one with the highest priority among the ones that hold. When the high-
est priority condition that holds changes, the action executed changes accordingly.
Thus, the conditions must be evaluated continuously so that the action associated
with the current highest priority condition that holds, is always the one being exe-
cuted. A running action terminates when its corresponding condition ceases to hold
or when another condition with higher priority takes precedence. Figure 2.16 shows
an example of a TR program for navigating in a obstacle free environment.
Equal(pos,goal) ? Idle
Heading Towards (goal) ? Go Forwards
(else) ? Rotate
Fig. 2.16: Example of teleoreactive program carrying out a navigation task. If the robot is in the
goal position, the action performed is Idle (no actions executed). Otherwise if it is heading towards
the goal, the action performed is Go Forwards. Otherwise, the robot performs the action Rotate.
TR programs have been extended in several directions, including integrating TR
programs with automatic planning and machine learning [2, 42], removing redun-
dant parts of a TR program [28], and using TR programs to play robot soccer [14].
2.4 Decision Trees 35
2.3.1 Advantages and disadvantages
The main advantages of a TR program are:
• Reactive execution: TR programs enable reactive executions by continually mon-
itoring the conditions and aborting actions when needed.
• Intuitive structure: The list of condition-action rules is intuitive to design for
small problems.
The main disadvantages of a TR program are:
• Maintainability: Due to its structure (a long list of rules), adding or removing
condition-action rules is prone to cause errors when a TR program has to encode
a complex system. In those cases, a TR program takes the shape of a long list.
• Failure handling: To enable failure handling, a TR program needs to have a con-
dition that checks if an action fails.
2.3.2 How BTs Generalize Teleo-Reactive Programs
?
?
c1 a1
· · · ?
cm am
Fig. 2.17: The BT that is analogous to a given TR.
The core idea of continuously checking conditions and applying the correspond-
ing rules can be captured using a Fallback node and pairs of conditions and actions.
Thus, a general TR program can be represented in the BT of Fig. 2.17. A more for-
mal argument using a state space representation of BTs will be given in Section 5.4.
2.4 Decision Trees
A Decision Tree (DT) is a directed tree that represents a list of nested if-then clauses
used to derive decisions [37]. Leaf nodes describe decisions, conclusions, or actions
36 2 How Behavior Trees Generalize and Relate to Earlier Ideas
to be carried out, whereas non-leaf nodes describe predicates to be evaluated. Fig-
ure 2.18 shows a DT where according to some conditions, a robot will decide what
to do.
Have Task
to Do?
Task is
Urgent?
Recharge
Now!
yes no
Battery Level
? 10%?
Battery Level
? 30%?
yes no
Perform
Task!
Recharge
Now!
yes no
Perform
Task!
Recharge
Now!
yes no
Fig. 2.18: Example of DT executing a generic robotic task. The predicate are evaluated traversing
the tree in a top-down fashion.
2.4.1 Advantages and disadvantages
The main advantages of a DT are:
• Modularity: The DT structure is modular, in the sense that a sub-DT can be de-
veloped independently from the rest of the DT, and added where suitable.
• Hierarchy: DT’s structure is hierarchical, in the sense that predicates are evalu-
ated in a top-down fashion.
• Intuitive structure: It is straightforward to design and understand DTs.
The main disadvantages of a DT are:
• No information flow out from the nodes, giving an absence of failure handling
• Repetitions: To describe a reactive behavior, a given predicate must be reevalu-
ated at different depths of the tree resulting in a DT with many repetitions.
• Maintainability: Due to repetitions, if the number of outgoing arcs from a predi-
cate should change, this will affect the entire tree where such predicates appears.
2.4 Decision Trees 37
?
? Todo when
False
Predicate
Todo when
True
Predicate
Todo when
True
Todo when
False
FalseTrue
Fig. 2.19: The basic building blocs of Decision Trees are ‘If ... then ... else ...’ statements (left),
and those can be created in BTs as illustrated above (right).
?
? Recharge
Now
?
Have Task
To Do
??
?
Task is
Urgent
?
Battery
Level > 10%
Perform
Task
Recharge
Now
?
Battery
Level > 30%
Perform
Task
Recharge
Now
Fig. 2.20: A BT that is equivalent to the Decision Tree in Figure 2.18.
2.4.2 How BTs Generalize Decision Trees
A general DT can be converted into a BT using the mapping shown in Fig. 2.19.
By converting the Predicate to a Condition, letting the leaves be actions always
returning running, we can map each decision node of the DT to a small BT. Applying
the mapping to the DT of Fig. 2.18 we get the BT of Fig. 2.20. A more formal
argument using a state space representation of BTs will be given in Section 5.1. Note
that this structure requires actions always returning running, reflecting the drawback
of DTs that no information flows out of the actions
38 2 How Behavior Trees Generalize and Relate to Earlier Ideas
2.5 Advantages and Disadvantages of Behavior Trees
Having looked at how BTs relate to a set of existing control architectures we will
now take a step back and list a number of advantages and disadvantages of BTs.
2.5.1 Advantages
As described in Section 1.2 many advantages stem from BTs being both modular
and reactive. Below we list a set of advantages of BTs.
Modular: By modular, we mean the degree to which a system’s components may
be separated into building blocks, and recombined [13]. A modular system can
be designed, implemented, tested and reused one module at a time. The benefits
of modularity thus increases, the more complex a system is, by enabling a divide
and conquer approach when designing, implementing and testing.
BTs are modular, since each subtree of a BT can be seen as a module in the
above sense, with a standard interface given by the return statuses. Thus, BTs are
modular on all scales ranging from the topmost subtrees to all the leaves of the
tree.
Hierarchical organization: If a control architecture contains several levels of de-
cision making it is denoted hierarchical. The possibility of designing and ana-
lyzing structures on different hierarchical levels is important for both humans
and machines, as it enables e.g., iterative refinement and extensions of plan, see
Section 3.5.
BTs are hierarchical, since each level of a BT automatically defines a level in the
hierarchy.
Reusable code: Having reusable code is very important in any large, complex,
long-term project. The ability to reuse designs relies in an essential way on the
ability to build larger things from smaller parts, and on the independence of the
input and output of those parts from their use in the project. To enable reuse of
code, each module must interface the CA in a rigorous and well-defined fashion.
BTs enable reusable code, since given the proper implementation, any subtree
can be reused in multiple places of a BT. Furthermore, when writing the code of
a leaf node, the developer needs to just take care of returning the correct return
status which is universally predefined as either running, success, or failure. Un-
like FSMs and HFSMs, where the outgoing transitions require knowledge about
the next state, in BTs leaf nodes are developed disregarding which node is go-
ing to be executed next. Hence, the BT logic is independent from the leaf node
executions and vice versa.
Reactivity: By reactive we mean the ability to quickly and efficiently react to
changes. For unstructured environments where outcomes of actions are not cer-
tain, and the state of the world is constantly changed by external actors, plans that
2.5 Advantages and Disadvantages of Behavior Trees 39
were created offline and then executed in an open loop fashion are often likely to
fail.
BTs are reactive, since the continual generation of ticks and their tree traversal re-
sult in a closed loop execution. Actions are executed and aborted according to the
ticks’ traversal, which depends on the leaf nodes’ return statuses. Leaf nodes are
tightly connected with the environment (e.g. condition nodes evaluate the overall
system properties and action nodes return failure/success if the action failed/suc-
ceeded). Thus, BTs are highly responsive to changes in the environment.
Human readable: A readable structure is desirable for reducing the cost of devel-
opment and debugging, especially when the task is human designed. The struc-
ture should remain readable even for large systems. Human readability requires
a coherent and compact structure.
BTs are human readable due to the tree structure and modularity.
Expressive: A control architecture must be sufficiently expressive to encode a
large variety of behaviors.
BTs are at least as expressive as FSMs, see Section 2.1, the Subsumption Archi-
tecture, see Section 2.2, Teleo-reactive programs, see Section 2.3, and Decision
Trees, see Section 2.4.
Suitable for analysis: Safety critical robot applications often require an analysis
of qualitative and quantitative system properties. These properties include: safety,
in the sense of avoiding irreversible undesired behaviors; robustness, in the sense
of a large domain of operation; efficiency, in the sense of time to completion;
reliability, in the sense of success probability; and composability, in the sense on
analyzing whether properties are preserved over compositions of sub-tasks.
BTs have tools available to evaluate such system properties, see Chapters 4 and
5 below.
Suitable for automatic synthesis: In some problem instances, it is preferable that
the action ordering of a task, or a policy, is automatically synthesized using task-
planning or machine learning techniques. The CA can influence the efficiency
of such synthesis techniques (e.g. a FSM with a large number of transitions can
drastically deteriorate the speed of an algorithm that has to consider all the pos-
sible paths in the FSMs).
BTs are suitable for automatic synthesis in terms of both planning, see Sec-
tion 3.5 and learning, see [cite Learning papers].
To illustrate the advantages listed above, we consider the following simple ex-
ample.
Example 2.1. A robot is tasked to find a ball, pick it up and place it into a bin. If the
robot fails to complete the task, it should go to a safe position and wait for a human
operator. After picking up the ball (Figure 2.21a), the robot moves towards the bin
(Figure 2.21b). While moving towards the bin, an external entity takes the ball from
the robot’s gripper (Figure 2.21c) and immediately throws it in front of the robot,
where it can be seen (Figure 2.21d). The robot aborts the execution of moving and
it starts to approach the ball again.
40 2 How Behavior Trees Generalize and Relate to Earlier Ideas
(a) The robot is picking up the ball. (b) The robot moves toward the bin (far
away from the robot) with the ball in the
hand.
(c) An external entity (a human) takes the
ball from the robot gripper.
(d) The robot approaches the ball in the new
location.
Fig. 2.21: Execution stages of Example 2.1.
2.5
A
dvantages
and
D
isadvantages
ofB
ehaviorTrees
41
Find Ball Approach Ball Grasp Ball Move To Bin Place Ball
Wait for Help SuccessFailure
Ball Found Ball Close Ball Grasped Bin Reached
Ball Placed
Help OK
Help not OK
Fault Fault Fault Fault Fault
Ball Lost
Ball Lost
Ball Lost
Ball Lost
Ball Found ? Ball Far
Ball Found ? Ball Far
Ball Found ? Ball Far
Ball Found ? Ball Close ? Ball not Grasped
Ball Found ? Ball Close ? Ball not Grasped
Ball Found ? Ball Close ? Ball Grasped ? Bin not Reached
Fig. 2.22: FSM modeling the robot’s behavior in Example 2.1. The initial state has a thicker border.
42 2 How Behavior Trees Generalize and Relate to Earlier Ideas
In this example, the robot does not simply execute a pick-and-place task. It con-
tinually monitors the progress of the actions, stops whenever needed, skips planned
actions, decides the actions to execute, and responds to exogenous events. In order
to execute some actions, the robot might need to inject new actions into the plan
(e.g. the robot might need to empty the bin before placing the ball). Hence the task
requires a CA suitable for extensions. These extensions might be man made (e.g.
the robot asks the operator to update the current action policy) requiring a CA to
be human readable, or automated (e.g. using model-based reasoning) requiring a
CA to be suitable for automatic synthesis. In either case, to be able to easily extend
and modify the action policy, its representation must be modular. In addition, new
actions may subsume existing ones whenever needed (e.g. empty the bin if it is full
must be executed before place the ball). This requires a hierarchical representation
of the policy. Moreover there might be multiple different ways of carrying out a task
(e.g. picking the ball using the left hand or the right hand). The robot must be able to
decide which option is the best, requiring the CA to be suitable for analysis. Finally,
once the policy is designed, it is desirable that it can be reused in other contexts.
Most used CAs do not show characteristics suitable for the properties described
above. Take as an example a FSM modeling the behavior of the robot in Exam-
ple 2.1, depicted in Figure 2.22. As it can be seen, even for this simple example the
FSM gets fairly complex with many transitions.
2.5.2 Disadvantages
In this section we describe some disadvantages of BTs experienced by different BT
developers.
The BT engine can be complex to implement. The implementation of the BT en-
gine can get complicated using single threaded sequential programming. To guar-
antee the full functionality of BTs, the tick’s generation and traversal should be
executed in parallel with the action execution. However the BT engine only needs
to be implemented once, it can be reused, and several BT engines are available
as off the shelf software libraries.1
Checking all the conditions can be expensive. A BT needs to check several con-
ditions to implement the closed-loop task execution. In some applications this
checking is expensive or not feasible. In those cases a closed-loop execution (us-
ing any CA) presents more costs than advantages. However it is still possible
to design an open-loop task execution using BTs with memory nodes, see Sec-
tion 1.3.2.
1 C++ library: https://github.com/miccol/Behavior-Tree
ROS library: http://wiki.ros.org/behavior_tree
python library: https://github.com/futureneer/beetree
2.5 Advantages and Disadvantages of Behavior Trees 43
Sometimes a feed-forward execution is just fine. In applications where the robot
operates in a very structured environment, predictable in space and time, BTs do
not have any advantages over simpler CAs.
BTs are different from FSM. BTs, despite being easy to understand, require a
new mindset when designing a task execution. The execution is not focused on
states but on conditions and the execution is not event driven but tick driven. At
least some of the design principles described in Chapter 3 needs to be learned
and applied.
BTs are less mature. Although there is software for developing BTs, it is still far
behind the amount and maturity of the software available for e.g. FSMs.

Chapter 3
Design principles
BTs are fairly easy to understand and use, but to make full use of their potential it
can be good to be aware of a set of design principles that can be used in different
situations. In this chapter we will describe these principles using a number of ex-
amples. First, in Section 3.1, we will describe the benefit of using explicit success
conditions in sequences, then, in Section 3.2, we describe how the reactivity of a
BT can be increased by creating implicit sequences, using fallback nodes. In Sec-
tion 3.3, we show how BTs can also be designed in a way that is similar to Decision
Trees. Then, in Section 3.4, we show how safety can be improved using sequences.
Finally, in Section 3.7, we discuss the choice of granularity when designing a BT.
Note that these design principles are applicable at any level of a BT and can be
combined freely.
Thus the safety principle can be combined with an implicit sequence etc.
3.1 Improving Readability using Explicit Success
Conditions
One advantage of BTs is that the switching structure is clearly shown in the graphi-
cal representation of the tree. However, one detail that is not shown is the when the
individual actions return success and failure.
?
Unlock
Door
Open Door
Pass
through
Door
Fig. 3.1: Simple Sequence
45
46 3 Design principles
Consider the sequence in Figure 3.1. One can assume that Unlock Door returns
success when it has unlocked the door, but what if it is called when the door is al-
ready unlocked? Depending on the implementation it might either return success
immediately, or actually try to unlock the door again, with the possibility of re-
turning failure if the key cannot be turned further. A similar uncertainty holds re-
garding the implementation of Open Door (what if the door is already open?) and
Pass through Door. To address this problem, and remove uncertainties regarding the
implementation, explicit success conditions can be included in the BT.
?
?
Door
Unlocked
Unlock
Door
?
Door
Open
Open
Door
?
Agent Has
Passed
Pass
through
Door
Fig. 3.2: Sequence with explicit success conditions. Note how each action is paired with a condition
through a fallback node, making the success condition of the pair explicit.
In Figure 3.2, the BT from Figure 3.1 has been extended to include explicit suc-
cess conditions. These conditions are added in a pair with the corresponding action
using a Fallback node. Now, if the door is already unlocked and open, the two first
conditions of Figure 3.2 will return Success, the third will return Failure, and the
agent will proceed to execute the action Pass through Door.
3.2 Improving Reactivity using Implicit Sequences
It turns out that we can improve the reactivity of the BT in Figure 3.2 even further,
using the fact that BTs generalize the Teleo-reactive approach, see Section 2.3.2.
Consider the case when the agent has already passed the door, but the door is closed
behind it. The BT in Figure 3.2 would then proceed to unlock the door, open it, and
then notice that it had already passed it and return success.
?
?
Agent Has
Passed
Door
Open
Pass
through
Door
?
Door
Unlocked
Open Door
?
Has Key Unlock
Door
Fig. 3.3: An Implicit Sequence is constructed using a fallback node, reversing the order of the
actions and pairing them with appropriate preconditions.
3.4 Improving Safety using Sequences 47
The key observation needed to improve reactivity is to realize that the goal is to
get through the door, and that the other actions are just means to get to that goal. In
the BT in Figure 3.3 we have reversed the order of the actions in order the check the
goal state first. We then changed fallbacks to sequences and vice versa, and finally
changed the conditions. Now, instead of checking outcomes, or success conditions
as we did in Figure 3.2, we check preconditions, conditions needed to execute the
corresponding actions, in Figure 3.3. First the BT checks if the agent has passed the
door, if so it returns success. If not, it proceeds to check if the door is open, and if so
passes through it. If neither of the previous conditions are satisfied, it checks if the
door is unlocked, and if so starts to open it. As a final check, if nothing else returns
success, it checks if it has the key to the door. If it does, it tries to open it, if not it
returns failure.
The use of implicit sequences is particularly important in cases where the agent
needs to undo some of its own actions, such as closing a door after passing it. A
systematic way of creating implicit sequences is to use back chaining, as described
in Section 3.5.
3.3 Handling Different Cases using a Decision Tree
Structure
Sometimes, a reactive switching policy can be easily described in terms of a set of
cases, much like a Decision Tree. Then, the fact that BTs generalize Decision Trees
can be exploited, see Section 2.4.2.
A simple Pac-Man example can be found in Figure 3.4. The cases are separated
by the two conditions Ghost Close and Ghost Scared. If no ghost is close, Pac-Man
continues to eat pills. If a ghost is close, the BT checks the second condition, Ghost
Scared, which turns true if Pac-Man eats a Power Pill. If the ghost is scared, Pac-
Man chases it, if not, Pac-Man avoids the Ghost.
3.4 Improving Safety using Sequences
In some agents, in particular robots capable of performing irreversible actions such
as damaging equipment, it is very important to be able to guarantee that some sit-
uations will never occur. These unwanted situations might be as simple as failing
to reach the recharging station before running out of battery, or as serious as falling
down a staircase and hurting someone.
A sequence node can be used to guarantee safety, as shown in Fig. 3.5. Looking
closer at the BT in Fig. 3.5 we see that it will probably lead to an unwanted chat-
tering behavior. It will recharge until it reaches just over 20% and then start doing
Main Task, but the stop as soon as the battery is back at 20%, and possibly end up
48 3 Design principles
?
Eat Pills?
Ghost
Close
?
Avoid
Ghost
?
Chase
Ghost
Ghost
Scared
Fig. 3.4: Simple Pac-Man example using a DT structure.
?
?
Do Main
Task
Battery
Level > 20 %
Recharge
Battery
Fig. 3.5: A BT that is guaranteed not to run out of batteries, as long as Main Task keeps the robot
close enough to the recharging station so that 20% of battery will be enough to travel back.
chattering i.e. quickly switching between the two tasks. The solution is to make sure
that once recharging, the robot waits until the battery is back at 100%. This can be
achieved by the BT in Fig 3.6.
?
?
Do Main
Task
Battery
Level > 20 %
and not
Recharging
Recharge
Battery
Fig. 3.6: By changing the condition in Fig. 3.5 the robot now keeps recharging until the Battery
level reaches 100%.
3.5 Creating Deliberative BTs using Backchaining 49
3.5 Creating Deliberative BTs using Backchaining
BT can also be used to create deliberative agents, where the actions are carried out
in order to reach a specific goal. We will use an example to see how this is done.
Imagine we want the agent to end up inside a house. To make that goal explicit, we
create the trivial BT in Figure 3.7, with just a single condition checking if the goal
is achieved or not.
Is Inside
House
Fig. 3.7: A BT composed of a single conditions checking if the goal is achieved.
Now imagine we have a set of small BTs such as the ones in Figs. 3.8 and 3.9,
each on the format of the general Postcondition-Precondition-Action (PPA) BT in
Figure 3.11.
?
Is Inside
House
?
Go InsideDoor is
Open
Fig. 3.8: PPA for achieving the postcondition Is Inside House. If the postcondition is not satisfied
already, the BT checks the precondition Door is Open, if so it executes the action Go Inside.
If we have such a set, be can work our way backwards from the goal (backchain-
ing) by replacing preconditions with PPAs having the corresponding postcondition.
Thus replacing the single condition in Figure 3.7 with the PPA of Figure 3.8 we
get Figure 3.8. More interestingly, if we replace the precondition Door is Open in
Figure 3.8 with the PPA of Figure 3.9 we get the BT of Figure 3.10
Thus we can iteratively build a deliberative BT by applying Algorithm 4. Look-
ing at the BT in Figure 3.10 we note that it first checks if the agent Is Inside House,
it so it returns Success. If not it checks if Door is Open, and if it is, it proceeds to
Go Inside. If not it checks if Door Unlocked and correspondingly executes Open
Door. Else it checks if Door is Weak, and it Has Crowbar and proceeds to Brake
Door Open if that is the case. Else it returns Failure. If an action is executed it might
either succeed, which will result in a new condition being satisfied and another ac-
tion being executed until the task is finished, or it might fail. If Go Inside fails, the
50 3 Design principles
?
Door is
Open
?
Open DoorDoor is
Unlocked
?
Brake
Door Open
Door is
Weak
Has
Crowbar
Fig. 3.9: PPA for achieving the postcondition Is Door is Open. If the postcondition is not satisfied,
the BT checks the first precondition Door is Unlocked, if so it executes the action Open Door, if not
it checks the second set of preconditions, starting with Door is Weak, if so it checks Has Crowbar,
if both are satisfied it executes Brake Door Open.
Algorithm 4: Pseudocode of Backchaining Algorithm
Data: Set of Goal Conditions Ci, and a set of PPAs
Result: A reactive BT working to achieve the Cis
1 Replace all Ci with PPAs having Ci as postcondition;
2 do
3 successively replace the preconditions of a PPA with other complete PPA having the
corresponding condition as postcondition, and therefore including at leas one action to
achieve this condition ;
4 while until BT returns Running or Success;
?
Is Inside
House
?
Go Inside?
Door is
Open
?
Open DoorDoor is
Unlocked
?
Brake
Door Open
Door is
Weak
Has
Crowbar
Fig. 3.10: The result of replacing Door is Open in Figure 3.8 with the PPA of Figure 3.9.
whole BT returns failure, but if Open Door failes, the conditions Door is Weak and
Has Crowbar are checked.
In general, we let the PPA have the form of Figure 3.11, with one postcondition
C that can be achieved by either one of set of actions Ai, each of these action are
combined in a sequence with its corresponding list of preconditions Ci j, and these
3.6 Creating Un-Reactive BTs using Memory Nodes 51
?
C
?
A1C11 C12
?
A2C21 C22
Fig. 3.11: General format of a Postcondition-Precondition-Action (PPA) BT. The Postcondition C
can be achieved by either one of actions A1 or A2, which have Preconditions C1i and C2i respec-
tively.)
action precondition sequences are fallbacks for achieving the same objective. We
see that from an efficiency point of view it makes sense to put actions that are most
likely to succeed first (to avoid unnecessary failures) and check preconditions that
are most likely to fail first (to quickly move on to the next fallback option).
3.6 Creating Un-Reactive BTs using Memory Nodes
As mentioned is Section 1.3.2, sometimes a child, once executed, does not need to
be re-executed for the whole execution of a task. Control flow nodes with mem-
ory are used to simplify the design of a BT avoiding the unwanted re-execution of
some nodes. The use of nodes with memory is advised exclusively for those cases
where there is no unexpected event that will undo the execution of the sub-tree in a
composition with memory, as in Example 3.1 below.
Example 3.1 (Nodes with Memory). Consider the behavior of an industrial manip-
ulator in a production line. That has to pick, move, and place objects. The robot’s
actions are carried out in a fixed workspace, with high precision. Human operators
make sure that nothing on the line changes. If they need a change in the line, the
software is manually updated accordingly. In this example the robot operates in a
structured environment that is fully predictable in space and time. In this case we
can disregard any unexpected change letting us describing the desired behavior by
a sequence with memory of pick and place as in Figure 3.12. In this scenario, after
picking we can be sure that the object does not slips out of the robot’s grippers.
Hence while the robot is moving the object, the BT does not need to check if the
object is still picked.
52 3 Design principles
??
Pick
Object
Move
Object
Place
Object
Fig. 3.12: Example of a Un-Reactive sequence composition of the behaviors pick,move, and place.
3.7 Choosing the Proper Granularity of a BT
In any modular design, the choice of the granularity of the modules needs to be de-
cided on. In a BTs framework, this is translated into the choice of what to represent
as a leaf node (single action or condition) and what to represent as a BT. In BTs, in
general, there are two reasons behind encoding a behavior inside a leaf node:
• Module to be re-used: It is advisable to aggregate a behavior in a leaf node when-
ever that behavior has to he reused in different parts of the tree or in different
projects. As in Example 3.2 below.
• Modules may have to be re-executed due to unexpected changes in the environ-
ment: It is advisable to separate a behavior in different sub-behaviors whenever
the execution of a sub-behavior might be undone by unexpected uncontrollable
changes (e.g. environmental changes) as in Example 3.3 below. In that case, we
do not separate the different steps of assemble object as we do not need to ac-
count for any affecting unexpected changes during the execution of the different
steps.
Example 3.2 (Re-use). Consider the BT in Figure 3.13 describing the behavior of a
humanoid robot. The actions sit and stand are re-used in different parts of the tree.
Example 3.3 (Re-execution needed).
Consider an assembly task for an industrial robot that coexists in a semi-
structured environment with human workers. The tasks to perform are pick object,
assemble object, and place object. A closed-loop execution of this task can be rep-
resented with the BT in Figure 3.14. Note that the BT can reactively handle the
unexpected changes due to the human worker in the line such as: the worker picks
up the object that the robot is trying to reach, the object slips out from the robots
grippers while the robot is placing it, etc. If we had instead chosen to aggregrate
the actions pick object, assemble object, and place object into a single action we
would lose reactiveness when, for example, the robot has to re-pick and assembled
object slept out from the robot’s grippers. With a single action the robot will try to
re-assemble an assembled object.
The advice above should give the designer an idea on how to reach a balanced
BT that is neither too sparse nor too compact. A sparse BT might be unreasonably
3.7 Choosing the Proper Granularity of a BT 53
?
?
Toe Bumper
Pressed
?
Say
Ouch
Back Off
0.2m
Self Protection
?
?
?
I Know
What to Do
Ask What
to Do
User Interaction
?
New User
Suggestion
Set Current
Activity
Activity Manager
?
?
Activity Sit Sit
?
Activity
Ball Game
?
Activity
Stand Up
Stand
Up
?
Activity Say
Goodbye
?
Activity
Sleep
Go To
Sleep
?
?
?
Ball
Close
Approach
Ball
?
Ball
Grasped
Grasp
Ball
Throw
Ball
Track
Ball
Ball Game ?
Say
Goodbye
Wave
Hand
Ball Game
Fig. 3.13: Robot activity manager
?
?
Object
Picked
Pick
Object
?
Object
Assembled
Assemble
Object
?
Object
Placed
Place
Object
Fig. 3.14: Closed loop example
complex. While a compact BT may risk being not sufficiently reactive, by executing
too many operations in a feed-forward fashion, losing one main advantage of BTs.

Chapter 4
Analysis of Efficiency, Safety, and Robustness
Autonomous agents will need to be efficient, robust, and reliable in order to be used
on a large scale. In this chapter, we present a mathematical framework for analyzing
the these properties for a BT (4.1). The analysis includes efficiency (4.2), in terms of
execution time’s bound; robustness (4.2), in terms of capability to operate in large
domains; and safety (4.3), in terms of avoiding some particular parts of the state
space. Some of the results of this chapter were previously published in the journal
paper [9].
4.1 Statespace Formulation of BTs
In this section we present a new formulation of BTs. The new formulation is more
formal, and will allow us to analyze how properties are preserved over modular
compositions of BTs. In the functional version, the tick is replaced by a recursive
function call that includes both the return status, the system dynamics and the system
state.
Definition 4.1 (Behavior Tree). A BT is a three-tuple
Ti = { fi,ri,? t}, (4.1)
where i?N is the index of the tree, fi :Rn?Rn is the right hand side of an ordinary
difference equation, ? t is a time step and ri : Rn? {R,S ,F} is the return status
that can be equal to either Running (R), Success (S ), or Failure (F ). Let the Run-
ning/Activation region (Ri), Success region (Si) and Failure region (Fi) correspond
to a partitioning of the state space, defined as follows:
Ri = {x : ri(x) = R} (4.2)
Si = {x : ri(x) = S } (4.3)
Fi = {x : ri(x) = F}. (4.4)
55
56 4 Analysis of Efficiency, Safety, and Robustness
Finally, let xk = x(tk) be the system state at time tk, then the execution of a BT Ti is
a standard ordinary difference equation
xk+1 = fi(xk), (4.5)
tk+1 = tk +? t. (4.6)
The return status ri will be used when combining BTs recursively, as explained
below.
Assumption 1 From now on we will assume that all BTs evolve in the same contin-
uous space Rn using the same time step ? t.
Remark 4.1. It is often the case, that different BTs, controlling different vehicle sub-
systems evolving in different state spaces, need to be combined into a single BT.
Such cases can be accommodated in the assumption above by letting all systems
evolve in a larger state space, that is the Cartesian product of the smaller state spaces.
Definition 4.2 (Sequence compositions of BTs). Two or more BTs can be com-
posed into a more complex BT using a Sequence operator,
T0 = Sequence(T1,T2).
Then r0, f0 are defined as follows
If xk ? S1 (4.7)
r0(xk) = r2(xk) (4.8)
f0(xk) = f2(xk) (4.9)
else
r0(xk) = r1(xk) (4.10)
f0(xk) = f1(xk). (4.11)
T1 and T2 are called children of T0. Note that when executing the new BT, T0 first
keeps executing its first child T1 as long as it returns Running or Failure. The second
child is executed only when the first returns Success, and T0 returns Success only
when all children have succeeded, hence the name Sequence, just as the classical
definition of Sequences in Algorithm 1 of Section 1.3. For notational convenience,
we write
Sequence(T1,Sequence(T2,T3)) = Sequence(T1,T2,T3), (4.12)
and similarly for arbitrarily long compositions.
Definition 4.3 (Fallback compositions of BTs). Two or more BTs can be com-
posed into a more complex BT using a Fallback operator,
4.1 Statespace Formulation of BTs 57
T0 = Fallback(T1,T2).
Then r0, f0 are defined as follows
If xk ? F1 (4.13)
r0(xk) = r2(xk) (4.14)
f0(xk) = f2(xk) (4.15)
else
r0(xk) = r1(xk) (4.16)
f0(xk) = f1(xk). (4.17)
Note that when executing the new BT, T0 first keeps executing its first child T1
as long as it returns Running or Success. The second child is executed only when
the first returns Failure, and T0 returns Failure only when all children have tried,
but failed, hence the name Fallback, just as the classical definition of Fallbacks in
Algorithm 2 of Section 1.3.
For notational convenience, we write
Fallback(T1,Fallback(T2,T3)) = Fallback(T1,T2,T3), (4.18)
and similarly for arbitrarily long compositions.
Parallel compositions only make sense if the BTs to be composed control sepa-
rate parts of the state space, thus we make the following assumption.
Assumption 2 Whenever two BTs T1,T2 are composed in parallel, we assume that
there is a partition of the state space x = (x1,x2) such that f1(x) = ( f11(x), f12(x))
implies f12(x) = x and f2(x) = ( f21(x), f22(x)) implies f21(x) = x (i.e. the two BTs
control different parts of the system).
Definition 4.4 (Parallel compositions of BTs). Two or more BTs can be composed
into a more complex BT using a Parallel operator,
T0 = Parallel(T1,T2).
Let x = (x1,x2) be the partitioning of the state space described in Assumption 2,
then f0(x) = ( f11(x), f22(x)) and r0 is defined as follows
58 4 Analysis of Efficiency, Safety, and Robustness
If M = 1
r0(x) = S If r1(x) = S ? r2(x) = S (4.19)
r0(x) = F If r1(x) = F ? r2(x) = F (4.20)
r0(x) = R else (4.21)
If M = 2
r0(x) = S If r1(x) = S ? r2(x) = S (4.22)
r0(x) = F If r1(x) = F ? r2(x) = F (4.23)
r0(x) = R else (4.24)
4.2 Efficiency and Robustness
In this section we will show how some aspects of time efficiency and robustness
carry across modular compositions of BTs. This result will then enable us to con-
clude, that if two BTs are efficient, then their composition will also be efficient, if
the right conditions are satisfied. We also show how the Fallback composition can
be used to increase the region of attraction of a BT, thereby making it more robust
to uncertainties in the initial configuration.
Note that, as in [6], by robustness we mean large regions of attraction. We do not
investigate e.g. disturbance rejection, or other forms of robustness.
Many control problems, in particular in robotics, can be formulated in terms of
achieving a given goal configuration in a way that is time efficient and robust with
respect to the initial configuration. Since all BTs return either Success, Failure or
Running, the definitions below will include a finite time, at which Success must be
achieved.
In order to formalize the discussion above, we say that efficiency can be measured
by the size of a time bound ? in Definition 4.5 and robustness can be measured by
the size of the region of attraction R? in the same definition.
Definition 4.5 (Finite Time Successful). A BT is Finite Time Successful (FTS)
with region of attraction R?, if for all starting points x(0) ? R? ? R, there is a time ? ,
and a time ? ?(x(0)) such that ? ?(x) ? ? for all starting points, and x(t) ? R? for all
t ? [0,? ?) and x(t) ? S for t = ? ?)
As noted in the following Lemma, exponential stability implies FTS, given the right
choices of the sets S,F,R.
Lemma 4.1 (Exponential stability and FTS). A BT for which xs is a globally ex-
ponentially stable equilibrium of the execution (4.5), and S ? {x : ||x? xs|| ? ?},
? > 0, F = /0, R = Rn \S, is FTS.
Proof. Global exponential stability implies that there exists a > 0 such that ||x(k)?
xs|| ? e?ak for all k. Then, for each ? there is a time ? such that ||x(k)?xs|| ? e?a? <
? , which implies that there is a ? ? < ? such that x(? ?) ? S and the BT is FTS.
4.2 Efficiency and Robustness 59
We are now ready to look at how these properties extend across compositions of
BTs.
Lemma 4.2. (Robustness and Efficiency of Sequence Compositions) If T1,T2 are
FTS, with S1 = R?2 ? S2, then T0 = Sequence(T1,T2) is FTS with ?0 = ?1 + ?2,
R?0 = R
?
1?R?2 and S0 = S1?S2 = S2.
Proof. First we consider the case when x(0) ? R?1. Then, as T1 is FTS, the state
will reach S1 in a time k1 < ?1, without leaving R?1. Then T2 starts executing, and
will keep the state inside S1, since S1 = R?2 ? S2. T2 will then bring the state into
S2, in a time k2 < ?2, and T0 will return Success. Thus we have the combined time
k1 + k2 < ?1 + ?1.
If x(0) ? R?2, T1 immediately returns Success, and T2 starts executing as above.
The Lemma above is illustrated in Figure 4.2, and Example 4.1 below.
?
Open
Front
Door
Pass
through
Door
Fig. 4.1: A Sequence is used to to create an Enter Through Front Door BT. Passing the door is
only tried if the opening action succeeds. Sequences are denoted by a white box with an arrow.
R?1
R?1
S1
S1
R?2 S2
Fig. 4.2: The sets R?1,S1,R
?
2,S2 of Example 4.1 and Lemma 4.2.
60 4 Analysis of Efficiency, Safety, and Robustness
Example 4.1. Consider the BT in Figure 4.1. If we know that Open Front Door is
FTS and will finish in less than ?1 seconds, and that Pass through Door is FTS
and will finish in less than ?2 seconds. Then, as long as S1 = R?2 ? S2, Lemma 4.2
states that the combined BT in Figure 4.1 is also FTS, with an upper bound on the
execution time of ?1+?2. Note that the condition S1 =R?2?S2 implies that the action
Pass through Door will not make the system leave S1, by e.g. accidentally colliding
with the door and thereby closing it without having passed through it.
The result for Fallback compositions is related, but with a slightly different con-
dition on Si and R?j. Note that this is the theoretical underpinning of the design
principle Implicit Sequences described in Section 3.2.
Lemma 4.3. (Robustness and Efficiency of Fallback Compositions) If T1,T2 are
FTS, with S2 ? R?1 and R1 = R1, then T0 = Fallback(T1,T2) is FTS with ?0 =
?1 + ?2, R?0 = R
?
1?R?2 and S0 = S1.
Proof. First we consider the case when x(0) ? R?1. Then, as T1 is FTS, the state
will reach S1 before k = ?1 < ?0, without leaving R?1. If x(0) ? R?2 \ R?1, T2 will
execute, and the state will progress towards S2. But as S2 ? R?1, x(k1) ? R?1 at some
time k1 < ?2. Then, we have the case above, reaching x(k2) ? S1 in a total time of
k2 < ?1 + k1 < ?1 + ?2.
The Lemma above is illustrated in Figure 4.3, and Example 4.2 below.
R1
F1
R1S1
S2
R2
F2
R2
Rn
Fig. 4.3: The sets S1,F1,R1 (solid boundaries) and S2,F2,R2 (dashed boundaries) of Example 4.2
and Lemma 4.3.
Remark 4.2. As can be noted, the necessary conditions in Lemma 4.2, includ-
ing S1 = R?2 ? S2 might be harder to satisfy than the conditions of Lemma 4.3, in-
cluding S2 ? R?1. Therefore, Lemma 4.3 is often preferable from a practical point of
view, e.g. using implicit sequences as shown below.
4.2 Efficiency and Robustness 61
?
Open
Front
Door
Pass
through
Door
Fig. 4.4: An Implicit Sequence created using a Fallback, as described in Example 4.2 and Lemma
4.3.
Example 4.2. This example will illustrate the design principle Implicit sequences,
see Section 3.2. Consider the BT in Figure 4.4. During execution, if the door is
closed, then Pass through Door will fail and Open Front Door will start to execute.
Now, right before Open Front Door returns Success, the first action Pass through
Door (with higher priority) will realize that the state of the world has now changed
enough to enable a possible success and starts to execute, i.e. return Running instead
of Failure. The combined action of this BT will thus make the robot open the door
(if necessary) and then pass through if.
Thus, even though a Fallback composition is used, the result is sometimes a se-
quential execution of the children in reverse order (from right to left). Hence the
name Implicit sequence.
The example above illustrates how we can increase the robustness of a BT. If
we want to be able to handle more diverse situations, such as a closed door, we
do not have to make the door passing action more complex, instead we combine it
with another BT that can handle the situation and move the system into a part of the
statespace that the first BT can handle. The sets S0,F0,R0 and f0 of the combined BT
are shown in Figure 4.5, together with the vector field f0(x)?x. As can be seen, the
combined BT can now move a larger set of initial conditions to the desired region
S0 = S1.
Lemma 4.4. (Robustness and Efficiency of Parallel Compositions) If T1,T2 are
FTS, then T0 = Parallel(T1,T2) is FTS with
If M = 1
R?0 = {R?1?R?2}\{S1?S2} (4.25)
S0 = S1?S2 (4.26)
?0 = min(?1,?2) (4.27)
If M = 2
R?0 = {R?1?R?2}\{S1?S2} (4.28)
S0 = S1?S2 (4.29)
?0 = max(?1,?2) (4.30)
62 4 Analysis of Efficiency, Safety, and Robustness
R0
F0
S0
F0
R0
Rn
f0 = f1
f0 = f2
Fig. 4.5: The sets S0,F0,R0 and the vector field ( f0(x)? x) of Example 4.2 and Lemma 4.3.
Proof. The parallel composition executes T1 and T2 independently. If M = 1 the
parallel composition returns success if either T1 or T2 returns success, thus ?0 =
min(?1,?2). It returns running if either T1 or T2 returns running and the other does
not return success. If M = 2 the parallel composition returns success if and only if
both T1 and T2 return success, thus ?0 = max(?1,?2). It returns running if either T1
or T2 returns running and the other does not return failure.
4.3 Safety
In this section we will show how some aspects of safety carry across modular com-
positions of BTs. The results will enable us to design a BTs to handle safety guar-
antees and a BT to handle the task execution separately.
In order to formalize the discussion above, we say that safety can be measured by
the ability to avoid a particular part of the statespace, that we for simplicity denote
the Obstacle Region.
Definition 4.6 (Safe). A BT is Safe, with respect to the obstacle region O ? Rn,
and the initialization region I ? R, if for all starting points x(0) ? I, we have that
x(t) 6? O, for all t ? 0.
In order to make statements about the safety of composite BTs we also need the
following definition.
Definition 4.7 (Safeguarding). A BT is Safeguarding, with respect to the step
length d, the obstacle region O ? Rn, and the initialization region I ? R, if it is
4.3 Safety 63
safe, and FTS with region of attraction R? ? I and a success region S, such that I
surrounds S in the following sense:
{x ? X ? Rn : inf
s?S
||x? s|| ? d} ? I, (4.31)
where X is the reachable part of the state space Rn.
This implies that the system, under the control of another BT with maximal states-
pace steplength d, cannot leave S without entering I, and thus avoiding O, see
Lemma 4.5 below.
Example 4.3. To illustrate how safety can be improved using a Sequence composi-
tion, we consider the UAV control BT in Figure 4.6. The sets Si,Fi,Ri are shown
in Figure 4.7. As T1 is Guarrantee altitude above 1000 ft, its failure region F1 is a
small part of the state space (corresponding to a crash) surrounded by the running
region R1 that is supposed to move the UAV away from the ground, guaranteeing a
minimum altitude of 1000 ft. The success region S1 is large, every state sufficiently
distant from F1. The BT that performs the mission, T2, has a smaller success region
S2, surrounded by a very large running region R2, containing a small failure region
F2. The function f0 is governed by Equations (4.9) and (4.9) and is depicted in form
of the vector field ( f0(x)? x) in Figure 4.8.
?
Guarantee
Altitude >
1000 ft
Perform
Mission
Fig. 4.6: The Safety of the UAV control BT is Guaranteed by the first Action.
The discussion above is formalized in Lemma 4.5 below.
Lemma 4.5 (Safety of Sequence Compositions). If T1 is safeguarding, with re-
spect to the obstacle O1 initial region I1, and margin d, and T2 is an arbitrary BT
with maxx ||x? f2(x)|| < d, then the composition T0 = Sequence(T1,T2) is Safe
with respect to O1 and I1.
Proof. T1 is safeguarding, which implies that T1 is safe and thus any trajectory
starting in I1 will stay out of O1 as long as T1 is executing. But if the trajectory
reaches S1, T2 will execute until the trajectory leaves S1. We must now show that
the trajectory cannot reach O1 without first entering I1. But any trajectory leaving S1
must immediately enter I1, as the first state outside S1 must lie in the set {x ? Rn :
infs?S1 ||x? s|| ? d} ? I1 due to the fact that for T2, ||x(k)? x(k+ 1)|| = ||x(k)?
f2(x(k))||< d.
64 4 Analysis of Efficiency, Safety, and Robustness
R1S1
F1F2
S2R2
R2
Rn
Fig. 4.7: The sets S1,F1,R1 (solid boundaries) and S2,F2,R2 (dashed boundaries) of Example 4.3
and Lemma 4.5.
R0
R0
F0F0
S0
Rn
f0 = f1
f0 = f2
Fig. 4.8: The sets S0,F0,R0 and the vector field ( f0(x)? x) of Example 4.3 and Lemma 4.5.
We conclude this section with a discussion about undesired chattering in switch-
ing systems.
The issue of undesired chattering, i.e., switching back and fourth between differ-
ent sub-controllers, is always an important concern when designing switched control
systems, and BTs are no exception. As is suggested by the right part of Figure 4.8,
chattering can be a problem when vector fields meet at a switching surface.
Although the efficiency of some compositions can be computed using Lemma
4.2 and 4.3 above, chattering can significantly reduce the efficiency of others. In-
spired by [11] the following result can give an indication of when chattering is to be
expected.
Let Ri and R j be the running region of Ti and T j respectively. We want to study
the behavior of the system when a composition of Ti and T j is applied. In some
cases the execution of a BT will lead to the running region of the other BT and vice-
versa. Then, both BTs are alternatively executed and the state trajectory chatters
4.3 Safety 65
on the boundary between Ri and R j. We formalize this discussion in the following
lemma.
Lemma 4.6. Given a composition T0 = Sequence(T1,T2), where fi depend on ? t
such that || fi(x)? x|| ? 0 when ? t ? 0. Let s : Rn ? R be such that s(x) = 0 if
x ? ?S1?R2, s(x)< 0 if x ? interior(S1)?R2, s(x)> 0 if x ? interior(Rn \S1)?R2,
and let
?i(x) = (
? s
?x
)T ( fi(x)? x).
Then, x ? ?S1 is chatter free, i.e., avoids switching between T1 and T2 at every
timestep, for small enough ? t, if ?1(x)< 0 or ?2(x)> 0.
Proof. When the condition holds, the vector field is pointing outwards on at least
one side of the switching boundary.
Note that this condition is not satisfied on the right hand side of Figure 4.8. This
concludes our analysis of BT compositions.
66 4 Analysis of Efficiency, Safety, and Robustness
4.4 Examples
In this section we show some BTs of example and we analyze their properties.
Section 4.4.1 Illustrates how to analyze robustness and efficiency of a robot exe-
cuting a generic task. Section 4.3 illustrates to compute safety using the functional
representation of Section 4.1. Section 6.4 illustrate how to compute the performance
estimate of a given BT. Finally, Section 4.4.3 illustrate the properties above of a
complex BT .
All BTs were implemented using the ROS BT package.1 A video showing the
executions of the BTs used in Sections 4.4.2-4.4.1 is publicly available. 2
4.4.1 Robustness and Efficiency
To illustrate Lemma 4.3 we look at the BT of Figure 4.9 controlling a NAO robot.
The BT has three sub-trees Walk Home, which is first tried, if that fails (the robot
cannot walk if it is not standing up) it tries the sub-tree Sit to Stand, and if that fails,
it tries Lie down to Sit Up. Thus, each fallback action brings the system into the
running region of the action to its left, e.g., the result of Sit to Stand is to enable the
execution of Walk Home.
Example 4.4. Let xk = (x1k,x2k) ?R2, where x1k ? [0,0.5] is the horizontal position
of the robot head and x2k ? [0,0.55] is vertical position (height above the floor) of
the robot head. The objective of the robot is to get to the destination at (0,0.48).
?
Walk
Home
Sit to
Stand
Lie Down
to Sit Up
Fig. 4.9: The combination T3=Fallback(T4,T5,T6) increases robustness by increasing the region
of attraction.
First we describe the sets Si,Fi,Ri and the corresponding vector fields of the
functional representation. Then we apply Lemma 4.3 to see that the combination
does indeed improve robustness. For this example ? t = 1s.
For Walk Home, T4, we have that
1 library available at http://wiki.ros.org/behavior_tree.
2 https://youtu.be/fH7jx4ZsTG8
4.4 Examples 67
S4 = {x : x1 ? 0} (4.32)
R4 = {x : x1 6= 0,x2 ? 0.48} (4.33)
F4 = {x : x1 6= 0,x2 < 0.48} (4.34)
f4(x) =
(
x1?0.1
x2
)
(4.35)
that is, it runs as long as the vertical position of the robot head, x2, is at least 0.48m
above the floor, and moves towards the origin with a speed of 0.1m/s. If the robot is
not standing up x2 < 0.48m it returns Failure. A phase portrait of f4(x)?x is shown
in Figure 4.10. Note that T4 is FTS with the completion time bound ?4 = 0.5/0.1 =
10 and region of attraction R?4 = R4.
0 0.1 0.2 0.3 0.4 0.5
0
0.1
0.2
0.3
0.4
0.5
x1 [m]
x 2
 [m
]
Fig. 4.10: The Action Walk Home, keeps the head around x2 = 0.5 and moves it towards the
destination x1 = 0.
For Sit to Stand, T5, we have that
S5 = {x : 0.48? x2} (4.36)
R5 = {x : 0.3? x2 < 0.48} (4.37)
F5 = {x : x2 < 0.3} (4.38)
f5(x) =
(
x1
x2 +0.05
)
(4.39)
that is, it runs as long as the vertical position of the robot head, x2, is in between
0.3m and 0.48m above the floor. If 0.48? x2 the robot is standing up, and it returns
Success. If x2 ? 0.3 the robot is lying down, and it returns Failure. A phase portrait
of f5(x)? x is shown in Figure 4.11. Note that T5 is FTS with the completion time
bound ?5 = ceil(0.18/0.05) = ceil(3.6) = 4 and region of attraction R?5 = R5
68 4 Analysis of Efficiency, Safety, and Robustness
0 0.1 0.2 0.3 0.4 0.5
0
0.1
0.2
0.3
0.4
0.5
x1 [m]
x 2
 [m
]
Fig. 4.11: The Action Sit to Stand moves the head upwards in the vertical direction towards stand-
ing.
For Lie down to Sit Up, T6, we have that
S6 = {x : 0.3? x2} (4.40)
R6 = {x : 0? x2 < 0.3} (4.41)
F6 = /0 (4.42)
f6(x) =
(
x1
x2 +0.03
)
(4.43)
that is, it runs as long as the vertical position of the robot head, x2, is below 0.3m
above the floor. If 0.3 ? x2 the robot is sitting up (or standing up), and it returns
Success. If x2 < 0.3 the robot is lying down, and it returns Running. A phase portrait
of f6(x)? x is shown in Figure 4.12. Note that T6 is FTS with the completion time
bound ?6 = 0.3/0.03 = 10 and region of attraction R?6 = R6
Informally, we can look at the phase portrait in Figure 4.13 to get a feeling for
what is going on. As can be seen the fallbacks make sure that the robot gets on its
feet and walks back, independently of where it started in {x : 0 < x1 ? 0.5,0? x2 ?
0.55}.
Formally, we can use Lemma 4.3 to compute robustness in terms of the region of
attraction R?3, and efficiency in terms of bounds on completion time ?3. The results
are described in the following Lemma.
Lemma 4.7. Given T4,T5,T6 defined in Equations (4.32)-(4.43).
The combined BT T3 = Fallback(T4,T5,T6) is FTS, with region of attraction
R?3 = {x : 0 < x1 ? 0.5,0? x2 ? 0.55}, completion time bound ?3 = 24.
Proof. We note that T4,T5,T6 are FTS with ?4 = 10, ?5 = 4, ?6 = 10 and regions of
attractions equal to the running regions R?i = Ri. Thus we have that S6 ? R5 = R?5 and
4.4 Examples 69
0 0.1 0.2 0.3 0.4 0.5
0
0.1
0.2
0.3
0.4
0.5
x1 [m]
x 2
 [m
]
Fig. 4.12: The Action Lie down to Sit Up moves the head upwards in the vertical direction towards
sitting.
0 0.1 0.2 0.3 0.4 0.5
0
0.1
0.2
0.3
0.4
0.5
x1 [m]
x 2
 [m
]
Fig. 4.13: The combination Fallback(T4,T5,T6) first gets up, and then walks home.
S5 ? R4 = R?4. Applying Lemma 4.3 twice now gives the desired results, R?3 = R?4?
R?5?R?6 = {x : 0? x1? 0.5,0? x2? 0.55} and ?3 = ?4+?5+?6 = 10+4+10= 24.
4.4.2 Safety
To illustrate Lemma 4.5 we choose the BT of Figure 4.14. The idea is that the first
sub-tree in the sequence (named Guarantee Power Supply) is to guarantee that the
70 4 Analysis of Efficiency, Safety, and Robustness
combination does not run out of power, under very general assumptions about what
is going on in the second BT.
First we describe the sets Si,Fi,Ri and the corresponding vector fields of the
functional representation. Then we apply Lemma 4.5 to see that the combination
does indeed guarantee against running out of batteries.
?
Guarantee
Power
Supply
Do Other
Task
Fig. 4.14: A BT where the first action guarantees that the combination does not run out of battery.
Example 4.5. Let T1 be Guarantee Power Supply and T2 be Do other tasks. Let
furthermore xk =(x1k,x2k)?R2, where x1k ? [0,100] is the distance from the current
position to the recharging station and x2k ? [0,100] is the battery level. For this
example ? t = 10s.
For Guarantee Power Supply, T1, we have that
S1 = {x : 100? x2 or (0.1? x1,20 < x2)} (4.44)
R1 = {x : x2 ? 20 or (x2 < 100 and x1 < 0.1)} (4.45)
F1 = /0 (4.46)
f1(x) =
(
x1
x2 +1
)
if x1 < 0.1,x2 < 100 (4.47)
=
(
x1?1
x2?0.1
)
else (4.48)
that is, when running, the robot moves to x1 < 0.1 and recharges. While moving,
the battery level decreases and while charging the battery level increases. If at the
recharge position, it returns Success only after reaching x2 ? 100. Outside of the
recharge area, it returns Success as long as the battery level is above 20. A phase
portrait of f1(x)? x is shown in Figure 4.15.
For Do Other Task, T2, we have that
4.4 Examples 71
0 20 40 60 80 100
0
10
20
30
40
50
60
70
80
90
100
x1 [m]
x 2
 [%
]
Fig. 4.15: The Guarantee Power Supply Action
S2 = /0 (4.49)
R2 = R2 (4.50)
F2 = /0 (4.51)
f2(x) =
(
x1 +(50? x1)/50
x2?0.1
)
(4.52)
that is, when running, the robot moves towards x1 = 50 and does some important
task, while the battery level keeps on decreasing. A phase portrait of f2(x)? x is
shown in Figure 4.15.
0 20 40 60 80 100
0
10
20
30
40
50
60
70
80
90
100
x1 [m]
x 2
 [%
]
Fig. 4.16: The Do Other Task Action
72 4 Analysis of Efficiency, Safety, and Robustness
Given T1 and T2, the composition T0=Sequence(T1,T2) is created to improve
the safety of T2, as described below.
Informally, we can look at the phase portrait in Figure 4.17 to get a feeling for
what is going on. The obstacle to be avoided is the Empty Battery state O= {x : x2 =
0}, and T0 makes sure that this state is never reached, since the Guarantee Power
Supply action starts executing as soon as Do Other Task brings the battery level
below 20%. The remaining battery level is also enough for the robot to move back
to the recharging station, given that the robot position is limited by the reachable
space, i.e., x1k ? [0,100].
0 20 40 60 80 100
0
10
20
30
40
50
60
70
80
90
100
x1 [m]
x 2
 [%
]
Fig. 4.17: Phase portrait of T0=Sequence(T1,T2). Note that T1 guarantees that the combination
does not run out of battery. The dashed line is a simulated execution, starting at (80,50).
Formally, we state the following Lemma
Lemma 4.8. Let the obstacle region be O= {x : x2 = 0} and the initialization region
be I = {x : x1 ? [0,100],x2 ? 15}.
Furthermore, let T1 be given by (4.44)-(4.48) and T2 be an arbitrary BT satis-
fying maxx ||x? f2(x)||< d = 5, then T0=Sequence(T1,T2) is Safe with respect to
I and O, i.e. if x(0) ? I, then x(t) 6? O, for all t > 0.
Proof. First we see that T1 is Safe with respect to O and I. Then we notice that T1
is Safeguarding with margin d = 10 for the reachable set X = {x : x1 ? [0,100],x2 ?
[0,100]}. Finally we conclude that T0 is Safe, according to Lemma 4.5.
Note that if we did not constraint the robot to move in some reachable set X = {x :
x1 ? [0,100],x2 ? [0,100]}, it would be able to move so far away from the recharging
station that the battery would not be sufficient to bring it back again before reaching
x2 = 0.
4.4 Examples 73
?
Guarantee
Power
Supply
?
?
Toe Bumper
Pressed
?
Say
Ouch
Back Off
0.2m
Self Protection
?
?
?
I Know
What to Do
Ask What
to Do
User Interaction
?
New User
Suggestion
Set Current
Activity
Activity Manager
?
?
Activity Sit Sit
?
Activity
Ball Game
?
Activity
Stand Up
Stand
Up
?
Activity Say
Goodbye
?
Activity
Sleep
Go To
Sleep
?
?
?
Ball
Close
Approach
Ball
?
Ball
Grasped
Grasp
Ball
Throw
Ball
Track
Ball
Ball Game ?
Say
Goodbye
Wave
Hand
Ball Game
Fig. 4.18: A BT that combines some capabilities of the NAO robot in an interactive and modular
way. Note how atomic actions can easily be replaced by more complex sub-BTs.
4.4.3 Complex BT
Below we will use a larger BT to illustrate modularity, as well as the applicability
of the proposed analysis tools to more complex problems.
Example 4.6. The BT in Figure 4.18 is designed for controlling a NAO humanoid
robot in an interactive capability demo, and includes the BTs of Figures 4.14 and
4.9 as subtrees, as discussed below.
The top left part of the tree includes some exception handling, in terms of battery
management, and backing up and complaining in case the toe bumpers are pressed.
The top right part of the tree is a parallel node, listening for new user commands,
along with a request for such commands if none are given and an execution of the
corresponding activities if a command has been received.
The subtree Perform Activities is composed of checking of what activity to do,
and execution of the corresponding command. Since the activities are mutually ex-
clusive, we let the Current Activity hold only the latest command and no ambiguities
of control commands will occur.
The subtree Play Ball Game runs the ball tracker, in parallel with moving closer
to the ball, grasping it, and throwing it.
74 4 Analysis of Efficiency, Safety, and Robustness
As can be seen, the design is quite modular. A HDS implementation of the same
functionality would need an extensive amount of transition arrows going in between
the different actions.
We will now apply the analysis tools of the paper to the example, initially assum-
ing that all atomic actions are FTS, as described in Definition 4.5.
Comparing Figures 4.14 and 4.18 we see that they are identical, if we let Do
Other Task correspond to the whole right part of the larger BT. Thus, according to
Lemma 4.8, the complete BT is safe, i.e. it will not run out of batteries, as long
as the reachable state space is bounded by 100 distance units from the recharging
station and the time steps are small enough so that maxx ||x? f2(x)|| < d = 5, i.e.
the battery does not decrease more than 5% in a single time step.
The design of the right subtree in Play Ball Game is made to satisfy Lemma 4.2,
with the condition S1 = R?2 ? S2. Let T1 = Fallback(Ball Close?, Approach Ball),
T2 = Fallback(Ball Grasped?, Grasp Ball), T3 = Throw Ball. Note that the use of
condition action pairs makes the success regions explicit. Thus S1 = R?2 ? S2, i.e.
Ball Close is designed to describe the Region of Attraction of Grasp Ball, and S2 =
R?3?S3, i.e. Ball Grasped is designed to describe the Region of Attraction of Throw
Ball. Finally, applying Lemma 4.2 twice we conclude that the right part of Play
Ball Game is FTS with completion time bound ?1 + ?2 + ?3, region of attraction
R?1?R?2?R?3 and success region S1?S2?S3.
The parallel composition at the top of Play Ball Game combines Ball Tracker
which always returns Running, with the subtree discussed above. The parallel node
has M = 1, i.e. it only needs the Success of one child to return Success. Thus, it is
clear from Definition 4.4 that the whole BT Play Ball Game has the same properties
regarding FTS as the right subtree.
Finally, we note that Play Ball Game fails if the robot is not standing up. There-
fore, we improve the robustness of that subtree in a way similar to Example 4.4 in
Figure 4.9. Thus we create the composition Fallback(Play Ball Game, T5, T6), with
T5 = Sit to Stand, T6 = Lie Down to Sit Up.
4.4 Examples 75
Assuming that that high dimensional dynamics of Play Ball Game is somehow
captured in the x1 dimension we can apply an argument similar to Lemma 4.7 to
conclude that the combined BT is indeed also FTS with completion time bound
?1 +?2 +?3 +?5 +?6, region of attraction R?1?R?2?R?3?R?5?R?6 and success region
S1?S2?S3.
The rest of the BT concerns user interaction and is thus not suitable for doing
performance analysis.
Note that the assumption on all atomic actions being FTS is fairly strong. For
example, the NAO grasping capabilities are somewhat unreliable. A deterministic
analysis such as this one is still useful for making good design choices, but in order
to capture the stochastic properties of a BT, we need the tools of Chapter 6.
But first we will use the tools developed in this chapter to formally investigate
how BTs relate to other control architectures.

Chapter 5
Formal Analysis of How Behavior Trees
Generalize Earlier Ideas
In this chapter, we will formalize the arguments of Chapter 2, using the tools devel-
oped in Chapter 4. In particular, we prove that BTs generalize Decision Trees (5.1),
the Subsumptions Architecture (5.2), Sequential Behavior Compositions (5.3) and
the Teleo-Reactive Approach (5.4). Some of the results of this chapter were previ-
ously published in the journal paper [9].
5.1 How BTs Generalize Decision Trees
Have Task
to Do?
Task is
Urgent?
Recharge
Now!
yes no
Battery Level
? 10%?
Battery Level
? 30%?
yes no
Perform
Task!
Recharge
Now!
yes no
Perform
Task!
Recharge
Now!
yes no
Fig. 5.1: The Decision Tree of a robot control system. The decisions are interior nodes, and the
actions are leaves.
Consider the Decision Tree of Figure 5.1, the robot has to decide whether to
perform a given task or recharge its batteries. This decision is taken based upon the
urgency of the task, and the current battery level. The following Lemma shows how
to create an equivalent BT from a given Decision Tree.
Lemma 5.1. Given a Decision Tree as follows
77
78 5 Formal Analysis of How Behavior Trees Generalize Earlier Ideas
DTi =
{
DTi1 if predicate Pi is true
DTi2 if predicate Pi is false
(5.1)
where DTi1, DTi2 are either atomic actions, or sub DTs with identical structure, we
can create an equivalent BT by setting
Ti = Fallback(Sequence(Pi,Ti1),Ti2) (5.2)
for non-atomic actions, Ti = DTi for atomic actions and requiring all actions to
return Running all the time.
The original Decision Tree and the new BT are equivalent in the sense that the
same values for Pi will always lead to the same atomic action being executed. The
lemma is illustrated in Figure 5.2.
Proof. The BT equivalent of the Decision Tree is given by
Ti = Fallback(Sequence(Pi,Ti1),Ti2)
For the atomic actions always returning running we have ri = R, for the actions
being predicates we have that ri = Pi. This, together with Definitions 4.2-4.3 gives
that
fi(x) =
{
fi1 if predicate Pi is true
fi2 if predicate Pi is false
(5.3)
which is equivalent to (5.1).
Informally, first we note that by requiring all actions to return Running, we ba-
sically disable the feedback functionality that is built into the BT. Instead whatever
action that is ticked will be the one that executes, just as the Decision Tree. Sec-
ond the result is a direct consequence of the fact that the predicates of the Decision
Trees are essentially ‘If ... then ... else ...’ statements, that can be captured by BTs
as shown in Figure 5.2.
?
? Todo when
False
Predicate
Todo when
True
Predicate
Todo when
True
Todo when
False
FalseTrue
Fig. 5.2: The basic building blocs of Decision Trees are ‘If ... then ... else ...’ statements (left), and
those can be created in BTs as illustrated above (right).
Note that this observation opens possibilities of using the extensive literature on
learning Decision Trees from human operators, see e.g. [37], to create BTs. These
learned BTs can then be extended with safety or robustness features, as described in
Section 4.2.
5.2 How BTs Generalize the Subsumption Architecture 79
?
? Recharge
Now
?
Have Task
To Do
??
?
Task is
Urgent
?
Battery
Level > 10%
Perform
Task
Recharge
Now
?
Battery
Level > 30%
Perform
Task
Recharge
Now
Fig. 5.3: A BT that is equivalent to the Decision Tree in Figure 5.1. A more compact version of
the same tree can be found in Figure 5.4.
?
Recharge
Now!
?
Recharge
Now!
Have Task
to Do
?
Battery
Level > 30 %
?
Task is
Urgent
Battery
Level > 10 %
Fig. 5.4: A more compact formulation of the BT in Figure 5.3.
We finish this section with an example of how BTs generalize Decision Trees.
Consider the Decision Tree in Figure 5.1. Applying Lemma 5.1 we get the equiva-
lent BT of Figure 5.3. However the direct mapping does not always take full advan-
tage of the features of BTs. Thus a more compact, and still equivalent, BT can be
found in Figure 5.4, where again, we assume that all actions always return Running.
5.2 How BTs Generalize the Subsumption
Architecture
In this section we will see how the subsumption architecture, proposed by Brooks [4],
can be realized using a Fallback composition. The basic idea in [4] was to have a
80 5 Formal Analysis of How Behavior Trees Generalize Earlier Ideas
number of controllers set up in parallel and each controller was allowed to output
both actuator commands, and a binary value, signaling if it wanted to control the
robot or not. The controllers were then ordered according to some priority, and the
highest priority controller, out of the ones signaling for action, was allowed to con-
trol the robot. Thus, a higher level controller was able to subsume the actions of a
lower level one.
Sensors Stop if Overheated
Recharge if Needed
Do Other Tasks
S
S
S Actuators
Fig. 5.5: The Subsumption architecture. A higher level behavior can subsume (or suppress) a lower
level one.
An example of a Subsumption architecture can be found in Figure 5.5. Here, the
basic level controller Do Other Tasks is assumed to be controlling the robot for most
of the time. However, when the battery level is low enough, the Recharge if Needed
controller will signal that it needs to command the robot, subsume the lower level
controller, and guide the robot towards the recharging station. Similarly, if there is
risk for overheating, the top level controller Stop if Overheated will subsume both
of the lower level ones, and stop the robot until it has cooled down.
Lemma 5.2. Given a Subsumption architecture, we can create an equivalent BT by
arranging the controllers as actions under a Fallback composition, in order from
higher to lower priority. Furthermore, we let the return status of the actions be Fail-
ure if they do not need to execute, and Running if they do. They never return Success.
Formally, a subsumption architecture composition Si(x)= Sub(Si1(x),Si2(x)) can be
defined by
Si(x) =
{
Si1(x) if Si1 needs to execute
Si2(x) else
(5.4)
Then we write an equivalent BT as follows
Ti = Fallback(Ti1,Ti2) (5.5)
where Ti j is defined by fi j(x) = Si j(x) and
ri j(x) =
{
R if Si j needs to execute
F else.
(5.6)
Proof. By the above arrangement, and Definition 4.3 we have that
fi(x) =
{
fi1(x) if Si1 needs to execute
fi2(x) else,
(5.7)
5.3 How BTs Generalize Sequential Behavior Compositions 81
which is equivalent to (5.4) above. In other words, actions will be checked in order
of priority, until one that returns running is found.
A BT version of the example in Figure 5.5 can be found in Figure 5.6. Table
5.1 illustrates how the two control structures are equivalent, listing all the 23 possi-
ble return status combinations. Note that no action is executed if all actions return
Failure.
?
Stop if Overheated Recharge if Needed Do Other Tasks
Fig. 5.6: A BT version of the subsumption example in Figure 5.5.
Table 5.1: Possible outcomes of Subsumption-BT example.
Stop if over
heated
Recharge if
Needed
Do Other
Tasks
Executed
Action
Running Running Running Stop ...
Running Running Failure Stop ...
Running Failure Running Stop ...
Running Failure Failure Stop ...
Failure Running Running Recharge ...
Failure Running Failure Recharge ...
Failure Failure Running Do other ...
Failure Failure Failure -
5.3 How BTs Generalize Sequential Behavior
Compositions
In this section, we will see how the Fallback composition, and Lemma 4.3, can also
be used to implement the Sequential Behavior Compositions proposed in [6].
The basic idea proposed by [6] is to extend the region of attraction by using a
family of controllers, where the asymptotically stable equilibrium of each controller
was either the goal state, or inside the region of attraction of another controller,
positioned earlier in the sequence.
We will now describe the construction of [6] in some detail, and then see how this
concept is captured in the BT framework. Given a family of controllers U = {?i},
82 5 Formal Analysis of How Behavior Trees Generalize Earlier Ideas
we say that ?i prepares ? j if the goal G(?i) is inside the domain D(? j). Assume
the overall goal is located at G(?1). A set of execution regions C(?i) for each
controller was then calculated according to the following scheme:
1. Let a Queue contain ?1. Let C(?1) = D(?1), N = 1, D1 = D(?1).
2. Remove the first element of the queue and append all controllers that prepare it
to the back of the queue.
3. Remove all elements in the queue that already has a defined C(?i).
4. Let ? j be the first element in the queue. Let C(? j) = D(? j) \DN , DN+1 =
DN ?D(? j) and N? N +1.
5. Repeat steps 2, 3 and 4 until the queue is empty.
The combined controller is then executed by finding j such that x ?C(? j) and
then invoking controller ? j.
Looking at the design of the Fallback operator in BTs, it turns out that it does ex-
actly the job of the Burridge algorithm above, as long as the subtrees of the Fallback
are ordered in the same fashion as the queue above. We formalize this in Lemma 5.3
below.
Lemma 5.3. Given a set of controllers U = {?i} we define the corresponding re-
gions Si = G(?i),R?i = D(?i),Fi = Complement(D(?i)), and consider the con-
trollers as atomic BTs, Ti = ?i. Assume S1 is the overall goal region. Iteratively
create a larger BT TL as follows
1. Let TL = T1.
2. Find a BT T? ?U such that S? ? R?L
3. Let TL? Fallback(TL,T?)
4. Let U ?U \T?
5. Repeat steps 2, 3 and 4 until U is empty.
If all Ti are FTS, then so is TL.
Proof. The statement is a direct consequence of iteratively applying Lemma 4.3.
Thus, we see that BTs generalize the Sequential Behavior Compositions of [6],
with the execution region computations and controller switching replaced by the
Fallback composition, as long as the ordering is given by Lemma 5.3 above.
5.4 How BTs Generalize TRs
In this section, we use the following Lemma to show how to create a BT with the
same execution as a given TR. The lemma is illustrated by Example 5.1 and Fig-
ure 5.7.
5.4 How BTs Generalize TRs 83
Lemma 5.4 (TR-BT analogy). Given a TR in terms of conditions ki and actions ai,
an equivalent BT can be constructed as follows
TT R = Fallback(Sequence(c1,a1), . . . ,Sequence(cm,am)), (5.8)
where we convert the True/False of the conditions to Success/Failure, and let the
actions only return Running.
Proof. It is straightforward to see that the BT above executes the exact same ai as
the original TR would have, depending on the values of the conditions ci, i.e. it finds
the first condition ci that returns Success, and executes the corresponding ai.
?
?
c1 a1
· · · ?
cm am
Fig. 5.7: The BT that is analogous to a given TR.
We will now illustrate the lemma with an example from Nilssons original pa-
per [31].
Example 5.1. The TR Goto(loc) is described as follows, with conditions on the left
and corresponding actions to the right:
Equal(pos,loc)? Idle (5.9)
Heading Towards (loc)? Go Forwards (5.10)
(else)? Rotate (5.11)
where pos is the current robot position and loc is the current destination.
Executing this TR, we get the following behavior. If the robot is at the destination
it does nothing. If it is heading the right way it moves forward, and else it rotates
on the spot. In a perfect world without obstacles, this will get the robot to the goal,
just as predicted in Lemma 5.5. Applying Lemma 5.4, the GoTo TR is translated to
a BT in Figure 5.8.
The example continues in [31] with a higher level recursive TR, called Am-
ble(loc), designed to add a basic obstacle avoidance behavior
84 5 Formal Analysis of How Behavior Trees Generalize Earlier Ideas
?
?
Equal
(pos,loc) Idle
?
Heading
Towards
(loc)
Go
Forwards
?
True Rotate
Fig. 5.8: The BT version of the TR GoTo.
Equal(pos,loc)? Idle (5.12)
Clear Path(pos,loc)? GoTo(loc) (5.13)
(else)? Amble(new point(pos,loc)) (5.14)
where new point picks a new random point in the vicinity of pos and loc.
Again, if the robot is at the destination it does nothing. If the path to goal is
clear it executes the GoTo TR. Else it picks a new point relative to its current posi-
tion and destination (loc) and recursively executes a new copy of Amble with that
destination. Applying Lemma 5.4, the Amble TR is translated to a BT in Figure 5.9.
?
?
Equal
(pos,loc) Idle
?
Clear Path
(pos,loc)
GoTo(loc)
?
True
Amble
(new
point(pos,loc))
Fig. 5.9: The BT version of the TR Amble.
5.4.1 Universal TRs and FT-Successful BTs
Using the functional form of BTs introduced in 4.1 we can show that Lemma 4.3 is a
richer version of Lemma 5.5 below, and also fix one of its assumptions. Lemma 4.3
includes execution time, but more importantly builds on a finite difference equation
system model over a continuous state space. Thus control theory concepts can be
used to include phenomena such as imperfect sensing and actuation into the analy-
5.4 How BTs Generalize TRs 85
sis, that was removed in the strong assumptions of Lemma 5.5. Thus, the BT analogy
provides a powerful tool for analyzing TR designs.
Lemma 5.5 (Nilsson 1994). If a TR-program is Universal, and there are no sensing
and execution errors, then the execution of the program will lead to the satisfaction
of k1.
Proof. In [31] it is stated that it is easy to see that this is the case.
The idea of the proof is indeed straight forward, but as we will see when we
compare it to the BT results in Section 5.4.1 below, the proof is incomplete.
In Lemma 4.3, Si,Ri,Fi correspond to Success, Running and Failure regions and
R? denotes the region of attraction.
Lemma 4.3 shows under what conditions we can guarantee that the Success re-
gion S0 is reached in finite time. If we for illustrative purposes assume that the
regions of attraction are identical to the running regions Ri = R?i, the Lemma states
that as long as the system starts in R?0 = R
?
1 ?R?2 it will reach S0 = S1 in less than
?0 = ?1 + ?2 time units. The condition analogous to the Regression property is that
S2 ? R?1, i.e. that the Success region of the second BT is a subset of the region of
attraction R?1 of the first BT. The regions of attraction, R
?
1 and R
?
2 are very important,
but there is no corresponding concept in Lemma 5.5. In fact, we can construct a
counter example showing that Lemma 5.5 does not hold.
Example 5.2 (Counter Example). Assume that a TR program is Universal in the
sense described above. Thus, the execution of action ai eventually leads to the sat-
isfaction of k j where j < i for all i 6= 1. However, assume it is also the case that
the execution of ai, on its way towards satisfying k j actually leads to a violation of
ki. This would lead to the first true condition being some km, with m > i and the
execution of the corresponding action am. Thus, the chain of decreasing condition
numbers is broken, and the goal condition a1 might never be reached.
The fix is however quite straightforward, and amounts to using the following
definition with a stronger assumption.
Definition 5.1 (Stronger Regression property). For each ki, i > 1 there is k j, j <
i such that the execution of action ai leads to the satisfaction of k j, without ever
violating ki.

Chapter 6
Stochastic BTs
Some of the results of this chapter were previously published in the paper [8].
We are interested in modeling the reliability of reactive robot plan executions,
in terms of execution times and success probabilities. To clarify what we mean by
these concepts, we consider the following minimalistic example: a robot is searching
for an object, and can choose between the two subtasks searching on the table, and
opening/searching the drawer. One possible plan is depicted in Figure 6.1. Here,
the robot first searches the table and then, if the object was not found on the table,
opens the drawer and searches the drawer. In the figure, each task is assigned an
execution time, and a success probability. For example, searching the table has a
success probability of 0.1 and an execution time of 5s. Given a plan like this, it
is fairly straightforward to compute the reliability of the entire plan, in terms of
execution time distribution and success probability. In this chapter, we show how to
compute such performance metrics for arbitrary complex plans encoded using BTs.
In particular, we will define Stochastic BTs in Section 6.1, transform them into
DTMCs in Section 6.2, compute reliabilities in Section 6.3 and describe examples
Section 6.4.
Before motivating our study of BTs we will make a few more observations re-
garding the example above. First we note that the plan would still make sense if we
changed the order of searching on the table and opening/searching the drawer, both
subtasks achieve the objective of finding the object. Such subtasks, where ordering
is not critical, and succeeding in just one is enough, will be called Fallbacks. Note
however that it does not make sense to swap the order of opening the drawer and
searching the drawer. Here, the order cannot be changed, and both subtasks must
succeed. It does not make sense to search the drawer if we were not able to open
it. We call such a set of subtasks a Sequence. Note that adding subtasks to a Se-
quence generally decreases overall success probabilities, whereas adding Fallbacks
generally increases overall success probabilities.
87
88 6 Stochastic BTs
Search
Table
(T=5s)
start
Open
Drawer
(T=10s)
Search
Drawer
(T=10s)
Task
Succeeded
Task
Failed
0.1(success)
0.9(failure)
0.9(success)
0.1(failure)
0
.1
(f
ai
lu
re
)
0.
9(
su
cc
es
s)
Fig. 6.1: A simple plan for a search task, modelled by a Markov Chain.
6.1 Stochastic BTs
In this section we will show how some probabilistic measures as term of Mean
Time to Succeed (MTTS), Mean Time to Fail (MTTF), and probability over time
carry across modular compositions of BTs. The advantage of using BTs lie in their
modularity and hierarchical structure, which provides good scalability, as explained
below. These features would be lost if the whole process from problem formulation
to solution was carried out within the classical framework. To do show the properties
above, we need to introduce some concepts from Markov theory.
?
?Search Table
(T=5s, P=0.1)
Open Drawer
(T=10s, P=0.9)
Search Drawer
(T=10s, P=0.9)
Fig. 6.2: The BT equivalent of the Markov chain in Figure 6.1. The atomic actions are the leaves
of the tree, while the interior nodes correspond to Sequence compositions (arrow) and Fallbacks
compositions (question mark).
6.1 Stochastic BTs 89
6.1.1 Markov Chains and Markov Processes
Markov theory [32] deals with memory-less processes. If a process is given by
a sequence of actions that changes the system’s state disregarding its history, a
DTMC is suitable to model the plan execution. Whereas if a process is given by
a transition rates between states, a Continuous Time Markov Chain (CTMC) it then
suitable to model such plan execution. A DTMC is given by a collection of states
S = {s1,s2, . . . ,sd} and the transitions probabilities pi j between states si and s j.
A CTMC is given by a collection of states S and the transition rates q?1i j between
states si and s j.
s1
s2 s3 s4
p
13p 1
2
p 2
1
p14
p34
1
Fig. 6.3: Example of a DTMC with 4 states and 6 transitions.
Definition 6.1. The stochastic sequence {Xn,n = 0,1,2, . . .} is a DTMC provided
that:
P{Xn+1 = sn+1|Xn = sn,Xn?1 = sn?1, . . . ,X0 = s0}=
= P{Xn+1 = sn+1|Xn = sn}
(6.1)
? n ? N, and ? s ?S
The expression on the right hand side of (6.1) is the so-called one step transition
probability of the chain and denotes the probability that the process goes from state
sn to state sn+1. We use the following notation:
pi j = P{Xn+1 = s j|Xn = si} (6.2)
to denote the probability to jump from a state si to a state s j. Since we only consider
homogeneous DTMC, the above probabilities do not change in time.
Definition 6.2. The one-step transition matrix P is a |S |× |S |matrix in which the
entries are the transition probabilities pi j.
Let ?(k) = [?1(k), . . . ,?|S |(k)]>, where ?i is the probability of being in state i, then
the Markov process can be described as a discrete time system with the following
time evolution:
90 6 Stochastic BTs{
?(k+1) = P>?(k)
?(0) = ?0.
. (6.3)
where ?0 is assumed to be known a priori.
Definition 6.3. The stochastic sequence {X(t), t ? 0} is a CTMC provided that:
P{X(tn+1) = sn+1|X(tn) = sn,X(tn?1) = sn?1, . . . ,
,X(t0) = s0}= P{X(tn+1) = sn+1|X(tn) = sn}
(6.4)
? n ? N, ? s ?S , and all sequences {t0, t1, . . . , tn+1} such that t0 < t1 < .. . < tn <
tn+1. We use the following notation:
pi j(?) = P{X(t + ?) = s j|X(?) = si} (6.5)
to denote the probability to be in a state s j after a time interval of length ? given that
at present time is into a state si. Since we only consider homogeneous CTMC, the
above probabilities only depend on the time length ? .
To study the continuous time behavior of a Markov process we define the so-
called infinitesimal generator matrix Q.
Definition 6.4. The infinitesimal generator of the transition probability matrix P(t)
is given by:
Q = [qi j] (6.6)
where
qi j =
?????
lim
? t?0
pi j(? t)
? t
if i 6= j
??
k 6=i
qk j otherwise.
(6.7)
Then, the continuous time behavior of the Markov process is described by the fol-
lowing ordinary differential equation, known as the Cauchy problem:{
??(t) = Q>?(t)
?(0) = ?0
(6.8)
where the initial probability vector ?0 is assumed to be known a priori.
Definition 6.5. The average sojourn time SJi of a state si in a CTMC is the average
time spent in that state. It is given by [39]:
SJi =?
1
qii
(6.9)
Definition 6.6. Considering the CTMC {X(t), t ? 0}, the stochastic sequence {Yn,n=
0,1,2, . . .} is a DTMC and it is called Embedded MC (EMC) of the process
X(t) [39].
6.1 Stochastic BTs 91
The transition probabilities of the EMC ri j are defined as:
ri j = P{Yn+1 = s j|Yn = si} (6.10)
and they can be easily obtained as a function of the transition rates qi j:
ri j =
????
qi j
qii
if i 6= j
1??
k 6=i
rk j otherwise. (6.11)
On the other hand the infinitesimal generator matrix Q can be reconstructed from
the EMC as follows
qi j =
???
1
SJ j
ri j if i 6= j
??
k 6=i
rk j otherwise . (6.12)
6.1.2 Formulation
We are now ready to make some definitions and assumptions, needed to compute
the performance estimates. We begin with a formal definition of the BTs, first intro-
duced in Chapter 1.
Definition 6.7. An action A in a BT, is called stochastic if the following holds:
• It first returns running, for an amount of time that might be zero or non-zero,
then consistently returns either success or failure for the rest of the execution of
its parent node1.
• The probability to succeed ps and the probability to fail p f are known a priori.
• The probability to succeed ps(t) and the probability to fail p f (t) are exponen-
tially distributed with the following Probability Density Functions (PDFs):
p?s(t) = psµe?µt (6.13)
p? f (t) = p f ?e??t (6.14)
from which we can calculate the Cumulative Distribution Functions (CDFs)
p?s(t) = ps(1? e?µt) (6.15)
p? f (t) = p f (1? e??t) (6.16)
Definition 6.8. An action A in a BT, is called deterministic (in terms of execution
time, not outcome) if the following holds:
1 The execution of the parent node starts when it receives a tick and finishes when it returns either
success/failure to its parent.
92 6 Stochastic BTs
• It first returns running, for an amount of time that might be zero or non-zero,
then consistently returns either success or failure for the rest of the execution of
its parent node.
• The probability to succeed ps and the probability to fail p f are known a priori.
• The time to succeed and the time to fail are deterministic variables ?s and ? f
known a priori.
• The probability to succeed ps(t) and the probability to fail p f (t) have the follow-
ing PDFs:
p?s(t) = ps? (t? ?s) (6.17)
p? f (t) = p f ? (t? ? f ) (6.18)
where ? (·) is the Dirac’s delta function. From the PDFs we can calculate the
CDFs:
p?s(t) = psH(t? ?s) (6.19)
p? f (t) = p f H(t? ? f ) (6.20)
where H(·) is the step function.
Remark 6.1. Note that it makes sense to sometimes have ?s 6= ? f . Imagine a door
opening task which takes 10s to complete successfully but fails 30% of the time
after 5s when the critical grasp phase fails.
Example 6.1. For comparison, given a deterministic action with ?s, we let the rates
of a stochastic action have µ = ??1s . Then the PDFs and CDFs are as seen in Fig. 6.4.
As we want to analyze the BT composition of actions, we must also define actions
that include both stochastic and deterministic parts.
Definition 6.9. An action A in a BT, is called hybrid if one of ps(t) and p f (t) is a
random variable with exponential distribution, and the other one is deterministic.
Thus hybrid actions come in two different variations:
Deterministic success time
For this type of hybrid action, the following holds:
• It first returns running, for an amount of time that might be zero or non-zero,
then consistently returns either success or failure for the rest of the execution of
its parent node.
• The probability to succeed ps is known a priori.
• The time to succeed is a deterministic variable ?s known a priori.
6.1 Stochastic BTs 93
t0 ?
p?(t)
(a) PDFs.
t0 ?
p?(t)
(b) CDFs.
Fig. 6.4: Cumulative and probability density distribution function for a deterministic (blue lines)
and stochastic action (green curve).
• The probability to fail has the following PDF:
p? f (t) =
?????
p f (1? e??t) if t < ?s
1? ps if t = ?s
0 otherwise
. (6.21)
In this case the CDF and the PDF of the probability to succeed are discontinuous.
In fact this hybrid action will return failure if, after the success time ?s, it does not
return success. Then, to have an analogy with stochastic actions we derive the PDF
of the probability to succeed:
p?s(t) = ps? (t? ?s) (6.22)
and the CDFs as follows:
p?s(t) = psH(t? ?s) (6.23)
94 6 Stochastic BTs
p? f (t) =
{
p f (1? e??t) if t < ?s
1? p?s(t) otherwise
. (6.24)
Thus, the probability of running is zero after ?s i.e. after ?s it either fails or succeeds.
Moreover, the success rate is set to µ = ??1s .
Deterministic failure time
For this type of hybrid action, the following holds:
• It first returns running, for an amount of time that might be zero or non-zero,
then consistently returns either success or failure for the rest of the execution of
its parent node.
• The probability to fail p f is known a priori.
• The time to succeed is a random variables with exponential distribution with rate
µ known a priori.
• The probability to succeed has the following PDF:
p?s(t) =
?????
ps(1? e?µt) if t < ? f
1? p f if t = ? f
0 otherwise
. (6.25)
To have an analogy with stochastic actions we derive the PDF of the probability to
fail:
p? f (t) = p f ? (t? ? f ) (6.26)
and the CDFs as follows:
p? f (t) = p f H(t? ? f ) (6.27)
p?s(t) =
{
ps(1? e?µt) if t < ? f
1? p? f (t) otherwise
. (6.28)
Moreover, the failure rate is set to ? = ??1f
Remark 6.2. Note that the addition of deterministic execution times makes (6.8)
discontinuous on the right hand side, but it still has a unique solution in the
Carathe?odory sense [11].
We will now give an example of how these concepts transfer over BT composi-
tions.
Example 6.2. Consider the BT in Fig. 6.5. The parallel node is set to returns success
as soon as one child returns success, and the two children are of different kinds,
one deterministic and the other stochastic. Note that the MTTS and MTTF of this
6.1 Stochastic BTs 95
?
?
1
Deterministic
Action
Stochastic
Action
Fig. 6.5: Parallel node of Example 6.2.
BT has to account for the heterogeneity of its children. The deterministic child can
succeed only at time ?s. The CDF of the parallel node is given by the sum of the
CDFs of its children. The PDF has a jump at time ?s accounting for the fact that the
parallel node is more likely to return success after that time. Thus, the PDF and the
CDF of a Success return status are shown in Fig. 6.6.
t0 ?s
p?(t)
(a) PDF.
t0 ?s
p?(t)
(b) CDF.
Fig. 6.6: Cumulative and probability density distribution function of Success of the parallel node
in Figure 6.5.
96 6 Stochastic BTs
Definition 6.10. A BT T1 and a BT T2 are said to be equivalent if and only if T1
can be created from T2 by permutations of the children of Fallbacks and Parallel
compositions.
An example of two equivalent BTs is shown in Fig. 6.7.
Assumption 3 For each action A in the BT, one of the following holds
• The action A is a stochastic action.
• The action A is a deterministic action.
• The action A is a hybrid action.
Assumption 4 For each condition C in the BT, the following holds
• It consistently returns the same value (success or failure) throughout the execu-
tion of its parent node.
• The probability to succeed at any given time ps(t) and the probability to fail at
any given time p f (t) are known a priori.
We are now ready to define a SBT.
Definition 6.11. A SBT is a BT satisfying Assumptions 3 and 4.
Given a SBT, we want to use the probabilistic descriptions of its actions and
conditions, ps(t), p f (t), µ and ? , to recursively compute analogous descriptions for
every sub-trees and finally the whole tree.
To illustrate the investigated problems and SBTs we take a look at the following
example.
Example 6.3. Imagine a robot that is to search for a set of keys on a table and in
a drawer. The robot knows that the keys are often located in the drawer, so that
location is more likely than the table. However, searching the table takes less time,
since the drawer must be opened first. Two possible plans are conceivable: searching
the table first, and then the drawer, as in Fig. 6.7a, or the other way around as in
Fig. 6.7b. These two plans can be formulated as SBTs and analyzed through the
scope of Problem 1 and 2, using the results of Section 6.1 below. Depending on the
user requirements in terms of available time or desired reliability at a given time,
the proper SBT can be chosen.
Remark 6.3. Note that Assumption 1 corresponds to the return status of the search
actions in Example 6.3 behaving in a reasonable way, e.g., not switching between
success and failure.
6.2 Transforming a SBT into a DTMC
The first step of our approach is to define, for each control flow node in V , a vector
representation of the children’s outcomes and a description of its execution policy,
6.2 Transforming a SBT into a DTMC 97
?
Search on
the Table
Search in
the Drawer
1
(a)
?
Search on
the Table
Search in
the Drawer
1
(b)
Fig. 6.7: BT modeling of two plan options. In (a), the robot searches on the table first, and in the
drawer only if the table search fails. In (b), the table is searched only if nothing is found in the
drawer.
then we map the execution into a DTMC with a direct representation of the one-step
transition matrix, and finally we compute the probability of success and failure over
time for each node.
Note that the modularity of BTs comes from the recursive tree structure, any BT
can be inserted as sub-tree in another BT. This modularity allows us to do the anal-
ysis in a recursive fashion, beginning with the leaves of the BT, i.e. the actions and
conditions which have known probabilistic parameters according to Assumptions 3
and 4, and then progressing upwards in a scalable fashion.
To keep track of the execution of a given flow control node, the children outcomes
are collected in a vector state called the marking of the node, and the transitions
between markings are defined according to the execution policy of the node. In
detail, let m(k) = [m1(k),m2(k), . . . ,mN(k)] be a marking of a given BT node with
N children at time step k with
mi(k) =
?????
?1 if child i returns failure at k
1 if child i returns success at k
0 otherwise
(6.29)
Example 6.4. Consider the BT in Figure 6.7(a). If the first child (Search Table) has
failed, and the second (Search Drawer) is currently running, the marking would be
m(k) = [?1,0].
We define an event related to a BT node when one of its children returns either
success or failure. Defining ei(k) to be the vector associated to the event of the i-th
running child, all zeros except the i-th entry which is equal to ei(k) ? {?1,1}:
ei(k) =
{
?1 if child i has failed at k
1 if child i has succeeeded at k.
(6.30)
We would like to describe the time evolution of the node marking due to an event
associated with the child i as follows:
98 6 Stochastic BTs
m(k+1) = m(k)+ ei(k) (6.31)
with the event ei(k) restricted to the feasible set of events at m(k), i.e.
ei(k) ?F (m(k)).
In general, F (m(k))?F0, with
F0 = {ei : ei ? {?1,0,1}N , ||ei||2 = 1}, (6.32)
i.e. events having only one nonzero element, with value ?1 or 1. We will now de-
scribe the set F (m(k)) for the three different node types.
Feasibility condition in the Fallback node
FFB(m(k)) = {ei ?F0 :?i : mi(k) = 0,ei 6= 0,
m j(k) =?1,? j,0 < j < i},
(6.33)
i.e. the event of a child returning success or failure is only allowed if it was ticked,
which only happens if it is the first child, or if all children before it have returned
failure.
Feasibility condition in the Sequence node
FS(m(k)) = {ei ?F0 :?i : mi(k) = 0,ei 6= 0,
m j(k) = 1,? j,0 < j < i},
(6.34)
i.e. the event of a child returning success or failure is only allowed if it was ticked,
which only happens if it is the first child, or if all children before it have returned
success.
Feasibility condition in the Parallell node
FP(m(k)) = {ei ?F0 :?i : mi(k) = 0,ei 6= 0,
? j:m j(k)>0m j(k)< M
? j:m j(k)<0m j(k)< N?M+1},
(6.35)
i.e. the event of a child returning success or failure is only allowed it if has not
returned yet, and the conditions for success (< M successful children) and failure
(< N?M?1 failed children) of the parallell node are not yet fulfilled.
6.2 Transforming a SBT into a DTMC 99
Example 6.5. Continuing Example 6.4 above, F (m(k))=FFB([?1,0])= {(0,1),(0,?1)},
i.e. the second child returning success or failure. Note that if the first child would
have returned success, the feasible set would be empty FFB([1,0]) = /0.
The Reachability Graph (RG), see Figure 6.8, of a BT node can now be com-
puted starting from the initial marking m(0) = m0 = 0>, taking into account all the
possible event combinations that satisfy the feasibility condition.
Definition 6.12. A marking mi is reachable from a marking m j if there exists a
sequence of feasible events ? = [?1,?2, . . . ,?g] such that mi = m j +?gh=1 ?h.
Remark 6.4. Note that m(k) = mi when mi is the marking at time k.
pf1 ps1
pf2 ps2
pf3 ps3
psN?1
pfN psN
1
1
1
1 1
m0 [0 0 0 · · · 0]
m1[?1 0 0 · · · 0] m2 [1 0 0 · · · 0]
m3[1 ? 1 0 · · · 0] m4 [1 1 0 · · · 0]
m5[1 1 ? 1 · · · 0] . . .
ms?2 [1 1 1 · · · 0]
ms?1[1 1 1 · · · ? 1] ms [1 1 1 · · · 1]
e1 = ?1 e1 = 1
e2 = ?1 e2 = 1
e3 = ?1 e3 = 1
eN?1 = 1
eN = ?1 eN = 1
Fig. 6.8: Reachability graph of the sequence node (blue rectangles) with N children and its DTMC
representation (cyan circles). When the node returns success/failure the related DTMC is in an
absorbing state.
6.2.1 Computing Transition Properties of the DTMC
The RG of a BT node comprises all the reachable markings, the transitions between
them describe events which have a certain success/failure probability. We can then
map the node execution to a DTMC where the states are the markings in the RG
100 6 Stochastic BTs
pf1 ps1
pf2 ps2
pf3 ps3
pfN?1
pfN psN
1
1
1
11
m0 [0 0 0 · · · 0]
m1 [1 0 0 · · · 0]m2[?1 0 0 · · · 0]
m3 [?1 1 0 · · · 0]m4[?1 ? 1 0 · · · 0]
m5 [?1 ? 1 1 · · · 0]. . .
ms?2[?1 ? 1 ? 1 · · · 0]
ms?1 [?1 ? 1 ? 1 · · · 1]ms[?1 ? 1 ? 1 · · · ? 1]
e1 = ?1 e1 = 1
e2 = ?1 e2 = 1
e3 = ?1 e3 = 1
eN?1 = ?1
eN = ?1 eN = 1
Fig. 6.9: Reachability graph of the fallback node (blue rectangles) with N children and its DTMC
representation (cyan circles). When the node returns success/failure the related DTMC is in an
absorbing state.
[0 0]
[1 1]
p?s1
p?f1
p?s2
p?f2
p?f2 p?s2 p?s1 p?f1
11 1
11
m0
m1[?1 0] m2[1 0] m3 [0 ? 1]m4 [0 1]
m5 m6 [?1 1]m7[1 ? 1]
e1 = 1e1 = ?1 e2 = 1 e2 = ?1
e2 = 1e2 = ?1 e1 = 1 e1 = ?1
Fig. 6.10: Reachability graph of the parallel node (blue rectangles) with 2 children and its DTMC
representation (cyan circles). When the node returns success/failure the related DTMC is in an
absorbing state.
and the one-step transition matrix P is given by the probability of jump between
markings, with off diagonal entries defined as follows:
6.3 Reliability of a SBT 101
pi j =
?????
p?sh if m j?mi ?F (mi)? eheTh (m j?mi)> 0
p? f h if m j?mi ?F (mi)? eheTh (m j?mi)< 0
0 otherwise
(6.36)
and diagonal entries defined as:
pii = 1??
j
pi j. (6.37)
with:
p?sh =
pshµh?h
p f hµh + psh?h
·
?? ?
j:e j?F (mi)
µ j? j
p f jµ j + ps j? j
???1 (6.38)
and
p? f h =
p f hµh?h
p f hµh + psh?h
·
?? ?
j:e j?F (mi)
µ j? j
p f jµ j + ps j? j
???1 (6.39)
where ps j and p f j is the ps and p f of child j.
Remark 6.5. For sequence and selector node the following holds: p?sh = psh and
p? f h = p f h.
In Figs. 6.8 and 6.9 the mapping from RG to a DTCM related to a sequence node
and a fallback node are shown. In Fig. 6.10 the mapping for a parallel node with
two children and M = 2 is shown. We choose not to depict the mapping of a general
parallel node, due to its large amount of states and possible transition between them.
To obtain the continuous time probability vector ?(t) we need to compute the
infinitesimal generator matrix Q associated with the BT node. For doing so we con-
struct a CTMC for which the EMC is the DTMC of the BT node above computed.
According to (6.7) the map from the EMC and the related CTMC is direct, given
the average sojourn times SJi.
6.3 Reliability of a SBT
6.3.1 Average sojourn time
We now compute the average sojourn time of each marking mi of a BT node.
Lemma 6.1. For a BT node with psi, p f i,µi,?i given for each child, the average
sojourn time of in a marking mi is:
102 6 Stochastic BTs
SJi =
(
?
h:eh?F (mi)
(
psh
µh
+
p f h
?h
)?1)?1
(6.40)
with h : eh ?F (mi).
Proof. In each marking one of the following occur: the running child h fails or
succeeds. To take into account both probabilities and time rates, that influence the
average sojourn time, we describe the child execution using an additional CTMC,
depicted in Fig. 6.11
Running
Failure Success
pfh?hµh
pfhµh+psh?h
psh?hµh
pfhµh+psh?h
? ?hµh
pfhµh+psh?h
Fig. 6.11: CTMC of a child’s execution.
According to (6.9) the average sojourn time is:
?i =
p f hµh + psh?h
?hµh
=
psh
µh
+
p f h
?h
(6.41)
and the rate of leaving that state is ?i?1. Now to account all the possible running
children outcome, e.g. in a parallel node, we consider all the rates associate to the
running children. The rate of such node is the sum of all the rates associated to the
running children ?i?1. Finally, the average sojourn time of a marking mi is given by
the inverse of the combined rate:
1
SJi
= ?
h:eh?F (mh)
1
psh
µh
+
p f h
?h
(6.42)
from which we obtain (6.40).
Remark 6.6. The EMC associated with the CTMC in Fig. 6.11 is depicted in
Fig. 6.12. It describes the child’s execution as a DTMC.
6.3 Reliability of a SBT 103
Running
Failure Success
pfh psh
Fig. 6.12: DTMC of a child’s execution.
6.3.2 Mean Time To Fail and Mean Time To Succeed
To derive a closed form of the mean time to fail (MTTF) and mean time to succeed
(MTTS) of a BT node, we take the probability to reach a success (failure) state from
the DTCM and the average time spent in each state visited before reaching this state
obtained from (6.40). We rearrange the state space of the DTMC so that the initial
state is first, the other transient states are second, the failure states are second last
and the success states are last:
P>c =
?? T 0 0RF I 0
RS 0 I
?? (6.43)
where T is the matrix describing the one-step transition from a transit state to an-
other one, RF is a the matrix describing the one-step transition from a transit state
to a failure state, and RS is the matrix describing the one-step transition from a tran-
sit state to a success state. We call this rearrangement the canonization of the state
space.
Lemma 6.2. Let A be a matrix with the i j-th entry defined as exp(ti j) where ti j is
the time needed to transit from a state j to a state i if j, i are neighbors in the RG, 0
otherwise. The MTTF and MTTS of the BT node can be computed as follows
MT T F =
?|SF |i=1 u
F
i1log(h
F
i1)
?|SF |i=1 u
F
i1
(6.44)
where:
HF , AF
?
?
i=0
AiT . (6.45)
and
MT T S =
?|SS|i=1 u
S
i1log(h
S
i1)
?|SS|i=1 u
S
i1
(6.46)
104 6 Stochastic BTs
where:
HS , AS
?
?
i=0
AiT (6.47)
where AT , AF , and AS are the sub-matrices of A corresponding to the canonization
described in (6.43), for which the following holds:
A =
??AT 0 0AF 0 0
AS 0 0
?? . (6.48)
Proof. Failure and success states are absorbing, hence we focus our attention on the
probability of leaving a transient state, described by the matrix U , defined below:
U =
?
?
k=0
T i, (6.49)
Thus, considering i as the initial transient state, the entries ui j is the mean number
of visits of j starting from i before being absorbed, we have to distinguish the case
in which the absorbing state is a failure state from the case in which it is a success
state:
UF , RFU (6.50)
US , RSU. (6.51)
Equations (6.50) and (6.51) represent the mean number of visits before being ab-
sorbed in a failure or success state respectively.
To derive MTTF (MTTS) we take into account the mean time needed to reach
every single failure (success) state with its probability, normalized over the proba-
bility of reaching any failure (success) state, starting from the initial state. Hence
we sum the probabilities of reaching a state starting from the initial one, taking into
account only the first column of the matrices obtaining Eq. (6.44) and Eq. (6.46).
Remark 6.7. Since there are no self loops in the transient state of the DTMC above,
the matrix T is nilpotent. Hence ui j is finite ?i, j.
6.3.3 Probabilities Over Time
Since all the marking of a BT node have a non null corresponding average sojourn
time, the corresponding DTMC is a EMC of a CTMC with infinitesimal generator
matrix Q(t) as defined in (6.7). Hence, we can compute the probability distribution
over time of the node according to (6.8) with the initial condition ?0 = [1 0]> that
represents the state in which none of the children have returned success/failure yet.
6.3 Reliability of a SBT 105
6.3.4 Stochastic Execution Times
Proposition 6.1. Given a SBT, with known probabilistic parameters for actions and
conditions, we can compute probabilistic measures for the rest of the tree as follows:
For each node whose children have known probabilistic measures we compute the
related DTMC. Now the probability of a node to return success ps(t) (failure p f (t))
is given by the sum of the probabilities of the DTMC of being in a success (failure)
state. Let SS ?SA, and SF ?SA be the set of the success and failure states re-
spectively of a DTMC related to a node, i.e. those states representing a marking in
which the node returns success or failure, with SF ?SS = SA and SF ?SS = /0.
Then we have
p?s(t) = ?
i:si?SS
?i(t) (6.52)
p? f (t) = ?
i:si?SF
?i(t) (6.53)
where ?(t) is the probability vector of the DTMC related to the node (i.e. the solution
of (6.8)). The time to succeed (fail) for a node is given by a random variable with
exponential distribution and rate given by the inverse of the MTTS (MTTF) since for
such random variables the mean time is given by the inverse of the rate.
µ = MT T S?1 (6.54)
? = MT T F?1 (6.55)
Remark 6.8. Proposition 6.55 holds also for deterministic and hybrid BTs, as (6.8)
has a unique solution in the Carathe?odory sense [11].
6.3.5 Deterministic Execution Times
As the formulation of the deterministic case involves Dirac delta functions, see
Equation (6.17)-(6.18), the approach described above might lead to computational
difficulties. As an alternative, we can take advantage of the fact that we know the
exact time of possible transitions. Thus, the success and failure probabilities of a
deterministic node are unchanged in the intervals between the MT T F and MT T S
of its children.
Example 6.6. Consider the tree
T = fallback(A1,A2) (6.56)
106 6 Stochastic BTs
depicted in Fig. 6.13 and let ?Fi (?Si) be the MT T F (MT T S) of action i and p f i (psi)
its probability to fail (succeed). The success/failure probability over time of the tree
T is a discontinuous function depicted in Fig. 6.14.
?
Deterministic
Action 2
Deterministic
Action 1
Fig. 6.13: Example of a fallback node with two deterministic actions/subtrees.
t0 ?s1 ?f1+?s2 ?f1+?f2
ps1
ps1+pf1·ps2
pf1·pf2
p(t)
Fig. 6.14: Failure (red) and success (green) probability of the deterministic node of example. The
running probability is the complement of the other two (not shown).
Hence the success and failure probability have discrete jumps over time. These
piece-wise continuous functions can be described by the discrete time system (6.3)
introducing the information of the time when the transitions take place, which is
more tractable than directly solving (6.8). Then, the calculation of ?(t) is given by
a zero order hold of the discrete solution.
Proposition 6.2. Let P be the one-step transition matrix given in Definition 6.2 and
let ?Fi (?Si) be the time to fail (succeed) of action i and p f i (psi) its probability to
fail (succeed). Let ??(?) = [??1(?), . . . , ??|S |(?)]>, where ??i(?) is the probability of
being in a marking mi at time ? of a RG representing a deterministic node with N
children, let P?(?) be a matrix which entries p?i j(?) are defined as:
p?i j(?) =
???pi j ·? (?? (log(a? j1)) if i 6= j1??
k 6=i
p?ik otherwise (6.57)
6.4 Examples 107
with a?i j the i j-th entry of the matrix A? defined as:
A?,
?
?
i=0
Ai (6.58)
with A as defined in (6.48).
Then the evolution of ??(k) process can be described as a discrete time system
with the following time evolution:
??(? +??) = P?(?)>??(?) (6.59)
where ?? is the common factor of {?F1,?S1,?F2,?S2, . . . ,?FN ,?SN} Then for, deter-
ministic nodes, given ??(?) the probability over time is given by:
?(t) = ZOH(??(?)) (6.60)
where ZOH is the zero order hold function.
Proof. The proof is trivial considering that Eq. (6.59) is a piece-wise constant func-
tion and ?? is the common faction of all the step instants.
6.4 Examples
In this section, we present three examples. The first example is the BT in Figure
6.15a, which is fairly small and allows us to show the details of each step. The
second example is the deterministic time version of the same BT, illustrating the
differences between the two cases. The third example involves a more complex BT,
shown in Figure 6.16. This example will be used to verify the approach numeri-
cally, by performing Monte Carlo simulations and comparing the numeric results
to the analytical ones, see Table 6.2 and Figure 6.19. It is also used to illustrate the
difference in performance metrics, between two equivalent BTs, see Figure 6.21.
We will now carry out the computation of probabilistic parameters for an exam-
ple SBT.
Example 6.7. Given the tree shown in Fig. 6.15a, its probabilistic parameters are
given by evaluating the fallback node, since it is the child of the root node. The
given PDF of the i-th action are:
p?s(t) = psi µe
?µit (6.61)
p? f (t) = p fi?e
??it (6.62)
where:
• p fi probability of failure
108 6 Stochastic BTs
0?
?
Action
1
Action
2
Action
3
1
(a) BT of example.
s1
s5s2
s6s3
s7s4
pf1 ps1
pf2 ps2
pf3 ps3
1
1
11
m0 [0 0 0]
m1 [1 0 0]m2[?1 0 0]
m3 [?1 1 0]m4[?1 ? 1 0]
m5 [?1 ? 1 1]ms?2[?1 ? 1 ? 1]
(b) Markov Chain.
Fig. 6.15: BT and related DTMC modeling the plan of Example 6.4.
• psi probability of success
• ?i failure rate
• µi success rate
The DTMC related as shown in Fig. 6.15b has S = {s1,s2,s3,s4,s5,s6,s7}, SF =
{s4} and SS = {s5,s6,s7}.
According to the canonization in (6.43), the one-step transition matrix is:
P>c =
??????????
0 0 0 0 0 0 0
p f1 0 0 0 0 0 0
0 p f2 0 0 0 0 0
0 0 p f3 1 0 0 0
ps1 0 0 0 1 0 0
0 ps2 0 0 0 1 0
0 0 ps3 0 0 0 1
??????????
(6.63)
According to Equation (6.40) the average sojourn times are collected in the fol-
lowing vector
SJ =
[
ps1
µ1
+
p f1
?1
,
ps2
µ2
+
p f2
?2
,
ps3
µ3
+
p f3
?3
]
(6.64)
The infinitesimal generator matrix is defined, according to (6.7), as follows:
6.4 Examples 109
Q =
????????????????
?µ1?1
ps1 ?1+p f1 µ1
0 0 0 0 0 0
µ1?1 p f1
ps1 ?1+p f1 µ1
?µ2?2
ps2 ?2+p f2 µ2
0 0 0 0 0
0
µ2?2 p f2
ps2 ?2+p f2 µ2
?µ3?3
ps3 ?3+p f3 µ3
0 0 0 0
0 0
µ3?3 p f3
ps3 ?3+p f3 µ3
0 0 0 0
µ1?1 ps1
ps1 ?1+p f1 µ1
0 0 0 0 0 0
0
µ2?2 ps2
ps2 ?2+p f2 µ2
0 0 0 0 0
0 0
µ3?3 ps3
ps3 ?3+p f3 µ3
0 0 0 0
????????????????
. (6.65)
The probability vector, according to (6.8), is given by:
?(t) =
[
?1(t)?2(t)?3(t)?4(t)?5(t)?6(t)?7(t)
]> (6.66)
We can now derive closed form expression for MTTS and MTTF. Using the de-
composition in (6.43), the matrices computed according Equations 6.51 and 6.50
are:
US =
?? ps1 0 0p f1 ps2 ps2 0
p f1 p f2 ps3 p f2 ps3 ps3
?? (6.67)
UF =
[
p f1 p f2 p f3 p f2 p f3 p f3
]
(6.68)
Note that US is a 3× 3 matrix and US is a 1× 3 matrix since there are 3 transient
states, 3 success state and 1 failure state. For action i we define t fi = ?
?1
i the time
to fail and tsi = µ
?1
i the time to succeed. The non-zero entries of the matrix given
by (6.48) are:
a2,1 = e
t f1 a3,2 = e
t f2 a4,3 = e
t f3
a5,1 = ets1 a6,2 = ets2 a7,3 = ets3
(6.69)
from which we derive (6.45) and (6.47) as:
HS =
?? ets1 0 0et f1 ets2 ets2 0
et f1 et f2 ets3 et f2 ets3 ets3
?? (6.70)
HF =
[
et f1 et f2 et f3 et f2 et f3 et f3
]
(6.71)
Using Equations (6.44) and (6.46) we obtain the MTTS and MTTF. Finally, the
probabilistic parameters of the tree are expressed in a closed form according to
Equations (6.52)-(6.55):
110 6 Stochastic BTs
p?s(t) = ?5(t)+?6(t)+?7(t) (6.72)
p? f (t) = ?4(t) (6.73)
µ =
ps1+p f1 ps2+p f1 p f2 ps3
ps1 ts1+p f1 ps2 (t f1+ts2 )+p f1 p f2 ps3 (t f1+t f2+ts3 )
(6.74)
? = 1t f1+t f2+t f3
(6.75)
Example 6.8. Consider the tree given in Example 6.4, we now compute the perfor-
mances in case when the actions are all deterministic.
The computation of MTTF and MTTS follows from Example 6.4, whereas the
computation of ?(t) can be made according to Proposition 6.2.
According to (6.58) the matrix A? takes the form below
A? =
??????????
0 0 0 0 0 0 0
et f1 0 0 0 0 0 0
et f1 et f2 et f2 0 0 0 0 0
et f1 et f2 et f3 et f2 et f3 et f3 0 0 0 0
ets1 0 0 0 0 0 0
et f1 ets2 ets2 0 0 0 0 0
et f1 et f2 ets3 et f2 ets3 ets3 0 0 0 0
??????????
(6.76)
thereby, according to (6.57), the modified one step transition matrix takes the form
of (6.77), and the probability vector ?(t) is given by (6.60).
P?> =
??????????
1? (p f1 ? (t?t f1 )+ps1 ? (t?ts1 )) 0 0 0 0 0 0
p f1 ? (t?t f1 ) 1? (p f2 ? (t?(t f1+t f2 ))+ps2 ? (t?(t f1+ts2 ))) 0 0 0 0 0
0 p f2 ? (t?(t f1+t f2 )) 1? (p f3 ? (t?(t f1+t f2+t f3 ))+ps3 ? (t?(t f1+t f2+ts3 ))) 0 0 0 0
0 0 p f3 ? (t?(t f1+t f2+t f3 )) 1 0 0 0
ps1 ? (t?ts1 ) 0 0 0 1 0 0
0 ps2 ? (t?(t f1+ts2 )) 0 0 0 1 0
0 0 ps3 ? (t?(t f1+t f2+ts3 )) 0 0 0 1
??????????
(6.77)
Below we present a more complex example, extending Example 6.4 above. We
use this example for two purposes, first, to verify the correctness of the proposed
approach using Monte Carlo simulations, and second, to illustrate how changes in
the SBT lead to different performance metrics.
Example 6.9. The task given to a two armed robot is to find and collect objects
which can be found either on the floor, in the drawers or in the closet. The time
needed to search for a desired object on the floor is less than the time needed to
search for it in the drawers, since the latter has to be reached and opened first. On
the other hand, the object is more likely to be in the drawers than on the floor, or in
the closet. Moreover, the available policies for picking up objects are the one-hand
and the two-hands grasps. The one-hand grasp most likely fails, but it takes less
time to check if it has failed or not. Given these options, the task can be achieved
6.4 Examples 111
in different ways, each of them corresponding to a different performance measure.
The plan chosen for this example is modeled by the SBT shown in Fig. 6.16.
The performance estimates given by the proposed approach for the whole BT, as
well as for two sub trees can be seen in Figs. 6.17-6.18 .
? 0
? 1
? 2
? 3
? 4
? 5Obj.Pos.Retrieved
Search on
the Floor
Search in
the Drawers
Search in
the Closet
Object
Grasped
One Hand
Grasp
Two Hands
Grasp
Fig. 6.16: BT modeling the search and grasp plan. The leaf nodes are labeled with a text, and the
control flow nodes are labeled with a number, for easy reference.
We also use the example above to verify the correctness of the analytical esti-
mates, and the results can be seen in Table 6.2. We compared the analytical solution
derived using our approach with numerical results given by a massive Monte Carlo
simulation carried out using a BT implementation in the Robot Operative System
(ROS) [23] where actions and conditions are performed using ROS nodes with out-
comes computed using the C++ random number generator with exponential distri-
bution. The BT implementation in ROS was run approximately 80000 times to have
enough samples to get numerical averages close to the true values. For each run we
stored if the tree (and some sub-trees) succeeded or failed and how long it took,
allowing us to estimate µ , ? , ps(t), p f (t) experimentally. The match is reported in
Figs. 6.17-6.18 and in Table 6.1. As can be seen, all estimates are within 0.18 % of
the analytical results.
To further illustrate the difference between modeling the actions as determinis-
tic and stochastic, we again use the BT in Fig. 6.16 and compute the accumulated
Succes/Failure/Running probabilities for the two cases. Defining the time to suc-
ceed and fail as the inverse of the given rates and computing the probabilities as
described in Section 6.3.5 we get the results depicted in Figs. 6.19 and 6.20. As can
be seen, the largest deviation is found in the Failure probabilities. In the stochastic
112 6 Stochastic BTs
Measure Analytical Numerical Relative Error
µRoot 5.9039×10?3 5.8958×10?3 0.0012
?Root 4.4832×10?3 4.4908×10?3 0.0017
µ3 6.2905×10?3 6.2998×10?3 0.0014
?3 2.6415×10?3 2.6460×10?3 0.0017
µ5 9.6060×10?2 9.5891×10?2 0.0018
?5 4.8780×10?2 4.8701×10?2 0.0016
Table 6.1: Table comparing numerical and experimental results of MTTF and MTTS.
Label µ ? ps(t) p f (t)
Obj. Pos. Retrieved ? ? ps5(t) p f 5(t)
Object Grasped ? ? ps4(t) p f 4(t)
Search on the Floor 0.01 0.0167 0.3 0.7
Search in the Drawer 0.01 0.01 0.8 0.2
Search in the Closet 0.005 0.0056 0.2 0.8
One Hand Grasp 0.1 20 0.1 0.9
Two Hands Grasp 0.1 0.05 0.5 0.5
Table 6.2: Table collecting given parameters, the labels of the control flow nodes are given in
Fig. 6.16.
0 500 1000 1500
0
0.2
0.4
0.6
0.8
1
P
ro
b
a
b
ili
ti
e
s
 o
f 
R
o
o
t
Time [s]
 
 
Running
Failed
Succeeded
Fig. 6.17: Probability distribution over time for the Root node of the larger BT in Fig. 6.16. Nu-
merical results are marked with an ’x’ and analytical results are drawn using solid lines.
case the CDF rises instantly, whereas in the deterministic case it becomes non-zero
only after all the fallbacks in at least one of the two sub-trees have failed.
In Fig. 6.21 the results of swapping the order of “Search on the Floor” and
“Search in the Drawers” are shown in. As can be seen, the success probability after
100s is about 30% when starting with the drawers, and about 20% when starting
with the floor. Thus the optimal solution is a new BT, with the drawer search as the
first option. Note that the asymptotic probabilities are always the same for equiv-
alent BT, see Definition 6.10, as the changes considered are only permutations of
fallbacks.
6.4 Examples 113
0 50 100 150 200
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
P
ro
ba
bi
lit
ie
s 
of
 th
e 
no
de
 5
Time [s]
 
 
Running
Failed
Succeeded
(a) Node 5
0 500 1000 1500
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
P
ro
ba
bi
lit
ie
s 
of
 th
e 
no
de
 3
Time [s]
 
 
Running
Failed
Succeeded
(b) Node 3
Fig. 6.18: Comparison of probability distribution over time related to Node 5 (a) and Node 3 (b).
Numerical results are marked with an ’x’ and analytical results are drawn using solid lines.
114 6 Stochastic BTs
0 500 1000 1500
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
P
ro
b
a
b
ili
ti
e
s
 o
f 
R
o
o
t
Time [s]
 
 
Running
Failed
Succeeded
Fig. 6.19: Comparison of Success/Failure/Running probabilities of the root node in the case of
deterministic times (thick) and stochastic times (thin).
6.4 Examples 115
(a) Node 5
0 500 1000 1500
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
P
ro
b
a
b
ili
ti
e
s
 o
f 
th
e
 n
o
d
e
 3
Time [s]
 
 
Running
Failed
Succeeded
(b) Node 3
Fig. 6.20: Comparison of Success/Failure/Running probabilities of the node 5 (a) and node 3 (b)
in the case of deterministic times (thick) and stochastic times (thin).
116 6 Stochastic BTs
0 50 100 150 200 250 300 350 400 450 500
0
0.1
0.2
0.3
0.4
0.5
P
ro
b
a
b
ili
ti
e
s
 o
f 
R
o
o
t
Time [s]
Fig. 6.21: Success/Failure probabilities in the case of searching on the floor first (dashed) and
searching in the drawer first (solid).
References 117
References
1. J. Andrew (Drew) Bagnell, Felipe Cavalcanti, Lei Cui, Thomas Galluzzo, Martial Hebert,
Moslem Kazemi, Matthew Klingensmith, Jacqueline Libby, Tian Yu Liu, Nancy Pollard,
Mikhail Pivtoraiko, Jean-Sebastien Valois, and Ranqi Zhu. An Integrated System for Au-
tonomous Robotics Manipulation. In IEEE/RSJ International Conference on Intelligent
Robots and Systems, pages 2955–2962, October 2012.
2. Scott Benson and Nils J Nilsson. Reacting, planning, and learning in an autonomous agent.
In Machine intelligence 14, pages 29–64. Citeseer, 1995.
3. Iva Bojic, Tomislav Lipic, Mario Kusek, and Gordan Jezic. Extending the JADE Agent Be-
haviour Model with JBehaviourtrees Framework. In Agent and Multi-Agent Systems: Tech-
nologies and Applications, pages 159–168. Springer, 2011.
4. R. Brooks. A Robust Layered Control System for a Mobile Robot. Robotics and Automation,
IEEE Journal of, 2(1):14–23, 1986.
5. R.A. Brooks. Elephants don’t play chess. Robotics and autonomous systems, 6(1-2):3–15,
1990.
6. Robert R Burridge, Alfred A Rizzi, and Daniel E Koditschek. Sequential Composition of
Dynamically Dexterous Robot Behaviors. The International Journal of Robotics Research,
18(6):534–555, 1999.
7. A.J. Champandard. Understanding Behavior Trees. AiGameDev. com, 6, 2007.
8. Michele Colledanchise, Alejandro Marzinotto, and Petter O?gren. Performance Analysis of
Stochastic Behavior Trees. In Robotics and Automation (ICRA), 2014 IEEE International
Conference on, June 2014.
9. Michele Colledanchise and Petter O?gren. How behavior trees modularize hybrid control sys-
tems and generalize sequential behavior compositions, the subsumption architecture, and de-
cision trees. IEEE Transactions on Robotics, 33(2):372–389, 2017.
10. Edsger W. Dijkstra. Letters to the editor: go to statement considered harmful. Commun. ACM,
11:147–148, March 1968.
11. A.F. Filippov and F.M. Arscott. Differential Equations with Discontinuous Righthand Sides:
Control Systems. Mathematics and its Applications. Kluwer Academic Publishers, 1988.
12. Thomas Galluzzo, Moslem Kazemi, and Jean-Sebastien Valois. Bart - behavior architecture
for robotic tasks, https://code.google.com/p/bart/. Technical report, 2013.
13. JK Gershenson, GJ Prasad, and Y Zhang. Product modularity: definitions and benefits. Jour-
nal of Engineering design, 14(3):295–313, 2003.
14. Gerhard Gubisch, Gerald Steinbauer, Martin Weiglhofer, and Franz Wotawa. A teleo-reactive
architecture for fast, reactive and robust control of mobile robots. In New Frontiers in Applied
Artificial Intelligence, pages 541–550. Springer, 2008.
15. Kelleher R. Guerin, Colin Lea, Chris Paxton, and Gregory D. Hager. A framework for end-
user instruction of a robot assistant for manufacturing. In IEEE International Conference on
Robotics and Automation (ICRA), 2015.
16. David Harel. Statecharts: A visual formalism for complex systems, 1987.
17. Danying Hu, Yuanzheng Gong, Blake Hannaford, and Eric J. Seibel. Semi-autonomous sim-
ulated brain tumor ablation with raven ii surgical robot using behavior tree. In IEEE Interna-
tional Conference on Robotics and Automation (ICRA), 2015.
18. D. Isla. Handling Complexity in the Halo 2 AI. In Game Developers Conference, 2005.
19. Damian Isla. Halo 3-building a Better Battle. In Game Developers Conference, 2008.
20. Andreas Klo?ckner, Franciscus van der Linden, and Dirk Zimmer. The Modelica BehaviorTrees
Library: Mission planning in continuous-time for unmanned aircraft. In Proceedings of the
10th International Modelica Conference, 2014.
21. Andreas Klo?kner. Interfacing Behavior Trees with the World Using Description Logic. In
AIAA conference on Guidance, Navigation and Control, Boston, 2013.
22. C.U. Lim, R. Baumgarten, and S. Colton. Evolving Behaviour Trees for the Commercial
Game DEFCON. Applications of Evolutionary Computation, pages 100–110, 2010.
118 6 Stochastic BTs
23. Alejandro Marzinotto, Michele Colledanchise, Christian Smith, and Petter O?gren. Towards a
Unified Behavior Trees Framework for Robot Control. In Robotics and Automation (ICRA),
2014 IEEE International Conference on, June 2014.
24. G. H. Mealy. A method for synthesizing sequential circuits. The Bell System Technical Jour-
nal, 34(5):1045–1079, Sept 1955.
25. Ian Millington and John Funge. Artificial intelligence for games. CRC Press, 2009.
26. Michael Montemerlo, Jan Becker, Suhrid Bhat, Hendrik Dahlkamp, Dmitri Dolgov, Scott Et-
tinger, Dirk Haehnel, Tim Hilden, Gabe Hoffmann, Burkhard Huhnke, et al. Junior: The
stanford entry in the urban challenge. Journal of field Robotics, 25(9):569–597, 2008.
27. Edward F Moore. Gedanken-experiments on sequential machines. Automata studies, 34:129–
153, 1956.
28. Seyed R Mousavi and Krysia Broda. Simplification Of Teleo-Reactive sequences. Imperial
College of Science, Technology and Medicine, Department of Computing, 2003.
29. Tadao Murata. Petri nets: Properties, analysis and applications. Proceedings of the IEEE,
77(4):541–580, 1989.
30. M. Nicolau, D. Perez-Liebana, M. O’Neill, and A. Brabazon. Evolutionary behavior tree
approaches for navigating platform games. IEEE Transactions on Computational Intelligence
and AI in Games, PP(99):1–1, 2016.
31. Nils J. Nilsson. Teleo-reactive programs for agent control. JAIR, 1:139–158, 1994.
32. J.R. Norris. Markov Chains. Number no. 2008 in Cambridge Series in Statistical and Proba-
bilistic Mathematics. Cambridge University Press, 1998.
33. Petter O?gren. Increasing Modularity of UAV Control Systems using Computer Game Behavior
Trees. In AIAA Guidance, Navigation and Control Conference, Minneapolis, MN, 2012.
34. Chris Paxton, Andrew Hundt, Felix Jonathan, Kelleher Guerin, and Gregory D Hager.
Costar: Instructing collaborative robots with behavior trees and vision. arXiv preprint
arXiv:1611.06145, 2016.
35. Matthew Powers, Dave Wooden, Magnus Egerstedt, Henrik Christensen, and Tucker Balch.
The Sting Racing Team’s Entry to the Urban Challenge. In Experience from the DARPA Urban
Challenge, pages 43–65. Springer, 2012.
36. Steve Rabin. Game AI Pro, chapter 6. The Behavior Tree Starter Kit. CRC Press, 2014.
37. Claude Sammut, Scott Hurst, Dana Kedzier, and Donald Michie. Imitation in Animals and
Artifacts, chapter Learning to Fly, page 171. MIT Press, 2002.
38. Alexander Shoulson, Francisco M Garcia, Matthew Jones, Robert Mead, and Norman I Badler.
Parameterizing Behavior Trees. In Motion in Games. Springer, 2011.
39. William J Stewart. Probability, Markov chains, queues, and simulation: the mathematical
basis of performance modeling. Princeton University Press, 2009.
40. Chris Urmson, Joshua Anhalt, Drew Bagnell, Christopher Baker, Robert Bittner, MN Clark,
John Dolan, Dave Duggins, Tugrul Galatali, Chris Geyer, et al. Autonomous driving in urban
environments: Boss and the urban challenge. Journal of Field Robotics, 25(8):425–466, 2008.
41. Chris Urmson, J Andrew Bagnell, Christopher R Baker, Martial Hebert, Alonzo Kelly, Raj
Rajkumar, Paul E Rybski, Sebastian Scherer, Reid Simmons, Sanjiv Singh, et al. Tartan racing:
A multi-modal approach to the darpa urban challenge. 2007.
42. Blanca Vargas and E Morales. Solving navigation tasks with learned teleo-reactive programs.
Proceedings of IEEE International Conference on Robots and Systems (IROS), 2008.
